{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.96,
  "eval_steps": 500,
  "global_step": 600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0016,
      "grad_norm": 5.777158260345459,
      "learning_rate": 5e-06,
      "logits/chosen": -2.383577346801758,
      "logits/rejected": -2.5550010204315186,
      "logps/chosen": -997.095947265625,
      "logps/rejected": -1401.2965087890625,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.0032,
      "grad_norm": 29.931734085083008,
      "learning_rate": 4.992e-06,
      "logits/chosen": -2.4591455459594727,
      "logits/rejected": -2.4508743286132812,
      "logps/chosen": -889.494873046875,
      "logps/rejected": -2650.220703125,
      "loss": 0.6859,
      "rewards/accuracies": 0.3125,
      "rewards/chosen": -0.0005279185716062784,
      "rewards/margins": 0.01758369244635105,
      "rewards/rejected": -0.018111608922481537,
      "step": 2
    },
    {
      "epoch": 0.0048,
      "grad_norm": 7.421308517456055,
      "learning_rate": 4.984000000000001e-06,
      "logits/chosen": -2.387298107147217,
      "logits/rejected": -2.400231122970581,
      "logps/chosen": -877.0235595703125,
      "logps/rejected": -1620.46630859375,
      "loss": 0.6878,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.010252094827592373,
      "rewards/margins": 0.011494734324514866,
      "rewards/rejected": -0.0012426384491845965,
      "step": 3
    },
    {
      "epoch": 0.0064,
      "grad_norm": 8.491647720336914,
      "learning_rate": 4.976e-06,
      "logits/chosen": -2.3299200534820557,
      "logits/rejected": -2.475105047225952,
      "logps/chosen": -953.943359375,
      "logps/rejected": -1942.45849609375,
      "loss": 0.6801,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -6.537511944770813e-05,
      "rewards/margins": 0.02661166340112686,
      "rewards/rejected": -0.02667703852057457,
      "step": 4
    },
    {
      "epoch": 0.008,
      "grad_norm": 7.217437267303467,
      "learning_rate": 4.9680000000000005e-06,
      "logits/chosen": -2.424405574798584,
      "logits/rejected": -2.46640944480896,
      "logps/chosen": -1256.431884765625,
      "logps/rejected": -1457.0126953125,
      "loss": 0.6812,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.011346865445375443,
      "rewards/margins": 0.024357369169592857,
      "rewards/rejected": -0.013010501861572266,
      "step": 5
    },
    {
      "epoch": 0.0096,
      "grad_norm": 6.225366115570068,
      "learning_rate": 4.960000000000001e-06,
      "logits/chosen": -2.5838606357574463,
      "logits/rejected": -2.5992836952209473,
      "logps/chosen": -938.2471923828125,
      "logps/rejected": -1745.748291015625,
      "loss": 0.689,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.00911245308816433,
      "rewards/margins": 0.008689593523740768,
      "rewards/rejected": -0.017802048474550247,
      "step": 6
    },
    {
      "epoch": 0.0112,
      "grad_norm": 8.435750007629395,
      "learning_rate": 4.952e-06,
      "logits/chosen": -2.483788013458252,
      "logits/rejected": -2.45876145362854,
      "logps/chosen": -1286.958740234375,
      "logps/rejected": -2144.93798828125,
      "loss": 0.6827,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.0014164212625473738,
      "rewards/margins": 0.021252466365695,
      "rewards/rejected": -0.019836043938994408,
      "step": 7
    },
    {
      "epoch": 0.0128,
      "grad_norm": 6.893909931182861,
      "learning_rate": 4.9440000000000004e-06,
      "logits/chosen": -2.526834726333618,
      "logits/rejected": -2.5802536010742188,
      "logps/chosen": -1098.858154296875,
      "logps/rejected": -1681.0372314453125,
      "loss": 0.6879,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.006822490599006414,
      "rewards/margins": 0.010760593228042126,
      "rewards/rejected": -0.003938103094696999,
      "step": 8
    },
    {
      "epoch": 0.0144,
      "grad_norm": 6.476867198944092,
      "learning_rate": 4.936e-06,
      "logits/chosen": -2.525251626968384,
      "logits/rejected": -2.5307137966156006,
      "logps/chosen": -1156.2413330078125,
      "logps/rejected": -1707.1953125,
      "loss": 0.6761,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.0015508650103583932,
      "rewards/margins": 0.035054970532655716,
      "rewards/rejected": -0.03350410610437393,
      "step": 9
    },
    {
      "epoch": 0.016,
      "grad_norm": 6.029538154602051,
      "learning_rate": 4.928000000000001e-06,
      "logits/chosen": -2.4935433864593506,
      "logits/rejected": -2.474785327911377,
      "logps/chosen": -962.8341674804688,
      "logps/rejected": -1336.4739990234375,
      "loss": 0.6726,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.010607386007905006,
      "rewards/margins": 0.04225526005029678,
      "rewards/rejected": -0.031647875905036926,
      "step": 10
    },
    {
      "epoch": 0.0176,
      "grad_norm": 5.764677047729492,
      "learning_rate": 4.92e-06,
      "logits/chosen": -2.579183340072632,
      "logits/rejected": -2.5417375564575195,
      "logps/chosen": -855.5267333984375,
      "logps/rejected": -1480.712646484375,
      "loss": 0.6719,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.0050948625430464745,
      "rewards/margins": 0.04409470409154892,
      "rewards/rejected": -0.04918956756591797,
      "step": 11
    },
    {
      "epoch": 0.0192,
      "grad_norm": 5.572897434234619,
      "learning_rate": 4.9120000000000006e-06,
      "logits/chosen": -2.5378787517547607,
      "logits/rejected": -2.5528461933135986,
      "logps/chosen": -994.4022216796875,
      "logps/rejected": -1402.746826171875,
      "loss": 0.6692,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.00486366730183363,
      "rewards/margins": 0.05027425289154053,
      "rewards/rejected": -0.05513792484998703,
      "step": 12
    },
    {
      "epoch": 0.0208,
      "grad_norm": 8.677556991577148,
      "learning_rate": 4.904000000000001e-06,
      "logits/chosen": -2.4339964389801025,
      "logits/rejected": -2.392798662185669,
      "logps/chosen": -1155.759033203125,
      "logps/rejected": -1554.5931396484375,
      "loss": 0.6582,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.002712750341743231,
      "rewards/margins": 0.07392475754022598,
      "rewards/rejected": -0.07121200859546661,
      "step": 13
    },
    {
      "epoch": 0.0224,
      "grad_norm": 5.772674083709717,
      "learning_rate": 4.896e-06,
      "logits/chosen": -2.3930609226226807,
      "logits/rejected": -2.4590721130371094,
      "logps/chosen": -1166.37060546875,
      "logps/rejected": -1731.8026123046875,
      "loss": 0.6746,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.00047166342847049236,
      "rewards/margins": 0.037793707102537155,
      "rewards/rejected": -0.037322044372558594,
      "step": 14
    },
    {
      "epoch": 0.024,
      "grad_norm": 5.9789276123046875,
      "learning_rate": 4.8880000000000005e-06,
      "logits/chosen": -2.5120468139648438,
      "logits/rejected": -2.521805763244629,
      "logps/chosen": -825.6015014648438,
      "logps/rejected": -1392.1414794921875,
      "loss": 0.6582,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.003991508856415749,
      "rewards/margins": 0.0750049576163292,
      "rewards/rejected": -0.07899646461009979,
      "step": 15
    },
    {
      "epoch": 0.0256,
      "grad_norm": 7.461836338043213,
      "learning_rate": 4.880000000000001e-06,
      "logits/chosen": -2.482703685760498,
      "logits/rejected": -2.4834096431732178,
      "logps/chosen": -1601.0765380859375,
      "logps/rejected": -1890.500732421875,
      "loss": 0.6417,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.008066796697676182,
      "rewards/margins": 0.10860419273376465,
      "rewards/rejected": -0.11667098850011826,
      "step": 16
    },
    {
      "epoch": 0.0272,
      "grad_norm": 6.696410179138184,
      "learning_rate": 4.872000000000001e-06,
      "logits/chosen": -2.2976319789886475,
      "logits/rejected": -2.504713535308838,
      "logps/chosen": -909.9552612304688,
      "logps/rejected": -1605.83740234375,
      "loss": 0.6628,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.016479289159178734,
      "rewards/margins": 0.06566496938467026,
      "rewards/rejected": -0.08214426785707474,
      "step": 17
    },
    {
      "epoch": 0.0288,
      "grad_norm": 5.730576992034912,
      "learning_rate": 4.864e-06,
      "logits/chosen": -2.494868516921997,
      "logits/rejected": -2.5170273780822754,
      "logps/chosen": -718.1146850585938,
      "logps/rejected": -1341.41845703125,
      "loss": 0.6536,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.006640315055847168,
      "rewards/margins": 0.08292777091264725,
      "rewards/rejected": -0.07628745585680008,
      "step": 18
    },
    {
      "epoch": 0.0304,
      "grad_norm": 5.351961135864258,
      "learning_rate": 4.856e-06,
      "logits/chosen": -2.2484681606292725,
      "logits/rejected": -2.5302162170410156,
      "logps/chosen": -777.997314453125,
      "logps/rejected": -1522.199951171875,
      "loss": 0.6517,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.0043878923170268536,
      "rewards/margins": 0.08642282336950302,
      "rewards/rejected": -0.08203492313623428,
      "step": 19
    },
    {
      "epoch": 0.032,
      "grad_norm": 5.9492926597595215,
      "learning_rate": 4.848000000000001e-06,
      "logits/chosen": -2.427757740020752,
      "logits/rejected": -2.4902050495147705,
      "logps/chosen": -1203.291748046875,
      "logps/rejected": -1451.47900390625,
      "loss": 0.6262,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020780373364686966,
      "rewards/margins": 0.1411726027727127,
      "rewards/rejected": -0.12039223313331604,
      "step": 20
    },
    {
      "epoch": 0.0336,
      "grad_norm": 6.540633678436279,
      "learning_rate": 4.84e-06,
      "logits/chosen": -2.303931713104248,
      "logits/rejected": -2.5109848976135254,
      "logps/chosen": -1161.491455078125,
      "logps/rejected": -1683.808349609375,
      "loss": 0.6433,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.004983187187463045,
      "rewards/margins": 0.10777640342712402,
      "rewards/rejected": -0.11275959014892578,
      "step": 21
    },
    {
      "epoch": 0.0352,
      "grad_norm": 6.436901092529297,
      "learning_rate": 4.8320000000000005e-06,
      "logits/chosen": -2.400743007659912,
      "logits/rejected": -2.4598302841186523,
      "logps/chosen": -853.2847290039062,
      "logps/rejected": -1669.84033203125,
      "loss": 0.6078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.005872583016753197,
      "rewards/margins": 0.18278947472572327,
      "rewards/rejected": -0.1886620670557022,
      "step": 22
    },
    {
      "epoch": 0.0368,
      "grad_norm": 5.8360090255737305,
      "learning_rate": 4.824000000000001e-06,
      "logits/chosen": -2.4765625,
      "logits/rejected": -2.5283117294311523,
      "logps/chosen": -1193.60595703125,
      "logps/rejected": -1400.964599609375,
      "loss": 0.6429,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.009444882161915302,
      "rewards/margins": 0.10741741955280304,
      "rewards/rejected": -0.11686229705810547,
      "step": 23
    },
    {
      "epoch": 0.0384,
      "grad_norm": 5.09824275970459,
      "learning_rate": 4.816e-06,
      "logits/chosen": -2.4321236610412598,
      "logits/rejected": -2.500823974609375,
      "logps/chosen": -684.755859375,
      "logps/rejected": -1265.620361328125,
      "loss": 0.6217,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.00216085952706635,
      "rewards/margins": 0.15424855053424835,
      "rewards/rejected": -0.15208768844604492,
      "step": 24
    },
    {
      "epoch": 0.04,
      "grad_norm": 4.6456685066223145,
      "learning_rate": 4.808e-06,
      "logits/chosen": -2.4003920555114746,
      "logits/rejected": -2.6259267330169678,
      "logps/chosen": -662.1038818359375,
      "logps/rejected": -1401.2833251953125,
      "loss": 0.6219,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.005369471851736307,
      "rewards/margins": 0.15287218987941742,
      "rewards/rejected": -0.14750270545482635,
      "step": 25
    },
    {
      "epoch": 0.0416,
      "grad_norm": 6.444249629974365,
      "learning_rate": 4.800000000000001e-06,
      "logits/chosen": -2.4268743991851807,
      "logits/rejected": -2.515354633331299,
      "logps/chosen": -1249.900634765625,
      "logps/rejected": -1548.016357421875,
      "loss": 0.6071,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.02955174446105957,
      "rewards/margins": 0.19209963083267212,
      "rewards/rejected": -0.2216513752937317,
      "step": 26
    },
    {
      "epoch": 0.0432,
      "grad_norm": 5.8396430015563965,
      "learning_rate": 4.792000000000001e-06,
      "logits/chosen": -2.4963107109069824,
      "logits/rejected": -2.5389151573181152,
      "logps/chosen": -1776.93798828125,
      "logps/rejected": -1911.4761962890625,
      "loss": 0.619,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.008384992368519306,
      "rewards/margins": 0.16205109655857086,
      "rewards/rejected": -0.17043611407279968,
      "step": 27
    },
    {
      "epoch": 0.0448,
      "grad_norm": 4.950774192810059,
      "learning_rate": 4.784e-06,
      "logits/chosen": -2.5377228260040283,
      "logits/rejected": -2.5655124187469482,
      "logps/chosen": -770.48486328125,
      "logps/rejected": -1328.5189208984375,
      "loss": 0.6363,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.019844507798552513,
      "rewards/margins": 0.12086965888738632,
      "rewards/rejected": -0.14071418344974518,
      "step": 28
    },
    {
      "epoch": 0.0464,
      "grad_norm": 4.218019962310791,
      "learning_rate": 4.7760000000000005e-06,
      "logits/chosen": -2.5830776691436768,
      "logits/rejected": -2.615169048309326,
      "logps/chosen": -836.572021484375,
      "logps/rejected": -1111.2818603515625,
      "loss": 0.6193,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.015565921552479267,
      "rewards/margins": 0.16033843159675598,
      "rewards/rejected": -0.17590436339378357,
      "step": 29
    },
    {
      "epoch": 0.048,
      "grad_norm": 6.1509175300598145,
      "learning_rate": 4.768000000000001e-06,
      "logits/chosen": -2.3730645179748535,
      "logits/rejected": -2.498508930206299,
      "logps/chosen": -1609.7783203125,
      "logps/rejected": -1804.330078125,
      "loss": 0.5917,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.015220570378005505,
      "rewards/margins": 0.2305750548839569,
      "rewards/rejected": -0.2457956224679947,
      "step": 30
    },
    {
      "epoch": 0.0496,
      "grad_norm": 4.998894214630127,
      "learning_rate": 4.76e-06,
      "logits/chosen": -2.418651819229126,
      "logits/rejected": -2.497138738632202,
      "logps/chosen": -1092.2430419921875,
      "logps/rejected": -1448.130126953125,
      "loss": 0.5809,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.0014558564871549606,
      "rewards/margins": 0.2704559862613678,
      "rewards/rejected": -0.2719117999076843,
      "step": 31
    },
    {
      "epoch": 0.0512,
      "grad_norm": 7.974624156951904,
      "learning_rate": 4.752e-06,
      "logits/chosen": -2.4644689559936523,
      "logits/rejected": -2.4903476238250732,
      "logps/chosen": -1456.8184814453125,
      "logps/rejected": -1984.0936279296875,
      "loss": 0.6069,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.039417147636413574,
      "rewards/margins": 0.2027800977230072,
      "rewards/rejected": -0.24219724535942078,
      "step": 32
    },
    {
      "epoch": 0.0528,
      "grad_norm": 6.433887481689453,
      "learning_rate": 4.744000000000001e-06,
      "logits/chosen": -2.5184032917022705,
      "logits/rejected": -2.4885895252227783,
      "logps/chosen": -1556.9276123046875,
      "logps/rejected": -2208.9404296875,
      "loss": 0.5729,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.036615803837776184,
      "rewards/margins": 0.2789185047149658,
      "rewards/rejected": -0.3155343532562256,
      "step": 33
    },
    {
      "epoch": 0.0544,
      "grad_norm": 5.127695560455322,
      "learning_rate": 4.736000000000001e-06,
      "logits/chosen": -2.527791976928711,
      "logits/rejected": -2.5352911949157715,
      "logps/chosen": -761.0938720703125,
      "logps/rejected": -1747.624755859375,
      "loss": 0.564,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.0006397361867129803,
      "rewards/margins": 0.28775492310523987,
      "rewards/rejected": -0.2871151864528656,
      "step": 34
    },
    {
      "epoch": 0.056,
      "grad_norm": 4.690290451049805,
      "learning_rate": 4.728e-06,
      "logits/chosen": -2.3896756172180176,
      "logits/rejected": -2.4915108680725098,
      "logps/chosen": -954.8023071289062,
      "logps/rejected": -1395.8271484375,
      "loss": 0.6103,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.022553065791726112,
      "rewards/margins": 0.18402671813964844,
      "rewards/rejected": -0.2065797746181488,
      "step": 35
    },
    {
      "epoch": 0.0576,
      "grad_norm": 5.159278869628906,
      "learning_rate": 4.7200000000000005e-06,
      "logits/chosen": -2.4312891960144043,
      "logits/rejected": -2.5728580951690674,
      "logps/chosen": -1027.1085205078125,
      "logps/rejected": -1698.792236328125,
      "loss": 0.5754,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020159317180514336,
      "rewards/margins": 0.2611401081085205,
      "rewards/rejected": -0.2409808188676834,
      "step": 36
    },
    {
      "epoch": 0.0592,
      "grad_norm": 5.163532257080078,
      "learning_rate": 4.712000000000001e-06,
      "logits/chosen": -2.444011688232422,
      "logits/rejected": -2.545302391052246,
      "logps/chosen": -985.62548828125,
      "logps/rejected": -1722.9822998046875,
      "loss": 0.5289,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.023259827867150307,
      "rewards/margins": 0.4088696837425232,
      "rewards/rejected": -0.38560980558395386,
      "step": 37
    },
    {
      "epoch": 0.0608,
      "grad_norm": 4.443084716796875,
      "learning_rate": 4.704e-06,
      "logits/chosen": -2.4531683921813965,
      "logits/rejected": -2.3953018188476562,
      "logps/chosen": -1051.037109375,
      "logps/rejected": -1488.4656982421875,
      "loss": 0.4829,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03958432748913765,
      "rewards/margins": 0.6120326519012451,
      "rewards/rejected": -0.5724484324455261,
      "step": 38
    },
    {
      "epoch": 0.0624,
      "grad_norm": 4.36039924621582,
      "learning_rate": 4.6960000000000004e-06,
      "logits/chosen": -2.346738815307617,
      "logits/rejected": -2.3932557106018066,
      "logps/chosen": -781.6734619140625,
      "logps/rejected": -1389.060302734375,
      "loss": 0.5071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.025782395154237747,
      "rewards/margins": 0.5120918154716492,
      "rewards/rejected": -0.4863094687461853,
      "step": 39
    },
    {
      "epoch": 0.064,
      "grad_norm": 4.423152446746826,
      "learning_rate": 4.688000000000001e-06,
      "logits/chosen": -2.3941683769226074,
      "logits/rejected": -2.4453883171081543,
      "logps/chosen": -1348.4906005859375,
      "logps/rejected": -1369.6048583984375,
      "loss": 0.5197,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.08326391875743866,
      "rewards/margins": 0.4253552258014679,
      "rewards/rejected": -0.34209129214286804,
      "step": 40
    },
    {
      "epoch": 0.0656,
      "grad_norm": 3.917776346206665,
      "learning_rate": 4.680000000000001e-06,
      "logits/chosen": -2.5225353240966797,
      "logits/rejected": -2.4893646240234375,
      "logps/chosen": -631.3782348632812,
      "logps/rejected": -1237.5419921875,
      "loss": 0.5319,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.003564846236258745,
      "rewards/margins": 0.3783791661262512,
      "rewards/rejected": -0.38194403052330017,
      "step": 41
    },
    {
      "epoch": 0.0672,
      "grad_norm": 6.309618949890137,
      "learning_rate": 4.672e-06,
      "logits/chosen": -2.3947300910949707,
      "logits/rejected": -2.33028244972229,
      "logps/chosen": -997.8880615234375,
      "logps/rejected": -1573.5198974609375,
      "loss": 0.5715,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.01999068260192871,
      "rewards/margins": 0.27362799644470215,
      "rewards/rejected": -0.29361870884895325,
      "step": 42
    },
    {
      "epoch": 0.0688,
      "grad_norm": 4.295537948608398,
      "learning_rate": 4.664000000000001e-06,
      "logits/chosen": -2.4997317790985107,
      "logits/rejected": -2.4784295558929443,
      "logps/chosen": -943.6978149414062,
      "logps/rejected": -1176.74560546875,
      "loss": 0.5582,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.027471639215946198,
      "rewards/margins": 0.3107304871082306,
      "rewards/rejected": -0.3382021188735962,
      "step": 43
    },
    {
      "epoch": 0.0704,
      "grad_norm": 7.20757532119751,
      "learning_rate": 4.656000000000001e-06,
      "logits/chosen": -2.440206289291382,
      "logits/rejected": -2.521519899368286,
      "logps/chosen": -1279.581787109375,
      "logps/rejected": -1728.439453125,
      "loss": 0.5333,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.021382711827754974,
      "rewards/margins": 0.37735024094581604,
      "rewards/rejected": -0.35596752166748047,
      "step": 44
    },
    {
      "epoch": 0.072,
      "grad_norm": 4.294131278991699,
      "learning_rate": 4.648e-06,
      "logits/chosen": -2.427238702774048,
      "logits/rejected": -2.499267339706421,
      "logps/chosen": -936.76953125,
      "logps/rejected": -1329.57373046875,
      "loss": 0.5473,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05417850241065025,
      "rewards/margins": 0.3269869089126587,
      "rewards/rejected": -0.38116541504859924,
      "step": 45
    },
    {
      "epoch": 0.0736,
      "grad_norm": 5.159995079040527,
      "learning_rate": 4.6400000000000005e-06,
      "logits/chosen": -2.423997163772583,
      "logits/rejected": -2.4125783443450928,
      "logps/chosen": -1069.165283203125,
      "logps/rejected": -1962.3826904296875,
      "loss": 0.4657,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.025747397914528847,
      "rewards/margins": 0.7605292797088623,
      "rewards/rejected": -0.786276638507843,
      "step": 46
    },
    {
      "epoch": 0.0752,
      "grad_norm": 6.723729610443115,
      "learning_rate": 4.632000000000001e-06,
      "logits/chosen": -2.5509090423583984,
      "logits/rejected": -2.4923243522644043,
      "logps/chosen": -1556.790771484375,
      "logps/rejected": -1895.181640625,
      "loss": 0.5837,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.12032730132341385,
      "rewards/margins": 0.2908268868923187,
      "rewards/rejected": -0.41115421056747437,
      "step": 47
    },
    {
      "epoch": 0.0768,
      "grad_norm": 4.9094438552856445,
      "learning_rate": 4.624e-06,
      "logits/chosen": -2.403075933456421,
      "logits/rejected": -2.5514211654663086,
      "logps/chosen": -858.0516357421875,
      "logps/rejected": -1559.831298828125,
      "loss": 0.5251,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0030367602594196796,
      "rewards/margins": 0.39764222502708435,
      "rewards/rejected": -0.40067896246910095,
      "step": 48
    },
    {
      "epoch": 0.0784,
      "grad_norm": 5.90323543548584,
      "learning_rate": 4.616e-06,
      "logits/chosen": -2.402954339981079,
      "logits/rejected": -2.5007476806640625,
      "logps/chosen": -1644.49365234375,
      "logps/rejected": -2142.56591796875,
      "loss": 0.4077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04832523688673973,
      "rewards/margins": 0.7789440751075745,
      "rewards/rejected": -0.7306188941001892,
      "step": 49
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.876892566680908,
      "learning_rate": 4.608000000000001e-06,
      "logits/chosen": -2.4634196758270264,
      "logits/rejected": -2.524357795715332,
      "logps/chosen": -1243.4114990234375,
      "logps/rejected": -2200.423095703125,
      "loss": 0.4226,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0012695789337158203,
      "rewards/margins": 0.7439866065979004,
      "rewards/rejected": -0.745256245136261,
      "step": 50
    },
    {
      "epoch": 0.0816,
      "grad_norm": 5.304353713989258,
      "learning_rate": 4.600000000000001e-06,
      "logits/chosen": -2.554231882095337,
      "logits/rejected": -2.532021999359131,
      "logps/chosen": -1630.2579345703125,
      "logps/rejected": -1748.79052734375,
      "loss": 0.4516,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.009376813657581806,
      "rewards/margins": 0.6017025709152222,
      "rewards/rejected": -0.6110793948173523,
      "step": 51
    },
    {
      "epoch": 0.0832,
      "grad_norm": 5.187316417694092,
      "learning_rate": 4.592e-06,
      "logits/chosen": -2.498135566711426,
      "logits/rejected": -2.4083938598632812,
      "logps/chosen": -1384.689208984375,
      "logps/rejected": -1931.995849609375,
      "loss": 0.4644,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.07917461544275284,
      "rewards/margins": 0.5850769877433777,
      "rewards/rejected": -0.6642515659332275,
      "step": 52
    },
    {
      "epoch": 0.0848,
      "grad_norm": 4.838135242462158,
      "learning_rate": 4.5840000000000005e-06,
      "logits/chosen": -2.445882797241211,
      "logits/rejected": -2.4829466342926025,
      "logps/chosen": -1116.0863037109375,
      "logps/rejected": -1792.969970703125,
      "loss": 0.5174,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.07026398181915283,
      "rewards/margins": 0.489179402589798,
      "rewards/rejected": -0.5594433546066284,
      "step": 53
    },
    {
      "epoch": 0.0864,
      "grad_norm": 5.2209553718566895,
      "learning_rate": 4.576000000000001e-06,
      "logits/chosen": -2.413048267364502,
      "logits/rejected": -2.4262566566467285,
      "logps/chosen": -887.2513427734375,
      "logps/rejected": -1720.2169189453125,
      "loss": 0.4544,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.022820793092250824,
      "rewards/margins": 0.6332731246948242,
      "rewards/rejected": -0.6104522347450256,
      "step": 54
    },
    {
      "epoch": 0.088,
      "grad_norm": 4.8002119064331055,
      "learning_rate": 4.568e-06,
      "logits/chosen": -2.254833459854126,
      "logits/rejected": -2.3849010467529297,
      "logps/chosen": -939.0093994140625,
      "logps/rejected": -1890.1427001953125,
      "loss": 0.3753,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.018575191497802734,
      "rewards/margins": 0.9412721395492554,
      "rewards/rejected": -0.9598473310470581,
      "step": 55
    },
    {
      "epoch": 0.0896,
      "grad_norm": 4.960271835327148,
      "learning_rate": 4.56e-06,
      "logits/chosen": -2.579571485519409,
      "logits/rejected": -2.515536069869995,
      "logps/chosen": -1340.374755859375,
      "logps/rejected": -1811.5596923828125,
      "loss": 0.4404,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.053728677332401276,
      "rewards/margins": 0.6789557337760925,
      "rewards/rejected": -0.7326843738555908,
      "step": 56
    },
    {
      "epoch": 0.0912,
      "grad_norm": 3.3769338130950928,
      "learning_rate": 4.552000000000001e-06,
      "logits/chosen": -2.22818660736084,
      "logits/rejected": -2.4143457412719727,
      "logps/chosen": -834.120849609375,
      "logps/rejected": -1612.02587890625,
      "loss": 0.428,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.009922838769853115,
      "rewards/margins": 0.7907403111457825,
      "rewards/rejected": -0.8006631731987,
      "step": 57
    },
    {
      "epoch": 0.0928,
      "grad_norm": 4.254573345184326,
      "learning_rate": 4.544000000000001e-06,
      "logits/chosen": -2.465895652770996,
      "logits/rejected": -2.4853782653808594,
      "logps/chosen": -1072.5191650390625,
      "logps/rejected": -1706.7333984375,
      "loss": 0.4479,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.04329273849725723,
      "rewards/margins": 0.7244612574577332,
      "rewards/rejected": -0.7677540183067322,
      "step": 58
    },
    {
      "epoch": 0.0944,
      "grad_norm": 4.614320278167725,
      "learning_rate": 4.536e-06,
      "logits/chosen": -2.4181833267211914,
      "logits/rejected": -2.4571948051452637,
      "logps/chosen": -1143.388671875,
      "logps/rejected": -1698.9920654296875,
      "loss": 0.4434,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.008206438273191452,
      "rewards/margins": 0.6621529459953308,
      "rewards/rejected": -0.6703594326972961,
      "step": 59
    },
    {
      "epoch": 0.096,
      "grad_norm": 114.27096557617188,
      "learning_rate": 4.5280000000000005e-06,
      "logits/chosen": -2.4065511226654053,
      "logits/rejected": -2.4462428092956543,
      "logps/chosen": -1039.031494140625,
      "logps/rejected": -3243.99658203125,
      "loss": 0.9381,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.0578995943069458,
      "rewards/margins": 0.39896953105926514,
      "rewards/rejected": -0.45686912536621094,
      "step": 60
    },
    {
      "epoch": 0.0976,
      "grad_norm": 4.4341230392456055,
      "learning_rate": 4.520000000000001e-06,
      "logits/chosen": -2.4552948474884033,
      "logits/rejected": -2.548647880554199,
      "logps/chosen": -834.3111572265625,
      "logps/rejected": -1361.443603515625,
      "loss": 0.4711,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0879419595003128,
      "rewards/margins": 0.5348865389823914,
      "rewards/rejected": -0.622828483581543,
      "step": 61
    },
    {
      "epoch": 0.0992,
      "grad_norm": 4.643270969390869,
      "learning_rate": 4.512e-06,
      "logits/chosen": -2.54868221282959,
      "logits/rejected": -2.5269510746002197,
      "logps/chosen": -976.1460571289062,
      "logps/rejected": -1663.8165283203125,
      "loss": 0.4991,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.187369242310524,
      "rewards/margins": 0.749457597732544,
      "rewards/rejected": -0.9368268251419067,
      "step": 62
    },
    {
      "epoch": 0.1008,
      "grad_norm": 4.303009986877441,
      "learning_rate": 4.504e-06,
      "logits/chosen": -2.494508743286133,
      "logits/rejected": -2.4935150146484375,
      "logps/chosen": -1258.249755859375,
      "logps/rejected": -1744.1854248046875,
      "loss": 0.4449,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08252592384815216,
      "rewards/margins": 0.6143494844436646,
      "rewards/rejected": -0.6968754529953003,
      "step": 63
    },
    {
      "epoch": 0.1024,
      "grad_norm": 3.9266281127929688,
      "learning_rate": 4.496000000000001e-06,
      "logits/chosen": -2.4731204509735107,
      "logits/rejected": -2.5203022956848145,
      "logps/chosen": -921.2763671875,
      "logps/rejected": -1744.591064453125,
      "loss": 0.3809,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.022436067461967468,
      "rewards/margins": 0.8827598094940186,
      "rewards/rejected": -0.8603237271308899,
      "step": 64
    },
    {
      "epoch": 0.104,
      "grad_norm": 4.099432945251465,
      "learning_rate": 4.488e-06,
      "logits/chosen": -2.388988971710205,
      "logits/rejected": -2.4264137744903564,
      "logps/chosen": -967.2359008789062,
      "logps/rejected": -2085.13232421875,
      "loss": 0.4029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.023308193311095238,
      "rewards/margins": 0.8329147100448608,
      "rewards/rejected": -0.8562229871749878,
      "step": 65
    },
    {
      "epoch": 0.1056,
      "grad_norm": 3.6696200370788574,
      "learning_rate": 4.48e-06,
      "logits/chosen": -2.2503409385681152,
      "logits/rejected": -2.409578800201416,
      "logps/chosen": -1728.78466796875,
      "logps/rejected": -1662.9283447265625,
      "loss": 0.4228,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.1354823112487793,
      "rewards/margins": 1.030614972114563,
      "rewards/rejected": -0.8951326608657837,
      "step": 66
    },
    {
      "epoch": 0.1072,
      "grad_norm": 4.834355354309082,
      "learning_rate": 4.4720000000000006e-06,
      "logits/chosen": -2.500420093536377,
      "logits/rejected": -2.5279905796051025,
      "logps/chosen": -1192.21923828125,
      "logps/rejected": -2089.546875,
      "loss": 0.413,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.11657924950122833,
      "rewards/margins": 0.784795880317688,
      "rewards/rejected": -0.9013752341270447,
      "step": 67
    },
    {
      "epoch": 0.1088,
      "grad_norm": 3.6707637310028076,
      "learning_rate": 4.464000000000001e-06,
      "logits/chosen": -2.4371845722198486,
      "logits/rejected": -2.486832857131958,
      "logps/chosen": -755.0999755859375,
      "logps/rejected": -1264.963134765625,
      "loss": 0.4467,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.07509183883666992,
      "rewards/margins": 0.7163953185081482,
      "rewards/rejected": -0.7914870977401733,
      "step": 68
    },
    {
      "epoch": 0.1104,
      "grad_norm": 4.412095546722412,
      "learning_rate": 4.456e-06,
      "logits/chosen": -2.5222582817077637,
      "logits/rejected": -2.530050277709961,
      "logps/chosen": -875.586669921875,
      "logps/rejected": -1423.85693359375,
      "loss": 0.4496,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.04253988713026047,
      "rewards/margins": 0.6108039021492004,
      "rewards/rejected": -0.6533437967300415,
      "step": 69
    },
    {
      "epoch": 0.112,
      "grad_norm": 4.693994998931885,
      "learning_rate": 4.4480000000000004e-06,
      "logits/chosen": -2.441682815551758,
      "logits/rejected": -2.4925615787506104,
      "logps/chosen": -1033.46142578125,
      "logps/rejected": -1597.0738525390625,
      "loss": 0.3942,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.015601971186697483,
      "rewards/margins": 0.8712390661239624,
      "rewards/rejected": -0.8868409991264343,
      "step": 70
    },
    {
      "epoch": 0.1136,
      "grad_norm": 3.6723878383636475,
      "learning_rate": 4.440000000000001e-06,
      "logits/chosen": -2.282296657562256,
      "logits/rejected": -2.425055503845215,
      "logps/chosen": -813.8991088867188,
      "logps/rejected": -1360.2625732421875,
      "loss": 0.4578,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.012647485360503197,
      "rewards/margins": 0.6152610778808594,
      "rewards/rejected": -0.6279085278511047,
      "step": 71
    },
    {
      "epoch": 0.1152,
      "grad_norm": 3.3391969203948975,
      "learning_rate": 4.432e-06,
      "logits/chosen": -2.412693500518799,
      "logits/rejected": -2.408931255340576,
      "logps/chosen": -719.9785766601562,
      "logps/rejected": -1575.9459228515625,
      "loss": 0.3826,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.024913480505347252,
      "rewards/margins": 1.0122792720794678,
      "rewards/rejected": -1.037192702293396,
      "step": 72
    },
    {
      "epoch": 0.1168,
      "grad_norm": 5.337649822235107,
      "learning_rate": 4.424e-06,
      "logits/chosen": -2.4722418785095215,
      "logits/rejected": -2.482541799545288,
      "logps/chosen": -1153.8218994140625,
      "logps/rejected": -1240.9375,
      "loss": 0.475,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.11305580288171768,
      "rewards/margins": 0.5441272854804993,
      "rewards/rejected": -0.6571831107139587,
      "step": 73
    },
    {
      "epoch": 0.1184,
      "grad_norm": 3.6771862506866455,
      "learning_rate": 4.416000000000001e-06,
      "logits/chosen": -2.471193552017212,
      "logits/rejected": -2.477119207382202,
      "logps/chosen": -1147.043701171875,
      "logps/rejected": -1417.807861328125,
      "loss": 0.3984,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.03233852609992027,
      "rewards/margins": 0.8718539476394653,
      "rewards/rejected": -0.9041925072669983,
      "step": 74
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.306926727294922,
      "learning_rate": 4.408000000000001e-06,
      "logits/chosen": -2.4748406410217285,
      "logits/rejected": -2.476750373840332,
      "logps/chosen": -981.0155639648438,
      "logps/rejected": -1468.7720947265625,
      "loss": 0.3877,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.16935759782791138,
      "rewards/margins": 0.9771731495857239,
      "rewards/rejected": -1.1465307474136353,
      "step": 75
    },
    {
      "epoch": 0.1216,
      "grad_norm": 2.8831162452697754,
      "learning_rate": 4.4e-06,
      "logits/chosen": -2.281566619873047,
      "logits/rejected": -2.4291300773620605,
      "logps/chosen": -715.8392944335938,
      "logps/rejected": -1480.139404296875,
      "loss": 0.3201,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.03338942676782608,
      "rewards/margins": 1.1474330425262451,
      "rewards/rejected": -1.1808223724365234,
      "step": 76
    },
    {
      "epoch": 0.1232,
      "grad_norm": 4.195013523101807,
      "learning_rate": 4.3920000000000005e-06,
      "logits/chosen": -2.443937301635742,
      "logits/rejected": -2.498157501220703,
      "logps/chosen": -874.0169067382812,
      "logps/rejected": -1316.942626953125,
      "loss": 0.4337,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.1892099231481552,
      "rewards/margins": 0.6941751837730408,
      "rewards/rejected": -0.8833851218223572,
      "step": 77
    },
    {
      "epoch": 0.1248,
      "grad_norm": 3.533186912536621,
      "learning_rate": 4.384000000000001e-06,
      "logits/chosen": -2.460679292678833,
      "logits/rejected": -2.5314974784851074,
      "logps/chosen": -828.7847900390625,
      "logps/rejected": -1679.3978271484375,
      "loss": 0.3738,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1500023752450943,
      "rewards/margins": 1.2177469730377197,
      "rewards/rejected": -1.3677494525909424,
      "step": 78
    },
    {
      "epoch": 0.1264,
      "grad_norm": 5.251435279846191,
      "learning_rate": 4.376e-06,
      "logits/chosen": -2.428579807281494,
      "logits/rejected": -2.4032108783721924,
      "logps/chosen": -1451.02392578125,
      "logps/rejected": -1898.55029296875,
      "loss": 0.3685,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10095509886741638,
      "rewards/margins": 0.9122613668441772,
      "rewards/rejected": -1.0132163763046265,
      "step": 79
    },
    {
      "epoch": 0.128,
      "grad_norm": 3.8912696838378906,
      "learning_rate": 4.368e-06,
      "logits/chosen": -2.4700093269348145,
      "logits/rejected": -2.493675947189331,
      "logps/chosen": -1226.7545166015625,
      "logps/rejected": -1739.671630859375,
      "loss": 0.3921,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1307486891746521,
      "rewards/margins": 0.922287106513977,
      "rewards/rejected": -1.053035855293274,
      "step": 80
    },
    {
      "epoch": 0.1296,
      "grad_norm": 5.438251972198486,
      "learning_rate": 4.360000000000001e-06,
      "logits/chosen": -2.4751548767089844,
      "logits/rejected": -2.474551200866699,
      "logps/chosen": -1537.556640625,
      "logps/rejected": -2213.0029296875,
      "loss": 0.3727,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.28010302782058716,
      "rewards/margins": 1.1754176616668701,
      "rewards/rejected": -1.4555206298828125,
      "step": 81
    },
    {
      "epoch": 0.1312,
      "grad_norm": 3.6982758045196533,
      "learning_rate": 4.352e-06,
      "logits/chosen": -2.3063390254974365,
      "logits/rejected": -2.3717260360717773,
      "logps/chosen": -928.5242919921875,
      "logps/rejected": -1706.3719482421875,
      "loss": 0.4432,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.02406725287437439,
      "rewards/margins": 0.7992755174636841,
      "rewards/rejected": -0.8233427405357361,
      "step": 82
    },
    {
      "epoch": 0.1328,
      "grad_norm": 3.1924326419830322,
      "learning_rate": 4.344e-06,
      "logits/chosen": -2.356764554977417,
      "logits/rejected": -2.308676242828369,
      "logps/chosen": -1075.246337890625,
      "logps/rejected": -1610.909912109375,
      "loss": 0.2689,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.09648031741380692,
      "rewards/margins": 1.542906403541565,
      "rewards/rejected": -1.4464260339736938,
      "step": 83
    },
    {
      "epoch": 0.1344,
      "grad_norm": 3.5851633548736572,
      "learning_rate": 4.3360000000000005e-06,
      "logits/chosen": -2.3311450481414795,
      "logits/rejected": -2.4191408157348633,
      "logps/chosen": -708.0391235351562,
      "logps/rejected": -1201.893798828125,
      "loss": 0.4109,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10602901875972748,
      "rewards/margins": 0.7890390157699585,
      "rewards/rejected": -0.8950679898262024,
      "step": 84
    },
    {
      "epoch": 0.136,
      "grad_norm": 3.3972227573394775,
      "learning_rate": 4.328000000000001e-06,
      "logits/chosen": -2.2745485305786133,
      "logits/rejected": -2.3526556491851807,
      "logps/chosen": -1237.2530517578125,
      "logps/rejected": -1811.6837158203125,
      "loss": 0.2979,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0517534501850605,
      "rewards/margins": 1.3414555788040161,
      "rewards/rejected": -1.3932090997695923,
      "step": 85
    },
    {
      "epoch": 0.1376,
      "grad_norm": 3.0943892002105713,
      "learning_rate": 4.32e-06,
      "logits/chosen": -2.4424753189086914,
      "logits/rejected": -2.6081202030181885,
      "logps/chosen": -863.8726806640625,
      "logps/rejected": -1171.138916015625,
      "loss": 0.4318,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.0013262461870908737,
      "rewards/margins": 0.7555155754089355,
      "rewards/rejected": -0.7541893124580383,
      "step": 86
    },
    {
      "epoch": 0.1392,
      "grad_norm": 6.824993133544922,
      "learning_rate": 4.312e-06,
      "logits/chosen": -2.26567006111145,
      "logits/rejected": -2.4199228286743164,
      "logps/chosen": -1184.958251953125,
      "logps/rejected": -1732.1868896484375,
      "loss": 0.383,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.12924934923648834,
      "rewards/margins": 1.0110704898834229,
      "rewards/rejected": -1.1403197050094604,
      "step": 87
    },
    {
      "epoch": 0.1408,
      "grad_norm": 2.9939441680908203,
      "learning_rate": 4.304000000000001e-06,
      "logits/chosen": -2.4545109272003174,
      "logits/rejected": -2.515630006790161,
      "logps/chosen": -962.5986328125,
      "logps/rejected": -1317.592041015625,
      "loss": 0.3709,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.1769241839647293,
      "rewards/margins": 1.0671230554580688,
      "rewards/rejected": -1.2440472841262817,
      "step": 88
    },
    {
      "epoch": 0.1424,
      "grad_norm": 3.2820374965667725,
      "learning_rate": 4.296e-06,
      "logits/chosen": -2.4707083702087402,
      "logits/rejected": -2.4873335361480713,
      "logps/chosen": -1149.957275390625,
      "logps/rejected": -1625.29931640625,
      "loss": 0.3003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.148725226521492,
      "rewards/margins": 1.2516520023345947,
      "rewards/rejected": -1.4003772735595703,
      "step": 89
    },
    {
      "epoch": 0.144,
      "grad_norm": 4.2410359382629395,
      "learning_rate": 4.288e-06,
      "logits/chosen": -2.292142868041992,
      "logits/rejected": -2.3967607021331787,
      "logps/chosen": -1299.8642578125,
      "logps/rejected": -1860.296630859375,
      "loss": 0.3864,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.1806352585554123,
      "rewards/margins": 1.2282143831253052,
      "rewards/rejected": -1.4088494777679443,
      "step": 90
    },
    {
      "epoch": 0.1456,
      "grad_norm": 3.539700984954834,
      "learning_rate": 4.2800000000000005e-06,
      "logits/chosen": -2.5238661766052246,
      "logits/rejected": -2.4962992668151855,
      "logps/chosen": -942.8016357421875,
      "logps/rejected": -1926.316650390625,
      "loss": 0.3897,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.1027974933385849,
      "rewards/margins": 0.9161090850830078,
      "rewards/rejected": -1.018906593322754,
      "step": 91
    },
    {
      "epoch": 0.1472,
      "grad_norm": 2.327420473098755,
      "learning_rate": 4.272000000000001e-06,
      "logits/chosen": -2.2779834270477295,
      "logits/rejected": -2.38816499710083,
      "logps/chosen": -699.9099731445312,
      "logps/rejected": -1502.68603515625,
      "loss": 0.3084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.15832284092903137,
      "rewards/margins": 1.4348328113555908,
      "rewards/rejected": -1.5931555032730103,
      "step": 92
    },
    {
      "epoch": 0.1488,
      "grad_norm": 3.553140878677368,
      "learning_rate": 4.264e-06,
      "logits/chosen": -2.5239953994750977,
      "logits/rejected": -2.5327048301696777,
      "logps/chosen": -940.0181274414062,
      "logps/rejected": -1413.186767578125,
      "loss": 0.4078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1792048066854477,
      "rewards/margins": 0.768405020236969,
      "rewards/rejected": -0.9476098418235779,
      "step": 93
    },
    {
      "epoch": 0.1504,
      "grad_norm": 2.9112439155578613,
      "learning_rate": 4.256e-06,
      "logits/chosen": -2.4378762245178223,
      "logits/rejected": -2.390841007232666,
      "logps/chosen": -1178.6810302734375,
      "logps/rejected": -1942.3280029296875,
      "loss": 0.2211,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20701630413532257,
      "rewards/margins": 1.681829571723938,
      "rewards/rejected": -1.8888459205627441,
      "step": 94
    },
    {
      "epoch": 0.152,
      "grad_norm": 3.533766031265259,
      "learning_rate": 4.248000000000001e-06,
      "logits/chosen": -2.3642613887786865,
      "logits/rejected": -2.3864657878875732,
      "logps/chosen": -780.42041015625,
      "logps/rejected": -1323.309814453125,
      "loss": 0.3933,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.17855724692344666,
      "rewards/margins": 0.9528135061264038,
      "rewards/rejected": -1.1313707828521729,
      "step": 95
    },
    {
      "epoch": 0.1536,
      "grad_norm": 5.412832260131836,
      "learning_rate": 4.24e-06,
      "logits/chosen": -2.227529525756836,
      "logits/rejected": -2.3135101795196533,
      "logps/chosen": -1793.0361328125,
      "logps/rejected": -2308.60986328125,
      "loss": 0.3618,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.14720723032951355,
      "rewards/margins": 1.1961324214935303,
      "rewards/rejected": -1.343339443206787,
      "step": 96
    },
    {
      "epoch": 0.1552,
      "grad_norm": 2.4717166423797607,
      "learning_rate": 4.232e-06,
      "logits/chosen": -2.4376637935638428,
      "logits/rejected": -2.4160306453704834,
      "logps/chosen": -1514.1527099609375,
      "logps/rejected": -1871.991455078125,
      "loss": 0.2473,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05610981211066246,
      "rewards/margins": 1.9479868412017822,
      "rewards/rejected": -1.8918769359588623,
      "step": 97
    },
    {
      "epoch": 0.1568,
      "grad_norm": 2.8663933277130127,
      "learning_rate": 4.2240000000000006e-06,
      "logits/chosen": -2.4955952167510986,
      "logits/rejected": -2.466695785522461,
      "logps/chosen": -1014.5949096679688,
      "logps/rejected": -1734.2327880859375,
      "loss": 0.2758,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05485974997282028,
      "rewards/margins": 1.458674669265747,
      "rewards/rejected": -1.513534426689148,
      "step": 98
    },
    {
      "epoch": 0.1584,
      "grad_norm": 2.89676833152771,
      "learning_rate": 4.216e-06,
      "logits/chosen": -2.4123430252075195,
      "logits/rejected": -2.445830821990967,
      "logps/chosen": -1041.836181640625,
      "logps/rejected": -1452.9610595703125,
      "loss": 0.3042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.14857217669487,
      "rewards/margins": 1.1992714405059814,
      "rewards/rejected": -1.3478436470031738,
      "step": 99
    },
    {
      "epoch": 0.16,
      "grad_norm": 4.1963019371032715,
      "learning_rate": 4.208e-06,
      "logits/chosen": -2.268817186355591,
      "logits/rejected": -2.4280753135681152,
      "logps/chosen": -832.0985107421875,
      "logps/rejected": -1240.9068603515625,
      "loss": 0.4,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.21588222682476044,
      "rewards/margins": 0.8761605620384216,
      "rewards/rejected": -1.0920428037643433,
      "step": 100
    },
    {
      "epoch": 0.1616,
      "grad_norm": 3.204695701599121,
      "learning_rate": 4.2000000000000004e-06,
      "logits/chosen": -2.4962916374206543,
      "logits/rejected": -2.4844586849212646,
      "logps/chosen": -856.2902221679688,
      "logps/rejected": -1615.654052734375,
      "loss": 0.3368,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.11948814988136292,
      "rewards/margins": 1.130797028541565,
      "rewards/rejected": -1.2502851486206055,
      "step": 101
    },
    {
      "epoch": 0.1632,
      "grad_norm": 2.5167012214660645,
      "learning_rate": 4.192000000000001e-06,
      "logits/chosen": -2.2445967197418213,
      "logits/rejected": -2.4790804386138916,
      "logps/chosen": -1188.63427734375,
      "logps/rejected": -1609.4036865234375,
      "loss": 0.3391,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.07233432680368423,
      "rewards/margins": 1.2304503917694092,
      "rewards/rejected": -1.30278480052948,
      "step": 102
    },
    {
      "epoch": 0.1648,
      "grad_norm": 6.240241050720215,
      "learning_rate": 4.184e-06,
      "logits/chosen": -2.441589832305908,
      "logits/rejected": -2.4485952854156494,
      "logps/chosen": -924.1279907226562,
      "logps/rejected": -1535.0303955078125,
      "loss": 0.4642,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.4198063611984253,
      "rewards/margins": 0.8683212995529175,
      "rewards/rejected": -1.2881277799606323,
      "step": 103
    },
    {
      "epoch": 0.1664,
      "grad_norm": 2.88150691986084,
      "learning_rate": 4.176e-06,
      "logits/chosen": -2.498318672180176,
      "logits/rejected": -2.4959816932678223,
      "logps/chosen": -795.31787109375,
      "logps/rejected": -1326.9429931640625,
      "loss": 0.3413,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.07539597153663635,
      "rewards/margins": 1.062537670135498,
      "rewards/rejected": -1.1379334926605225,
      "step": 104
    },
    {
      "epoch": 0.168,
      "grad_norm": 5.859161853790283,
      "learning_rate": 4.168000000000001e-06,
      "logits/chosen": -2.45375394821167,
      "logits/rejected": -2.396920680999756,
      "logps/chosen": -938.7039184570312,
      "logps/rejected": -1441.9359130859375,
      "loss": 0.4436,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.180232435464859,
      "rewards/margins": 0.9859802722930908,
      "rewards/rejected": -1.166212558746338,
      "step": 105
    },
    {
      "epoch": 0.1696,
      "grad_norm": 3.2874221801757812,
      "learning_rate": 4.16e-06,
      "logits/chosen": -2.3340017795562744,
      "logits/rejected": -2.3949129581451416,
      "logps/chosen": -1465.526123046875,
      "logps/rejected": -2216.86865234375,
      "loss": 0.2324,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.08080911636352539,
      "rewards/margins": 2.21992826461792,
      "rewards/rejected": -2.3007373809814453,
      "step": 106
    },
    {
      "epoch": 0.1712,
      "grad_norm": 3.46250319480896,
      "learning_rate": 4.152e-06,
      "logits/chosen": -2.3385212421417236,
      "logits/rejected": -2.4153292179107666,
      "logps/chosen": -1124.3406982421875,
      "logps/rejected": -1901.711181640625,
      "loss": 0.3279,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04264888912439346,
      "rewards/margins": 1.2065978050231934,
      "rewards/rejected": -1.1639487743377686,
      "step": 107
    },
    {
      "epoch": 0.1728,
      "grad_norm": 5.7182936668396,
      "learning_rate": 4.1440000000000005e-06,
      "logits/chosen": -2.468228816986084,
      "logits/rejected": -2.484130859375,
      "logps/chosen": -1077.501953125,
      "logps/rejected": -1691.16552734375,
      "loss": 0.3233,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.15436001121997833,
      "rewards/margins": 1.2421308755874634,
      "rewards/rejected": -1.3964906930923462,
      "step": 108
    },
    {
      "epoch": 0.1744,
      "grad_norm": 2.5204930305480957,
      "learning_rate": 4.136000000000001e-06,
      "logits/chosen": -2.3205463886260986,
      "logits/rejected": -2.4084458351135254,
      "logps/chosen": -896.6912231445312,
      "logps/rejected": -1418.5079345703125,
      "loss": 0.2326,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.16559544205665588,
      "rewards/margins": 1.595067024230957,
      "rewards/rejected": -1.760662317276001,
      "step": 109
    },
    {
      "epoch": 0.176,
      "grad_norm": 3.672863006591797,
      "learning_rate": 4.128e-06,
      "logits/chosen": -2.415785551071167,
      "logits/rejected": -2.4012420177459717,
      "logps/chosen": -1573.3699951171875,
      "logps/rejected": -1902.076171875,
      "loss": 0.2999,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5752886533737183,
      "rewards/margins": 1.3048595190048218,
      "rewards/rejected": -1.88014817237854,
      "step": 110
    },
    {
      "epoch": 0.1776,
      "grad_norm": 2.758054733276367,
      "learning_rate": 4.12e-06,
      "logits/chosen": -2.2387988567352295,
      "logits/rejected": -2.3464741706848145,
      "logps/chosen": -1092.822265625,
      "logps/rejected": -1934.2626953125,
      "loss": 0.3173,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.14779254794120789,
      "rewards/margins": 1.481509804725647,
      "rewards/rejected": -1.6293023824691772,
      "step": 111
    },
    {
      "epoch": 0.1792,
      "grad_norm": 3.51092529296875,
      "learning_rate": 4.112000000000001e-06,
      "logits/chosen": -2.423769474029541,
      "logits/rejected": -2.40720272064209,
      "logps/chosen": -1258.038330078125,
      "logps/rejected": -1600.9141845703125,
      "loss": 0.3249,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.22913143038749695,
      "rewards/margins": 1.5761014223098755,
      "rewards/rejected": -1.8052328824996948,
      "step": 112
    },
    {
      "epoch": 0.1808,
      "grad_norm": 2.4401259422302246,
      "learning_rate": 4.104e-06,
      "logits/chosen": -2.4996144771575928,
      "logits/rejected": -2.486800193786621,
      "logps/chosen": -1111.9854736328125,
      "logps/rejected": -1758.878173828125,
      "loss": 0.2189,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.2552917003631592,
      "rewards/margins": 1.921882152557373,
      "rewards/rejected": -2.1771740913391113,
      "step": 113
    },
    {
      "epoch": 0.1824,
      "grad_norm": 2.110849618911743,
      "learning_rate": 4.096e-06,
      "logits/chosen": -2.416252374649048,
      "logits/rejected": -2.467639446258545,
      "logps/chosen": -806.2451782226562,
      "logps/rejected": -1394.4798583984375,
      "loss": 0.2791,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08220276981592178,
      "rewards/margins": 1.474043369293213,
      "rewards/rejected": -1.556246042251587,
      "step": 114
    },
    {
      "epoch": 0.184,
      "grad_norm": 4.0337629318237305,
      "learning_rate": 4.0880000000000005e-06,
      "logits/chosen": -2.4232237339019775,
      "logits/rejected": -2.428703546524048,
      "logps/chosen": -732.0713500976562,
      "logps/rejected": -921.5111083984375,
      "loss": 0.447,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.3119714856147766,
      "rewards/margins": 0.8600640892982483,
      "rewards/rejected": -1.172035574913025,
      "step": 115
    },
    {
      "epoch": 0.1856,
      "grad_norm": 2.3061866760253906,
      "learning_rate": 4.08e-06,
      "logits/chosen": -2.372110366821289,
      "logits/rejected": -2.39100980758667,
      "logps/chosen": -535.443359375,
      "logps/rejected": -1018.3807983398438,
      "loss": 0.3431,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.16312366724014282,
      "rewards/margins": 1.183103084564209,
      "rewards/rejected": -1.346226692199707,
      "step": 116
    },
    {
      "epoch": 0.1872,
      "grad_norm": 3.262235164642334,
      "learning_rate": 4.072e-06,
      "logits/chosen": -2.3800668716430664,
      "logits/rejected": -2.3775794506073,
      "logps/chosen": -625.9942626953125,
      "logps/rejected": -1550.088134765625,
      "loss": 0.2523,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.31171715259552,
      "rewards/margins": 1.8031421899795532,
      "rewards/rejected": -2.1148593425750732,
      "step": 117
    },
    {
      "epoch": 0.1888,
      "grad_norm": 2.3869738578796387,
      "learning_rate": 4.064e-06,
      "logits/chosen": -2.492366075515747,
      "logits/rejected": -2.426870107650757,
      "logps/chosen": -857.9932250976562,
      "logps/rejected": -1215.491943359375,
      "loss": 0.2574,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.21735452115535736,
      "rewards/margins": 1.5536785125732422,
      "rewards/rejected": -1.7710330486297607,
      "step": 118
    },
    {
      "epoch": 0.1904,
      "grad_norm": 2.379779100418091,
      "learning_rate": 4.056000000000001e-06,
      "logits/chosen": -2.4281182289123535,
      "logits/rejected": -2.510866641998291,
      "logps/chosen": -1113.99755859375,
      "logps/rejected": -1834.54248046875,
      "loss": 0.287,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.2678978741168976,
      "rewards/margins": 1.5082626342773438,
      "rewards/rejected": -1.7761603593826294,
      "step": 119
    },
    {
      "epoch": 0.192,
      "grad_norm": 1.9459013938903809,
      "learning_rate": 4.048e-06,
      "logits/chosen": -2.459183931350708,
      "logits/rejected": -2.4387874603271484,
      "logps/chosen": -697.8385009765625,
      "logps/rejected": -1850.4478759765625,
      "loss": 0.2326,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.24488157033920288,
      "rewards/margins": 2.0289547443389893,
      "rewards/rejected": -2.273836135864258,
      "step": 120
    },
    {
      "epoch": 0.1936,
      "grad_norm": 2.395322799682617,
      "learning_rate": 4.04e-06,
      "logits/chosen": -2.4002771377563477,
      "logits/rejected": -2.408482551574707,
      "logps/chosen": -937.3818359375,
      "logps/rejected": -1440.01025390625,
      "loss": 0.2274,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.020366281270980835,
      "rewards/margins": 1.7213118076324463,
      "rewards/rejected": -1.741678237915039,
      "step": 121
    },
    {
      "epoch": 0.1952,
      "grad_norm": 3.667409896850586,
      "learning_rate": 4.0320000000000005e-06,
      "logits/chosen": -2.3035333156585693,
      "logits/rejected": -2.3409948348999023,
      "logps/chosen": -526.32470703125,
      "logps/rejected": -1170.1763916015625,
      "loss": 0.32,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.04658423364162445,
      "rewards/margins": 1.9765853881835938,
      "rewards/rejected": -2.02316951751709,
      "step": 122
    },
    {
      "epoch": 0.1968,
      "grad_norm": 3.6410887241363525,
      "learning_rate": 4.024e-06,
      "logits/chosen": -2.41646671295166,
      "logits/rejected": -2.482295036315918,
      "logps/chosen": -1100.54345703125,
      "logps/rejected": -1223.838623046875,
      "loss": 0.3861,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.2879422903060913,
      "rewards/margins": 1.3792297840118408,
      "rewards/rejected": -1.6671720743179321,
      "step": 123
    },
    {
      "epoch": 0.1984,
      "grad_norm": 2.7401483058929443,
      "learning_rate": 4.016e-06,
      "logits/chosen": -2.352450132369995,
      "logits/rejected": -2.415504217147827,
      "logps/chosen": -1372.249267578125,
      "logps/rejected": -1752.1375732421875,
      "loss": 0.2753,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.2517732083797455,
      "rewards/margins": 2.1727797985076904,
      "rewards/rejected": -2.4245529174804688,
      "step": 124
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.897634744644165,
      "learning_rate": 4.008e-06,
      "logits/chosen": -2.3176608085632324,
      "logits/rejected": -2.4674034118652344,
      "logps/chosen": -818.3677368164062,
      "logps/rejected": -1466.919921875,
      "loss": 0.2582,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.003130462020635605,
      "rewards/margins": 1.5885162353515625,
      "rewards/rejected": -1.585385799407959,
      "step": 125
    },
    {
      "epoch": 0.2016,
      "grad_norm": 2.7919366359710693,
      "learning_rate": 4.000000000000001e-06,
      "logits/chosen": -2.4109137058258057,
      "logits/rejected": -2.2715041637420654,
      "logps/chosen": -796.6652221679688,
      "logps/rejected": -1924.887451171875,
      "loss": 0.2462,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.22896552085876465,
      "rewards/margins": 1.598818063735962,
      "rewards/rejected": -1.8277837038040161,
      "step": 126
    },
    {
      "epoch": 0.2032,
      "grad_norm": 2.559756278991699,
      "learning_rate": 3.992e-06,
      "logits/chosen": -2.505685329437256,
      "logits/rejected": -2.4893593788146973,
      "logps/chosen": -1191.7369384765625,
      "logps/rejected": -1581.1273193359375,
      "loss": 0.253,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2606949210166931,
      "rewards/margins": 1.620897889137268,
      "rewards/rejected": -1.8815927505493164,
      "step": 127
    },
    {
      "epoch": 0.2048,
      "grad_norm": 2.052039623260498,
      "learning_rate": 3.984e-06,
      "logits/chosen": -2.2151694297790527,
      "logits/rejected": -2.2838356494903564,
      "logps/chosen": -1385.010986328125,
      "logps/rejected": -2051.345458984375,
      "loss": 0.1875,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.1597253978252411,
      "rewards/margins": 2.723198890686035,
      "rewards/rejected": -2.5634732246398926,
      "step": 128
    },
    {
      "epoch": 0.2064,
      "grad_norm": 1.8168867826461792,
      "learning_rate": 3.9760000000000006e-06,
      "logits/chosen": -2.375739097595215,
      "logits/rejected": -2.4571986198425293,
      "logps/chosen": -1028.0880126953125,
      "logps/rejected": -1826.8101806640625,
      "loss": 0.2142,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.4021643102169037,
      "rewards/margins": 2.261357545852661,
      "rewards/rejected": -2.6635220050811768,
      "step": 129
    },
    {
      "epoch": 0.208,
      "grad_norm": 2.4511003494262695,
      "learning_rate": 3.968e-06,
      "logits/chosen": -2.434173822402954,
      "logits/rejected": -2.473037004470825,
      "logps/chosen": -537.5145874023438,
      "logps/rejected": -1348.2607421875,
      "loss": 0.2379,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17180082201957703,
      "rewards/margins": 1.5162779092788696,
      "rewards/rejected": -1.6880786418914795,
      "step": 130
    },
    {
      "epoch": 0.2096,
      "grad_norm": 3.697261333465576,
      "learning_rate": 3.96e-06,
      "logits/chosen": -2.3012475967407227,
      "logits/rejected": -2.5040555000305176,
      "logps/chosen": -1158.4647216796875,
      "logps/rejected": -1860.9627685546875,
      "loss": 0.3208,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.27815839648246765,
      "rewards/margins": 1.3586840629577637,
      "rewards/rejected": -1.6368422508239746,
      "step": 131
    },
    {
      "epoch": 0.2112,
      "grad_norm": 1.67403244972229,
      "learning_rate": 3.9520000000000004e-06,
      "logits/chosen": -2.2047948837280273,
      "logits/rejected": -2.4485700130462646,
      "logps/chosen": -962.3466186523438,
      "logps/rejected": -1366.508544921875,
      "loss": 0.2813,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.018666863441467285,
      "rewards/margins": 1.9027272462844849,
      "rewards/rejected": -1.8840605020523071,
      "step": 132
    },
    {
      "epoch": 0.2128,
      "grad_norm": 7.227810382843018,
      "learning_rate": 3.944e-06,
      "logits/chosen": -2.2799153327941895,
      "logits/rejected": -2.1915135383605957,
      "logps/chosen": -735.9043579101562,
      "logps/rejected": -1661.015869140625,
      "loss": 0.3708,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.23493711650371552,
      "rewards/margins": 1.1542118787765503,
      "rewards/rejected": -1.3891489505767822,
      "step": 133
    },
    {
      "epoch": 0.2144,
      "grad_norm": 2.7487289905548096,
      "learning_rate": 3.936e-06,
      "logits/chosen": -2.164417266845703,
      "logits/rejected": -2.1750171184539795,
      "logps/chosen": -1369.783935546875,
      "logps/rejected": -2018.528076171875,
      "loss": 0.28,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.06329622864723206,
      "rewards/margins": 2.0045852661132812,
      "rewards/rejected": -1.9412890672683716,
      "step": 134
    },
    {
      "epoch": 0.216,
      "grad_norm": 2.2185282707214355,
      "learning_rate": 3.928e-06,
      "logits/chosen": -2.393886089324951,
      "logits/rejected": -2.451674461364746,
      "logps/chosen": -1124.8636474609375,
      "logps/rejected": -1539.018310546875,
      "loss": 0.21,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.2566457986831665,
      "rewards/margins": 2.3321776390075684,
      "rewards/rejected": -2.5888233184814453,
      "step": 135
    },
    {
      "epoch": 0.2176,
      "grad_norm": 2.0666964054107666,
      "learning_rate": 3.920000000000001e-06,
      "logits/chosen": -2.4351930618286133,
      "logits/rejected": -2.3645544052124023,
      "logps/chosen": -914.6356811523438,
      "logps/rejected": -1829.501953125,
      "loss": 0.1705,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.43337368965148926,
      "rewards/margins": 2.128699541091919,
      "rewards/rejected": -2.562072992324829,
      "step": 136
    },
    {
      "epoch": 0.2192,
      "grad_norm": 2.7948412895202637,
      "learning_rate": 3.912e-06,
      "logits/chosen": -2.40022873878479,
      "logits/rejected": -2.434770345687866,
      "logps/chosen": -1275.38623046875,
      "logps/rejected": -1721.7816162109375,
      "loss": 0.2446,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.2718428373336792,
      "rewards/margins": 1.9000065326690674,
      "rewards/rejected": -2.171849250793457,
      "step": 137
    },
    {
      "epoch": 0.2208,
      "grad_norm": 2.0689785480499268,
      "learning_rate": 3.904e-06,
      "logits/chosen": -2.3877782821655273,
      "logits/rejected": -2.4453649520874023,
      "logps/chosen": -696.7930297851562,
      "logps/rejected": -1044.6904296875,
      "loss": 0.3154,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20408175885677338,
      "rewards/margins": 1.26399827003479,
      "rewards/rejected": -1.4680800437927246,
      "step": 138
    },
    {
      "epoch": 0.2224,
      "grad_norm": 2.000675916671753,
      "learning_rate": 3.8960000000000005e-06,
      "logits/chosen": -2.24735951423645,
      "logits/rejected": -2.3915257453918457,
      "logps/chosen": -658.0923461914062,
      "logps/rejected": -1295.322998046875,
      "loss": 0.2728,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.16451233625411987,
      "rewards/margins": 2.044132947921753,
      "rewards/rejected": -2.2086453437805176,
      "step": 139
    },
    {
      "epoch": 0.224,
      "grad_norm": 2.777254343032837,
      "learning_rate": 3.888e-06,
      "logits/chosen": -2.4313173294067383,
      "logits/rejected": -2.466491937637329,
      "logps/chosen": -872.178466796875,
      "logps/rejected": -1573.3756103515625,
      "loss": 0.2495,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.11351258307695389,
      "rewards/margins": 1.8166122436523438,
      "rewards/rejected": -1.9301247596740723,
      "step": 140
    },
    {
      "epoch": 0.2256,
      "grad_norm": 2.1828911304473877,
      "learning_rate": 3.88e-06,
      "logits/chosen": -2.3876113891601562,
      "logits/rejected": -2.4259696006774902,
      "logps/chosen": -961.1243286132812,
      "logps/rejected": -1619.15625,
      "loss": 0.2168,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.24345333874225616,
      "rewards/margins": 1.933893084526062,
      "rewards/rejected": -2.1773464679718018,
      "step": 141
    },
    {
      "epoch": 0.2272,
      "grad_norm": 2.33107328414917,
      "learning_rate": 3.872e-06,
      "logits/chosen": -2.3056912422180176,
      "logits/rejected": -2.323157787322998,
      "logps/chosen": -1179.336669921875,
      "logps/rejected": -1982.01904296875,
      "loss": 0.1704,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.2873044013977051,
      "rewards/margins": 2.850069284439087,
      "rewards/rejected": -3.137373685836792,
      "step": 142
    },
    {
      "epoch": 0.2288,
      "grad_norm": 3.128355026245117,
      "learning_rate": 3.864000000000001e-06,
      "logits/chosen": -2.485975742340088,
      "logits/rejected": -2.465226650238037,
      "logps/chosen": -1649.9453125,
      "logps/rejected": -1743.7667236328125,
      "loss": 0.3115,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.44606447219848633,
      "rewards/margins": 1.5215235948562622,
      "rewards/rejected": -1.967588186264038,
      "step": 143
    },
    {
      "epoch": 0.2304,
      "grad_norm": 2.198086977005005,
      "learning_rate": 3.856e-06,
      "logits/chosen": -2.317775011062622,
      "logits/rejected": -2.394287347793579,
      "logps/chosen": -1220.736083984375,
      "logps/rejected": -1814.7510986328125,
      "loss": 0.1951,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.2733727693557739,
      "rewards/margins": 1.919477939605713,
      "rewards/rejected": -2.192850351333618,
      "step": 144
    },
    {
      "epoch": 0.232,
      "grad_norm": 3.693150520324707,
      "learning_rate": 3.848e-06,
      "logits/chosen": -2.47483491897583,
      "logits/rejected": -2.419583797454834,
      "logps/chosen": -1360.066162109375,
      "logps/rejected": -1456.9869384765625,
      "loss": 0.2423,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.5374501347541809,
      "rewards/margins": 1.792967677116394,
      "rewards/rejected": -2.3304178714752197,
      "step": 145
    },
    {
      "epoch": 0.2336,
      "grad_norm": 2.1991612911224365,
      "learning_rate": 3.8400000000000005e-06,
      "logits/chosen": -2.115344762802124,
      "logits/rejected": -2.2781994342803955,
      "logps/chosen": -1125.8660888671875,
      "logps/rejected": -1905.482666015625,
      "loss": 0.1708,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3205452859401703,
      "rewards/margins": 2.2745161056518555,
      "rewards/rejected": -2.5950613021850586,
      "step": 146
    },
    {
      "epoch": 0.2352,
      "grad_norm": 4.570766448974609,
      "learning_rate": 3.832e-06,
      "logits/chosen": -2.4413623809814453,
      "logits/rejected": -2.434114933013916,
      "logps/chosen": -1013.01416015625,
      "logps/rejected": -1565.8284912109375,
      "loss": 0.2593,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.46672937273979187,
      "rewards/margins": 2.4415626525878906,
      "rewards/rejected": -2.9082915782928467,
      "step": 147
    },
    {
      "epoch": 0.2368,
      "grad_norm": 2.356839895248413,
      "learning_rate": 3.824e-06,
      "logits/chosen": -2.3647284507751465,
      "logits/rejected": -2.4543638229370117,
      "logps/chosen": -892.5068969726562,
      "logps/rejected": -1911.655029296875,
      "loss": 0.1632,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3284927010536194,
      "rewards/margins": 2.512971878051758,
      "rewards/rejected": -2.8414649963378906,
      "step": 148
    },
    {
      "epoch": 0.2384,
      "grad_norm": 5.235751628875732,
      "learning_rate": 3.816e-06,
      "logits/chosen": -2.3217933177948,
      "logits/rejected": -2.3714725971221924,
      "logps/chosen": -1194.24853515625,
      "logps/rejected": -1861.245849609375,
      "loss": 0.3665,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.6689460277557373,
      "rewards/margins": 2.074821710586548,
      "rewards/rejected": -2.743767738342285,
      "step": 149
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.1953325271606445,
      "learning_rate": 3.8080000000000006e-06,
      "logits/chosen": -2.2086591720581055,
      "logits/rejected": -2.316559314727783,
      "logps/chosen": -1588.52392578125,
      "logps/rejected": -2365.3974609375,
      "loss": 0.1358,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.13734327256679535,
      "rewards/margins": 3.066324472427368,
      "rewards/rejected": -3.203667640686035,
      "step": 150
    },
    {
      "epoch": 0.2416,
      "grad_norm": 2.225823402404785,
      "learning_rate": 3.8000000000000005e-06,
      "logits/chosen": -2.4408979415893555,
      "logits/rejected": -2.3986165523529053,
      "logps/chosen": -770.1968994140625,
      "logps/rejected": -1311.0177001953125,
      "loss": 0.2846,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.3598247468471527,
      "rewards/margins": 1.9278658628463745,
      "rewards/rejected": -2.2876906394958496,
      "step": 151
    },
    {
      "epoch": 0.2432,
      "grad_norm": 2.1186068058013916,
      "learning_rate": 3.7920000000000003e-06,
      "logits/chosen": -2.2326810359954834,
      "logits/rejected": -2.4166340827941895,
      "logps/chosen": -981.3995361328125,
      "logps/rejected": -1484.55859375,
      "loss": 0.2309,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.48539721965789795,
      "rewards/margins": 2.0392236709594727,
      "rewards/rejected": -2.524620771408081,
      "step": 152
    },
    {
      "epoch": 0.2448,
      "grad_norm": 2.901292085647583,
      "learning_rate": 3.7840000000000005e-06,
      "logits/chosen": -2.2971115112304688,
      "logits/rejected": -2.341630458831787,
      "logps/chosen": -1537.4832763671875,
      "logps/rejected": -1900.0205078125,
      "loss": 0.1807,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.31244587898254395,
      "rewards/margins": 2.435847520828247,
      "rewards/rejected": -2.748293399810791,
      "step": 153
    },
    {
      "epoch": 0.2464,
      "grad_norm": 2.2643656730651855,
      "learning_rate": 3.7760000000000004e-06,
      "logits/chosen": -2.31129789352417,
      "logits/rejected": -2.39145565032959,
      "logps/chosen": -816.6561279296875,
      "logps/rejected": -2015.1668701171875,
      "loss": 0.1696,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.4412989020347595,
      "rewards/margins": 3.2064208984375,
      "rewards/rejected": -3.647719621658325,
      "step": 154
    },
    {
      "epoch": 0.248,
      "grad_norm": 5.6966962814331055,
      "learning_rate": 3.7680000000000006e-06,
      "logits/chosen": -2.3389012813568115,
      "logits/rejected": -2.37499737739563,
      "logps/chosen": -695.6979370117188,
      "logps/rejected": -1319.918212890625,
      "loss": 0.3537,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.388245552778244,
      "rewards/margins": 1.7443039417266846,
      "rewards/rejected": -2.132549524307251,
      "step": 155
    },
    {
      "epoch": 0.2496,
      "grad_norm": 1.7958711385726929,
      "learning_rate": 3.7600000000000004e-06,
      "logits/chosen": -2.283714771270752,
      "logits/rejected": -2.3962247371673584,
      "logps/chosen": -545.1898193359375,
      "logps/rejected": -1428.1845703125,
      "loss": 0.2039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.27766311168670654,
      "rewards/margins": 2.2130889892578125,
      "rewards/rejected": -2.4907517433166504,
      "step": 156
    },
    {
      "epoch": 0.2512,
      "grad_norm": 1.8370215892791748,
      "learning_rate": 3.7520000000000002e-06,
      "logits/chosen": -2.3790457248687744,
      "logits/rejected": -2.481402635574341,
      "logps/chosen": -1007.8465576171875,
      "logps/rejected": -1430.0509033203125,
      "loss": 0.174,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.37609854340553284,
      "rewards/margins": 2.8198676109313965,
      "rewards/rejected": -3.1959664821624756,
      "step": 157
    },
    {
      "epoch": 0.2528,
      "grad_norm": 2.5481293201446533,
      "learning_rate": 3.7440000000000005e-06,
      "logits/chosen": -2.442845582962036,
      "logits/rejected": -2.4602744579315186,
      "logps/chosen": -1036.7803955078125,
      "logps/rejected": -1693.9356689453125,
      "loss": 0.1743,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4936876595020294,
      "rewards/margins": 2.520641803741455,
      "rewards/rejected": -3.0143299102783203,
      "step": 158
    },
    {
      "epoch": 0.2544,
      "grad_norm": 2.3251798152923584,
      "learning_rate": 3.7360000000000003e-06,
      "logits/chosen": -2.3971097469329834,
      "logits/rejected": -2.407517910003662,
      "logps/chosen": -1139.618896484375,
      "logps/rejected": -1721.0052490234375,
      "loss": 0.2311,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.26937219500541687,
      "rewards/margins": 2.166779041290283,
      "rewards/rejected": -2.4361510276794434,
      "step": 159
    },
    {
      "epoch": 0.256,
      "grad_norm": 1.7349932193756104,
      "learning_rate": 3.7280000000000006e-06,
      "logits/chosen": -2.100235939025879,
      "logits/rejected": -2.2499773502349854,
      "logps/chosen": -1270.231201171875,
      "logps/rejected": -2065.24658203125,
      "loss": 0.1779,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42029839754104614,
      "rewards/margins": 2.773397922515869,
      "rewards/rejected": -2.3530993461608887,
      "step": 160
    },
    {
      "epoch": 0.2576,
      "grad_norm": 2.5434937477111816,
      "learning_rate": 3.7200000000000004e-06,
      "logits/chosen": -2.437279462814331,
      "logits/rejected": -2.485292434692383,
      "logps/chosen": -1223.253662109375,
      "logps/rejected": -1417.849853515625,
      "loss": 0.2803,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4003908634185791,
      "rewards/margins": 1.537566065788269,
      "rewards/rejected": -1.9379568099975586,
      "step": 161
    },
    {
      "epoch": 0.2592,
      "grad_norm": 2.4364917278289795,
      "learning_rate": 3.712e-06,
      "logits/chosen": -2.4374377727508545,
      "logits/rejected": -2.3169736862182617,
      "logps/chosen": -986.2681274414062,
      "logps/rejected": -1873.625732421875,
      "loss": 0.2074,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.42750999331474304,
      "rewards/margins": 2.0830955505371094,
      "rewards/rejected": -2.510605573654175,
      "step": 162
    },
    {
      "epoch": 0.2608,
      "grad_norm": 5.411618709564209,
      "learning_rate": 3.7040000000000005e-06,
      "logits/chosen": -2.388655662536621,
      "logits/rejected": -2.4405691623687744,
      "logps/chosen": -702.893310546875,
      "logps/rejected": -1612.7685546875,
      "loss": 0.2993,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.29508176445961,
      "rewards/margins": 2.01835560798645,
      "rewards/rejected": -2.3134372234344482,
      "step": 163
    },
    {
      "epoch": 0.2624,
      "grad_norm": 1.7554477453231812,
      "learning_rate": 3.6960000000000003e-06,
      "logits/chosen": -2.3530797958374023,
      "logits/rejected": -2.4237780570983887,
      "logps/chosen": -983.9425048828125,
      "logps/rejected": -1480.0430908203125,
      "loss": 0.1938,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.35396111011505127,
      "rewards/margins": 2.9926342964172363,
      "rewards/rejected": -3.346595287322998,
      "step": 164
    },
    {
      "epoch": 0.264,
      "grad_norm": 2.3769662380218506,
      "learning_rate": 3.6880000000000005e-06,
      "logits/chosen": -2.3254776000976562,
      "logits/rejected": -2.459878444671631,
      "logps/chosen": -794.9078369140625,
      "logps/rejected": -1473.1329345703125,
      "loss": 0.2239,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5464792251586914,
      "rewards/margins": 1.9995028972625732,
      "rewards/rejected": -2.5459821224212646,
      "step": 165
    },
    {
      "epoch": 0.2656,
      "grad_norm": 2.3531956672668457,
      "learning_rate": 3.6800000000000003e-06,
      "logits/chosen": -2.405430316925049,
      "logits/rejected": -2.3857674598693848,
      "logps/chosen": -1573.0726318359375,
      "logps/rejected": -2273.7216796875,
      "loss": 0.1258,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5620136857032776,
      "rewards/margins": 3.2109599113464355,
      "rewards/rejected": -3.7729732990264893,
      "step": 166
    },
    {
      "epoch": 0.2672,
      "grad_norm": 2.4528303146362305,
      "learning_rate": 3.6720000000000006e-06,
      "logits/chosen": -2.3121891021728516,
      "logits/rejected": -2.4042413234710693,
      "logps/chosen": -1148.7208251953125,
      "logps/rejected": -1531.4013671875,
      "loss": 0.2869,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.6466580629348755,
      "rewards/margins": 1.969074010848999,
      "rewards/rejected": -2.615732192993164,
      "step": 167
    },
    {
      "epoch": 0.2688,
      "grad_norm": 1.2126965522766113,
      "learning_rate": 3.6640000000000004e-06,
      "logits/chosen": -2.330474615097046,
      "logits/rejected": -2.3676578998565674,
      "logps/chosen": -1072.44140625,
      "logps/rejected": -1741.8687744140625,
      "loss": 0.1299,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5910494923591614,
      "rewards/margins": 2.817208766937256,
      "rewards/rejected": -3.4082581996917725,
      "step": 168
    },
    {
      "epoch": 0.2704,
      "grad_norm": 1.8774281740188599,
      "learning_rate": 3.6560000000000002e-06,
      "logits/chosen": -2.1512985229492188,
      "logits/rejected": -2.2904136180877686,
      "logps/chosen": -647.2568359375,
      "logps/rejected": -1376.341064453125,
      "loss": 0.1621,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2316291630268097,
      "rewards/margins": 2.501668691635132,
      "rewards/rejected": -2.7332980632781982,
      "step": 169
    },
    {
      "epoch": 0.272,
      "grad_norm": 2.5106778144836426,
      "learning_rate": 3.6480000000000005e-06,
      "logits/chosen": -2.2560336589813232,
      "logits/rejected": -2.2848329544067383,
      "logps/chosen": -1407.9261474609375,
      "logps/rejected": -2304.40966796875,
      "loss": 0.2967,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.5883364677429199,
      "rewards/margins": 2.570617198944092,
      "rewards/rejected": -3.1589536666870117,
      "step": 170
    },
    {
      "epoch": 0.2736,
      "grad_norm": 15.777143478393555,
      "learning_rate": 3.6400000000000003e-06,
      "logits/chosen": -2.31667160987854,
      "logits/rejected": -2.2964959144592285,
      "logps/chosen": -891.256591796875,
      "logps/rejected": -1913.869140625,
      "loss": 0.2851,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.45486700534820557,
      "rewards/margins": 2.4242074489593506,
      "rewards/rejected": -2.8790745735168457,
      "step": 171
    },
    {
      "epoch": 0.2752,
      "grad_norm": 1.2202856540679932,
      "learning_rate": 3.6320000000000005e-06,
      "logits/chosen": -2.323598623275757,
      "logits/rejected": -2.2983949184417725,
      "logps/chosen": -896.8298950195312,
      "logps/rejected": -2022.98876953125,
      "loss": 0.1401,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5342899560928345,
      "rewards/margins": 3.34799861907959,
      "rewards/rejected": -3.8822882175445557,
      "step": 172
    },
    {
      "epoch": 0.2768,
      "grad_norm": 3.2610714435577393,
      "learning_rate": 3.6240000000000004e-06,
      "logits/chosen": -2.2869200706481934,
      "logits/rejected": -2.236400604248047,
      "logps/chosen": -1127.1907958984375,
      "logps/rejected": -1550.057861328125,
      "loss": 0.3128,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.4409853219985962,
      "rewards/margins": 2.834916591644287,
      "rewards/rejected": -3.2759017944335938,
      "step": 173
    },
    {
      "epoch": 0.2784,
      "grad_norm": 1.6443626880645752,
      "learning_rate": 3.616e-06,
      "logits/chosen": -2.4180731773376465,
      "logits/rejected": -2.446880340576172,
      "logps/chosen": -991.0286254882812,
      "logps/rejected": -1389.666259765625,
      "loss": 0.1712,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.35257017612457275,
      "rewards/margins": 2.4060816764831543,
      "rewards/rejected": -2.7586517333984375,
      "step": 174
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.234976053237915,
      "learning_rate": 3.6080000000000004e-06,
      "logits/chosen": -2.3357694149017334,
      "logits/rejected": -2.2921698093414307,
      "logps/chosen": -1137.77734375,
      "logps/rejected": -2157.838134765625,
      "loss": 0.2006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5414891242980957,
      "rewards/margins": 2.7176294326782227,
      "rewards/rejected": -3.2591187953948975,
      "step": 175
    },
    {
      "epoch": 0.2816,
      "grad_norm": 2.4141323566436768,
      "learning_rate": 3.6000000000000003e-06,
      "logits/chosen": -2.435011386871338,
      "logits/rejected": -2.3603129386901855,
      "logps/chosen": -854.4802856445312,
      "logps/rejected": -1597.15673828125,
      "loss": 0.1642,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6699696779251099,
      "rewards/margins": 3.8395330905914307,
      "rewards/rejected": -4.509502410888672,
      "step": 176
    },
    {
      "epoch": 0.2832,
      "grad_norm": 1.8527511358261108,
      "learning_rate": 3.5920000000000005e-06,
      "logits/chosen": -2.3748509883880615,
      "logits/rejected": -2.392765760421753,
      "logps/chosen": -714.018798828125,
      "logps/rejected": -1320.4990234375,
      "loss": 0.1634,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19486145675182343,
      "rewards/margins": 2.418196439743042,
      "rewards/rejected": -2.613058090209961,
      "step": 177
    },
    {
      "epoch": 0.2848,
      "grad_norm": 1.8339602947235107,
      "learning_rate": 3.5840000000000003e-06,
      "logits/chosen": -2.265319585800171,
      "logits/rejected": -2.355309247970581,
      "logps/chosen": -1932.6475830078125,
      "logps/rejected": -1647.3089599609375,
      "loss": 0.1658,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.4408212900161743,
      "rewards/margins": 3.5309135913848877,
      "rewards/rejected": -3.090092182159424,
      "step": 178
    },
    {
      "epoch": 0.2864,
      "grad_norm": 1.7930437326431274,
      "learning_rate": 3.576e-06,
      "logits/chosen": -2.255856513977051,
      "logits/rejected": -2.3736183643341064,
      "logps/chosen": -703.4029541015625,
      "logps/rejected": -1245.45751953125,
      "loss": 0.2005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.23038360476493835,
      "rewards/margins": 2.339446544647217,
      "rewards/rejected": -2.5698299407958984,
      "step": 179
    },
    {
      "epoch": 0.288,
      "grad_norm": 2.327746868133545,
      "learning_rate": 3.5680000000000004e-06,
      "logits/chosen": -2.321254014968872,
      "logits/rejected": -2.3379898071289062,
      "logps/chosen": -775.1973876953125,
      "logps/rejected": -1314.758544921875,
      "loss": 0.2267,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.45585110783576965,
      "rewards/margins": 2.09039044380188,
      "rewards/rejected": -2.546241521835327,
      "step": 180
    },
    {
      "epoch": 0.2896,
      "grad_norm": 1.8550668954849243,
      "learning_rate": 3.5600000000000002e-06,
      "logits/chosen": -2.3999218940734863,
      "logits/rejected": -2.4058024883270264,
      "logps/chosen": -1119.43896484375,
      "logps/rejected": -1696.9078369140625,
      "loss": 0.151,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5211852788925171,
      "rewards/margins": 2.6747305393218994,
      "rewards/rejected": -3.195915699005127,
      "step": 181
    },
    {
      "epoch": 0.2912,
      "grad_norm": 2.1074023246765137,
      "learning_rate": 3.5520000000000005e-06,
      "logits/chosen": -2.3173859119415283,
      "logits/rejected": -2.309441328048706,
      "logps/chosen": -1166.6993408203125,
      "logps/rejected": -1855.2772216796875,
      "loss": 0.1392,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6128904223442078,
      "rewards/margins": 4.454507350921631,
      "rewards/rejected": -5.0673980712890625,
      "step": 182
    },
    {
      "epoch": 0.2928,
      "grad_norm": 2.6120569705963135,
      "learning_rate": 3.5440000000000003e-06,
      "logits/chosen": -2.4201416969299316,
      "logits/rejected": -2.416632652282715,
      "logps/chosen": -882.1990966796875,
      "logps/rejected": -1524.1981201171875,
      "loss": 0.1951,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.5338276624679565,
      "rewards/margins": 2.7429747581481934,
      "rewards/rejected": -3.2768025398254395,
      "step": 183
    },
    {
      "epoch": 0.2944,
      "grad_norm": 4.394293785095215,
      "learning_rate": 3.5360000000000005e-06,
      "logits/chosen": -2.1321804523468018,
      "logits/rejected": -2.148343324661255,
      "logps/chosen": -1116.2672119140625,
      "logps/rejected": -2186.41064453125,
      "loss": 0.2697,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.4440643787384033,
      "rewards/margins": 2.50490140914917,
      "rewards/rejected": -2.948965549468994,
      "step": 184
    },
    {
      "epoch": 0.296,
      "grad_norm": 3.77988862991333,
      "learning_rate": 3.5280000000000004e-06,
      "logits/chosen": -2.2071712017059326,
      "logits/rejected": -2.250199317932129,
      "logps/chosen": -1352.15380859375,
      "logps/rejected": -1748.323974609375,
      "loss": 0.1996,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.5272799134254456,
      "rewards/margins": 3.0357818603515625,
      "rewards/rejected": -3.5630617141723633,
      "step": 185
    },
    {
      "epoch": 0.2976,
      "grad_norm": 3.1289355754852295,
      "learning_rate": 3.52e-06,
      "logits/chosen": -2.2949588298797607,
      "logits/rejected": -2.2754909992218018,
      "logps/chosen": -1303.509033203125,
      "logps/rejected": -2237.87451171875,
      "loss": 0.1778,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0635740756988525,
      "rewards/margins": 2.172611713409424,
      "rewards/rejected": -3.2361857891082764,
      "step": 186
    },
    {
      "epoch": 0.2992,
      "grad_norm": 4.410188674926758,
      "learning_rate": 3.5120000000000004e-06,
      "logits/chosen": -2.362032413482666,
      "logits/rejected": -2.43119478225708,
      "logps/chosen": -1248.1905517578125,
      "logps/rejected": -1692.3599853515625,
      "loss": 0.2694,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.032613754272461,
      "rewards/margins": 2.3153738975524902,
      "rewards/rejected": -3.347987651824951,
      "step": 187
    },
    {
      "epoch": 0.3008,
      "grad_norm": 2.258246898651123,
      "learning_rate": 3.5040000000000002e-06,
      "logits/chosen": -2.2911324501037598,
      "logits/rejected": -2.442878007888794,
      "logps/chosen": -720.9606323242188,
      "logps/rejected": -1374.5987548828125,
      "loss": 0.2263,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.522857666015625,
      "rewards/margins": 1.9479507207870483,
      "rewards/rejected": -2.470808267593384,
      "step": 188
    },
    {
      "epoch": 0.3024,
      "grad_norm": 2.2726762294769287,
      "learning_rate": 3.4960000000000005e-06,
      "logits/chosen": -2.3729097843170166,
      "logits/rejected": -2.3510634899139404,
      "logps/chosen": -1042.6658935546875,
      "logps/rejected": -1773.7489013671875,
      "loss": 0.1525,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.39280635118484497,
      "rewards/margins": 3.7140111923217773,
      "rewards/rejected": -4.106817245483398,
      "step": 189
    },
    {
      "epoch": 0.304,
      "grad_norm": 2.3698344230651855,
      "learning_rate": 3.4880000000000003e-06,
      "logits/chosen": -2.188194990158081,
      "logits/rejected": -2.2725374698638916,
      "logps/chosen": -942.1041259765625,
      "logps/rejected": -1585.26611328125,
      "loss": 0.1733,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5274035930633545,
      "rewards/margins": 2.7674686908721924,
      "rewards/rejected": -3.294872283935547,
      "step": 190
    },
    {
      "epoch": 0.3056,
      "grad_norm": 2.1285650730133057,
      "learning_rate": 3.48e-06,
      "logits/chosen": -2.3986411094665527,
      "logits/rejected": -2.4213950634002686,
      "logps/chosen": -1413.6131591796875,
      "logps/rejected": -1834.987548828125,
      "loss": 0.168,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.679044783115387,
      "rewards/margins": 2.2526471614837646,
      "rewards/rejected": -2.931691884994507,
      "step": 191
    },
    {
      "epoch": 0.3072,
      "grad_norm": 3.715106964111328,
      "learning_rate": 3.4720000000000004e-06,
      "logits/chosen": -2.267573356628418,
      "logits/rejected": -2.3407609462738037,
      "logps/chosen": -1132.596435546875,
      "logps/rejected": -1615.272705078125,
      "loss": 0.3439,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.6952680349349976,
      "rewards/margins": 2.5385842323303223,
      "rewards/rejected": -3.233851909637451,
      "step": 192
    },
    {
      "epoch": 0.3088,
      "grad_norm": 1.6077755689620972,
      "learning_rate": 3.464e-06,
      "logits/chosen": -2.3719513416290283,
      "logits/rejected": -2.417867660522461,
      "logps/chosen": -1172.532470703125,
      "logps/rejected": -1571.7464599609375,
      "loss": 0.1173,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.750707745552063,
      "rewards/margins": 3.2077839374542236,
      "rewards/rejected": -3.958491802215576,
      "step": 193
    },
    {
      "epoch": 0.3104,
      "grad_norm": 2.760540723800659,
      "learning_rate": 3.4560000000000005e-06,
      "logits/chosen": -2.224351644515991,
      "logits/rejected": -2.346921682357788,
      "logps/chosen": -805.364013671875,
      "logps/rejected": -1678.970947265625,
      "loss": 0.1944,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6713283061981201,
      "rewards/margins": 3.4182825088500977,
      "rewards/rejected": -4.089611053466797,
      "step": 194
    },
    {
      "epoch": 0.312,
      "grad_norm": 4.159808158874512,
      "learning_rate": 3.4480000000000003e-06,
      "logits/chosen": -2.33426570892334,
      "logits/rejected": -2.420269012451172,
      "logps/chosen": -1133.2972412109375,
      "logps/rejected": -1415.9013671875,
      "loss": 0.2911,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.6552489995956421,
      "rewards/margins": 2.071715831756592,
      "rewards/rejected": -2.7269649505615234,
      "step": 195
    },
    {
      "epoch": 0.3136,
      "grad_norm": 1.311795949935913,
      "learning_rate": 3.44e-06,
      "logits/chosen": -2.1748080253601074,
      "logits/rejected": -2.227570056915283,
      "logps/chosen": -1054.73291015625,
      "logps/rejected": -1792.704345703125,
      "loss": 0.0995,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2765786647796631,
      "rewards/margins": 4.1288580894470215,
      "rewards/rejected": -4.4054365158081055,
      "step": 196
    },
    {
      "epoch": 0.3152,
      "grad_norm": 1.3443551063537598,
      "learning_rate": 3.4320000000000003e-06,
      "logits/chosen": -2.3623170852661133,
      "logits/rejected": -2.294614315032959,
      "logps/chosen": -1004.7554321289062,
      "logps/rejected": -1667.4105224609375,
      "loss": 0.1033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6549750566482544,
      "rewards/margins": 3.397099018096924,
      "rewards/rejected": -4.052074432373047,
      "step": 197
    },
    {
      "epoch": 0.3168,
      "grad_norm": 1.2824479341506958,
      "learning_rate": 3.424e-06,
      "logits/chosen": -2.368997812271118,
      "logits/rejected": -2.4182991981506348,
      "logps/chosen": -936.3828125,
      "logps/rejected": -1784.031494140625,
      "loss": 0.1354,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5890302062034607,
      "rewards/margins": 3.7321271896362305,
      "rewards/rejected": -4.321157455444336,
      "step": 198
    },
    {
      "epoch": 0.3184,
      "grad_norm": 1.2149852514266968,
      "learning_rate": 3.4160000000000004e-06,
      "logits/chosen": -2.36103892326355,
      "logits/rejected": -2.389537811279297,
      "logps/chosen": -941.8350830078125,
      "logps/rejected": -1589.35546875,
      "loss": 0.0983,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5680639147758484,
      "rewards/margins": 3.2664785385131836,
      "rewards/rejected": -3.834542751312256,
      "step": 199
    },
    {
      "epoch": 0.32,
      "grad_norm": 6.35372257232666,
      "learning_rate": 3.4080000000000002e-06,
      "logits/chosen": -2.3456785678863525,
      "logits/rejected": -2.39849591255188,
      "logps/chosen": -1334.4619140625,
      "logps/rejected": -1133.9503173828125,
      "loss": 0.5131,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.6135604381561279,
      "rewards/margins": 1.5064865350723267,
      "rewards/rejected": -2.120047092437744,
      "step": 200
    },
    {
      "epoch": 0.3216,
      "grad_norm": 1.7573002576828003,
      "learning_rate": 3.4000000000000005e-06,
      "logits/chosen": -2.2823660373687744,
      "logits/rejected": -2.3437626361846924,
      "logps/chosen": -1193.978515625,
      "logps/rejected": -1399.828369140625,
      "loss": 0.1895,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9937269687652588,
      "rewards/margins": 2.6179404258728027,
      "rewards/rejected": -3.6116676330566406,
      "step": 201
    },
    {
      "epoch": 0.3232,
      "grad_norm": 3.440423011779785,
      "learning_rate": 3.3920000000000003e-06,
      "logits/chosen": -2.2848057746887207,
      "logits/rejected": -2.4133145809173584,
      "logps/chosen": -1389.04931640625,
      "logps/rejected": -2012.363037109375,
      "loss": 0.3103,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.8212368488311768,
      "rewards/margins": 3.203169822692871,
      "rewards/rejected": -4.024407386779785,
      "step": 202
    },
    {
      "epoch": 0.3248,
      "grad_norm": 2.2689645290374756,
      "learning_rate": 3.384e-06,
      "logits/chosen": -2.2567875385284424,
      "logits/rejected": -2.3171677589416504,
      "logps/chosen": -1050.67822265625,
      "logps/rejected": -1533.4454345703125,
      "loss": 0.1257,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7725587487220764,
      "rewards/margins": 2.6475396156311035,
      "rewards/rejected": -3.4200985431671143,
      "step": 203
    },
    {
      "epoch": 0.3264,
      "grad_norm": 1.1519876718521118,
      "learning_rate": 3.3760000000000004e-06,
      "logits/chosen": -2.364748954772949,
      "logits/rejected": -2.3288161754608154,
      "logps/chosen": -720.4313354492188,
      "logps/rejected": -1620.478759765625,
      "loss": 0.1009,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6808611750602722,
      "rewards/margins": 3.1071455478668213,
      "rewards/rejected": -3.7880070209503174,
      "step": 204
    },
    {
      "epoch": 0.328,
      "grad_norm": 2.0061278343200684,
      "learning_rate": 3.368e-06,
      "logits/chosen": -2.2625811100006104,
      "logits/rejected": -2.3867549896240234,
      "logps/chosen": -1006.4478149414062,
      "logps/rejected": -1778.1307373046875,
      "loss": 0.1366,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7272860407829285,
      "rewards/margins": 3.2846693992614746,
      "rewards/rejected": -4.011955738067627,
      "step": 205
    },
    {
      "epoch": 0.3296,
      "grad_norm": 0.8481177091598511,
      "learning_rate": 3.3600000000000004e-06,
      "logits/chosen": -2.040559768676758,
      "logits/rejected": -2.406493663787842,
      "logps/chosen": -895.4422607421875,
      "logps/rejected": -1994.37353515625,
      "loss": 0.0578,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19972507655620575,
      "rewards/margins": 3.7973103523254395,
      "rewards/rejected": -3.997035264968872,
      "step": 206
    },
    {
      "epoch": 0.3312,
      "grad_norm": 1.995493769645691,
      "learning_rate": 3.3520000000000003e-06,
      "logits/chosen": -2.3788764476776123,
      "logits/rejected": -2.4058125019073486,
      "logps/chosen": -1302.8416748046875,
      "logps/rejected": -2136.404296875,
      "loss": 0.1314,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9796342849731445,
      "rewards/margins": 3.9753994941711426,
      "rewards/rejected": -4.955034255981445,
      "step": 207
    },
    {
      "epoch": 0.3328,
      "grad_norm": 1.2260183095932007,
      "learning_rate": 3.344e-06,
      "logits/chosen": -2.2508420944213867,
      "logits/rejected": -2.268211841583252,
      "logps/chosen": -1348.0947265625,
      "logps/rejected": -2098.818603515625,
      "loss": 0.1087,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10623656213283539,
      "rewards/margins": 4.804724216461182,
      "rewards/rejected": -4.910960674285889,
      "step": 208
    },
    {
      "epoch": 0.3344,
      "grad_norm": 5.727268218994141,
      "learning_rate": 3.3360000000000003e-06,
      "logits/chosen": -2.172034502029419,
      "logits/rejected": -2.237546920776367,
      "logps/chosen": -1506.883056640625,
      "logps/rejected": -1995.1256103515625,
      "loss": 0.2837,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.7363646626472473,
      "rewards/margins": 3.651413917541504,
      "rewards/rejected": -4.3877787590026855,
      "step": 209
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.7645533084869385,
      "learning_rate": 3.328e-06,
      "logits/chosen": -2.135887384414673,
      "logits/rejected": -2.249732732772827,
      "logps/chosen": -1186.677734375,
      "logps/rejected": -1982.6907958984375,
      "loss": 0.0627,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5951682329177856,
      "rewards/margins": 5.338804244995117,
      "rewards/rejected": -5.933972358703613,
      "step": 210
    },
    {
      "epoch": 0.3376,
      "grad_norm": 1.5121663808822632,
      "learning_rate": 3.3200000000000004e-06,
      "logits/chosen": -2.3508520126342773,
      "logits/rejected": -2.346285343170166,
      "logps/chosen": -1128.064453125,
      "logps/rejected": -2208.2607421875,
      "loss": 0.125,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6064597964286804,
      "rewards/margins": 3.649259328842163,
      "rewards/rejected": -4.255719184875488,
      "step": 211
    },
    {
      "epoch": 0.3392,
      "grad_norm": 2.1407434940338135,
      "learning_rate": 3.3120000000000002e-06,
      "logits/chosen": -2.2721855640411377,
      "logits/rejected": -2.238359212875366,
      "logps/chosen": -867.0086669921875,
      "logps/rejected": -1925.7283935546875,
      "loss": 0.1217,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6461419463157654,
      "rewards/margins": 3.5428953170776367,
      "rewards/rejected": -4.189037799835205,
      "step": 212
    },
    {
      "epoch": 0.3408,
      "grad_norm": 3.0984694957733154,
      "learning_rate": 3.3040000000000005e-06,
      "logits/chosen": -2.317171335220337,
      "logits/rejected": -2.359715700149536,
      "logps/chosen": -881.4340209960938,
      "logps/rejected": -1522.5772705078125,
      "loss": 0.2718,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.358696848154068,
      "rewards/margins": 3.224797487258911,
      "rewards/rejected": -3.583494186401367,
      "step": 213
    },
    {
      "epoch": 0.3424,
      "grad_norm": 3.7444353103637695,
      "learning_rate": 3.2960000000000003e-06,
      "logits/chosen": -2.191789388656616,
      "logits/rejected": -2.358574390411377,
      "logps/chosen": -1093.6461181640625,
      "logps/rejected": -2132.473876953125,
      "loss": 0.152,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6030736565589905,
      "rewards/margins": 4.7787299156188965,
      "rewards/rejected": -5.381802558898926,
      "step": 214
    },
    {
      "epoch": 0.344,
      "grad_norm": 3.434607982635498,
      "learning_rate": 3.288e-06,
      "logits/chosen": -2.397155523300171,
      "logits/rejected": -2.405914545059204,
      "logps/chosen": -1177.2384033203125,
      "logps/rejected": -1494.90966796875,
      "loss": 0.2311,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.0021045207977295,
      "rewards/margins": 2.813936948776245,
      "rewards/rejected": -3.816041946411133,
      "step": 215
    },
    {
      "epoch": 0.3456,
      "grad_norm": 1.852060079574585,
      "learning_rate": 3.2800000000000004e-06,
      "logits/chosen": -2.257767677307129,
      "logits/rejected": -2.3370513916015625,
      "logps/chosen": -900.9909057617188,
      "logps/rejected": -1649.96923828125,
      "loss": 0.1492,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7938998937606812,
      "rewards/margins": 3.1379809379577637,
      "rewards/rejected": -3.9318807125091553,
      "step": 216
    },
    {
      "epoch": 0.3472,
      "grad_norm": 1.049085021018982,
      "learning_rate": 3.272e-06,
      "logits/chosen": -2.370121479034424,
      "logits/rejected": -2.344517469406128,
      "logps/chosen": -972.7061157226562,
      "logps/rejected": -1333.982421875,
      "loss": 0.1128,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.955317497253418,
      "rewards/margins": 3.1700236797332764,
      "rewards/rejected": -4.125341415405273,
      "step": 217
    },
    {
      "epoch": 0.3488,
      "grad_norm": 6.696905136108398,
      "learning_rate": 3.2640000000000004e-06,
      "logits/chosen": -2.271049976348877,
      "logits/rejected": -2.430845260620117,
      "logps/chosen": -1017.3236083984375,
      "logps/rejected": -1709.254150390625,
      "loss": 0.3697,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.8384207487106323,
      "rewards/margins": 3.178318500518799,
      "rewards/rejected": -4.0167388916015625,
      "step": 218
    },
    {
      "epoch": 0.3504,
      "grad_norm": 1.855015754699707,
      "learning_rate": 3.2560000000000003e-06,
      "logits/chosen": -2.2989988327026367,
      "logits/rejected": -2.3580875396728516,
      "logps/chosen": -1513.4212646484375,
      "logps/rejected": -1612.697998046875,
      "loss": 0.1569,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.1326935291290283,
      "rewards/margins": 3.5701937675476074,
      "rewards/rejected": -4.702887058258057,
      "step": 219
    },
    {
      "epoch": 0.352,
      "grad_norm": 2.0186121463775635,
      "learning_rate": 3.248e-06,
      "logits/chosen": -2.295718193054199,
      "logits/rejected": -2.3307907581329346,
      "logps/chosen": -829.0020141601562,
      "logps/rejected": -1288.4154052734375,
      "loss": 0.182,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0186035633087158,
      "rewards/margins": 2.8217811584472656,
      "rewards/rejected": -3.8403847217559814,
      "step": 220
    },
    {
      "epoch": 0.3536,
      "grad_norm": 5.899198532104492,
      "learning_rate": 3.2400000000000003e-06,
      "logits/chosen": -2.3575828075408936,
      "logits/rejected": -2.322275400161743,
      "logps/chosen": -804.1525268554688,
      "logps/rejected": -1441.16845703125,
      "loss": 0.4598,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.9783703684806824,
      "rewards/margins": 2.469216823577881,
      "rewards/rejected": -3.447587251663208,
      "step": 221
    },
    {
      "epoch": 0.3552,
      "grad_norm": 2.4099831581115723,
      "learning_rate": 3.232e-06,
      "logits/chosen": -2.3399500846862793,
      "logits/rejected": -2.342888355255127,
      "logps/chosen": -578.1664428710938,
      "logps/rejected": -1013.5521240234375,
      "loss": 0.2191,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.537879467010498,
      "rewards/margins": 2.4056034088134766,
      "rewards/rejected": -2.9434828758239746,
      "step": 222
    },
    {
      "epoch": 0.3568,
      "grad_norm": 0.9246054291725159,
      "learning_rate": 3.2240000000000004e-06,
      "logits/chosen": -2.2567028999328613,
      "logits/rejected": -2.332524299621582,
      "logps/chosen": -820.8355102539062,
      "logps/rejected": -1593.5042724609375,
      "loss": 0.0711,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7087075114250183,
      "rewards/margins": 4.405350208282471,
      "rewards/rejected": -5.114057540893555,
      "step": 223
    },
    {
      "epoch": 0.3584,
      "grad_norm": 2.543654203414917,
      "learning_rate": 3.216e-06,
      "logits/chosen": -2.3330321311950684,
      "logits/rejected": -2.3732850551605225,
      "logps/chosen": -1023.7777709960938,
      "logps/rejected": -1458.517333984375,
      "loss": 0.2261,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9119924306869507,
      "rewards/margins": 2.97090744972229,
      "rewards/rejected": -3.8829002380371094,
      "step": 224
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.942504405975342,
      "learning_rate": 3.208e-06,
      "logits/chosen": -2.429553508758545,
      "logits/rejected": -2.3419265747070312,
      "logps/chosen": -1440.6165771484375,
      "logps/rejected": -2019.2147216796875,
      "loss": 0.2459,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.104016661643982,
      "rewards/margins": 3.2161056995391846,
      "rewards/rejected": -4.320122241973877,
      "step": 225
    },
    {
      "epoch": 0.3616,
      "grad_norm": 4.043807506561279,
      "learning_rate": 3.2000000000000003e-06,
      "logits/chosen": -2.40923810005188,
      "logits/rejected": -2.426762580871582,
      "logps/chosen": -1029.3392333984375,
      "logps/rejected": -1777.9501953125,
      "loss": 0.1837,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.0116918087005615,
      "rewards/margins": 3.0551400184631348,
      "rewards/rejected": -4.066831588745117,
      "step": 226
    },
    {
      "epoch": 0.3632,
      "grad_norm": 2.4177732467651367,
      "learning_rate": 3.192e-06,
      "logits/chosen": -2.326904773712158,
      "logits/rejected": -2.247073173522949,
      "logps/chosen": -903.485107421875,
      "logps/rejected": -1453.324951171875,
      "loss": 0.1349,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6976357698440552,
      "rewards/margins": 3.7255306243896484,
      "rewards/rejected": -4.423166275024414,
      "step": 227
    },
    {
      "epoch": 0.3648,
      "grad_norm": 3.8945353031158447,
      "learning_rate": 3.1840000000000003e-06,
      "logits/chosen": -2.273475170135498,
      "logits/rejected": -2.3119056224823,
      "logps/chosen": -1329.8302001953125,
      "logps/rejected": -1461.8028564453125,
      "loss": 0.4055,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.9408591985702515,
      "rewards/margins": 1.7787578105926514,
      "rewards/rejected": -2.7196171283721924,
      "step": 228
    },
    {
      "epoch": 0.3664,
      "grad_norm": 1.650787591934204,
      "learning_rate": 3.176e-06,
      "logits/chosen": -2.3840761184692383,
      "logits/rejected": -2.399319887161255,
      "logps/chosen": -997.17822265625,
      "logps/rejected": -1832.8375244140625,
      "loss": 0.1295,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5570638179779053,
      "rewards/margins": 3.960299253463745,
      "rewards/rejected": -4.51736307144165,
      "step": 229
    },
    {
      "epoch": 0.368,
      "grad_norm": 2.250349760055542,
      "learning_rate": 3.1680000000000004e-06,
      "logits/chosen": -2.330620765686035,
      "logits/rejected": -2.387728691101074,
      "logps/chosen": -1002.8512573242188,
      "logps/rejected": -1395.13134765625,
      "loss": 0.2309,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.8462499976158142,
      "rewards/margins": 2.8666293621063232,
      "rewards/rejected": -3.7128794193267822,
      "step": 230
    },
    {
      "epoch": 0.3696,
      "grad_norm": 1.838847041130066,
      "learning_rate": 3.1600000000000002e-06,
      "logits/chosen": -2.315321207046509,
      "logits/rejected": -2.3758749961853027,
      "logps/chosen": -703.65478515625,
      "logps/rejected": -1145.0240478515625,
      "loss": 0.2187,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7708826065063477,
      "rewards/margins": 2.164659261703491,
      "rewards/rejected": -2.935541868209839,
      "step": 231
    },
    {
      "epoch": 0.3712,
      "grad_norm": 2.8969919681549072,
      "learning_rate": 3.152e-06,
      "logits/chosen": -2.2100815773010254,
      "logits/rejected": -2.272317886352539,
      "logps/chosen": -1271.739990234375,
      "logps/rejected": -2089.88623046875,
      "loss": 0.0983,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6599785685539246,
      "rewards/margins": 3.729617118835449,
      "rewards/rejected": -4.3895955085754395,
      "step": 232
    },
    {
      "epoch": 0.3728,
      "grad_norm": 1.3549081087112427,
      "learning_rate": 3.1440000000000003e-06,
      "logits/chosen": -2.1963324546813965,
      "logits/rejected": -2.378168821334839,
      "logps/chosen": -786.179443359375,
      "logps/rejected": -1187.7481689453125,
      "loss": 0.2019,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6314069032669067,
      "rewards/margins": 2.638383150100708,
      "rewards/rejected": -3.269789934158325,
      "step": 233
    },
    {
      "epoch": 0.3744,
      "grad_norm": 1.5110536813735962,
      "learning_rate": 3.136e-06,
      "logits/chosen": -2.381573438644409,
      "logits/rejected": -2.391602039337158,
      "logps/chosen": -884.8841552734375,
      "logps/rejected": -1383.6103515625,
      "loss": 0.1821,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8134611248970032,
      "rewards/margins": 2.741448402404785,
      "rewards/rejected": -3.5549097061157227,
      "step": 234
    },
    {
      "epoch": 0.376,
      "grad_norm": 1.6940287351608276,
      "learning_rate": 3.1280000000000004e-06,
      "logits/chosen": -2.2391574382781982,
      "logits/rejected": -2.323418140411377,
      "logps/chosen": -1361.8360595703125,
      "logps/rejected": -1646.7510986328125,
      "loss": 0.1477,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7005588412284851,
      "rewards/margins": 3.4623193740844727,
      "rewards/rejected": -4.162878036499023,
      "step": 235
    },
    {
      "epoch": 0.3776,
      "grad_norm": 1.9273267984390259,
      "learning_rate": 3.12e-06,
      "logits/chosen": -2.2104358673095703,
      "logits/rejected": -2.2820253372192383,
      "logps/chosen": -907.3993530273438,
      "logps/rejected": -2122.64501953125,
      "loss": 0.1205,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4222421646118164,
      "rewards/margins": 3.907167434692383,
      "rewards/rejected": -4.329409599304199,
      "step": 236
    },
    {
      "epoch": 0.3792,
      "grad_norm": 2.3540027141571045,
      "learning_rate": 3.112e-06,
      "logits/chosen": -2.2834603786468506,
      "logits/rejected": -2.407205104827881,
      "logps/chosen": -665.6972045898438,
      "logps/rejected": -1429.355224609375,
      "loss": 0.167,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.7467348575592041,
      "rewards/margins": 3.290260076522827,
      "rewards/rejected": -4.036994934082031,
      "step": 237
    },
    {
      "epoch": 0.3808,
      "grad_norm": 0.9534522294998169,
      "learning_rate": 3.1040000000000003e-06,
      "logits/chosen": -2.294153928756714,
      "logits/rejected": -2.3327503204345703,
      "logps/chosen": -620.6871948242188,
      "logps/rejected": -1321.55322265625,
      "loss": 0.1259,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4303383231163025,
      "rewards/margins": 3.6941685676574707,
      "rewards/rejected": -4.12450647354126,
      "step": 238
    },
    {
      "epoch": 0.3824,
      "grad_norm": 1.5806611776351929,
      "learning_rate": 3.096e-06,
      "logits/chosen": -2.384486675262451,
      "logits/rejected": -2.4192707538604736,
      "logps/chosen": -869.9327392578125,
      "logps/rejected": -1476.149169921875,
      "loss": 0.1327,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.879945695400238,
      "rewards/margins": 3.406670093536377,
      "rewards/rejected": -4.286615371704102,
      "step": 239
    },
    {
      "epoch": 0.384,
      "grad_norm": 1.2965137958526611,
      "learning_rate": 3.0880000000000003e-06,
      "logits/chosen": -2.3014166355133057,
      "logits/rejected": -2.3106143474578857,
      "logps/chosen": -1269.20703125,
      "logps/rejected": -1968.3594970703125,
      "loss": 0.0939,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8350778818130493,
      "rewards/margins": 4.057702541351318,
      "rewards/rejected": -4.892780780792236,
      "step": 240
    },
    {
      "epoch": 0.3856,
      "grad_norm": 1.7628803253173828,
      "learning_rate": 3.08e-06,
      "logits/chosen": -2.322058916091919,
      "logits/rejected": -2.409468173980713,
      "logps/chosen": -1250.4132080078125,
      "logps/rejected": -1776.3699951171875,
      "loss": 0.1032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8245277404785156,
      "rewards/margins": 3.3595523834228516,
      "rewards/rejected": -4.184079647064209,
      "step": 241
    },
    {
      "epoch": 0.3872,
      "grad_norm": 1.2789618968963623,
      "learning_rate": 3.072e-06,
      "logits/chosen": -2.2946574687957764,
      "logits/rejected": -2.2512879371643066,
      "logps/chosen": -711.7877197265625,
      "logps/rejected": -1716.465087890625,
      "loss": 0.1242,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6462641358375549,
      "rewards/margins": 3.691861152648926,
      "rewards/rejected": -4.338125228881836,
      "step": 242
    },
    {
      "epoch": 0.3888,
      "grad_norm": 3.1490793228149414,
      "learning_rate": 3.0640000000000002e-06,
      "logits/chosen": -2.3224780559539795,
      "logits/rejected": -2.370464563369751,
      "logps/chosen": -1055.890869140625,
      "logps/rejected": -1576.2449951171875,
      "loss": 0.2174,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.8549923300743103,
      "rewards/margins": 3.2289910316467285,
      "rewards/rejected": -4.083983421325684,
      "step": 243
    },
    {
      "epoch": 0.3904,
      "grad_norm": 1.9790641069412231,
      "learning_rate": 3.056e-06,
      "logits/chosen": -2.334434986114502,
      "logits/rejected": -2.4052860736846924,
      "logps/chosen": -986.2021484375,
      "logps/rejected": -1529.532470703125,
      "loss": 0.1687,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9609677195549011,
      "rewards/margins": 3.418571710586548,
      "rewards/rejected": -4.379539489746094,
      "step": 244
    },
    {
      "epoch": 0.392,
      "grad_norm": 1.5484366416931152,
      "learning_rate": 3.0480000000000003e-06,
      "logits/chosen": -2.3219728469848633,
      "logits/rejected": -2.3844261169433594,
      "logps/chosen": -683.0291748046875,
      "logps/rejected": -1506.2352294921875,
      "loss": 0.1556,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6772217154502869,
      "rewards/margins": 2.7426106929779053,
      "rewards/rejected": -3.419832229614258,
      "step": 245
    },
    {
      "epoch": 0.3936,
      "grad_norm": 1.3457398414611816,
      "learning_rate": 3.04e-06,
      "logits/chosen": -2.085265636444092,
      "logits/rejected": -2.2891361713409424,
      "logps/chosen": -1382.3812255859375,
      "logps/rejected": -2164.586181640625,
      "loss": 0.1123,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6635743975639343,
      "rewards/margins": 3.724020004272461,
      "rewards/rejected": -4.387594223022461,
      "step": 246
    },
    {
      "epoch": 0.3952,
      "grad_norm": 1.398331880569458,
      "learning_rate": 3.0320000000000004e-06,
      "logits/chosen": -2.313602924346924,
      "logits/rejected": -2.3413968086242676,
      "logps/chosen": -718.392333984375,
      "logps/rejected": -1557.8958740234375,
      "loss": 0.1055,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.7196072936058044,
      "rewards/margins": 4.3215484619140625,
      "rewards/rejected": -5.041155815124512,
      "step": 247
    },
    {
      "epoch": 0.3968,
      "grad_norm": 2.0018904209136963,
      "learning_rate": 3.024e-06,
      "logits/chosen": -2.2358415126800537,
      "logits/rejected": -2.3794641494750977,
      "logps/chosen": -827.257568359375,
      "logps/rejected": -1406.83251953125,
      "loss": 0.2186,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.7009119987487793,
      "rewards/margins": 3.568347454071045,
      "rewards/rejected": -4.269259929656982,
      "step": 248
    },
    {
      "epoch": 0.3984,
      "grad_norm": 1.7910466194152832,
      "learning_rate": 3.016e-06,
      "logits/chosen": -2.318359851837158,
      "logits/rejected": -2.392448902130127,
      "logps/chosen": -574.30224609375,
      "logps/rejected": -817.0177001953125,
      "loss": 0.24,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8419782519340515,
      "rewards/margins": 1.7216941118240356,
      "rewards/rejected": -2.5636723041534424,
      "step": 249
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.7895424365997314,
      "learning_rate": 3.0080000000000003e-06,
      "logits/chosen": -2.317225217819214,
      "logits/rejected": -2.3651719093322754,
      "logps/chosen": -787.3615112304688,
      "logps/rejected": -1191.7821044921875,
      "loss": 0.1399,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6928555965423584,
      "rewards/margins": 2.9178948402404785,
      "rewards/rejected": -3.6107499599456787,
      "step": 250
    },
    {
      "epoch": 0.4016,
      "grad_norm": 2.101303815841675,
      "learning_rate": 3e-06,
      "logits/chosen": -2.2483930587768555,
      "logits/rejected": -2.296578884124756,
      "logps/chosen": -1770.211181640625,
      "logps/rejected": -2525.602294921875,
      "loss": 0.1223,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0896486043930054,
      "rewards/margins": 3.8922648429870605,
      "rewards/rejected": -4.981913089752197,
      "step": 251
    },
    {
      "epoch": 0.4032,
      "grad_norm": 1.300816535949707,
      "learning_rate": 2.9920000000000003e-06,
      "logits/chosen": -2.3500585556030273,
      "logits/rejected": -2.4312920570373535,
      "logps/chosen": -977.9588012695312,
      "logps/rejected": -1417.281982421875,
      "loss": 0.1431,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.7730346918106079,
      "rewards/margins": 3.0007779598236084,
      "rewards/rejected": -3.7738125324249268,
      "step": 252
    },
    {
      "epoch": 0.4048,
      "grad_norm": 3.0024845600128174,
      "learning_rate": 2.984e-06,
      "logits/chosen": -2.357908248901367,
      "logits/rejected": -2.39847731590271,
      "logps/chosen": -1149.325439453125,
      "logps/rejected": -1675.381591796875,
      "loss": 0.1771,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9527326822280884,
      "rewards/margins": 3.082491397857666,
      "rewards/rejected": -4.035223960876465,
      "step": 253
    },
    {
      "epoch": 0.4064,
      "grad_norm": 1.1717973947525024,
      "learning_rate": 2.976e-06,
      "logits/chosen": -2.2562954425811768,
      "logits/rejected": -2.3737690448760986,
      "logps/chosen": -932.6834716796875,
      "logps/rejected": -1512.205078125,
      "loss": 0.1493,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7617631554603577,
      "rewards/margins": 3.130026340484619,
      "rewards/rejected": -3.891789674758911,
      "step": 254
    },
    {
      "epoch": 0.408,
      "grad_norm": 6.851747512817383,
      "learning_rate": 2.9680000000000002e-06,
      "logits/chosen": -2.3603479862213135,
      "logits/rejected": -2.3499724864959717,
      "logps/chosen": -1558.89697265625,
      "logps/rejected": -1871.299072265625,
      "loss": 0.3928,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.737310767173767,
      "rewards/margins": 2.383831262588501,
      "rewards/rejected": -4.1211419105529785,
      "step": 255
    },
    {
      "epoch": 0.4096,
      "grad_norm": 2.559563636779785,
      "learning_rate": 2.96e-06,
      "logits/chosen": -2.1564369201660156,
      "logits/rejected": -2.367530345916748,
      "logps/chosen": -1169.1004638671875,
      "logps/rejected": -1491.3956298828125,
      "loss": 0.1936,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6304810047149658,
      "rewards/margins": 2.6079492568969727,
      "rewards/rejected": -3.2384302616119385,
      "step": 256
    },
    {
      "epoch": 0.4112,
      "grad_norm": 3.737609386444092,
      "learning_rate": 2.9520000000000003e-06,
      "logits/chosen": -2.3495402336120605,
      "logits/rejected": -2.4344985485076904,
      "logps/chosen": -1223.2093505859375,
      "logps/rejected": -1497.665283203125,
      "loss": 0.2896,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.4085662364959717,
      "rewards/margins": 2.407761812210083,
      "rewards/rejected": -3.8163270950317383,
      "step": 257
    },
    {
      "epoch": 0.4128,
      "grad_norm": 1.0839447975158691,
      "learning_rate": 2.944e-06,
      "logits/chosen": -2.2963192462921143,
      "logits/rejected": -2.4081554412841797,
      "logps/chosen": -925.71728515625,
      "logps/rejected": -1740.1884765625,
      "loss": 0.1008,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9428123831748962,
      "rewards/margins": 3.98006010055542,
      "rewards/rejected": -4.922872543334961,
      "step": 258
    },
    {
      "epoch": 0.4144,
      "grad_norm": 5.409466743469238,
      "learning_rate": 2.9360000000000003e-06,
      "logits/chosen": -2.348644495010376,
      "logits/rejected": -2.3287580013275146,
      "logps/chosen": -1782.06201171875,
      "logps/rejected": -2649.502197265625,
      "loss": 0.2648,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.5170384645462036,
      "rewards/margins": 4.107464790344238,
      "rewards/rejected": -5.624502658843994,
      "step": 259
    },
    {
      "epoch": 0.416,
      "grad_norm": 2.2148447036743164,
      "learning_rate": 2.928e-06,
      "logits/chosen": -2.37957763671875,
      "logits/rejected": -2.363960027694702,
      "logps/chosen": -790.137939453125,
      "logps/rejected": -2084.848876953125,
      "loss": 0.13,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9380184412002563,
      "rewards/margins": 4.902879238128662,
      "rewards/rejected": -5.840897083282471,
      "step": 260
    },
    {
      "epoch": 0.4176,
      "grad_norm": 1.9809366464614868,
      "learning_rate": 2.92e-06,
      "logits/chosen": -2.4079456329345703,
      "logits/rejected": -2.383596897125244,
      "logps/chosen": -1215.67724609375,
      "logps/rejected": -1577.9722900390625,
      "loss": 0.1805,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5252741575241089,
      "rewards/margins": 2.7985293865203857,
      "rewards/rejected": -4.323803424835205,
      "step": 261
    },
    {
      "epoch": 0.4192,
      "grad_norm": 1.8772406578063965,
      "learning_rate": 2.9120000000000002e-06,
      "logits/chosen": -2.200007677078247,
      "logits/rejected": -2.3064420223236084,
      "logps/chosen": -916.7288818359375,
      "logps/rejected": -1698.4151611328125,
      "loss": 0.1525,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6533792614936829,
      "rewards/margins": 4.755763530731201,
      "rewards/rejected": -5.409143447875977,
      "step": 262
    },
    {
      "epoch": 0.4208,
      "grad_norm": 1.6763818264007568,
      "learning_rate": 2.904e-06,
      "logits/chosen": -2.2668240070343018,
      "logits/rejected": -2.27404522895813,
      "logps/chosen": -752.1901245117188,
      "logps/rejected": -1436.008544921875,
      "loss": 0.1763,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.638434648513794,
      "rewards/margins": 4.026165008544922,
      "rewards/rejected": -4.664599418640137,
      "step": 263
    },
    {
      "epoch": 0.4224,
      "grad_norm": 4.643829822540283,
      "learning_rate": 2.8960000000000003e-06,
      "logits/chosen": -2.356435775756836,
      "logits/rejected": -2.4156389236450195,
      "logps/chosen": -1391.221435546875,
      "logps/rejected": -1554.602294921875,
      "loss": 0.1846,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0335161685943604,
      "rewards/margins": 2.288562297821045,
      "rewards/rejected": -3.3220784664154053,
      "step": 264
    },
    {
      "epoch": 0.424,
      "grad_norm": 1.0795965194702148,
      "learning_rate": 2.888e-06,
      "logits/chosen": -2.3339731693267822,
      "logits/rejected": -2.271331787109375,
      "logps/chosen": -1498.5687255859375,
      "logps/rejected": -2146.7353515625,
      "loss": 0.0609,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2683358192443848,
      "rewards/margins": 4.42303991317749,
      "rewards/rejected": -5.691375732421875,
      "step": 265
    },
    {
      "epoch": 0.4256,
      "grad_norm": 3.8686511516571045,
      "learning_rate": 2.88e-06,
      "logits/chosen": -2.2207131385803223,
      "logits/rejected": -2.1866888999938965,
      "logps/chosen": -885.0042114257812,
      "logps/rejected": -1455.9500732421875,
      "loss": 0.2965,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.9844586253166199,
      "rewards/margins": 3.0207555294036865,
      "rewards/rejected": -4.005214214324951,
      "step": 266
    },
    {
      "epoch": 0.4272,
      "grad_norm": 1.134663462638855,
      "learning_rate": 2.872e-06,
      "logits/chosen": -2.279616594314575,
      "logits/rejected": -2.3294625282287598,
      "logps/chosen": -888.7056274414062,
      "logps/rejected": -1403.7628173828125,
      "loss": 0.1368,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.05754816532135,
      "rewards/margins": 3.080756664276123,
      "rewards/rejected": -4.138304710388184,
      "step": 267
    },
    {
      "epoch": 0.4288,
      "grad_norm": 2.729318380355835,
      "learning_rate": 2.864e-06,
      "logits/chosen": -2.2914302349090576,
      "logits/rejected": -2.384509325027466,
      "logps/chosen": -833.170166015625,
      "logps/rejected": -1425.253173828125,
      "loss": 0.2345,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.6961199045181274,
      "rewards/margins": 3.251633405685425,
      "rewards/rejected": -3.9477529525756836,
      "step": 268
    },
    {
      "epoch": 0.4304,
      "grad_norm": 1.2833948135375977,
      "learning_rate": 2.8560000000000003e-06,
      "logits/chosen": -2.1851909160614014,
      "logits/rejected": -2.3253393173217773,
      "logps/chosen": -800.4691162109375,
      "logps/rejected": -1990.0167236328125,
      "loss": 0.1104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.553033173084259,
      "rewards/margins": 5.019336223602295,
      "rewards/rejected": -5.57236909866333,
      "step": 269
    },
    {
      "epoch": 0.432,
      "grad_norm": 1.3011631965637207,
      "learning_rate": 2.848e-06,
      "logits/chosen": -2.220993757247925,
      "logits/rejected": -2.2756152153015137,
      "logps/chosen": -902.1480712890625,
      "logps/rejected": -1402.4830322265625,
      "loss": 0.1816,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5505086779594421,
      "rewards/margins": 3.8805456161499023,
      "rewards/rejected": -4.43105411529541,
      "step": 270
    },
    {
      "epoch": 0.4336,
      "grad_norm": 1.0558208227157593,
      "learning_rate": 2.84e-06,
      "logits/chosen": -2.3746845722198486,
      "logits/rejected": -2.41697359085083,
      "logps/chosen": -924.0331420898438,
      "logps/rejected": -1732.2236328125,
      "loss": 0.0988,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9507866501808167,
      "rewards/margins": 3.506983995437622,
      "rewards/rejected": -4.457770347595215,
      "step": 271
    },
    {
      "epoch": 0.4352,
      "grad_norm": 4.075521469116211,
      "learning_rate": 2.832e-06,
      "logits/chosen": -2.3861663341522217,
      "logits/rejected": -2.3563342094421387,
      "logps/chosen": -1143.0465087890625,
      "logps/rejected": -1369.1077880859375,
      "loss": 0.3204,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.2598148584365845,
      "rewards/margins": 2.791734218597412,
      "rewards/rejected": -4.051548957824707,
      "step": 272
    },
    {
      "epoch": 0.4368,
      "grad_norm": 1.5417824983596802,
      "learning_rate": 2.824e-06,
      "logits/chosen": -2.2409589290618896,
      "logits/rejected": -2.1988115310668945,
      "logps/chosen": -958.8359375,
      "logps/rejected": -1639.40185546875,
      "loss": 0.1073,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9522560834884644,
      "rewards/margins": 3.7185802459716797,
      "rewards/rejected": -4.670836925506592,
      "step": 273
    },
    {
      "epoch": 0.4384,
      "grad_norm": 4.977201461791992,
      "learning_rate": 2.8160000000000002e-06,
      "logits/chosen": -2.1878461837768555,
      "logits/rejected": -2.3366312980651855,
      "logps/chosen": -1112.7984619140625,
      "logps/rejected": -1606.177734375,
      "loss": 0.2909,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.7042738199234009,
      "rewards/margins": 4.559440612792969,
      "rewards/rejected": -5.263714790344238,
      "step": 274
    },
    {
      "epoch": 0.44,
      "grad_norm": 4.2307868003845215,
      "learning_rate": 2.808e-06,
      "logits/chosen": -2.24558424949646,
      "logits/rejected": -2.3048558235168457,
      "logps/chosen": -1403.312744140625,
      "logps/rejected": -1872.605224609375,
      "loss": 0.2395,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.3806908130645752,
      "rewards/margins": 3.9826102256774902,
      "rewards/rejected": -5.3633012771606445,
      "step": 275
    },
    {
      "epoch": 0.4416,
      "grad_norm": 1.9647516012191772,
      "learning_rate": 2.8000000000000003e-06,
      "logits/chosen": -2.342532157897949,
      "logits/rejected": -2.380263328552246,
      "logps/chosen": -1105.57275390625,
      "logps/rejected": -1553.748291015625,
      "loss": 0.1192,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0173979997634888,
      "rewards/margins": 3.6688742637634277,
      "rewards/rejected": -4.686272144317627,
      "step": 276
    },
    {
      "epoch": 0.4432,
      "grad_norm": 0.6366689205169678,
      "learning_rate": 2.792e-06,
      "logits/chosen": -2.2884459495544434,
      "logits/rejected": -2.324716091156006,
      "logps/chosen": -957.7957153320312,
      "logps/rejected": -1674.1685791015625,
      "loss": 0.0918,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9420444369316101,
      "rewards/margins": 3.637336492538452,
      "rewards/rejected": -4.579380989074707,
      "step": 277
    },
    {
      "epoch": 0.4448,
      "grad_norm": 2.3581035137176514,
      "learning_rate": 2.784e-06,
      "logits/chosen": -2.2828869819641113,
      "logits/rejected": -2.3572661876678467,
      "logps/chosen": -1085.538330078125,
      "logps/rejected": -1376.6090087890625,
      "loss": 0.2331,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.9015481472015381,
      "rewards/margins": 2.5569095611572266,
      "rewards/rejected": -3.4584577083587646,
      "step": 278
    },
    {
      "epoch": 0.4464,
      "grad_norm": 0.995777428150177,
      "learning_rate": 2.776e-06,
      "logits/chosen": -2.2789969444274902,
      "logits/rejected": -2.2793123722076416,
      "logps/chosen": -1303.5699462890625,
      "logps/rejected": -2335.119384765625,
      "loss": 0.081,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3058055639266968,
      "rewards/margins": 4.949888706207275,
      "rewards/rejected": -6.255694389343262,
      "step": 279
    },
    {
      "epoch": 0.448,
      "grad_norm": 1.1404190063476562,
      "learning_rate": 2.768e-06,
      "logits/chosen": -2.24117374420166,
      "logits/rejected": -2.2577919960021973,
      "logps/chosen": -918.716064453125,
      "logps/rejected": -1457.970703125,
      "loss": 0.0738,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9764912724494934,
      "rewards/margins": 4.131425857543945,
      "rewards/rejected": -5.107917308807373,
      "step": 280
    },
    {
      "epoch": 0.4496,
      "grad_norm": 0.918555736541748,
      "learning_rate": 2.7600000000000003e-06,
      "logits/chosen": -2.3088815212249756,
      "logits/rejected": -2.4177985191345215,
      "logps/chosen": -1166.43798828125,
      "logps/rejected": -1347.888427734375,
      "loss": 0.1032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.49211204051971436,
      "rewards/margins": 3.8930091857910156,
      "rewards/rejected": -4.3851213455200195,
      "step": 281
    },
    {
      "epoch": 0.4512,
      "grad_norm": 0.7543146014213562,
      "learning_rate": 2.752e-06,
      "logits/chosen": -2.4075450897216797,
      "logits/rejected": -2.3814570903778076,
      "logps/chosen": -1625.9024658203125,
      "logps/rejected": -2129.3017578125,
      "loss": 0.0655,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.308188796043396,
      "rewards/margins": 3.935572624206543,
      "rewards/rejected": -5.24376106262207,
      "step": 282
    },
    {
      "epoch": 0.4528,
      "grad_norm": 3.285623788833618,
      "learning_rate": 2.744e-06,
      "logits/chosen": -2.3517510890960693,
      "logits/rejected": -2.3720884323120117,
      "logps/chosen": -930.5339965820312,
      "logps/rejected": -1729.9083251953125,
      "loss": 0.248,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9873232245445251,
      "rewards/margins": 4.142503261566162,
      "rewards/rejected": -5.12982702255249,
      "step": 283
    },
    {
      "epoch": 0.4544,
      "grad_norm": 1.1667739152908325,
      "learning_rate": 2.736e-06,
      "logits/chosen": -2.3527004718780518,
      "logits/rejected": -2.4089059829711914,
      "logps/chosen": -609.09423828125,
      "logps/rejected": -985.365966796875,
      "loss": 0.089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7416706681251526,
      "rewards/margins": 3.046872854232788,
      "rewards/rejected": -3.788543462753296,
      "step": 284
    },
    {
      "epoch": 0.456,
      "grad_norm": 1.2952200174331665,
      "learning_rate": 2.728e-06,
      "logits/chosen": -2.2753281593322754,
      "logits/rejected": -2.406614065170288,
      "logps/chosen": -1038.119873046875,
      "logps/rejected": -1881.145751953125,
      "loss": 0.1316,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.2399362325668335,
      "rewards/margins": 4.322778701782227,
      "rewards/rejected": -5.562716007232666,
      "step": 285
    },
    {
      "epoch": 0.4576,
      "grad_norm": 1.4149055480957031,
      "learning_rate": 2.7200000000000002e-06,
      "logits/chosen": -2.3513131141662598,
      "logits/rejected": -2.385067939758301,
      "logps/chosen": -855.2706909179688,
      "logps/rejected": -1107.11865234375,
      "loss": 0.2044,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6428483724594116,
      "rewards/margins": 2.8237664699554443,
      "rewards/rejected": -3.4666147232055664,
      "step": 286
    },
    {
      "epoch": 0.4592,
      "grad_norm": 0.7918720841407776,
      "learning_rate": 2.712e-06,
      "logits/chosen": -2.4005560874938965,
      "logits/rejected": -2.4264156818389893,
      "logps/chosen": -1140.0875244140625,
      "logps/rejected": -1716.63720703125,
      "loss": 0.1031,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.013662338256836,
      "rewards/margins": 3.8571178913116455,
      "rewards/rejected": -4.8707804679870605,
      "step": 287
    },
    {
      "epoch": 0.4608,
      "grad_norm": 1.9834156036376953,
      "learning_rate": 2.704e-06,
      "logits/chosen": -2.2295994758605957,
      "logits/rejected": -2.3636114597320557,
      "logps/chosen": -713.6134033203125,
      "logps/rejected": -1572.4986572265625,
      "loss": 0.1264,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8774973750114441,
      "rewards/margins": 2.848907947540283,
      "rewards/rejected": -3.726405143737793,
      "step": 288
    },
    {
      "epoch": 0.4624,
      "grad_norm": 0.8449904322624207,
      "learning_rate": 2.696e-06,
      "logits/chosen": -2.3967010974884033,
      "logits/rejected": -2.3983521461486816,
      "logps/chosen": -707.095947265625,
      "logps/rejected": -1359.21533203125,
      "loss": 0.0662,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8659148216247559,
      "rewards/margins": 4.327756881713867,
      "rewards/rejected": -5.193671226501465,
      "step": 289
    },
    {
      "epoch": 0.464,
      "grad_norm": 3.127732515335083,
      "learning_rate": 2.688e-06,
      "logits/chosen": -2.246572971343994,
      "logits/rejected": -2.3191161155700684,
      "logps/chosen": -1363.2147216796875,
      "logps/rejected": -1872.3580322265625,
      "loss": 0.2118,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.1611380577087402,
      "rewards/margins": 3.877769708633423,
      "rewards/rejected": -5.038907527923584,
      "step": 290
    },
    {
      "epoch": 0.4656,
      "grad_norm": 3.7709760665893555,
      "learning_rate": 2.68e-06,
      "logits/chosen": -2.1911978721618652,
      "logits/rejected": -2.235447406768799,
      "logps/chosen": -1136.020263671875,
      "logps/rejected": -1659.4310302734375,
      "loss": 0.2545,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.1134424209594727,
      "rewards/margins": 4.013430118560791,
      "rewards/rejected": -5.126873016357422,
      "step": 291
    },
    {
      "epoch": 0.4672,
      "grad_norm": 2.3524184226989746,
      "learning_rate": 2.672e-06,
      "logits/chosen": -2.339843273162842,
      "logits/rejected": -2.4097492694854736,
      "logps/chosen": -1385.0723876953125,
      "logps/rejected": -1559.2109375,
      "loss": 0.2085,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.2330435514450073,
      "rewards/margins": 3.745849370956421,
      "rewards/rejected": -4.978892803192139,
      "step": 292
    },
    {
      "epoch": 0.4688,
      "grad_norm": 6.182058811187744,
      "learning_rate": 2.6640000000000007e-06,
      "logits/chosen": -2.314999580383301,
      "logits/rejected": -2.38771390914917,
      "logps/chosen": -1180.3203125,
      "logps/rejected": -1251.2169189453125,
      "loss": 0.3977,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.1796215772628784,
      "rewards/margins": 2.9354865550994873,
      "rewards/rejected": -4.115108489990234,
      "step": 293
    },
    {
      "epoch": 0.4704,
      "grad_norm": 1.6341198682785034,
      "learning_rate": 2.656e-06,
      "logits/chosen": -2.300549030303955,
      "logits/rejected": -2.3347222805023193,
      "logps/chosen": -1721.287353515625,
      "logps/rejected": -2131.84912109375,
      "loss": 0.0972,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1971266269683838,
      "rewards/margins": 3.992112636566162,
      "rewards/rejected": -5.189239501953125,
      "step": 294
    },
    {
      "epoch": 0.472,
      "grad_norm": 2.9836955070495605,
      "learning_rate": 2.648e-06,
      "logits/chosen": -2.2942962646484375,
      "logits/rejected": -2.378063678741455,
      "logps/chosen": -1195.79296875,
      "logps/rejected": -1597.2392578125,
      "loss": 0.1564,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3329049348831177,
      "rewards/margins": 4.107041358947754,
      "rewards/rejected": -5.439946174621582,
      "step": 295
    },
    {
      "epoch": 0.4736,
      "grad_norm": 2.009368658065796,
      "learning_rate": 2.64e-06,
      "logits/chosen": -2.1703524589538574,
      "logits/rejected": -2.195103883743286,
      "logps/chosen": -1117.53271484375,
      "logps/rejected": -2389.248779296875,
      "loss": 0.1444,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.7564182877540588,
      "rewards/margins": 5.95618200302124,
      "rewards/rejected": -6.712599754333496,
      "step": 296
    },
    {
      "epoch": 0.4752,
      "grad_norm": 4.172726154327393,
      "learning_rate": 2.632e-06,
      "logits/chosen": -2.3459253311157227,
      "logits/rejected": -2.4181904792785645,
      "logps/chosen": -674.2925415039062,
      "logps/rejected": -1645.3372802734375,
      "loss": 0.2135,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.8995518088340759,
      "rewards/margins": 3.919128894805908,
      "rewards/rejected": -4.818680763244629,
      "step": 297
    },
    {
      "epoch": 0.4768,
      "grad_norm": 1.8501101732254028,
      "learning_rate": 2.6240000000000006e-06,
      "logits/chosen": -2.3649463653564453,
      "logits/rejected": -2.412398099899292,
      "logps/chosen": -1080.0826416015625,
      "logps/rejected": -1468.1602783203125,
      "loss": 0.1988,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6554319858551025,
      "rewards/margins": 2.9807348251342773,
      "rewards/rejected": -3.63616681098938,
      "step": 298
    },
    {
      "epoch": 0.4784,
      "grad_norm": 3.1954386234283447,
      "learning_rate": 2.616e-06,
      "logits/chosen": -2.1328673362731934,
      "logits/rejected": -2.311483144760132,
      "logps/chosen": -1203.50927734375,
      "logps/rejected": -1489.400146484375,
      "loss": 0.2383,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0754817724227905,
      "rewards/margins": 2.6007916927337646,
      "rewards/rejected": -3.6762735843658447,
      "step": 299
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.5167477130889893,
      "learning_rate": 2.608e-06,
      "logits/chosen": -2.232616901397705,
      "logits/rejected": -2.2943947315216064,
      "logps/chosen": -947.0877075195312,
      "logps/rejected": -1357.0712890625,
      "loss": 0.1127,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.047816276550293,
      "rewards/margins": 3.2682979106903076,
      "rewards/rejected": -4.3161139488220215,
      "step": 300
    },
    {
      "epoch": 0.4816,
      "grad_norm": 1.7408801317214966,
      "learning_rate": 2.6e-06,
      "logits/chosen": -2.3615689277648926,
      "logits/rejected": -2.358302593231201,
      "logps/chosen": -778.8631591796875,
      "logps/rejected": -1232.053955078125,
      "loss": 0.1567,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9194803833961487,
      "rewards/margins": 3.3787050247192383,
      "rewards/rejected": -4.298184871673584,
      "step": 301
    },
    {
      "epoch": 0.4832,
      "grad_norm": 1.4407373666763306,
      "learning_rate": 2.592e-06,
      "logits/chosen": -2.23988676071167,
      "logits/rejected": -2.3497159481048584,
      "logps/chosen": -687.0258178710938,
      "logps/rejected": -1525.805419921875,
      "loss": 0.2047,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.5443342924118042,
      "rewards/margins": 3.9201714992523193,
      "rewards/rejected": -4.464505672454834,
      "step": 302
    },
    {
      "epoch": 0.4848,
      "grad_norm": 3.3542819023132324,
      "learning_rate": 2.5840000000000006e-06,
      "logits/chosen": -2.4032175540924072,
      "logits/rejected": -2.3686046600341797,
      "logps/chosen": -1023.4866943359375,
      "logps/rejected": -1406.635009765625,
      "loss": 0.2622,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3238226175308228,
      "rewards/margins": 3.153352737426758,
      "rewards/rejected": -4.477175235748291,
      "step": 303
    },
    {
      "epoch": 0.4864,
      "grad_norm": 1.8579983711242676,
      "learning_rate": 2.576e-06,
      "logits/chosen": -2.1691243648529053,
      "logits/rejected": -2.309361696243286,
      "logps/chosen": -1017.6928100585938,
      "logps/rejected": -1591.2293701171875,
      "loss": 0.1956,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.52461177110672,
      "rewards/margins": 3.598154067993164,
      "rewards/rejected": -4.12276554107666,
      "step": 304
    },
    {
      "epoch": 0.488,
      "grad_norm": 2.642622232437134,
      "learning_rate": 2.568e-06,
      "logits/chosen": -2.150036334991455,
      "logits/rejected": -2.3535048961639404,
      "logps/chosen": -1051.6810302734375,
      "logps/rejected": -1500.7589111328125,
      "loss": 0.1733,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9253125190734863,
      "rewards/margins": 3.511594772338867,
      "rewards/rejected": -4.436907768249512,
      "step": 305
    },
    {
      "epoch": 0.4896,
      "grad_norm": 3.5949454307556152,
      "learning_rate": 2.56e-06,
      "logits/chosen": -2.253484010696411,
      "logits/rejected": -2.292247772216797,
      "logps/chosen": -1413.312744140625,
      "logps/rejected": -1993.15869140625,
      "loss": 0.1572,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.4797710180282593,
      "rewards/margins": 4.222550868988037,
      "rewards/rejected": -5.702321529388428,
      "step": 306
    },
    {
      "epoch": 0.4912,
      "grad_norm": 1.2093244791030884,
      "learning_rate": 2.552e-06,
      "logits/chosen": -2.3660826683044434,
      "logits/rejected": -2.4438180923461914,
      "logps/chosen": -675.570556640625,
      "logps/rejected": -1280.4287109375,
      "loss": 0.1176,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.443198561668396,
      "rewards/margins": 3.583385944366455,
      "rewards/rejected": -4.026584148406982,
      "step": 307
    },
    {
      "epoch": 0.4928,
      "grad_norm": 0.9217472076416016,
      "learning_rate": 2.5440000000000005e-06,
      "logits/chosen": -2.2734482288360596,
      "logits/rejected": -2.3068361282348633,
      "logps/chosen": -451.6304931640625,
      "logps/rejected": -1031.269287109375,
      "loss": 0.0978,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3607180118560791,
      "rewards/margins": 4.114380836486816,
      "rewards/rejected": -4.475099563598633,
      "step": 308
    },
    {
      "epoch": 0.4944,
      "grad_norm": 1.8278487920761108,
      "learning_rate": 2.536e-06,
      "logits/chosen": -2.2594590187072754,
      "logits/rejected": -2.2860827445983887,
      "logps/chosen": -764.601806640625,
      "logps/rejected": -1503.1968994140625,
      "loss": 0.1409,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.7139700651168823,
      "rewards/margins": 3.72812557220459,
      "rewards/rejected": -4.442095756530762,
      "step": 309
    },
    {
      "epoch": 0.496,
      "grad_norm": 1.8506386280059814,
      "learning_rate": 2.5280000000000006e-06,
      "logits/chosen": -2.194558620452881,
      "logits/rejected": -2.368211269378662,
      "logps/chosen": -836.3552856445312,
      "logps/rejected": -1759.6680908203125,
      "loss": 0.1215,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9529500007629395,
      "rewards/margins": 4.179579734802246,
      "rewards/rejected": -5.132530212402344,
      "step": 310
    },
    {
      "epoch": 0.4976,
      "grad_norm": 1.1197233200073242,
      "learning_rate": 2.52e-06,
      "logits/chosen": -2.352452516555786,
      "logits/rejected": -2.3354411125183105,
      "logps/chosen": -861.8787841796875,
      "logps/rejected": -2200.024658203125,
      "loss": 0.0463,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1531801223754883,
      "rewards/margins": 4.518958568572998,
      "rewards/rejected": -5.6721391677856445,
      "step": 311
    },
    {
      "epoch": 0.4992,
      "grad_norm": 3.953606367111206,
      "learning_rate": 2.512e-06,
      "logits/chosen": -2.354464292526245,
      "logits/rejected": -2.338487148284912,
      "logps/chosen": -1272.119873046875,
      "logps/rejected": -2031.1268310546875,
      "loss": 0.1993,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9794512391090393,
      "rewards/margins": 3.945197105407715,
      "rewards/rejected": -4.924648761749268,
      "step": 312
    },
    {
      "epoch": 0.5008,
      "grad_norm": 1.0310620069503784,
      "learning_rate": 2.5040000000000005e-06,
      "logits/chosen": -2.2856545448303223,
      "logits/rejected": -2.405141592025757,
      "logps/chosen": -1665.2930908203125,
      "logps/rejected": -1932.4307861328125,
      "loss": 0.0797,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.040541309863328934,
      "rewards/margins": 5.266037464141846,
      "rewards/rejected": -5.306578636169434,
      "step": 313
    },
    {
      "epoch": 0.5024,
      "grad_norm": 0.8544760942459106,
      "learning_rate": 2.496e-06,
      "logits/chosen": -2.2207398414611816,
      "logits/rejected": -2.3898556232452393,
      "logps/chosen": -1097.9195556640625,
      "logps/rejected": -1688.7470703125,
      "loss": 0.0764,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.217321753501892,
      "rewards/margins": 4.145196914672852,
      "rewards/rejected": -5.362518787384033,
      "step": 314
    },
    {
      "epoch": 0.504,
      "grad_norm": 1.1842360496520996,
      "learning_rate": 2.488e-06,
      "logits/chosen": -2.3355610370635986,
      "logits/rejected": -2.3547418117523193,
      "logps/chosen": -1124.2861328125,
      "logps/rejected": -1703.5279541015625,
      "loss": 0.0723,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.283892273902893,
      "rewards/margins": 3.9343161582946777,
      "rewards/rejected": -5.2182087898254395,
      "step": 315
    },
    {
      "epoch": 0.5056,
      "grad_norm": 2.600745677947998,
      "learning_rate": 2.4800000000000004e-06,
      "logits/chosen": -2.3317317962646484,
      "logits/rejected": -2.3718957901000977,
      "logps/chosen": -731.5401000976562,
      "logps/rejected": -1223.669921875,
      "loss": 0.1834,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6723150014877319,
      "rewards/margins": 3.0859479904174805,
      "rewards/rejected": -3.758262872695923,
      "step": 316
    },
    {
      "epoch": 0.5072,
      "grad_norm": 1.037670373916626,
      "learning_rate": 2.4720000000000002e-06,
      "logits/chosen": -2.2717437744140625,
      "logits/rejected": -2.4421980381011963,
      "logps/chosen": -985.040771484375,
      "logps/rejected": -1104.328369140625,
      "loss": 0.1012,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8511080145835876,
      "rewards/margins": 3.1459598541259766,
      "rewards/rejected": -3.99706768989563,
      "step": 317
    },
    {
      "epoch": 0.5088,
      "grad_norm": 1.271413803100586,
      "learning_rate": 2.4640000000000005e-06,
      "logits/chosen": -2.2590603828430176,
      "logits/rejected": -2.3143818378448486,
      "logps/chosen": -1138.00732421875,
      "logps/rejected": -1892.2052001953125,
      "loss": 0.1051,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8655272126197815,
      "rewards/margins": 4.181704044342041,
      "rewards/rejected": -5.0472307205200195,
      "step": 318
    },
    {
      "epoch": 0.5104,
      "grad_norm": 2.278864860534668,
      "learning_rate": 2.4560000000000003e-06,
      "logits/chosen": -2.1587576866149902,
      "logits/rejected": -2.280714511871338,
      "logps/chosen": -1568.6756591796875,
      "logps/rejected": -1763.6951904296875,
      "loss": 0.2276,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.312636137008667,
      "rewards/margins": 2.8688716888427734,
      "rewards/rejected": -4.1815080642700195,
      "step": 319
    },
    {
      "epoch": 0.512,
      "grad_norm": 1.2901986837387085,
      "learning_rate": 2.448e-06,
      "logits/chosen": -2.279522180557251,
      "logits/rejected": -2.4001805782318115,
      "logps/chosen": -588.9932250976562,
      "logps/rejected": -1285.2032470703125,
      "loss": 0.1206,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6479572653770447,
      "rewards/margins": 3.3167662620544434,
      "rewards/rejected": -3.9647231101989746,
      "step": 320
    },
    {
      "epoch": 0.5136,
      "grad_norm": 1.4257091283798218,
      "learning_rate": 2.4400000000000004e-06,
      "logits/chosen": -2.3047618865966797,
      "logits/rejected": -2.3235344886779785,
      "logps/chosen": -1112.4453125,
      "logps/rejected": -1949.3612060546875,
      "loss": 0.1145,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0543972253799438,
      "rewards/margins": 4.1138916015625,
      "rewards/rejected": -5.1682891845703125,
      "step": 321
    },
    {
      "epoch": 0.5152,
      "grad_norm": 3.538055658340454,
      "learning_rate": 2.432e-06,
      "logits/chosen": -2.359922409057617,
      "logits/rejected": -2.334838390350342,
      "logps/chosen": -1107.17138671875,
      "logps/rejected": -1713.9599609375,
      "loss": 0.1157,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1655267477035522,
      "rewards/margins": 3.6252169609069824,
      "rewards/rejected": -4.790743350982666,
      "step": 322
    },
    {
      "epoch": 0.5168,
      "grad_norm": 1.4405442476272583,
      "learning_rate": 2.4240000000000004e-06,
      "logits/chosen": -2.163163900375366,
      "logits/rejected": -2.2644803524017334,
      "logps/chosen": -1237.4830322265625,
      "logps/rejected": -2072.43115234375,
      "loss": 0.0645,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0416107177734375,
      "rewards/margins": 4.845813751220703,
      "rewards/rejected": -5.887424468994141,
      "step": 323
    },
    {
      "epoch": 0.5184,
      "grad_norm": 2.0983333587646484,
      "learning_rate": 2.4160000000000002e-06,
      "logits/chosen": -2.375760078430176,
      "logits/rejected": -2.4293880462646484,
      "logps/chosen": -1472.0343017578125,
      "logps/rejected": -1590.73583984375,
      "loss": 0.1619,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0285989046096802,
      "rewards/margins": 3.791252374649048,
      "rewards/rejected": -4.819850921630859,
      "step": 324
    },
    {
      "epoch": 0.52,
      "grad_norm": 8.616344451904297,
      "learning_rate": 2.408e-06,
      "logits/chosen": -2.3307974338531494,
      "logits/rejected": -2.304356336593628,
      "logps/chosen": -1330.980224609375,
      "logps/rejected": -1538.88671875,
      "loss": 0.5225,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.241766095161438,
      "rewards/margins": 3.2011985778808594,
      "rewards/rejected": -4.442964553833008,
      "step": 325
    },
    {
      "epoch": 0.5216,
      "grad_norm": 0.849904477596283,
      "learning_rate": 2.4000000000000003e-06,
      "logits/chosen": -2.245840072631836,
      "logits/rejected": -2.2426657676696777,
      "logps/chosen": -1253.1678466796875,
      "logps/rejected": -1990.1751708984375,
      "loss": 0.0622,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9346991777420044,
      "rewards/margins": 4.824849605560303,
      "rewards/rejected": -5.759548664093018,
      "step": 326
    },
    {
      "epoch": 0.5232,
      "grad_norm": 2.3244097232818604,
      "learning_rate": 2.392e-06,
      "logits/chosen": -2.3181684017181396,
      "logits/rejected": -2.418372631072998,
      "logps/chosen": -798.019775390625,
      "logps/rejected": -1393.3560791015625,
      "loss": 0.1717,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.1200308799743652,
      "rewards/margins": 4.16115140914917,
      "rewards/rejected": -5.281182289123535,
      "step": 327
    },
    {
      "epoch": 0.5248,
      "grad_norm": 1.147102952003479,
      "learning_rate": 2.3840000000000004e-06,
      "logits/chosen": -2.2412567138671875,
      "logits/rejected": -2.3497512340545654,
      "logps/chosen": -1641.1444091796875,
      "logps/rejected": -2077.921142578125,
      "loss": 0.0799,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0000207424163818,
      "rewards/margins": 4.349527835845947,
      "rewards/rejected": -5.349547863006592,
      "step": 328
    },
    {
      "epoch": 0.5264,
      "grad_norm": 1.0080044269561768,
      "learning_rate": 2.376e-06,
      "logits/chosen": -2.3536946773529053,
      "logits/rejected": -2.3694260120391846,
      "logps/chosen": -854.7633056640625,
      "logps/rejected": -1473.36572265625,
      "loss": 0.1104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8521131277084351,
      "rewards/margins": 3.919619083404541,
      "rewards/rejected": -4.771732330322266,
      "step": 329
    },
    {
      "epoch": 0.528,
      "grad_norm": 1.5855989456176758,
      "learning_rate": 2.3680000000000005e-06,
      "logits/chosen": -2.309326648712158,
      "logits/rejected": -2.3038618564605713,
      "logps/chosen": -671.82861328125,
      "logps/rejected": -1780.9609375,
      "loss": 0.1076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.923062264919281,
      "rewards/margins": 5.081305503845215,
      "rewards/rejected": -6.004367828369141,
      "step": 330
    },
    {
      "epoch": 0.5296,
      "grad_norm": 3.2917847633361816,
      "learning_rate": 2.3600000000000003e-06,
      "logits/chosen": -2.3363771438598633,
      "logits/rejected": -2.412583589553833,
      "logps/chosen": -1285.286865234375,
      "logps/rejected": -1522.624267578125,
      "loss": 0.1778,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3800172805786133,
      "rewards/margins": 3.429886817932129,
      "rewards/rejected": -4.809904098510742,
      "step": 331
    },
    {
      "epoch": 0.5312,
      "grad_norm": 2.356498956680298,
      "learning_rate": 2.352e-06,
      "logits/chosen": -2.245990514755249,
      "logits/rejected": -2.3694803714752197,
      "logps/chosen": -616.2153930664062,
      "logps/rejected": -1515.214111328125,
      "loss": 0.1515,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0034823417663574,
      "rewards/margins": 4.265713691711426,
      "rewards/rejected": -5.269196033477783,
      "step": 332
    },
    {
      "epoch": 0.5328,
      "grad_norm": 1.3656684160232544,
      "learning_rate": 2.3440000000000003e-06,
      "logits/chosen": -2.3204989433288574,
      "logits/rejected": -2.3403477668762207,
      "logps/chosen": -1074.734375,
      "logps/rejected": -1712.379638671875,
      "loss": 0.0909,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2257767915725708,
      "rewards/margins": 4.8234710693359375,
      "rewards/rejected": -6.049248218536377,
      "step": 333
    },
    {
      "epoch": 0.5344,
      "grad_norm": 1.8196228742599487,
      "learning_rate": 2.336e-06,
      "logits/chosen": -2.299683094024658,
      "logits/rejected": -2.354182481765747,
      "logps/chosen": -650.8189086914062,
      "logps/rejected": -1043.09326171875,
      "loss": 0.188,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9282981157302856,
      "rewards/margins": 2.553581714630127,
      "rewards/rejected": -3.481879949569702,
      "step": 334
    },
    {
      "epoch": 0.536,
      "grad_norm": 2.2003912925720215,
      "learning_rate": 2.3280000000000004e-06,
      "logits/chosen": -2.2585837841033936,
      "logits/rejected": -2.339015483856201,
      "logps/chosen": -657.878173828125,
      "logps/rejected": -1495.8670654296875,
      "loss": 0.1631,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.8096514344215393,
      "rewards/margins": 3.340493679046631,
      "rewards/rejected": -4.150145530700684,
      "step": 335
    },
    {
      "epoch": 0.5376,
      "grad_norm": 1.7038921117782593,
      "learning_rate": 2.3200000000000002e-06,
      "logits/chosen": -2.131169557571411,
      "logits/rejected": -2.390847682952881,
      "logps/chosen": -526.625732421875,
      "logps/rejected": -1681.8675537109375,
      "loss": 0.1468,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.4522605836391449,
      "rewards/margins": 4.690348148345947,
      "rewards/rejected": -5.142608642578125,
      "step": 336
    },
    {
      "epoch": 0.5392,
      "grad_norm": 1.5462697744369507,
      "learning_rate": 2.312e-06,
      "logits/chosen": -2.23356032371521,
      "logits/rejected": -2.34205961227417,
      "logps/chosen": -1115.6588134765625,
      "logps/rejected": -1660.719482421875,
      "loss": 0.1096,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0075277090072632,
      "rewards/margins": 3.414728879928589,
      "rewards/rejected": -4.422256946563721,
      "step": 337
    },
    {
      "epoch": 0.5408,
      "grad_norm": 1.1194971799850464,
      "learning_rate": 2.3040000000000003e-06,
      "logits/chosen": -2.158738613128662,
      "logits/rejected": -2.323246717453003,
      "logps/chosen": -1095.38818359375,
      "logps/rejected": -1564.221923828125,
      "loss": 0.1216,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8671501874923706,
      "rewards/margins": 3.9322993755340576,
      "rewards/rejected": -4.7994489669799805,
      "step": 338
    },
    {
      "epoch": 0.5424,
      "grad_norm": 1.1145466566085815,
      "learning_rate": 2.296e-06,
      "logits/chosen": -2.335561513900757,
      "logits/rejected": -2.392768383026123,
      "logps/chosen": -428.0898742675781,
      "logps/rejected": -1053.744873046875,
      "loss": 0.1445,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4262770116329193,
      "rewards/margins": 2.900352954864502,
      "rewards/rejected": -3.326630115509033,
      "step": 339
    },
    {
      "epoch": 0.544,
      "grad_norm": 3.596787214279175,
      "learning_rate": 2.2880000000000004e-06,
      "logits/chosen": -2.3710317611694336,
      "logits/rejected": -2.3908214569091797,
      "logps/chosen": -1726.477294921875,
      "logps/rejected": -2187.120361328125,
      "loss": 0.099,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5432813167572021,
      "rewards/margins": 4.4125590324401855,
      "rewards/rejected": -5.955840587615967,
      "step": 340
    },
    {
      "epoch": 0.5456,
      "grad_norm": 2.910829782485962,
      "learning_rate": 2.28e-06,
      "logits/chosen": -2.409365177154541,
      "logits/rejected": -2.4081366062164307,
      "logps/chosen": -1324.4808349609375,
      "logps/rejected": -1693.876220703125,
      "loss": 0.2305,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0939445495605469,
      "rewards/margins": 2.960564136505127,
      "rewards/rejected": -4.054508209228516,
      "step": 341
    },
    {
      "epoch": 0.5472,
      "grad_norm": 1.7608494758605957,
      "learning_rate": 2.2720000000000004e-06,
      "logits/chosen": -2.3164689540863037,
      "logits/rejected": -2.3938050270080566,
      "logps/chosen": -1060.94482421875,
      "logps/rejected": -1539.3951416015625,
      "loss": 0.1347,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.508272647857666,
      "rewards/margins": 3.8886711597442627,
      "rewards/rejected": -5.396944046020508,
      "step": 342
    },
    {
      "epoch": 0.5488,
      "grad_norm": 1.6270943880081177,
      "learning_rate": 2.2640000000000003e-06,
      "logits/chosen": -2.339033365249634,
      "logits/rejected": -2.3927998542785645,
      "logps/chosen": -1281.4139404296875,
      "logps/rejected": -2180.72998046875,
      "loss": 0.0747,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.106817603111267,
      "rewards/margins": 4.873089790344238,
      "rewards/rejected": -5.979907989501953,
      "step": 343
    },
    {
      "epoch": 0.5504,
      "grad_norm": 1.4561922550201416,
      "learning_rate": 2.256e-06,
      "logits/chosen": -2.2664380073547363,
      "logits/rejected": -2.3787124156951904,
      "logps/chosen": -971.2052001953125,
      "logps/rejected": -1309.93212890625,
      "loss": 0.1076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7525897026062012,
      "rewards/margins": 3.956407308578491,
      "rewards/rejected": -4.708996772766113,
      "step": 344
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.7292812466621399,
      "learning_rate": 2.2480000000000003e-06,
      "logits/chosen": -2.2865076065063477,
      "logits/rejected": -2.3866095542907715,
      "logps/chosen": -977.9734497070312,
      "logps/rejected": -1600.2474365234375,
      "loss": 0.0738,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8253114223480225,
      "rewards/margins": 4.3096747398376465,
      "rewards/rejected": -5.13498592376709,
      "step": 345
    },
    {
      "epoch": 0.5536,
      "grad_norm": 1.8103628158569336,
      "learning_rate": 2.24e-06,
      "logits/chosen": -2.416804552078247,
      "logits/rejected": -2.397423267364502,
      "logps/chosen": -1198.89306640625,
      "logps/rejected": -1623.44384765625,
      "loss": 0.1553,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8880279660224915,
      "rewards/margins": 3.695136785507202,
      "rewards/rejected": -4.583164691925049,
      "step": 346
    },
    {
      "epoch": 0.5552,
      "grad_norm": 1.4918632507324219,
      "learning_rate": 2.2320000000000004e-06,
      "logits/chosen": -2.3363633155822754,
      "logits/rejected": -2.418962001800537,
      "logps/chosen": -882.3782348632812,
      "logps/rejected": -1233.9736328125,
      "loss": 0.1658,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0782603025436401,
      "rewards/margins": 2.678027391433716,
      "rewards/rejected": -3.7562875747680664,
      "step": 347
    },
    {
      "epoch": 0.5568,
      "grad_norm": 2.7069294452667236,
      "learning_rate": 2.2240000000000002e-06,
      "logits/chosen": -2.364607334136963,
      "logits/rejected": -2.322779655456543,
      "logps/chosen": -1323.7772216796875,
      "logps/rejected": -1464.40625,
      "loss": 0.2133,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1830989122390747,
      "rewards/margins": 2.7822811603546143,
      "rewards/rejected": -3.9653806686401367,
      "step": 348
    },
    {
      "epoch": 0.5584,
      "grad_norm": 1.1741619110107422,
      "learning_rate": 2.216e-06,
      "logits/chosen": -2.23396372795105,
      "logits/rejected": -2.3480429649353027,
      "logps/chosen": -1376.1134033203125,
      "logps/rejected": -1845.94970703125,
      "loss": 0.1085,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4186904728412628,
      "rewards/margins": 3.9563989639282227,
      "rewards/rejected": -4.375089645385742,
      "step": 349
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.016902446746826,
      "learning_rate": 2.2080000000000003e-06,
      "logits/chosen": -2.2764623165130615,
      "logits/rejected": -2.3886771202087402,
      "logps/chosen": -801.7633666992188,
      "logps/rejected": -1729.7454833984375,
      "loss": 0.107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0321636199951172,
      "rewards/margins": 4.178743839263916,
      "rewards/rejected": -5.210906982421875,
      "step": 350
    },
    {
      "epoch": 0.5616,
      "grad_norm": 0.9792308807373047,
      "learning_rate": 2.2e-06,
      "logits/chosen": -2.4096877574920654,
      "logits/rejected": -2.3715338706970215,
      "logps/chosen": -1374.73095703125,
      "logps/rejected": -2134.32373046875,
      "loss": 0.0881,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4553464651107788,
      "rewards/margins": 4.777137279510498,
      "rewards/rejected": -6.232484340667725,
      "step": 351
    },
    {
      "epoch": 0.5632,
      "grad_norm": 0.8168057203292847,
      "learning_rate": 2.1920000000000004e-06,
      "logits/chosen": -2.1291091442108154,
      "logits/rejected": -2.2321765422821045,
      "logps/chosen": -1064.6097412109375,
      "logps/rejected": -1546.6334228515625,
      "loss": 0.1162,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.053603656589984894,
      "rewards/margins": 4.40915060043335,
      "rewards/rejected": -4.3555474281311035,
      "step": 352
    },
    {
      "epoch": 0.5648,
      "grad_norm": 3.734422445297241,
      "learning_rate": 2.184e-06,
      "logits/chosen": -2.3776466846466064,
      "logits/rejected": -2.4464874267578125,
      "logps/chosen": -1238.431396484375,
      "logps/rejected": -2351.3271484375,
      "loss": 0.2537,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.1507774591445923,
      "rewards/margins": 6.503170490264893,
      "rewards/rejected": -7.653946876525879,
      "step": 353
    },
    {
      "epoch": 0.5664,
      "grad_norm": 3.7391490936279297,
      "learning_rate": 2.176e-06,
      "logits/chosen": -2.4038968086242676,
      "logits/rejected": -2.391253709793091,
      "logps/chosen": -1224.521484375,
      "logps/rejected": -1765.010498046875,
      "loss": 0.2384,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.7622772455215454,
      "rewards/margins": 4.137903213500977,
      "rewards/rejected": -5.900181293487549,
      "step": 354
    },
    {
      "epoch": 0.568,
      "grad_norm": 2.081941843032837,
      "learning_rate": 2.1680000000000002e-06,
      "logits/chosen": -2.3610713481903076,
      "logits/rejected": -2.418074131011963,
      "logps/chosen": -1240.1072998046875,
      "logps/rejected": -1699.4207763671875,
      "loss": 0.1255,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3085365295410156,
      "rewards/margins": 3.320201873779297,
      "rewards/rejected": -4.628738880157471,
      "step": 355
    },
    {
      "epoch": 0.5696,
      "grad_norm": 4.013101577758789,
      "learning_rate": 2.16e-06,
      "logits/chosen": -2.2468106746673584,
      "logits/rejected": -2.2700488567352295,
      "logps/chosen": -941.3868408203125,
      "logps/rejected": -1550.168701171875,
      "loss": 0.2654,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.0012202262878418,
      "rewards/margins": 3.668665885925293,
      "rewards/rejected": -4.669886112213135,
      "step": 356
    },
    {
      "epoch": 0.5712,
      "grad_norm": 2.9938321113586426,
      "learning_rate": 2.1520000000000003e-06,
      "logits/chosen": -2.375196695327759,
      "logits/rejected": -2.382920026779175,
      "logps/chosen": -1014.4444580078125,
      "logps/rejected": -1468.8592529296875,
      "loss": 0.1878,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.3439459800720215,
      "rewards/margins": 2.8485262393951416,
      "rewards/rejected": -4.192472457885742,
      "step": 357
    },
    {
      "epoch": 0.5728,
      "grad_norm": 3.699941873550415,
      "learning_rate": 2.144e-06,
      "logits/chosen": -2.176372528076172,
      "logits/rejected": -2.2952091693878174,
      "logps/chosen": -880.74169921875,
      "logps/rejected": -1468.56884765625,
      "loss": 0.2523,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.1333783864974976,
      "rewards/margins": 3.996020793914795,
      "rewards/rejected": -5.129399299621582,
      "step": 358
    },
    {
      "epoch": 0.5744,
      "grad_norm": 0.6317238807678223,
      "learning_rate": 2.1360000000000004e-06,
      "logits/chosen": -2.355201482772827,
      "logits/rejected": -2.28916072845459,
      "logps/chosen": -1488.5599365234375,
      "logps/rejected": -2134.927734375,
      "loss": 0.046,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2996128797531128,
      "rewards/margins": 4.6003522872924805,
      "rewards/rejected": -5.899964809417725,
      "step": 359
    },
    {
      "epoch": 0.576,
      "grad_norm": 5.325170993804932,
      "learning_rate": 2.128e-06,
      "logits/chosen": -2.397275686264038,
      "logits/rejected": -2.425493001937866,
      "logps/chosen": -1317.5260009765625,
      "logps/rejected": -1870.3538818359375,
      "loss": 0.2602,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.4008829593658447,
      "rewards/margins": 3.8045499324798584,
      "rewards/rejected": -5.205432891845703,
      "step": 360
    },
    {
      "epoch": 0.5776,
      "grad_norm": 1.3182774782180786,
      "learning_rate": 2.12e-06,
      "logits/chosen": -2.128845691680908,
      "logits/rejected": -2.269840717315674,
      "logps/chosen": -862.1177978515625,
      "logps/rejected": -1631.696533203125,
      "loss": 0.0873,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8780878782272339,
      "rewards/margins": 4.284730434417725,
      "rewards/rejected": -5.162817478179932,
      "step": 361
    },
    {
      "epoch": 0.5792,
      "grad_norm": 3.9851136207580566,
      "learning_rate": 2.1120000000000003e-06,
      "logits/chosen": -2.267002582550049,
      "logits/rejected": -2.276033639907837,
      "logps/chosen": -1003.1756591796875,
      "logps/rejected": -1605.441162109375,
      "loss": 0.1702,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.8555251359939575,
      "rewards/margins": 4.492643356323242,
      "rewards/rejected": -5.34816837310791,
      "step": 362
    },
    {
      "epoch": 0.5808,
      "grad_norm": 0.5496670603752136,
      "learning_rate": 2.104e-06,
      "logits/chosen": -2.2736423015594482,
      "logits/rejected": -2.3194515705108643,
      "logps/chosen": -1149.72216796875,
      "logps/rejected": -2063.988037109375,
      "loss": 0.0491,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.153033971786499,
      "rewards/margins": 4.790014266967773,
      "rewards/rejected": -5.943048477172852,
      "step": 363
    },
    {
      "epoch": 0.5824,
      "grad_norm": 0.7612152695655823,
      "learning_rate": 2.0960000000000003e-06,
      "logits/chosen": -2.350778579711914,
      "logits/rejected": -2.3460044860839844,
      "logps/chosen": -1402.6444091796875,
      "logps/rejected": -2927.095458984375,
      "loss": 0.0586,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4074079990386963,
      "rewards/margins": 6.298969745635986,
      "rewards/rejected": -7.706377983093262,
      "step": 364
    },
    {
      "epoch": 0.584,
      "grad_norm": 1.7600831985473633,
      "learning_rate": 2.088e-06,
      "logits/chosen": -2.158608913421631,
      "logits/rejected": -2.364793062210083,
      "logps/chosen": -1005.83154296875,
      "logps/rejected": -1764.16748046875,
      "loss": 0.1375,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.7255558371543884,
      "rewards/margins": 3.6609482765197754,
      "rewards/rejected": -4.386504173278809,
      "step": 365
    },
    {
      "epoch": 0.5856,
      "grad_norm": 0.6165664792060852,
      "learning_rate": 2.08e-06,
      "logits/chosen": -2.2303287982940674,
      "logits/rejected": -2.2599761486053467,
      "logps/chosen": -1329.4615478515625,
      "logps/rejected": -1860.642822265625,
      "loss": 0.0407,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5648590326309204,
      "rewards/margins": 5.725686073303223,
      "rewards/rejected": -6.290545463562012,
      "step": 366
    },
    {
      "epoch": 0.5872,
      "grad_norm": 1.2105417251586914,
      "learning_rate": 2.0720000000000002e-06,
      "logits/chosen": -2.2394111156463623,
      "logits/rejected": -2.3404579162597656,
      "logps/chosen": -881.3046264648438,
      "logps/rejected": -1873.0081787109375,
      "loss": 0.1216,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0156636238098145,
      "rewards/margins": 4.124919891357422,
      "rewards/rejected": -5.140583038330078,
      "step": 367
    },
    {
      "epoch": 0.5888,
      "grad_norm": 4.255702495574951,
      "learning_rate": 2.064e-06,
      "logits/chosen": -2.211703300476074,
      "logits/rejected": -2.2611184120178223,
      "logps/chosen": -1484.15771484375,
      "logps/rejected": -1949.6318359375,
      "loss": 0.1671,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.79097318649292,
      "rewards/margins": 4.7864556312561035,
      "rewards/rejected": -6.577429294586182,
      "step": 368
    },
    {
      "epoch": 0.5904,
      "grad_norm": 0.7669296264648438,
      "learning_rate": 2.0560000000000003e-06,
      "logits/chosen": -2.2797389030456543,
      "logits/rejected": -2.3039300441741943,
      "logps/chosen": -643.1683349609375,
      "logps/rejected": -2017.977783203125,
      "loss": 0.0676,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.44919779896736145,
      "rewards/margins": 4.597718238830566,
      "rewards/rejected": -5.046915531158447,
      "step": 369
    },
    {
      "epoch": 0.592,
      "grad_norm": 3.3199896812438965,
      "learning_rate": 2.048e-06,
      "logits/chosen": -2.3310210704803467,
      "logits/rejected": -2.4265787601470947,
      "logps/chosen": -1116.7064208984375,
      "logps/rejected": -1205.535888671875,
      "loss": 0.2144,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.151732325553894,
      "rewards/margins": 2.490880250930786,
      "rewards/rejected": -3.6426126956939697,
      "step": 370
    },
    {
      "epoch": 0.5936,
      "grad_norm": 0.6381871104240417,
      "learning_rate": 2.04e-06,
      "logits/chosen": -2.259104013442993,
      "logits/rejected": -2.3242926597595215,
      "logps/chosen": -915.3543701171875,
      "logps/rejected": -1610.6466064453125,
      "loss": 0.0477,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1526100635528564,
      "rewards/margins": 4.729567050933838,
      "rewards/rejected": -5.882176876068115,
      "step": 371
    },
    {
      "epoch": 0.5952,
      "grad_norm": 2.3969736099243164,
      "learning_rate": 2.032e-06,
      "logits/chosen": -2.147536516189575,
      "logits/rejected": -2.2656748294830322,
      "logps/chosen": -797.3237915039062,
      "logps/rejected": -1746.1845703125,
      "loss": 0.1592,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.4551101624965668,
      "rewards/margins": 4.80354118347168,
      "rewards/rejected": -5.258650779724121,
      "step": 372
    },
    {
      "epoch": 0.5968,
      "grad_norm": 2.0883607864379883,
      "learning_rate": 2.024e-06,
      "logits/chosen": -2.2148449420928955,
      "logits/rejected": -2.284162759780884,
      "logps/chosen": -955.0655517578125,
      "logps/rejected": -1232.70556640625,
      "loss": 0.1537,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1163387298583984,
      "rewards/margins": 3.1991934776306152,
      "rewards/rejected": -4.315532207489014,
      "step": 373
    },
    {
      "epoch": 0.5984,
      "grad_norm": 2.3591344356536865,
      "learning_rate": 2.0160000000000003e-06,
      "logits/chosen": -2.233175754547119,
      "logits/rejected": -2.3366756439208984,
      "logps/chosen": -1274.18603515625,
      "logps/rejected": -1817.1549072265625,
      "loss": 0.0925,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2959518432617188,
      "rewards/margins": 4.680158615112305,
      "rewards/rejected": -5.976110458374023,
      "step": 374
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.5701839923858643,
      "learning_rate": 2.008e-06,
      "logits/chosen": -2.170339584350586,
      "logits/rejected": -2.3263533115386963,
      "logps/chosen": -754.0623168945312,
      "logps/rejected": -1446.16650390625,
      "loss": 0.1402,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7925085425376892,
      "rewards/margins": 3.540578842163086,
      "rewards/rejected": -4.333087921142578,
      "step": 375
    },
    {
      "epoch": 0.6016,
      "grad_norm": 5.43128776550293,
      "learning_rate": 2.0000000000000003e-06,
      "logits/chosen": -2.287191390991211,
      "logits/rejected": -2.292841672897339,
      "logps/chosen": -629.5521850585938,
      "logps/rejected": -1355.492919921875,
      "loss": 0.1203,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0423136949539185,
      "rewards/margins": 4.13589334487915,
      "rewards/rejected": -5.178206920623779,
      "step": 376
    },
    {
      "epoch": 0.6032,
      "grad_norm": 7.097494125366211,
      "learning_rate": 1.992e-06,
      "logits/chosen": -2.3602519035339355,
      "logits/rejected": -2.3324079513549805,
      "logps/chosen": -1247.4423828125,
      "logps/rejected": -1931.818603515625,
      "loss": 0.4845,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.7321299314498901,
      "rewards/margins": 3.7227606773376465,
      "rewards/rejected": -5.454890727996826,
      "step": 377
    },
    {
      "epoch": 0.6048,
      "grad_norm": 1.1362791061401367,
      "learning_rate": 1.984e-06,
      "logits/chosen": -2.186042547225952,
      "logits/rejected": -2.3729419708251953,
      "logps/chosen": -640.665283203125,
      "logps/rejected": -1131.2662353515625,
      "loss": 0.1083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7004680037498474,
      "rewards/margins": 3.8966727256774902,
      "rewards/rejected": -4.597140789031982,
      "step": 378
    },
    {
      "epoch": 0.6064,
      "grad_norm": 1.3543787002563477,
      "learning_rate": 1.9760000000000002e-06,
      "logits/chosen": -2.4102346897125244,
      "logits/rejected": -2.4629299640655518,
      "logps/chosen": -1079.481689453125,
      "logps/rejected": -1650.786865234375,
      "loss": 0.0812,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1004178524017334,
      "rewards/margins": 3.8594284057617188,
      "rewards/rejected": -4.959846019744873,
      "step": 379
    },
    {
      "epoch": 0.608,
      "grad_norm": 2.9528234004974365,
      "learning_rate": 1.968e-06,
      "logits/chosen": -2.260512590408325,
      "logits/rejected": -2.3463499546051025,
      "logps/chosen": -867.8685913085938,
      "logps/rejected": -1198.185546875,
      "loss": 0.2393,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.9193714261054993,
      "rewards/margins": 3.007520914077759,
      "rewards/rejected": -3.9268922805786133,
      "step": 380
    },
    {
      "epoch": 0.6096,
      "grad_norm": 1.6870479583740234,
      "learning_rate": 1.9600000000000003e-06,
      "logits/chosen": -2.23342227935791,
      "logits/rejected": -2.350520133972168,
      "logps/chosen": -708.6548461914062,
      "logps/rejected": -1296.975341796875,
      "loss": 0.1502,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9860678315162659,
      "rewards/margins": 2.939246654510498,
      "rewards/rejected": -3.925314426422119,
      "step": 381
    },
    {
      "epoch": 0.6112,
      "grad_norm": 1.5209406614303589,
      "learning_rate": 1.952e-06,
      "logits/chosen": -2.322134017944336,
      "logits/rejected": -2.4008195400238037,
      "logps/chosen": -915.54541015625,
      "logps/rejected": -1611.212890625,
      "loss": 0.1196,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9269262552261353,
      "rewards/margins": 4.314513683319092,
      "rewards/rejected": -5.2414398193359375,
      "step": 382
    },
    {
      "epoch": 0.6128,
      "grad_norm": 3.4364981651306152,
      "learning_rate": 1.944e-06,
      "logits/chosen": -2.2134666442871094,
      "logits/rejected": -2.3398001194000244,
      "logps/chosen": -895.4457397460938,
      "logps/rejected": -1605.0267333984375,
      "loss": 0.2334,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.660555362701416,
      "rewards/margins": 4.626175880432129,
      "rewards/rejected": -5.286731243133545,
      "step": 383
    },
    {
      "epoch": 0.6144,
      "grad_norm": 0.8772640824317932,
      "learning_rate": 1.936e-06,
      "logits/chosen": -2.229003667831421,
      "logits/rejected": -2.2770497798919678,
      "logps/chosen": -509.9969787597656,
      "logps/rejected": -1131.3944091796875,
      "loss": 0.125,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7795071005821228,
      "rewards/margins": 3.6793508529663086,
      "rewards/rejected": -4.458858489990234,
      "step": 384
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.6366260051727295,
      "learning_rate": 1.928e-06,
      "logits/chosen": -2.256129264831543,
      "logits/rejected": -2.3286166191101074,
      "logps/chosen": -534.4093017578125,
      "logps/rejected": -1678.037109375,
      "loss": 0.062,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8617600202560425,
      "rewards/margins": 6.084475040435791,
      "rewards/rejected": -6.946234703063965,
      "step": 385
    },
    {
      "epoch": 0.6176,
      "grad_norm": 1.3211946487426758,
      "learning_rate": 1.9200000000000003e-06,
      "logits/chosen": -2.2656126022338867,
      "logits/rejected": -2.3405838012695312,
      "logps/chosen": -1077.129150390625,
      "logps/rejected": -1844.0570068359375,
      "loss": 0.0641,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9850714206695557,
      "rewards/margins": 4.977387428283691,
      "rewards/rejected": -5.962459087371826,
      "step": 386
    },
    {
      "epoch": 0.6192,
      "grad_norm": 1.8819602727890015,
      "learning_rate": 1.912e-06,
      "logits/chosen": -2.2828691005706787,
      "logits/rejected": -2.369767665863037,
      "logps/chosen": -1112.8797607421875,
      "logps/rejected": -1409.190673828125,
      "loss": 0.231,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3693550825119019,
      "rewards/margins": 3.260605812072754,
      "rewards/rejected": -4.629960536956787,
      "step": 387
    },
    {
      "epoch": 0.6208,
      "grad_norm": 0.8562042713165283,
      "learning_rate": 1.9040000000000003e-06,
      "logits/chosen": -1.9444820880889893,
      "logits/rejected": -2.088411331176758,
      "logps/chosen": -1155.098876953125,
      "logps/rejected": -2386.57421875,
      "loss": 0.0541,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8127703666687012,
      "rewards/margins": 6.961055278778076,
      "rewards/rejected": -7.773825168609619,
      "step": 388
    },
    {
      "epoch": 0.6224,
      "grad_norm": 0.8123158812522888,
      "learning_rate": 1.8960000000000001e-06,
      "logits/chosen": -2.093010902404785,
      "logits/rejected": -2.2785212993621826,
      "logps/chosen": -941.0057373046875,
      "logps/rejected": -1556.8955078125,
      "loss": 0.0922,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9425545930862427,
      "rewards/margins": 4.627925395965576,
      "rewards/rejected": -5.570479869842529,
      "step": 389
    },
    {
      "epoch": 0.624,
      "grad_norm": 2.4496347904205322,
      "learning_rate": 1.8880000000000002e-06,
      "logits/chosen": -2.2732644081115723,
      "logits/rejected": -2.291476249694824,
      "logps/chosen": -1438.26171875,
      "logps/rejected": -1518.6058349609375,
      "loss": 0.1415,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1805720329284668,
      "rewards/margins": 3.0164976119995117,
      "rewards/rejected": -4.1970696449279785,
      "step": 390
    },
    {
      "epoch": 0.6256,
      "grad_norm": 3.0189476013183594,
      "learning_rate": 1.8800000000000002e-06,
      "logits/chosen": -2.213153123855591,
      "logits/rejected": -2.2917487621307373,
      "logps/chosen": -894.4783325195312,
      "logps/rejected": -1624.792236328125,
      "loss": 0.2531,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.8972765207290649,
      "rewards/margins": 3.595445156097412,
      "rewards/rejected": -4.4927215576171875,
      "step": 391
    },
    {
      "epoch": 0.6272,
      "grad_norm": 0.9058298468589783,
      "learning_rate": 1.8720000000000002e-06,
      "logits/chosen": -2.3628883361816406,
      "logits/rejected": -2.4041922092437744,
      "logps/chosen": -921.5757446289062,
      "logps/rejected": -1375.3199462890625,
      "loss": 0.0829,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9267483949661255,
      "rewards/margins": 4.231340408325195,
      "rewards/rejected": -5.1580891609191895,
      "step": 392
    },
    {
      "epoch": 0.6288,
      "grad_norm": 2.139892101287842,
      "learning_rate": 1.8640000000000003e-06,
      "logits/chosen": -2.2990469932556152,
      "logits/rejected": -2.341750383377075,
      "logps/chosen": -1229.0594482421875,
      "logps/rejected": -1853.396240234375,
      "loss": 0.1242,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0755921602249146,
      "rewards/margins": 4.747681617736816,
      "rewards/rejected": -5.823273658752441,
      "step": 393
    },
    {
      "epoch": 0.6304,
      "grad_norm": 0.8144043684005737,
      "learning_rate": 1.856e-06,
      "logits/chosen": -2.1958160400390625,
      "logits/rejected": -2.2804367542266846,
      "logps/chosen": -1368.1171875,
      "logps/rejected": -2336.65673828125,
      "loss": 0.0845,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7616231441497803,
      "rewards/margins": 5.552434921264648,
      "rewards/rejected": -6.314058780670166,
      "step": 394
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.7646900415420532,
      "learning_rate": 1.8480000000000001e-06,
      "logits/chosen": -2.2373225688934326,
      "logits/rejected": -2.3497986793518066,
      "logps/chosen": -934.7181396484375,
      "logps/rejected": -2335.582275390625,
      "loss": 0.0335,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1370823383331299,
      "rewards/margins": 7.5168843269348145,
      "rewards/rejected": -8.653966903686523,
      "step": 395
    },
    {
      "epoch": 0.6336,
      "grad_norm": 1.2914094924926758,
      "learning_rate": 1.8400000000000002e-06,
      "logits/chosen": -2.3804049491882324,
      "logits/rejected": -2.389370918273926,
      "logps/chosen": -797.6551513671875,
      "logps/rejected": -1299.812744140625,
      "loss": 0.1248,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8308320641517639,
      "rewards/margins": 4.069215297698975,
      "rewards/rejected": -4.9000468254089355,
      "step": 396
    },
    {
      "epoch": 0.6352,
      "grad_norm": 4.505801677703857,
      "learning_rate": 1.8320000000000002e-06,
      "logits/chosen": -2.3576369285583496,
      "logits/rejected": -2.460681676864624,
      "logps/chosen": -1256.959228515625,
      "logps/rejected": -1740.326904296875,
      "loss": 0.2227,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.4916973114013672,
      "rewards/margins": 3.507286310195923,
      "rewards/rejected": -4.998983860015869,
      "step": 397
    },
    {
      "epoch": 0.6368,
      "grad_norm": 1.898087978363037,
      "learning_rate": 1.8240000000000002e-06,
      "logits/chosen": -2.4187378883361816,
      "logits/rejected": -2.3882193565368652,
      "logps/chosen": -856.8004760742188,
      "logps/rejected": -1281.154541015625,
      "loss": 0.1315,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.8601682186126709,
      "rewards/margins": 3.8091702461242676,
      "rewards/rejected": -4.669338703155518,
      "step": 398
    },
    {
      "epoch": 0.6384,
      "grad_norm": 1.373468279838562,
      "learning_rate": 1.8160000000000003e-06,
      "logits/chosen": -2.3425135612487793,
      "logits/rejected": -2.354597806930542,
      "logps/chosen": -762.8995361328125,
      "logps/rejected": -1230.962646484375,
      "loss": 0.1025,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.056645154953003,
      "rewards/margins": 4.002908706665039,
      "rewards/rejected": -5.059554100036621,
      "step": 399
    },
    {
      "epoch": 0.64,
      "grad_norm": 10.554110527038574,
      "learning_rate": 1.808e-06,
      "logits/chosen": -2.2668092250823975,
      "logits/rejected": -2.3818142414093018,
      "logps/chosen": -1656.650146484375,
      "logps/rejected": -1733.9586181640625,
      "loss": 0.3658,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.1276445388793945,
      "rewards/margins": 2.4131295680999756,
      "rewards/rejected": -4.540773868560791,
      "step": 400
    },
    {
      "epoch": 0.6416,
      "grad_norm": 4.60828161239624,
      "learning_rate": 1.8000000000000001e-06,
      "logits/chosen": -2.2330830097198486,
      "logits/rejected": -2.315161943435669,
      "logps/chosen": -930.0046997070312,
      "logps/rejected": -1348.1605224609375,
      "loss": 0.3389,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.34390127658844,
      "rewards/margins": 3.084831953048706,
      "rewards/rejected": -4.4287333488464355,
      "step": 401
    },
    {
      "epoch": 0.6432,
      "grad_norm": 0.5496054887771606,
      "learning_rate": 1.7920000000000002e-06,
      "logits/chosen": -2.263399362564087,
      "logits/rejected": -2.4280478954315186,
      "logps/chosen": -1586.84375,
      "logps/rejected": -2365.695556640625,
      "loss": 0.0249,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0233869552612305,
      "rewards/margins": 5.178032398223877,
      "rewards/rejected": -6.201419353485107,
      "step": 402
    },
    {
      "epoch": 0.6448,
      "grad_norm": 1.6666995286941528,
      "learning_rate": 1.7840000000000002e-06,
      "logits/chosen": -2.3220062255859375,
      "logits/rejected": -2.2840940952301025,
      "logps/chosen": -1105.5235595703125,
      "logps/rejected": -2031.7413330078125,
      "loss": 0.0951,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.277389645576477,
      "rewards/margins": 4.217012882232666,
      "rewards/rejected": -5.494401931762695,
      "step": 403
    },
    {
      "epoch": 0.6464,
      "grad_norm": 2.653634548187256,
      "learning_rate": 1.7760000000000002e-06,
      "logits/chosen": -2.370051145553589,
      "logits/rejected": -2.3203277587890625,
      "logps/chosen": -1336.884765625,
      "logps/rejected": -1884.9368896484375,
      "loss": 0.1667,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.6085141897201538,
      "rewards/margins": 4.143807411193848,
      "rewards/rejected": -5.752321243286133,
      "step": 404
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.7935120463371277,
      "learning_rate": 1.7680000000000003e-06,
      "logits/chosen": -2.2257020473480225,
      "logits/rejected": -2.3873116970062256,
      "logps/chosen": -912.4197998046875,
      "logps/rejected": -1553.4281005859375,
      "loss": 0.0707,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7340429425239563,
      "rewards/margins": 4.022477149963379,
      "rewards/rejected": -4.756519794464111,
      "step": 405
    },
    {
      "epoch": 0.6496,
      "grad_norm": 4.976451873779297,
      "learning_rate": 1.76e-06,
      "logits/chosen": -2.319608211517334,
      "logits/rejected": -2.3354289531707764,
      "logps/chosen": -2406.969970703125,
      "logps/rejected": -2296.0263671875,
      "loss": 0.2184,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.3245060443878174,
      "rewards/margins": 4.427926063537598,
      "rewards/rejected": -6.752432346343994,
      "step": 406
    },
    {
      "epoch": 0.6512,
      "grad_norm": 2.1540327072143555,
      "learning_rate": 1.7520000000000001e-06,
      "logits/chosen": -2.355921983718872,
      "logits/rejected": -2.439409017562866,
      "logps/chosen": -1075.0784912109375,
      "logps/rejected": -1810.1795654296875,
      "loss": 0.099,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2167010307312012,
      "rewards/margins": 4.079712867736816,
      "rewards/rejected": -5.296413898468018,
      "step": 407
    },
    {
      "epoch": 0.6528,
      "grad_norm": 4.601476669311523,
      "learning_rate": 1.7440000000000002e-06,
      "logits/chosen": -2.2922720909118652,
      "logits/rejected": -2.289181709289551,
      "logps/chosen": -922.196044921875,
      "logps/rejected": -1482.0010986328125,
      "loss": 0.1883,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.6057624816894531,
      "rewards/margins": 4.701848983764648,
      "rewards/rejected": -6.30761194229126,
      "step": 408
    },
    {
      "epoch": 0.6544,
      "grad_norm": 3.212632417678833,
      "learning_rate": 1.7360000000000002e-06,
      "logits/chosen": -2.413313865661621,
      "logits/rejected": -2.402071237564087,
      "logps/chosen": -1474.8597412109375,
      "logps/rejected": -1716.85009765625,
      "loss": 0.151,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5867571830749512,
      "rewards/margins": 2.831742763519287,
      "rewards/rejected": -4.418499946594238,
      "step": 409
    },
    {
      "epoch": 0.656,
      "grad_norm": 1.0136011838912964,
      "learning_rate": 1.7280000000000002e-06,
      "logits/chosen": -2.3743999004364014,
      "logits/rejected": -2.3693501949310303,
      "logps/chosen": -888.6724853515625,
      "logps/rejected": -1556.069580078125,
      "loss": 0.102,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.017176628112793,
      "rewards/margins": 5.150139808654785,
      "rewards/rejected": -6.167316436767578,
      "step": 410
    },
    {
      "epoch": 0.6576,
      "grad_norm": 4.498985290527344,
      "learning_rate": 1.72e-06,
      "logits/chosen": -2.3196301460266113,
      "logits/rejected": -2.2739570140838623,
      "logps/chosen": -889.5922241210938,
      "logps/rejected": -1330.866455078125,
      "loss": 0.447,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.1758846044540405,
      "rewards/margins": 3.1008737087249756,
      "rewards/rejected": -4.276758193969727,
      "step": 411
    },
    {
      "epoch": 0.6592,
      "grad_norm": 1.1408456563949585,
      "learning_rate": 1.712e-06,
      "logits/chosen": -2.361551523208618,
      "logits/rejected": -2.3864059448242188,
      "logps/chosen": -850.0181884765625,
      "logps/rejected": -1880.82568359375,
      "loss": 0.0603,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9565879106521606,
      "rewards/margins": 4.5682196617126465,
      "rewards/rejected": -5.524807929992676,
      "step": 412
    },
    {
      "epoch": 0.6608,
      "grad_norm": 2.3350117206573486,
      "learning_rate": 1.7040000000000001e-06,
      "logits/chosen": -2.11580491065979,
      "logits/rejected": -2.1341536045074463,
      "logps/chosen": -1497.11279296875,
      "logps/rejected": -2021.069091796875,
      "loss": 0.1719,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.8128679990768433,
      "rewards/margins": 4.302242279052734,
      "rewards/rejected": -5.115110397338867,
      "step": 413
    },
    {
      "epoch": 0.6624,
      "grad_norm": 1.275847315788269,
      "learning_rate": 1.6960000000000002e-06,
      "logits/chosen": -2.232941150665283,
      "logits/rejected": -2.176527976989746,
      "logps/chosen": -979.1910400390625,
      "logps/rejected": -2029.38037109375,
      "loss": 0.1148,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8519943952560425,
      "rewards/margins": 4.790923118591309,
      "rewards/rejected": -5.642917156219482,
      "step": 414
    },
    {
      "epoch": 0.664,
      "grad_norm": 1.544653058052063,
      "learning_rate": 1.6880000000000002e-06,
      "logits/chosen": -2.2413082122802734,
      "logits/rejected": -2.383060932159424,
      "logps/chosen": -648.233642578125,
      "logps/rejected": -1412.842529296875,
      "loss": 0.1369,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.5905019044876099,
      "rewards/margins": 3.7636117935180664,
      "rewards/rejected": -4.354113578796387,
      "step": 415
    },
    {
      "epoch": 0.6656,
      "grad_norm": 3.244699716567993,
      "learning_rate": 1.6800000000000002e-06,
      "logits/chosen": -2.2777438163757324,
      "logits/rejected": -2.3132524490356445,
      "logps/chosen": -934.667724609375,
      "logps/rejected": -1555.0655517578125,
      "loss": 0.2281,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9681486487388611,
      "rewards/margins": 4.6713738441467285,
      "rewards/rejected": -5.639522552490234,
      "step": 416
    },
    {
      "epoch": 0.6672,
      "grad_norm": 2.5060312747955322,
      "learning_rate": 1.672e-06,
      "logits/chosen": -2.2807581424713135,
      "logits/rejected": -2.219395160675049,
      "logps/chosen": -1523.8626708984375,
      "logps/rejected": -2191.570068359375,
      "loss": 0.0942,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.4093364477157593,
      "rewards/margins": 6.286198139190674,
      "rewards/rejected": -7.695534706115723,
      "step": 417
    },
    {
      "epoch": 0.6688,
      "grad_norm": 1.8312666416168213,
      "learning_rate": 1.664e-06,
      "logits/chosen": -2.0675148963928223,
      "logits/rejected": -2.1317944526672363,
      "logps/chosen": -1090.204833984375,
      "logps/rejected": -2027.1234130859375,
      "loss": 0.0838,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4303255081176758,
      "rewards/margins": 4.591286659240723,
      "rewards/rejected": -5.02161169052124,
      "step": 418
    },
    {
      "epoch": 0.6704,
      "grad_norm": 4.667079925537109,
      "learning_rate": 1.6560000000000001e-06,
      "logits/chosen": -2.376941680908203,
      "logits/rejected": -2.2903225421905518,
      "logps/chosen": -970.0533447265625,
      "logps/rejected": -1365.9158935546875,
      "loss": 0.4397,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.5194064378738403,
      "rewards/margins": 3.250105857849121,
      "rewards/rejected": -4.76951265335083,
      "step": 419
    },
    {
      "epoch": 0.672,
      "grad_norm": 1.414838194847107,
      "learning_rate": 1.6480000000000001e-06,
      "logits/chosen": -2.4186606407165527,
      "logits/rejected": -2.3961849212646484,
      "logps/chosen": -1184.896728515625,
      "logps/rejected": -1777.70361328125,
      "loss": 0.0624,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0718960762023926,
      "rewards/margins": 4.303159713745117,
      "rewards/rejected": -5.375056266784668,
      "step": 420
    },
    {
      "epoch": 0.6736,
      "grad_norm": 2.247047185897827,
      "learning_rate": 1.6400000000000002e-06,
      "logits/chosen": -2.350503444671631,
      "logits/rejected": -2.3371920585632324,
      "logps/chosen": -1057.661865234375,
      "logps/rejected": -1870.739013671875,
      "loss": 0.1154,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.570137858390808,
      "rewards/margins": 5.352241516113281,
      "rewards/rejected": -6.922379493713379,
      "step": 421
    },
    {
      "epoch": 0.6752,
      "grad_norm": 1.5263526439666748,
      "learning_rate": 1.6320000000000002e-06,
      "logits/chosen": -2.3446836471557617,
      "logits/rejected": -2.377920389175415,
      "logps/chosen": -1202.998779296875,
      "logps/rejected": -1727.2127685546875,
      "loss": 0.1118,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.1115577220916748,
      "rewards/margins": 4.7742156982421875,
      "rewards/rejected": -5.885773658752441,
      "step": 422
    },
    {
      "epoch": 0.6768,
      "grad_norm": 2.0686020851135254,
      "learning_rate": 1.624e-06,
      "logits/chosen": -2.393162250518799,
      "logits/rejected": -2.3472089767456055,
      "logps/chosen": -907.3973388671875,
      "logps/rejected": -1076.697509765625,
      "loss": 0.1623,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9768299460411072,
      "rewards/margins": 3.6696529388427734,
      "rewards/rejected": -4.646482944488525,
      "step": 423
    },
    {
      "epoch": 0.6784,
      "grad_norm": 2.7782952785491943,
      "learning_rate": 1.616e-06,
      "logits/chosen": -2.1856658458709717,
      "logits/rejected": -2.38718843460083,
      "logps/chosen": -1201.359130859375,
      "logps/rejected": -1345.022705078125,
      "loss": 0.2438,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.5924890041351318,
      "rewards/margins": 2.308973789215088,
      "rewards/rejected": -3.9014627933502197,
      "step": 424
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.0245201587677,
      "learning_rate": 1.608e-06,
      "logits/chosen": -2.35506534576416,
      "logits/rejected": -2.3701629638671875,
      "logps/chosen": -1269.5308837890625,
      "logps/rejected": -1624.9866943359375,
      "loss": 0.1744,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.7902445793151855,
      "rewards/margins": 3.905231475830078,
      "rewards/rejected": -5.695476055145264,
      "step": 425
    },
    {
      "epoch": 0.6816,
      "grad_norm": 2.292104721069336,
      "learning_rate": 1.6000000000000001e-06,
      "logits/chosen": -2.3742895126342773,
      "logits/rejected": -2.378845453262329,
      "logps/chosen": -937.5547485351562,
      "logps/rejected": -1581.568359375,
      "loss": 0.1526,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3477184772491455,
      "rewards/margins": 3.2227776050567627,
      "rewards/rejected": -4.570496082305908,
      "step": 426
    },
    {
      "epoch": 0.6832,
      "grad_norm": 2.2140069007873535,
      "learning_rate": 1.5920000000000002e-06,
      "logits/chosen": -2.3282053470611572,
      "logits/rejected": -2.4058966636657715,
      "logps/chosen": -1044.7420654296875,
      "logps/rejected": -1728.13671875,
      "loss": 0.0927,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.294947624206543,
      "rewards/margins": 4.423521995544434,
      "rewards/rejected": -5.718469619750977,
      "step": 427
    },
    {
      "epoch": 0.6848,
      "grad_norm": 2.7640738487243652,
      "learning_rate": 1.5840000000000002e-06,
      "logits/chosen": -2.2030742168426514,
      "logits/rejected": -2.3580050468444824,
      "logps/chosen": -1362.5599365234375,
      "logps/rejected": -2062.2255859375,
      "loss": 0.1142,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3111447095870972,
      "rewards/margins": 4.796902656555176,
      "rewards/rejected": -6.1080474853515625,
      "step": 428
    },
    {
      "epoch": 0.6864,
      "grad_norm": 2.126131057739258,
      "learning_rate": 1.576e-06,
      "logits/chosen": -2.3998496532440186,
      "logits/rejected": -2.3944363594055176,
      "logps/chosen": -1449.7884521484375,
      "logps/rejected": -1468.80322265625,
      "loss": 0.144,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3367985486984253,
      "rewards/margins": 3.745988130569458,
      "rewards/rejected": -5.082787036895752,
      "step": 429
    },
    {
      "epoch": 0.688,
      "grad_norm": 5.8186869621276855,
      "learning_rate": 1.568e-06,
      "logits/chosen": -2.336317777633667,
      "logits/rejected": -2.2467715740203857,
      "logps/chosen": -1440.461669921875,
      "logps/rejected": -2649.19189453125,
      "loss": 0.2012,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.7840875387191772,
      "rewards/margins": 4.443249702453613,
      "rewards/rejected": -6.227336883544922,
      "step": 430
    },
    {
      "epoch": 0.6896,
      "grad_norm": 1.262837529182434,
      "learning_rate": 1.56e-06,
      "logits/chosen": -2.386038064956665,
      "logits/rejected": -2.3266777992248535,
      "logps/chosen": -663.759765625,
      "logps/rejected": -1408.241943359375,
      "loss": 0.1038,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9211678504943848,
      "rewards/margins": 4.218903541564941,
      "rewards/rejected": -5.140070915222168,
      "step": 431
    },
    {
      "epoch": 0.6912,
      "grad_norm": 3.6470885276794434,
      "learning_rate": 1.5520000000000001e-06,
      "logits/chosen": -2.3920416831970215,
      "logits/rejected": -2.3272817134857178,
      "logps/chosen": -969.1629638671875,
      "logps/rejected": -1285.828857421875,
      "loss": 0.2176,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.2910008430480957,
      "rewards/margins": 3.4591522216796875,
      "rewards/rejected": -4.750153064727783,
      "step": 432
    },
    {
      "epoch": 0.6928,
      "grad_norm": 2.7649519443511963,
      "learning_rate": 1.5440000000000002e-06,
      "logits/chosen": -2.274606943130493,
      "logits/rejected": -2.4235568046569824,
      "logps/chosen": -970.268310546875,
      "logps/rejected": -1611.625244140625,
      "loss": 0.1915,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.248692274093628,
      "rewards/margins": 4.359468460083008,
      "rewards/rejected": -5.608161449432373,
      "step": 433
    },
    {
      "epoch": 0.6944,
      "grad_norm": 4.554184436798096,
      "learning_rate": 1.536e-06,
      "logits/chosen": -2.367981195449829,
      "logits/rejected": -2.3509931564331055,
      "logps/chosen": -1619.474853515625,
      "logps/rejected": -1791.5618896484375,
      "loss": 0.1325,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.5073318481445312,
      "rewards/margins": 4.370066165924072,
      "rewards/rejected": -5.877398490905762,
      "step": 434
    },
    {
      "epoch": 0.696,
      "grad_norm": 3.4639413356781006,
      "learning_rate": 1.528e-06,
      "logits/chosen": -2.184155225753784,
      "logits/rejected": -2.305737257003784,
      "logps/chosen": -1283.4505615234375,
      "logps/rejected": -1387.570556640625,
      "loss": 0.2009,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.7845950126647949,
      "rewards/margins": 4.316022872924805,
      "rewards/rejected": -5.100617408752441,
      "step": 435
    },
    {
      "epoch": 0.6976,
      "grad_norm": 1.9588234424591064,
      "learning_rate": 1.52e-06,
      "logits/chosen": -2.1326704025268555,
      "logits/rejected": -2.165715217590332,
      "logps/chosen": -973.2789306640625,
      "logps/rejected": -1594.205322265625,
      "loss": 0.1958,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.8486963510513306,
      "rewards/margins": 4.3627800941467285,
      "rewards/rejected": -5.211476802825928,
      "step": 436
    },
    {
      "epoch": 0.6992,
      "grad_norm": 1.2679755687713623,
      "learning_rate": 1.512e-06,
      "logits/chosen": -2.0976147651672363,
      "logits/rejected": -2.2381975650787354,
      "logps/chosen": -742.351318359375,
      "logps/rejected": -1900.9765625,
      "loss": 0.106,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.23864248394966125,
      "rewards/margins": 5.686975955963135,
      "rewards/rejected": -5.925618648529053,
      "step": 437
    },
    {
      "epoch": 0.7008,
      "grad_norm": 1.5302085876464844,
      "learning_rate": 1.5040000000000001e-06,
      "logits/chosen": -2.453341484069824,
      "logits/rejected": -2.4280543327331543,
      "logps/chosen": -795.67236328125,
      "logps/rejected": -1249.961669921875,
      "loss": 0.1425,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.012331247329712,
      "rewards/margins": 4.112851619720459,
      "rewards/rejected": -5.12518310546875,
      "step": 438
    },
    {
      "epoch": 0.7024,
      "grad_norm": 1.460314154624939,
      "learning_rate": 1.4960000000000002e-06,
      "logits/chosen": -2.280134439468384,
      "logits/rejected": -2.3314054012298584,
      "logps/chosen": -685.4276123046875,
      "logps/rejected": -1280.322021484375,
      "loss": 0.136,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6713884472846985,
      "rewards/margins": 4.34824275970459,
      "rewards/rejected": -5.019631862640381,
      "step": 439
    },
    {
      "epoch": 0.704,
      "grad_norm": 2.2453272342681885,
      "learning_rate": 1.488e-06,
      "logits/chosen": -2.3940725326538086,
      "logits/rejected": -2.376437187194824,
      "logps/chosen": -1242.86328125,
      "logps/rejected": -1562.9384765625,
      "loss": 0.1801,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.4724360704421997,
      "rewards/margins": 4.088741302490234,
      "rewards/rejected": -5.561176300048828,
      "step": 440
    },
    {
      "epoch": 0.7056,
      "grad_norm": 1.2330042123794556,
      "learning_rate": 1.48e-06,
      "logits/chosen": -2.2556209564208984,
      "logits/rejected": -2.366342067718506,
      "logps/chosen": -1043.613525390625,
      "logps/rejected": -1687.09716796875,
      "loss": 0.0867,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8042711615562439,
      "rewards/margins": 4.029819965362549,
      "rewards/rejected": -4.834090709686279,
      "step": 441
    },
    {
      "epoch": 0.7072,
      "grad_norm": 5.021358013153076,
      "learning_rate": 1.472e-06,
      "logits/chosen": -2.3265764713287354,
      "logits/rejected": -2.3588201999664307,
      "logps/chosen": -1108.044921875,
      "logps/rejected": -1508.406982421875,
      "loss": 0.1383,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.985996961593628,
      "rewards/margins": 4.492450714111328,
      "rewards/rejected": -6.478448390960693,
      "step": 442
    },
    {
      "epoch": 0.7088,
      "grad_norm": 1.6013526916503906,
      "learning_rate": 1.464e-06,
      "logits/chosen": -2.241305351257324,
      "logits/rejected": -2.251222848892212,
      "logps/chosen": -1197.735107421875,
      "logps/rejected": -1675.99853515625,
      "loss": 0.0818,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.967013418674469,
      "rewards/margins": 5.260478496551514,
      "rewards/rejected": -6.22749137878418,
      "step": 443
    },
    {
      "epoch": 0.7104,
      "grad_norm": 0.960409939289093,
      "learning_rate": 1.4560000000000001e-06,
      "logits/chosen": -2.2852108478546143,
      "logits/rejected": -2.3843095302581787,
      "logps/chosen": -918.3167724609375,
      "logps/rejected": -1512.18359375,
      "loss": 0.1552,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7187216281890869,
      "rewards/margins": 3.654866933822632,
      "rewards/rejected": -4.3735880851745605,
      "step": 444
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.3710903525352478,
      "learning_rate": 1.4480000000000002e-06,
      "logits/chosen": -2.1249382495880127,
      "logits/rejected": -2.2249104976654053,
      "logps/chosen": -1192.301513671875,
      "logps/rejected": -2616.224609375,
      "loss": 0.0207,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2112793922424316,
      "rewards/margins": 7.295681476593018,
      "rewards/rejected": -8.506959915161133,
      "step": 445
    },
    {
      "epoch": 0.7136,
      "grad_norm": 0.7177699208259583,
      "learning_rate": 1.44e-06,
      "logits/chosen": -2.176520586013794,
      "logits/rejected": -2.280819892883301,
      "logps/chosen": -1238.5185546875,
      "logps/rejected": -1779.998779296875,
      "loss": 0.0739,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9007609486579895,
      "rewards/margins": 5.1219940185546875,
      "rewards/rejected": -6.022754669189453,
      "step": 446
    },
    {
      "epoch": 0.7152,
      "grad_norm": 1.4410938024520874,
      "learning_rate": 1.432e-06,
      "logits/chosen": -2.3712611198425293,
      "logits/rejected": -2.3803725242614746,
      "logps/chosen": -700.942626953125,
      "logps/rejected": -1483.2650146484375,
      "loss": 0.1488,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.7493588924407959,
      "rewards/margins": 4.524829864501953,
      "rewards/rejected": -5.27418851852417,
      "step": 447
    },
    {
      "epoch": 0.7168,
      "grad_norm": 0.6514350175857544,
      "learning_rate": 1.424e-06,
      "logits/chosen": -2.307248115539551,
      "logits/rejected": -2.409176826477051,
      "logps/chosen": -1032.9654541015625,
      "logps/rejected": -1546.2696533203125,
      "loss": 0.0652,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1606333255767822,
      "rewards/margins": 4.725781440734863,
      "rewards/rejected": -5.886414527893066,
      "step": 448
    },
    {
      "epoch": 0.7184,
      "grad_norm": 1.7354868650436401,
      "learning_rate": 1.416e-06,
      "logits/chosen": -2.1377952098846436,
      "logits/rejected": -2.235118865966797,
      "logps/chosen": -1149.4925537109375,
      "logps/rejected": -1630.6561279296875,
      "loss": 0.14,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9825867414474487,
      "rewards/margins": 2.6209590435028076,
      "rewards/rejected": -3.603545665740967,
      "step": 449
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.0078917741775513,
      "learning_rate": 1.4080000000000001e-06,
      "logits/chosen": -2.3712618350982666,
      "logits/rejected": -2.377774953842163,
      "logps/chosen": -1033.06591796875,
      "logps/rejected": -1812.4136962890625,
      "loss": 0.0961,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4054527282714844,
      "rewards/margins": 6.059449672698975,
      "rewards/rejected": -7.464901924133301,
      "step": 450
    },
    {
      "epoch": 0.7216,
      "grad_norm": 4.79097318649292,
      "learning_rate": 1.4000000000000001e-06,
      "logits/chosen": -2.3150622844696045,
      "logits/rejected": -2.33811092376709,
      "logps/chosen": -1376.618408203125,
      "logps/rejected": -1839.6943359375,
      "loss": 0.1507,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.7722898721694946,
      "rewards/margins": 3.1533007621765137,
      "rewards/rejected": -4.925590515136719,
      "step": 451
    },
    {
      "epoch": 0.7232,
      "grad_norm": 1.205383539199829,
      "learning_rate": 1.392e-06,
      "logits/chosen": -2.252249240875244,
      "logits/rejected": -2.297431468963623,
      "logps/chosen": -868.712158203125,
      "logps/rejected": -1931.4296875,
      "loss": 0.0658,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4958750009536743,
      "rewards/margins": 5.752316474914551,
      "rewards/rejected": -6.2481913566589355,
      "step": 452
    },
    {
      "epoch": 0.7248,
      "grad_norm": 0.6906717419624329,
      "learning_rate": 1.384e-06,
      "logits/chosen": -2.2235641479492188,
      "logits/rejected": -2.2763969898223877,
      "logps/chosen": -1063.647705078125,
      "logps/rejected": -2057.593994140625,
      "loss": 0.0398,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0381306409835815,
      "rewards/margins": 6.031444072723389,
      "rewards/rejected": -7.069573879241943,
      "step": 453
    },
    {
      "epoch": 0.7264,
      "grad_norm": 1.5388606786727905,
      "learning_rate": 1.376e-06,
      "logits/chosen": -2.325221061706543,
      "logits/rejected": -2.3758749961853027,
      "logps/chosen": -778.589599609375,
      "logps/rejected": -1448.062744140625,
      "loss": 0.145,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9971264004707336,
      "rewards/margins": 4.822598934173584,
      "rewards/rejected": -5.81972599029541,
      "step": 454
    },
    {
      "epoch": 0.728,
      "grad_norm": 1.5796905755996704,
      "learning_rate": 1.368e-06,
      "logits/chosen": -2.3555264472961426,
      "logits/rejected": -2.4144840240478516,
      "logps/chosen": -1205.12060546875,
      "logps/rejected": -2210.2666015625,
      "loss": 0.0528,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4301122426986694,
      "rewards/margins": 5.430172443389893,
      "rewards/rejected": -6.860284328460693,
      "step": 455
    },
    {
      "epoch": 0.7296,
      "grad_norm": 1.644614338874817,
      "learning_rate": 1.3600000000000001e-06,
      "logits/chosen": -2.264543294906616,
      "logits/rejected": -2.2737998962402344,
      "logps/chosen": -1255.5570068359375,
      "logps/rejected": -1962.187255859375,
      "loss": 0.107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6325727701187134,
      "rewards/margins": 5.132905006408691,
      "rewards/rejected": -6.765478610992432,
      "step": 456
    },
    {
      "epoch": 0.7312,
      "grad_norm": 1.5956709384918213,
      "learning_rate": 1.352e-06,
      "logits/chosen": -2.2799363136291504,
      "logits/rejected": -2.324608325958252,
      "logps/chosen": -861.7938842773438,
      "logps/rejected": -1312.5982666015625,
      "loss": 0.1466,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.653172492980957,
      "rewards/margins": 4.176574230194092,
      "rewards/rejected": -4.829746723175049,
      "step": 457
    },
    {
      "epoch": 0.7328,
      "grad_norm": 0.8323774337768555,
      "learning_rate": 1.344e-06,
      "logits/chosen": -2.3517978191375732,
      "logits/rejected": -2.3483970165252686,
      "logps/chosen": -653.4066162109375,
      "logps/rejected": -1992.3839111328125,
      "loss": 0.0673,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.936084508895874,
      "rewards/margins": 4.98081111907959,
      "rewards/rejected": -5.916895389556885,
      "step": 458
    },
    {
      "epoch": 0.7344,
      "grad_norm": 1.2351951599121094,
      "learning_rate": 1.336e-06,
      "logits/chosen": -2.347217082977295,
      "logits/rejected": -2.3192131519317627,
      "logps/chosen": -912.9454956054688,
      "logps/rejected": -2012.312255859375,
      "loss": 0.0907,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.033764362335205,
      "rewards/margins": 6.110687255859375,
      "rewards/rejected": -7.14445161819458,
      "step": 459
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.9953942894935608,
      "learning_rate": 1.328e-06,
      "logits/chosen": -2.0991640090942383,
      "logits/rejected": -2.276815176010132,
      "logps/chosen": -1235.7489013671875,
      "logps/rejected": -2303.1142578125,
      "loss": 0.0513,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5885071754455566,
      "rewards/margins": 6.688479423522949,
      "rewards/rejected": -7.276986122131348,
      "step": 460
    },
    {
      "epoch": 0.7376,
      "grad_norm": 4.291415691375732,
      "learning_rate": 1.32e-06,
      "logits/chosen": -2.212956190109253,
      "logits/rejected": -2.3218302726745605,
      "logps/chosen": -1295.644775390625,
      "logps/rejected": -1572.4041748046875,
      "loss": 0.2739,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0249220132827759,
      "rewards/margins": 4.7550458908081055,
      "rewards/rejected": -5.77996826171875,
      "step": 461
    },
    {
      "epoch": 0.7392,
      "grad_norm": 2.1731960773468018,
      "learning_rate": 1.3120000000000003e-06,
      "logits/chosen": -2.263110637664795,
      "logits/rejected": -2.2902307510375977,
      "logps/chosen": -1259.9495849609375,
      "logps/rejected": -1939.286376953125,
      "loss": 0.1357,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8718286752700806,
      "rewards/margins": 3.9552206993103027,
      "rewards/rejected": -4.827049732208252,
      "step": 462
    },
    {
      "epoch": 0.7408,
      "grad_norm": 0.8598617315292358,
      "learning_rate": 1.304e-06,
      "logits/chosen": -2.3064911365509033,
      "logits/rejected": -2.3960165977478027,
      "logps/chosen": -920.8121948242188,
      "logps/rejected": -1665.1558837890625,
      "loss": 0.0901,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.869936466217041,
      "rewards/margins": 5.186481952667236,
      "rewards/rejected": -6.056417942047119,
      "step": 463
    },
    {
      "epoch": 0.7424,
      "grad_norm": 6.4686360359191895,
      "learning_rate": 1.296e-06,
      "logits/chosen": -2.3031997680664062,
      "logits/rejected": -2.3474361896514893,
      "logps/chosen": -1126.006591796875,
      "logps/rejected": -1575.279296875,
      "loss": 0.4838,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.9458602666854858,
      "rewards/margins": 3.0903396606445312,
      "rewards/rejected": -4.036200046539307,
      "step": 464
    },
    {
      "epoch": 0.744,
      "grad_norm": 2.058363199234009,
      "learning_rate": 1.288e-06,
      "logits/chosen": -2.260009288787842,
      "logits/rejected": -2.354475259780884,
      "logps/chosen": -623.3614501953125,
      "logps/rejected": -995.877685546875,
      "loss": 0.1994,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.8137208819389343,
      "rewards/margins": 2.7252564430236816,
      "rewards/rejected": -3.5389769077301025,
      "step": 465
    },
    {
      "epoch": 0.7456,
      "grad_norm": 0.8437352180480957,
      "learning_rate": 1.28e-06,
      "logits/chosen": -2.37031626701355,
      "logits/rejected": -2.3430120944976807,
      "logps/chosen": -842.4524536132812,
      "logps/rejected": -1657.5208740234375,
      "loss": 0.069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1544268131256104,
      "rewards/margins": 4.312031269073486,
      "rewards/rejected": -5.466457843780518,
      "step": 466
    },
    {
      "epoch": 0.7472,
      "grad_norm": 0.9555975794792175,
      "learning_rate": 1.2720000000000003e-06,
      "logits/chosen": -2.3114211559295654,
      "logits/rejected": -2.3449976444244385,
      "logps/chosen": -1366.850830078125,
      "logps/rejected": -2191.585693359375,
      "loss": 0.0674,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9013832807540894,
      "rewards/margins": 5.897633075714111,
      "rewards/rejected": -6.799017429351807,
      "step": 467
    },
    {
      "epoch": 0.7488,
      "grad_norm": 1.2174333333969116,
      "learning_rate": 1.2640000000000003e-06,
      "logits/chosen": -2.316088914871216,
      "logits/rejected": -2.3961753845214844,
      "logps/chosen": -585.8817138671875,
      "logps/rejected": -1467.3154296875,
      "loss": 0.0972,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6275718212127686,
      "rewards/margins": 4.887161731719971,
      "rewards/rejected": -5.514733791351318,
      "step": 468
    },
    {
      "epoch": 0.7504,
      "grad_norm": 1.5620108842849731,
      "learning_rate": 1.256e-06,
      "logits/chosen": -2.263972043991089,
      "logits/rejected": -2.2762696743011475,
      "logps/chosen": -1025.1461181640625,
      "logps/rejected": -1510.3175048828125,
      "loss": 0.0947,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.7595682144165039,
      "rewards/margins": 4.244987487792969,
      "rewards/rejected": -5.004555702209473,
      "step": 469
    },
    {
      "epoch": 0.752,
      "grad_norm": 3.3314313888549805,
      "learning_rate": 1.248e-06,
      "logits/chosen": -2.3451321125030518,
      "logits/rejected": -2.384654998779297,
      "logps/chosen": -830.334228515625,
      "logps/rejected": -1584.4432373046875,
      "loss": 0.1977,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3697049617767334,
      "rewards/margins": 5.1562042236328125,
      "rewards/rejected": -6.525908946990967,
      "step": 470
    },
    {
      "epoch": 0.7536,
      "grad_norm": 0.7045863270759583,
      "learning_rate": 1.2400000000000002e-06,
      "logits/chosen": -2.2683544158935547,
      "logits/rejected": -2.3007724285125732,
      "logps/chosen": -925.0867919921875,
      "logps/rejected": -1644.17822265625,
      "loss": 0.0947,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7454878091812134,
      "rewards/margins": 5.159209251403809,
      "rewards/rejected": -5.904697418212891,
      "step": 471
    },
    {
      "epoch": 0.7552,
      "grad_norm": 1.0857669115066528,
      "learning_rate": 1.2320000000000002e-06,
      "logits/chosen": -2.1772117614746094,
      "logits/rejected": -2.356910467147827,
      "logps/chosen": -833.1248779296875,
      "logps/rejected": -1623.2193603515625,
      "loss": 0.0853,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7633028030395508,
      "rewards/margins": 5.318173408508301,
      "rewards/rejected": -6.081475734710693,
      "step": 472
    },
    {
      "epoch": 0.7568,
      "grad_norm": 2.470201253890991,
      "learning_rate": 1.224e-06,
      "logits/chosen": -2.382502317428589,
      "logits/rejected": -2.3970398902893066,
      "logps/chosen": -1402.0618896484375,
      "logps/rejected": -1765.0770263671875,
      "loss": 0.0945,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.4135173559188843,
      "rewards/margins": 3.807093620300293,
      "rewards/rejected": -5.220611095428467,
      "step": 473
    },
    {
      "epoch": 0.7584,
      "grad_norm": 0.6391035318374634,
      "learning_rate": 1.216e-06,
      "logits/chosen": -2.2423949241638184,
      "logits/rejected": -2.3577795028686523,
      "logps/chosen": -2071.379638671875,
      "logps/rejected": -2136.6201171875,
      "loss": 0.0307,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3599929809570312,
      "rewards/margins": 5.589945316314697,
      "rewards/rejected": -6.949938774108887,
      "step": 474
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.6395986080169678,
      "learning_rate": 1.2080000000000001e-06,
      "logits/chosen": -2.2561354637145996,
      "logits/rejected": -2.2719907760620117,
      "logps/chosen": -1038.360595703125,
      "logps/rejected": -2111.438232421875,
      "loss": 0.0565,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9905311465263367,
      "rewards/margins": 5.415382385253906,
      "rewards/rejected": -6.405913352966309,
      "step": 475
    },
    {
      "epoch": 0.7616,
      "grad_norm": 0.4202496111392975,
      "learning_rate": 1.2000000000000002e-06,
      "logits/chosen": -2.3506875038146973,
      "logits/rejected": -2.3367929458618164,
      "logps/chosen": -922.49462890625,
      "logps/rejected": -1630.2589111328125,
      "loss": 0.0343,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9299448728561401,
      "rewards/margins": 5.745137691497803,
      "rewards/rejected": -6.675082683563232,
      "step": 476
    },
    {
      "epoch": 0.7632,
      "grad_norm": 4.213387966156006,
      "learning_rate": 1.1920000000000002e-06,
      "logits/chosen": -2.3712308406829834,
      "logits/rejected": -2.390575885772705,
      "logps/chosen": -891.3948364257812,
      "logps/rejected": -1576.0089111328125,
      "loss": 0.2231,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.2346415519714355,
      "rewards/margins": 4.420471668243408,
      "rewards/rejected": -5.6551127433776855,
      "step": 477
    },
    {
      "epoch": 0.7648,
      "grad_norm": 0.7421482801437378,
      "learning_rate": 1.1840000000000002e-06,
      "logits/chosen": -2.4222259521484375,
      "logits/rejected": -2.456688404083252,
      "logps/chosen": -1342.919677734375,
      "logps/rejected": -2273.841064453125,
      "loss": 0.0421,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.415126919746399,
      "rewards/margins": 4.852367877960205,
      "rewards/rejected": -6.267495155334473,
      "step": 478
    },
    {
      "epoch": 0.7664,
      "grad_norm": 1.2384670972824097,
      "learning_rate": 1.176e-06,
      "logits/chosen": -1.9557538032531738,
      "logits/rejected": -2.3443195819854736,
      "logps/chosen": -1447.1983642578125,
      "logps/rejected": -1947.425048828125,
      "loss": 0.0748,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4607210159301758,
      "rewards/margins": 3.6729984283447266,
      "rewards/rejected": -5.133719444274902,
      "step": 479
    },
    {
      "epoch": 0.768,
      "grad_norm": 1.0948456525802612,
      "learning_rate": 1.168e-06,
      "logits/chosen": -2.444612741470337,
      "logits/rejected": -2.3433451652526855,
      "logps/chosen": -1189.965087890625,
      "logps/rejected": -2118.991943359375,
      "loss": 0.0874,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3575316667556763,
      "rewards/margins": 5.4998273849487305,
      "rewards/rejected": -6.857358455657959,
      "step": 480
    },
    {
      "epoch": 0.7696,
      "grad_norm": 1.3236641883850098,
      "learning_rate": 1.1600000000000001e-06,
      "logits/chosen": -2.3829352855682373,
      "logits/rejected": -2.367788314819336,
      "logps/chosen": -822.3180541992188,
      "logps/rejected": -1555.031494140625,
      "loss": 0.0801,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.200026035308838,
      "rewards/margins": 4.13092565536499,
      "rewards/rejected": -5.330952167510986,
      "step": 481
    },
    {
      "epoch": 0.7712,
      "grad_norm": 0.7084308862686157,
      "learning_rate": 1.1520000000000002e-06,
      "logits/chosen": -2.0826525688171387,
      "logits/rejected": -2.277014970779419,
      "logps/chosen": -706.7884521484375,
      "logps/rejected": -1543.600341796875,
      "loss": 0.0864,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9717942476272583,
      "rewards/margins": 5.313997745513916,
      "rewards/rejected": -6.285791397094727,
      "step": 482
    },
    {
      "epoch": 0.7728,
      "grad_norm": 2.5345349311828613,
      "learning_rate": 1.1440000000000002e-06,
      "logits/chosen": -2.312032699584961,
      "logits/rejected": -2.3102376461029053,
      "logps/chosen": -1045.1727294921875,
      "logps/rejected": -1543.65576171875,
      "loss": 0.1983,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2820929288864136,
      "rewards/margins": 3.201706647872925,
      "rewards/rejected": -4.483799457550049,
      "step": 483
    },
    {
      "epoch": 0.7744,
      "grad_norm": 0.735426664352417,
      "learning_rate": 1.1360000000000002e-06,
      "logits/chosen": -2.3537023067474365,
      "logits/rejected": -2.410701274871826,
      "logps/chosen": -845.2764282226562,
      "logps/rejected": -1808.97314453125,
      "loss": 0.0623,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.714833676815033,
      "rewards/margins": 5.490132808685303,
      "rewards/rejected": -6.204966068267822,
      "step": 484
    },
    {
      "epoch": 0.776,
      "grad_norm": 1.0095877647399902,
      "learning_rate": 1.128e-06,
      "logits/chosen": -2.073803424835205,
      "logits/rejected": -2.211294651031494,
      "logps/chosen": -1087.703369140625,
      "logps/rejected": -2051.903076171875,
      "loss": 0.0855,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6715277433395386,
      "rewards/margins": 5.47140645980835,
      "rewards/rejected": -6.1429338455200195,
      "step": 485
    },
    {
      "epoch": 0.7776,
      "grad_norm": 2.982189655303955,
      "learning_rate": 1.12e-06,
      "logits/chosen": -2.3584787845611572,
      "logits/rejected": -2.340027093887329,
      "logps/chosen": -696.31494140625,
      "logps/rejected": -1383.913330078125,
      "loss": 0.2131,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0470013618469238,
      "rewards/margins": 3.107706308364868,
      "rewards/rejected": -4.154707908630371,
      "step": 486
    },
    {
      "epoch": 0.7792,
      "grad_norm": 1.959394097328186,
      "learning_rate": 1.1120000000000001e-06,
      "logits/chosen": -2.2847213745117188,
      "logits/rejected": -2.38555645942688,
      "logps/chosen": -790.6190795898438,
      "logps/rejected": -1692.302490234375,
      "loss": 0.1412,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0228530168533325,
      "rewards/margins": 5.569525241851807,
      "rewards/rejected": -6.59237813949585,
      "step": 487
    },
    {
      "epoch": 0.7808,
      "grad_norm": 0.600882351398468,
      "learning_rate": 1.1040000000000001e-06,
      "logits/chosen": -2.2844107151031494,
      "logits/rejected": -2.3365166187286377,
      "logps/chosen": -1207.1099853515625,
      "logps/rejected": -1816.7132568359375,
      "loss": 0.0465,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0134005546569824,
      "rewards/margins": 4.896937370300293,
      "rewards/rejected": -5.910337924957275,
      "step": 488
    },
    {
      "epoch": 0.7824,
      "grad_norm": 2.243504524230957,
      "learning_rate": 1.0960000000000002e-06,
      "logits/chosen": -2.1205618381500244,
      "logits/rejected": -2.2045483589172363,
      "logps/chosen": -680.9058837890625,
      "logps/rejected": -1480.3280029296875,
      "loss": 0.1334,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9915300011634827,
      "rewards/margins": 4.528538703918457,
      "rewards/rejected": -5.520068645477295,
      "step": 489
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.9619650840759277,
      "learning_rate": 1.088e-06,
      "logits/chosen": -2.212064266204834,
      "logits/rejected": -2.3124780654907227,
      "logps/chosen": -666.1729125976562,
      "logps/rejected": -1946.9241943359375,
      "loss": 0.1233,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6315207481384277,
      "rewards/margins": 5.069365978240967,
      "rewards/rejected": -5.7008867263793945,
      "step": 490
    },
    {
      "epoch": 0.7856,
      "grad_norm": 1.3478493690490723,
      "learning_rate": 1.08e-06,
      "logits/chosen": -2.1311564445495605,
      "logits/rejected": -2.3184633255004883,
      "logps/chosen": -1330.24267578125,
      "logps/rejected": -2034.283203125,
      "loss": 0.1067,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8165764808654785,
      "rewards/margins": 3.6224048137664795,
      "rewards/rejected": -4.438981533050537,
      "step": 491
    },
    {
      "epoch": 0.7872,
      "grad_norm": 1.752917766571045,
      "learning_rate": 1.072e-06,
      "logits/chosen": -2.340132236480713,
      "logits/rejected": -2.364320755004883,
      "logps/chosen": -1234.7017822265625,
      "logps/rejected": -1771.2294921875,
      "loss": 0.0821,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3672538995742798,
      "rewards/margins": 4.57807731628418,
      "rewards/rejected": -5.94533109664917,
      "step": 492
    },
    {
      "epoch": 0.7888,
      "grad_norm": 3.9019830226898193,
      "learning_rate": 1.064e-06,
      "logits/chosen": -2.225080966949463,
      "logits/rejected": -2.3565127849578857,
      "logps/chosen": -1483.278076171875,
      "logps/rejected": -1898.989501953125,
      "loss": 0.2335,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.513677716255188,
      "rewards/margins": 3.1341371536254883,
      "rewards/rejected": -4.647815227508545,
      "step": 493
    },
    {
      "epoch": 0.7904,
      "grad_norm": 0.9776447415351868,
      "learning_rate": 1.0560000000000001e-06,
      "logits/chosen": -2.299994945526123,
      "logits/rejected": -2.341158628463745,
      "logps/chosen": -918.3170166015625,
      "logps/rejected": -1718.8603515625,
      "loss": 0.109,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1099209785461426,
      "rewards/margins": 3.331486701965332,
      "rewards/rejected": -4.441407680511475,
      "step": 494
    },
    {
      "epoch": 0.792,
      "grad_norm": 3.818758487701416,
      "learning_rate": 1.0480000000000002e-06,
      "logits/chosen": -2.272798776626587,
      "logits/rejected": -2.273073434829712,
      "logps/chosen": -637.8495483398438,
      "logps/rejected": -1079.982177734375,
      "loss": 0.3934,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.297010898590088,
      "rewards/margins": 3.3113229274749756,
      "rewards/rejected": -4.608334064483643,
      "step": 495
    },
    {
      "epoch": 0.7936,
      "grad_norm": 0.5417388677597046,
      "learning_rate": 1.04e-06,
      "logits/chosen": -2.406184196472168,
      "logits/rejected": -2.433821201324463,
      "logps/chosen": -1311.5450439453125,
      "logps/rejected": -1964.3294677734375,
      "loss": 0.032,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6453429460525513,
      "rewards/margins": 5.238028526306152,
      "rewards/rejected": -6.883371829986572,
      "step": 496
    },
    {
      "epoch": 0.7952,
      "grad_norm": 6.504404067993164,
      "learning_rate": 1.032e-06,
      "logits/chosen": -2.3671486377716064,
      "logits/rejected": -2.376701831817627,
      "logps/chosen": -1455.5390625,
      "logps/rejected": -1963.8638916015625,
      "loss": 0.3344,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.10003399848938,
      "rewards/margins": 4.027767658233643,
      "rewards/rejected": -6.127801418304443,
      "step": 497
    },
    {
      "epoch": 0.7968,
      "grad_norm": 1.3903388977050781,
      "learning_rate": 1.024e-06,
      "logits/chosen": -2.3622405529022217,
      "logits/rejected": -2.4109833240509033,
      "logps/chosen": -1254.872802734375,
      "logps/rejected": -1947.4677734375,
      "loss": 0.0681,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0240682363510132,
      "rewards/margins": 5.620136737823486,
      "rewards/rejected": -6.644205093383789,
      "step": 498
    },
    {
      "epoch": 0.7984,
      "grad_norm": 1.1257762908935547,
      "learning_rate": 1.016e-06,
      "logits/chosen": -2.385317325592041,
      "logits/rejected": -2.4201364517211914,
      "logps/chosen": -992.2071533203125,
      "logps/rejected": -1696.02978515625,
      "loss": 0.0544,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2040092945098877,
      "rewards/margins": 4.779555320739746,
      "rewards/rejected": -5.983564376831055,
      "step": 499
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.04011344909668,
      "learning_rate": 1.0080000000000001e-06,
      "logits/chosen": -2.1756651401519775,
      "logits/rejected": -2.178454875946045,
      "logps/chosen": -1454.131103515625,
      "logps/rejected": -2153.101806640625,
      "loss": 0.234,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5857212543487549,
      "rewards/margins": 6.06722354888916,
      "rewards/rejected": -7.652944564819336,
      "step": 500
    },
    {
      "epoch": 0.8016,
      "grad_norm": 2.520054817199707,
      "learning_rate": 1.0000000000000002e-06,
      "logits/chosen": -2.2113490104675293,
      "logits/rejected": -2.373490810394287,
      "logps/chosen": -946.0794677734375,
      "logps/rejected": -1757.7125244140625,
      "loss": 0.093,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1230472326278687,
      "rewards/margins": 3.8471381664276123,
      "rewards/rejected": -4.970185279846191,
      "step": 501
    },
    {
      "epoch": 0.8032,
      "grad_norm": 1.665177822113037,
      "learning_rate": 9.92e-07,
      "logits/chosen": -2.191518783569336,
      "logits/rejected": -2.3875067234039307,
      "logps/chosen": -593.6141357421875,
      "logps/rejected": -1090.7796630859375,
      "loss": 0.1469,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7454573512077332,
      "rewards/margins": 3.2846412658691406,
      "rewards/rejected": -4.030098915100098,
      "step": 502
    },
    {
      "epoch": 0.8048,
      "grad_norm": 1.6386172771453857,
      "learning_rate": 9.84e-07,
      "logits/chosen": -2.340486526489258,
      "logits/rejected": -2.3342275619506836,
      "logps/chosen": -969.238525390625,
      "logps/rejected": -1462.490234375,
      "loss": 0.1272,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0079419612884521,
      "rewards/margins": 3.948122024536133,
      "rewards/rejected": -4.956064224243164,
      "step": 503
    },
    {
      "epoch": 0.8064,
      "grad_norm": 0.9787618517875671,
      "learning_rate": 9.76e-07,
      "logits/chosen": -2.3038601875305176,
      "logits/rejected": -2.332249402999878,
      "logps/chosen": -797.3576049804688,
      "logps/rejected": -1454.7769775390625,
      "loss": 0.0731,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9125704169273376,
      "rewards/margins": 4.305781841278076,
      "rewards/rejected": -5.218352317810059,
      "step": 504
    },
    {
      "epoch": 0.808,
      "grad_norm": 3.351611375808716,
      "learning_rate": 9.68e-07,
      "logits/chosen": -2.2671637535095215,
      "logits/rejected": -2.3507847785949707,
      "logps/chosen": -931.8552856445312,
      "logps/rejected": -1481.225830078125,
      "loss": 0.2163,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.263612985610962,
      "rewards/margins": 3.607630968093872,
      "rewards/rejected": -4.871243953704834,
      "step": 505
    },
    {
      "epoch": 0.8096,
      "grad_norm": 1.1355229616165161,
      "learning_rate": 9.600000000000001e-07,
      "logits/chosen": -2.4313125610351562,
      "logits/rejected": -2.4186763763427734,
      "logps/chosen": -796.5885009765625,
      "logps/rejected": -1590.937255859375,
      "loss": 0.1011,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0300579071044922,
      "rewards/margins": 5.106457233428955,
      "rewards/rejected": -6.136514663696289,
      "step": 506
    },
    {
      "epoch": 0.8112,
      "grad_norm": 3.752986431121826,
      "learning_rate": 9.520000000000002e-07,
      "logits/chosen": -2.346965789794922,
      "logits/rejected": -2.347815990447998,
      "logps/chosen": -1422.720947265625,
      "logps/rejected": -1842.84765625,
      "loss": 0.2215,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.444011926651001,
      "rewards/margins": 4.308441638946533,
      "rewards/rejected": -6.752453327178955,
      "step": 507
    },
    {
      "epoch": 0.8128,
      "grad_norm": 3.280550241470337,
      "learning_rate": 9.440000000000001e-07,
      "logits/chosen": -2.246821880340576,
      "logits/rejected": -2.366999864578247,
      "logps/chosen": -1421.823486328125,
      "logps/rejected": -2370.382568359375,
      "loss": 0.1019,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3524532318115234,
      "rewards/margins": 7.021713733673096,
      "rewards/rejected": -8.374166488647461,
      "step": 508
    },
    {
      "epoch": 0.8144,
      "grad_norm": 1.7763159275054932,
      "learning_rate": 9.360000000000001e-07,
      "logits/chosen": -2.2900614738464355,
      "logits/rejected": -2.301368236541748,
      "logps/chosen": -1101.4720458984375,
      "logps/rejected": -1609.762451171875,
      "loss": 0.1517,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3277308940887451,
      "rewards/margins": 2.7803046703338623,
      "rewards/rejected": -4.108035087585449,
      "step": 509
    },
    {
      "epoch": 0.816,
      "grad_norm": 2.9812560081481934,
      "learning_rate": 9.28e-07,
      "logits/chosen": -2.3304457664489746,
      "logits/rejected": -2.3996481895446777,
      "logps/chosen": -806.7183837890625,
      "logps/rejected": -1224.4423828125,
      "loss": 0.1452,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3421462774276733,
      "rewards/margins": 3.0013880729675293,
      "rewards/rejected": -4.343534469604492,
      "step": 510
    },
    {
      "epoch": 0.8176,
      "grad_norm": 0.9729911684989929,
      "learning_rate": 9.200000000000001e-07,
      "logits/chosen": -2.078629970550537,
      "logits/rejected": -2.2428603172302246,
      "logps/chosen": -937.030029296875,
      "logps/rejected": -1609.4063720703125,
      "loss": 0.1263,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9348549842834473,
      "rewards/margins": 3.9163100719451904,
      "rewards/rejected": -4.8511643409729,
      "step": 511
    },
    {
      "epoch": 0.8192,
      "grad_norm": 3.572951555252075,
      "learning_rate": 9.120000000000001e-07,
      "logits/chosen": -2.2697794437408447,
      "logits/rejected": -2.3316516876220703,
      "logps/chosen": -746.555908203125,
      "logps/rejected": -1439.984619140625,
      "loss": 0.197,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.1998432874679565,
      "rewards/margins": 4.346848964691162,
      "rewards/rejected": -5.546692371368408,
      "step": 512
    },
    {
      "epoch": 0.8208,
      "grad_norm": 0.7424926161766052,
      "learning_rate": 9.04e-07,
      "logits/chosen": -2.2803587913513184,
      "logits/rejected": -2.3103082180023193,
      "logps/chosen": -846.4025268554688,
      "logps/rejected": -1962.79052734375,
      "loss": 0.0513,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6434487104415894,
      "rewards/margins": 4.674452781677246,
      "rewards/rejected": -5.317901611328125,
      "step": 513
    },
    {
      "epoch": 0.8224,
      "grad_norm": 1.2954559326171875,
      "learning_rate": 8.960000000000001e-07,
      "logits/chosen": -2.3608744144439697,
      "logits/rejected": -2.409420967102051,
      "logps/chosen": -1372.1282958984375,
      "logps/rejected": -1632.6407470703125,
      "loss": 0.107,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5818593502044678,
      "rewards/margins": 3.872128486633301,
      "rewards/rejected": -5.4539875984191895,
      "step": 514
    },
    {
      "epoch": 0.824,
      "grad_norm": 1.105369210243225,
      "learning_rate": 8.880000000000001e-07,
      "logits/chosen": -2.2638254165649414,
      "logits/rejected": -2.3377091884613037,
      "logps/chosen": -774.33056640625,
      "logps/rejected": -1757.435546875,
      "loss": 0.0758,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.849151611328125,
      "rewards/margins": 5.0002875328063965,
      "rewards/rejected": -5.8494391441345215,
      "step": 515
    },
    {
      "epoch": 0.8256,
      "grad_norm": 1.174282193183899,
      "learning_rate": 8.8e-07,
      "logits/chosen": -2.156287908554077,
      "logits/rejected": -2.3171207904815674,
      "logps/chosen": -1215.4970703125,
      "logps/rejected": -1879.5897216796875,
      "loss": 0.1056,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.1546635627746582,
      "rewards/margins": 5.648355007171631,
      "rewards/rejected": -6.803018093109131,
      "step": 516
    },
    {
      "epoch": 0.8272,
      "grad_norm": 6.560606002807617,
      "learning_rate": 8.720000000000001e-07,
      "logits/chosen": -2.262622594833374,
      "logits/rejected": -2.307960271835327,
      "logps/chosen": -1305.3546142578125,
      "logps/rejected": -1913.350341796875,
      "loss": 0.1175,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.6175544261932373,
      "rewards/margins": 4.4239726066589355,
      "rewards/rejected": -6.041526794433594,
      "step": 517
    },
    {
      "epoch": 0.8288,
      "grad_norm": 1.8117080926895142,
      "learning_rate": 8.640000000000001e-07,
      "logits/chosen": -2.370898485183716,
      "logits/rejected": -2.378446102142334,
      "logps/chosen": -920.4652099609375,
      "logps/rejected": -1509.275634765625,
      "loss": 0.1099,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.462227463722229,
      "rewards/margins": 4.0726518630981445,
      "rewards/rejected": -5.534879684448242,
      "step": 518
    },
    {
      "epoch": 0.8304,
      "grad_norm": 4.55350923538208,
      "learning_rate": 8.56e-07,
      "logits/chosen": -2.339789628982544,
      "logits/rejected": -2.378434181213379,
      "logps/chosen": -743.6388549804688,
      "logps/rejected": -1642.435791015625,
      "loss": 0.2789,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9492754340171814,
      "rewards/margins": 4.844724178314209,
      "rewards/rejected": -5.793999671936035,
      "step": 519
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.6393377780914307,
      "learning_rate": 8.480000000000001e-07,
      "logits/chosen": -2.313814163208008,
      "logits/rejected": -2.3717076778411865,
      "logps/chosen": -1137.423095703125,
      "logps/rejected": -1719.13134765625,
      "loss": 0.0544,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1130644083023071,
      "rewards/margins": 4.167991638183594,
      "rewards/rejected": -5.281055927276611,
      "step": 520
    },
    {
      "epoch": 0.8336,
      "grad_norm": 5.88096809387207,
      "learning_rate": 8.400000000000001e-07,
      "logits/chosen": -2.364025592803955,
      "logits/rejected": -2.321629762649536,
      "logps/chosen": -694.7316284179688,
      "logps/rejected": -1553.39892578125,
      "loss": 0.3845,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.7542327046394348,
      "rewards/margins": 3.2120742797851562,
      "rewards/rejected": -3.966306447982788,
      "step": 521
    },
    {
      "epoch": 0.8352,
      "grad_norm": 1.3648180961608887,
      "learning_rate": 8.32e-07,
      "logits/chosen": -2.332275629043579,
      "logits/rejected": -2.4417049884796143,
      "logps/chosen": -1302.843017578125,
      "logps/rejected": -1726.5048828125,
      "loss": 0.073,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4886564016342163,
      "rewards/margins": 5.3886399269104,
      "rewards/rejected": -6.877295970916748,
      "step": 522
    },
    {
      "epoch": 0.8368,
      "grad_norm": 0.5037994980812073,
      "learning_rate": 8.240000000000001e-07,
      "logits/chosen": -2.342061758041382,
      "logits/rejected": -2.336580753326416,
      "logps/chosen": -604.3845825195312,
      "logps/rejected": -1328.1309814453125,
      "loss": 0.0567,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8058583736419678,
      "rewards/margins": 4.768223285675049,
      "rewards/rejected": -5.5740814208984375,
      "step": 523
    },
    {
      "epoch": 0.8384,
      "grad_norm": 4.175205230712891,
      "learning_rate": 8.160000000000001e-07,
      "logits/chosen": -2.407897472381592,
      "logits/rejected": -2.3822755813598633,
      "logps/chosen": -1577.748779296875,
      "logps/rejected": -2025.7706298828125,
      "loss": 0.1866,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.0595977306365967,
      "rewards/margins": 4.226086616516113,
      "rewards/rejected": -6.285684585571289,
      "step": 524
    },
    {
      "epoch": 0.84,
      "grad_norm": 4.19993257522583,
      "learning_rate": 8.08e-07,
      "logits/chosen": -2.335670232772827,
      "logits/rejected": -2.333548069000244,
      "logps/chosen": -1378.3262939453125,
      "logps/rejected": -1475.0762939453125,
      "loss": 0.1685,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.4752503633499146,
      "rewards/margins": 3.366488456726074,
      "rewards/rejected": -4.841738700866699,
      "step": 525
    },
    {
      "epoch": 0.8416,
      "grad_norm": 0.7508164048194885,
      "learning_rate": 8.000000000000001e-07,
      "logits/chosen": -2.2321958541870117,
      "logits/rejected": -2.3204362392425537,
      "logps/chosen": -1002.0411376953125,
      "logps/rejected": -1222.44140625,
      "loss": 0.076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0749467611312866,
      "rewards/margins": 3.891960620880127,
      "rewards/rejected": -4.966907024383545,
      "step": 526
    },
    {
      "epoch": 0.8432,
      "grad_norm": 3.1787467002868652,
      "learning_rate": 7.920000000000001e-07,
      "logits/chosen": -2.363534688949585,
      "logits/rejected": -2.391907215118408,
      "logps/chosen": -1544.692626953125,
      "logps/rejected": -1816.460205078125,
      "loss": 0.2705,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.7400617599487305,
      "rewards/margins": 2.938138961791992,
      "rewards/rejected": -4.678200721740723,
      "step": 527
    },
    {
      "epoch": 0.8448,
      "grad_norm": 0.8464435338973999,
      "learning_rate": 7.84e-07,
      "logits/chosen": -2.27408504486084,
      "logits/rejected": -2.3213281631469727,
      "logps/chosen": -1019.5572509765625,
      "logps/rejected": -1726.22021484375,
      "loss": 0.056,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.13938570022583,
      "rewards/margins": 5.3109588623046875,
      "rewards/rejected": -6.450345039367676,
      "step": 528
    },
    {
      "epoch": 0.8464,
      "grad_norm": 0.7837693095207214,
      "learning_rate": 7.760000000000001e-07,
      "logits/chosen": -2.151740789413452,
      "logits/rejected": -2.34061598777771,
      "logps/chosen": -929.5638427734375,
      "logps/rejected": -1560.305419921875,
      "loss": 0.0781,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0347999334335327,
      "rewards/margins": 4.682596206665039,
      "rewards/rejected": -5.717396259307861,
      "step": 529
    },
    {
      "epoch": 0.848,
      "grad_norm": 1.7695683240890503,
      "learning_rate": 7.68e-07,
      "logits/chosen": -2.3380017280578613,
      "logits/rejected": -2.394097089767456,
      "logps/chosen": -945.6052856445312,
      "logps/rejected": -1628.563720703125,
      "loss": 0.1311,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.292185664176941,
      "rewards/margins": 4.021950721740723,
      "rewards/rejected": -5.314136505126953,
      "step": 530
    },
    {
      "epoch": 0.8496,
      "grad_norm": 1.00161612033844,
      "learning_rate": 7.6e-07,
      "logits/chosen": -2.252601146697998,
      "logits/rejected": -2.3730711936950684,
      "logps/chosen": -1135.697998046875,
      "logps/rejected": -1862.3936767578125,
      "loss": 0.0424,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0419392585754395,
      "rewards/margins": 6.4135541915893555,
      "rewards/rejected": -7.455493450164795,
      "step": 531
    },
    {
      "epoch": 0.8512,
      "grad_norm": 0.9308198690414429,
      "learning_rate": 7.520000000000001e-07,
      "logits/chosen": -2.197446584701538,
      "logits/rejected": -2.2763216495513916,
      "logps/chosen": -1033.622314453125,
      "logps/rejected": -1903.634765625,
      "loss": 0.083,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5954281687736511,
      "rewards/margins": 3.5940146446228027,
      "rewards/rejected": -4.1894426345825195,
      "step": 532
    },
    {
      "epoch": 0.8528,
      "grad_norm": 3.6804771423339844,
      "learning_rate": 7.44e-07,
      "logits/chosen": -2.3381879329681396,
      "logits/rejected": -2.360628604888916,
      "logps/chosen": -1113.745849609375,
      "logps/rejected": -1918.0855712890625,
      "loss": 0.1812,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.2732081413269043,
      "rewards/margins": 4.499306678771973,
      "rewards/rejected": -5.772514820098877,
      "step": 533
    },
    {
      "epoch": 0.8544,
      "grad_norm": 3.51332950592041,
      "learning_rate": 7.36e-07,
      "logits/chosen": -2.2463700771331787,
      "logits/rejected": -2.226616144180298,
      "logps/chosen": -1011.2376708984375,
      "logps/rejected": -1680.5606689453125,
      "loss": 0.1849,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.368739366531372,
      "rewards/margins": 6.137917518615723,
      "rewards/rejected": -7.506656646728516,
      "step": 534
    },
    {
      "epoch": 0.856,
      "grad_norm": 2.3090176582336426,
      "learning_rate": 7.280000000000001e-07,
      "logits/chosen": -2.249175548553467,
      "logits/rejected": -2.2988696098327637,
      "logps/chosen": -1006.8446655273438,
      "logps/rejected": -1770.681396484375,
      "loss": 0.151,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.4490344524383545,
      "rewards/margins": 4.470454216003418,
      "rewards/rejected": -5.919488906860352,
      "step": 535
    },
    {
      "epoch": 0.8576,
      "grad_norm": 2.955477714538574,
      "learning_rate": 7.2e-07,
      "logits/chosen": -2.235774517059326,
      "logits/rejected": -2.3575632572174072,
      "logps/chosen": -642.0610961914062,
      "logps/rejected": -1203.3251953125,
      "loss": 0.2118,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6818215250968933,
      "rewards/margins": 3.037446975708008,
      "rewards/rejected": -3.719268798828125,
      "step": 536
    },
    {
      "epoch": 0.8592,
      "grad_norm": 2.153261661529541,
      "learning_rate": 7.12e-07,
      "logits/chosen": -2.395613193511963,
      "logits/rejected": -2.3834104537963867,
      "logps/chosen": -1089.482177734375,
      "logps/rejected": -1786.6904296875,
      "loss": 0.0793,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.574856162071228,
      "rewards/margins": 5.526968479156494,
      "rewards/rejected": -7.101824760437012,
      "step": 537
    },
    {
      "epoch": 0.8608,
      "grad_norm": 1.4554133415222168,
      "learning_rate": 7.040000000000001e-07,
      "logits/chosen": -2.2115750312805176,
      "logits/rejected": -2.3462941646575928,
      "logps/chosen": -1028.1011962890625,
      "logps/rejected": -1191.37841796875,
      "loss": 0.1356,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.303329348564148,
      "rewards/margins": 3.1724302768707275,
      "rewards/rejected": -4.475759506225586,
      "step": 538
    },
    {
      "epoch": 0.8624,
      "grad_norm": 0.9248467683792114,
      "learning_rate": 6.96e-07,
      "logits/chosen": -2.2599430084228516,
      "logits/rejected": -2.384026050567627,
      "logps/chosen": -549.7342529296875,
      "logps/rejected": -1254.8079833984375,
      "loss": 0.076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6934268474578857,
      "rewards/margins": 4.056726455688477,
      "rewards/rejected": -4.750152587890625,
      "step": 539
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.64754718542099,
      "learning_rate": 6.88e-07,
      "logits/chosen": -2.300483226776123,
      "logits/rejected": -2.3236072063446045,
      "logps/chosen": -947.6695556640625,
      "logps/rejected": -1738.361328125,
      "loss": 0.0606,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8414281010627747,
      "rewards/margins": 5.404092311859131,
      "rewards/rejected": -6.24552059173584,
      "step": 540
    },
    {
      "epoch": 0.8656,
      "grad_norm": 0.5338348150253296,
      "learning_rate": 6.800000000000001e-07,
      "logits/chosen": -2.340609312057495,
      "logits/rejected": -2.338085174560547,
      "logps/chosen": -754.4259643554688,
      "logps/rejected": -1547.55126953125,
      "loss": 0.0324,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2494745254516602,
      "rewards/margins": 5.144556522369385,
      "rewards/rejected": -6.394030570983887,
      "step": 541
    },
    {
      "epoch": 0.8672,
      "grad_norm": 1.103546142578125,
      "learning_rate": 6.72e-07,
      "logits/chosen": -2.256326675415039,
      "logits/rejected": -2.382173538208008,
      "logps/chosen": -928.8292236328125,
      "logps/rejected": -1306.069580078125,
      "loss": 0.0919,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5878520011901855,
      "rewards/margins": 3.102865219116211,
      "rewards/rejected": -4.6907172203063965,
      "step": 542
    },
    {
      "epoch": 0.8688,
      "grad_norm": 1.0545830726623535,
      "learning_rate": 6.64e-07,
      "logits/chosen": -2.3249690532684326,
      "logits/rejected": -2.4035580158233643,
      "logps/chosen": -676.130126953125,
      "logps/rejected": -1158.3143310546875,
      "loss": 0.1065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1286464929580688,
      "rewards/margins": 4.04982852935791,
      "rewards/rejected": -5.1784749031066895,
      "step": 543
    },
    {
      "epoch": 0.8704,
      "grad_norm": 1.0792843103408813,
      "learning_rate": 6.560000000000002e-07,
      "logits/chosen": -2.269303798675537,
      "logits/rejected": -2.4026691913604736,
      "logps/chosen": -1716.8616943359375,
      "logps/rejected": -2327.91845703125,
      "loss": 0.0522,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7426011562347412,
      "rewards/margins": 4.475994110107422,
      "rewards/rejected": -6.218595504760742,
      "step": 544
    },
    {
      "epoch": 0.872,
      "grad_norm": 1.6464391946792603,
      "learning_rate": 6.48e-07,
      "logits/chosen": -2.361922264099121,
      "logits/rejected": -2.329118013381958,
      "logps/chosen": -987.552978515625,
      "logps/rejected": -1639.5482177734375,
      "loss": 0.0847,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6281005144119263,
      "rewards/margins": 4.853023529052734,
      "rewards/rejected": -6.4811248779296875,
      "step": 545
    },
    {
      "epoch": 0.8736,
      "grad_norm": 0.966556191444397,
      "learning_rate": 6.4e-07,
      "logits/chosen": -2.2665979862213135,
      "logits/rejected": -2.374110698699951,
      "logps/chosen": -849.2152709960938,
      "logps/rejected": -1655.3414306640625,
      "loss": 0.1124,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.791343092918396,
      "rewards/margins": 4.969263553619385,
      "rewards/rejected": -5.7606072425842285,
      "step": 546
    },
    {
      "epoch": 0.8752,
      "grad_norm": 1.677791953086853,
      "learning_rate": 6.320000000000002e-07,
      "logits/chosen": -2.315706253051758,
      "logits/rejected": -2.3581314086914062,
      "logps/chosen": -1081.5274658203125,
      "logps/rejected": -1437.013671875,
      "loss": 0.1193,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1104156970977783,
      "rewards/margins": 3.7779541015625,
      "rewards/rejected": -4.888369560241699,
      "step": 547
    },
    {
      "epoch": 0.8768,
      "grad_norm": 2.906527042388916,
      "learning_rate": 6.24e-07,
      "logits/chosen": -2.3619771003723145,
      "logits/rejected": -2.402146816253662,
      "logps/chosen": -1020.412841796875,
      "logps/rejected": -1515.352783203125,
      "loss": 0.1721,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0851510763168335,
      "rewards/margins": 5.174674034118652,
      "rewards/rejected": -6.259824275970459,
      "step": 548
    },
    {
      "epoch": 0.8784,
      "grad_norm": 2.248326301574707,
      "learning_rate": 6.160000000000001e-07,
      "logits/chosen": -2.3965952396392822,
      "logits/rejected": -2.386582136154175,
      "logps/chosen": -1215.19384765625,
      "logps/rejected": -1544.863525390625,
      "loss": 0.1122,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2179501056671143,
      "rewards/margins": 3.268214464187622,
      "rewards/rejected": -4.486164569854736,
      "step": 549
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.536306381225586,
      "learning_rate": 6.08e-07,
      "logits/chosen": -2.348614454269409,
      "logits/rejected": -2.451212167739868,
      "logps/chosen": -1225.841552734375,
      "logps/rejected": -1415.7677001953125,
      "loss": 0.1934,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.6698359251022339,
      "rewards/margins": 2.91957426071167,
      "rewards/rejected": -4.589410305023193,
      "step": 550
    },
    {
      "epoch": 0.8816,
      "grad_norm": 2.1509151458740234,
      "learning_rate": 6.000000000000001e-07,
      "logits/chosen": -2.3202662467956543,
      "logits/rejected": -2.368147850036621,
      "logps/chosen": -733.8508911132812,
      "logps/rejected": -1572.4156494140625,
      "loss": 0.1616,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.4408602714538574,
      "rewards/margins": 4.795939922332764,
      "rewards/rejected": -6.236800193786621,
      "step": 551
    },
    {
      "epoch": 0.8832,
      "grad_norm": 1.9812073707580566,
      "learning_rate": 5.920000000000001e-07,
      "logits/chosen": -2.428126335144043,
      "logits/rejected": -2.388068437576294,
      "logps/chosen": -862.9013061523438,
      "logps/rejected": -1633.8912353515625,
      "loss": 0.1399,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.491243839263916,
      "rewards/margins": 5.168153285980225,
      "rewards/rejected": -6.659397125244141,
      "step": 552
    },
    {
      "epoch": 0.8848,
      "grad_norm": 1.2502774000167847,
      "learning_rate": 5.84e-07,
      "logits/chosen": -2.3235232830047607,
      "logits/rejected": -2.412771463394165,
      "logps/chosen": -644.9198608398438,
      "logps/rejected": -1056.1072998046875,
      "loss": 0.1132,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8191386461257935,
      "rewards/margins": 4.084807395935059,
      "rewards/rejected": -4.9039459228515625,
      "step": 553
    },
    {
      "epoch": 0.8864,
      "grad_norm": 1.9413669109344482,
      "learning_rate": 5.760000000000001e-07,
      "logits/chosen": -2.3245792388916016,
      "logits/rejected": -2.3048412799835205,
      "logps/chosen": -1218.322509765625,
      "logps/rejected": -3004.560302734375,
      "loss": 0.1262,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.6248921155929565,
      "rewards/margins": 14.736377716064453,
      "rewards/rejected": -16.36126708984375,
      "step": 554
    },
    {
      "epoch": 0.888,
      "grad_norm": 2.916429042816162,
      "learning_rate": 5.680000000000001e-07,
      "logits/chosen": -2.385693311691284,
      "logits/rejected": -2.345151901245117,
      "logps/chosen": -1625.033447265625,
      "logps/rejected": -2104.93310546875,
      "loss": 0.1816,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.5585967302322388,
      "rewards/margins": 4.195228099822998,
      "rewards/rejected": -5.753824710845947,
      "step": 555
    },
    {
      "epoch": 0.8896,
      "grad_norm": 1.1605793237686157,
      "learning_rate": 5.6e-07,
      "logits/chosen": -2.36708664894104,
      "logits/rejected": -2.341702938079834,
      "logps/chosen": -1177.3009033203125,
      "logps/rejected": -1775.74755859375,
      "loss": 0.05,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7762620449066162,
      "rewards/margins": 4.6801438331604,
      "rewards/rejected": -6.4564056396484375,
      "step": 556
    },
    {
      "epoch": 0.8912,
      "grad_norm": 3.8512001037597656,
      "learning_rate": 5.520000000000001e-07,
      "logits/chosen": -2.4001641273498535,
      "logits/rejected": -2.398952007293701,
      "logps/chosen": -829.7592163085938,
      "logps/rejected": -1165.439453125,
      "loss": 0.2003,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.816667377948761,
      "rewards/margins": 3.346043586730957,
      "rewards/rejected": -4.162711143493652,
      "step": 557
    },
    {
      "epoch": 0.8928,
      "grad_norm": 6.434264183044434,
      "learning_rate": 5.44e-07,
      "logits/chosen": -2.3298897743225098,
      "logits/rejected": -2.322641372680664,
      "logps/chosen": -1504.51953125,
      "logps/rejected": -1738.29736328125,
      "loss": 0.3698,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.1789536476135254,
      "rewards/margins": 3.727949380874634,
      "rewards/rejected": -5.906903266906738,
      "step": 558
    },
    {
      "epoch": 0.8944,
      "grad_norm": 2.419424295425415,
      "learning_rate": 5.36e-07,
      "logits/chosen": -2.3055763244628906,
      "logits/rejected": -2.363302230834961,
      "logps/chosen": -818.4520874023438,
      "logps/rejected": -1052.564697265625,
      "loss": 0.2255,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.9942331314086914,
      "rewards/margins": 3.8100647926330566,
      "rewards/rejected": -4.804297924041748,
      "step": 559
    },
    {
      "epoch": 0.896,
      "grad_norm": 1.121002197265625,
      "learning_rate": 5.280000000000001e-07,
      "logits/chosen": -2.379730701446533,
      "logits/rejected": -2.3603568077087402,
      "logps/chosen": -1008.8865356445312,
      "logps/rejected": -1520.77392578125,
      "loss": 0.1013,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3054288625717163,
      "rewards/margins": 3.766324758529663,
      "rewards/rejected": -5.071753025054932,
      "step": 560
    },
    {
      "epoch": 0.8976,
      "grad_norm": 7.432123184204102,
      "learning_rate": 5.2e-07,
      "logits/chosen": -2.1263535022735596,
      "logits/rejected": -2.131894826889038,
      "logps/chosen": -1100.368408203125,
      "logps/rejected": -2694.215576171875,
      "loss": 0.0655,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9414665699005127,
      "rewards/margins": 6.596822261810303,
      "rewards/rejected": -7.538289546966553,
      "step": 561
    },
    {
      "epoch": 0.8992,
      "grad_norm": 0.688770055770874,
      "learning_rate": 5.12e-07,
      "logits/chosen": -2.2397847175598145,
      "logits/rejected": -2.32671856880188,
      "logps/chosen": -574.4862060546875,
      "logps/rejected": -1543.0711669921875,
      "loss": 0.0276,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7669546008110046,
      "rewards/margins": 5.01080846786499,
      "rewards/rejected": -5.7777628898620605,
      "step": 562
    },
    {
      "epoch": 0.9008,
      "grad_norm": 6.110816955566406,
      "learning_rate": 5.040000000000001e-07,
      "logits/chosen": -2.3638198375701904,
      "logits/rejected": -2.3695318698883057,
      "logps/chosen": -1712.0418701171875,
      "logps/rejected": -1670.31982421875,
      "loss": 0.2034,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.995166540145874,
      "rewards/margins": 3.5785980224609375,
      "rewards/rejected": -5.573764801025391,
      "step": 563
    },
    {
      "epoch": 0.9024,
      "grad_norm": 1.8641184568405151,
      "learning_rate": 4.96e-07,
      "logits/chosen": -2.221766471862793,
      "logits/rejected": -2.3340282440185547,
      "logps/chosen": -1401.7725830078125,
      "logps/rejected": -1622.06787109375,
      "loss": 0.1144,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.77057683467865,
      "rewards/margins": 4.018112659454346,
      "rewards/rejected": -5.788689613342285,
      "step": 564
    },
    {
      "epoch": 0.904,
      "grad_norm": 4.270277500152588,
      "learning_rate": 4.88e-07,
      "logits/chosen": -2.257758617401123,
      "logits/rejected": -2.337066411972046,
      "logps/chosen": -1412.966796875,
      "logps/rejected": -1922.4091796875,
      "loss": 0.2292,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.6404314041137695,
      "rewards/margins": 4.698577880859375,
      "rewards/rejected": -6.3390092849731445,
      "step": 565
    },
    {
      "epoch": 0.9056,
      "grad_norm": 1.6252988576889038,
      "learning_rate": 4.800000000000001e-07,
      "logits/chosen": -2.2440109252929688,
      "logits/rejected": -2.2956483364105225,
      "logps/chosen": -1253.747802734375,
      "logps/rejected": -1819.7855224609375,
      "loss": 0.0921,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6026333570480347,
      "rewards/margins": 3.7655880451202393,
      "rewards/rejected": -5.368221282958984,
      "step": 566
    },
    {
      "epoch": 0.9072,
      "grad_norm": 0.7145819067955017,
      "learning_rate": 4.7200000000000004e-07,
      "logits/chosen": -2.1781301498413086,
      "logits/rejected": -2.2550296783447266,
      "logps/chosen": -1119.502197265625,
      "logps/rejected": -1735.057373046875,
      "loss": 0.0601,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1846123933792114,
      "rewards/margins": 5.337810039520264,
      "rewards/rejected": -6.522421836853027,
      "step": 567
    },
    {
      "epoch": 0.9088,
      "grad_norm": 4.583967685699463,
      "learning_rate": 4.64e-07,
      "logits/chosen": -2.067988634109497,
      "logits/rejected": -2.276289701461792,
      "logps/chosen": -1078.1842041015625,
      "logps/rejected": -1724.4871826171875,
      "loss": 0.2311,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.699604868888855,
      "rewards/margins": 3.534703493118286,
      "rewards/rejected": -5.23430871963501,
      "step": 568
    },
    {
      "epoch": 0.9104,
      "grad_norm": 1.1733036041259766,
      "learning_rate": 4.5600000000000006e-07,
      "logits/chosen": -2.409090280532837,
      "logits/rejected": -2.406935214996338,
      "logps/chosen": -849.5267333984375,
      "logps/rejected": -1347.77001953125,
      "loss": 0.0695,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1985797882080078,
      "rewards/margins": 4.198424339294434,
      "rewards/rejected": -5.397003650665283,
      "step": 569
    },
    {
      "epoch": 0.912,
      "grad_norm": 1.4124414920806885,
      "learning_rate": 4.4800000000000004e-07,
      "logits/chosen": -2.352602481842041,
      "logits/rejected": -2.3177568912506104,
      "logps/chosen": -1092.560791015625,
      "logps/rejected": -1831.589111328125,
      "loss": 0.0825,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4724348783493042,
      "rewards/margins": 5.033097743988037,
      "rewards/rejected": -6.505532264709473,
      "step": 570
    },
    {
      "epoch": 0.9136,
      "grad_norm": 0.7173577547073364,
      "learning_rate": 4.4e-07,
      "logits/chosen": -2.3734970092773438,
      "logits/rejected": -2.3993051052093506,
      "logps/chosen": -586.2052001953125,
      "logps/rejected": -1311.881591796875,
      "loss": 0.1018,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5491827130317688,
      "rewards/margins": 4.320007801055908,
      "rewards/rejected": -4.869190692901611,
      "step": 571
    },
    {
      "epoch": 0.9152,
      "grad_norm": 0.9579256772994995,
      "learning_rate": 4.3200000000000006e-07,
      "logits/chosen": -2.359279155731201,
      "logits/rejected": -2.398550271987915,
      "logps/chosen": -934.840576171875,
      "logps/rejected": -1784.8719482421875,
      "loss": 0.0883,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2844159603118896,
      "rewards/margins": 4.8065996170043945,
      "rewards/rejected": -6.091015815734863,
      "step": 572
    },
    {
      "epoch": 0.9168,
      "grad_norm": 2.0989935398101807,
      "learning_rate": 4.2400000000000004e-07,
      "logits/chosen": -2.250774621963501,
      "logits/rejected": -2.374598264694214,
      "logps/chosen": -817.434326171875,
      "logps/rejected": -1492.2181396484375,
      "loss": 0.1508,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9551114439964294,
      "rewards/margins": 4.588000774383545,
      "rewards/rejected": -5.543111801147461,
      "step": 573
    },
    {
      "epoch": 0.9184,
      "grad_norm": 3.6271276473999023,
      "learning_rate": 4.16e-07,
      "logits/chosen": -2.422560930252075,
      "logits/rejected": -2.4494268894195557,
      "logps/chosen": -1646.5751953125,
      "logps/rejected": -2226.361083984375,
      "loss": 0.2319,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.9084030389785767,
      "rewards/margins": 4.485055446624756,
      "rewards/rejected": -6.393457889556885,
      "step": 574
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.39409393072128296,
      "learning_rate": 4.0800000000000005e-07,
      "logits/chosen": -2.353001356124878,
      "logits/rejected": -2.3974084854125977,
      "logps/chosen": -447.824462890625,
      "logps/rejected": -1402.7069091796875,
      "loss": 0.0697,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6531118154525757,
      "rewards/margins": 4.806395053863525,
      "rewards/rejected": -5.459506988525391,
      "step": 575
    },
    {
      "epoch": 0.9216,
      "grad_norm": 1.5012801885604858,
      "learning_rate": 4.0000000000000003e-07,
      "logits/chosen": -2.309730052947998,
      "logits/rejected": -2.3093841075897217,
      "logps/chosen": -1299.130859375,
      "logps/rejected": -2192.304443359375,
      "loss": 0.1656,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.5725631713867188,
      "rewards/margins": 6.918143272399902,
      "rewards/rejected": -8.490706443786621,
      "step": 576
    },
    {
      "epoch": 0.9232,
      "grad_norm": 2.668091058731079,
      "learning_rate": 3.92e-07,
      "logits/chosen": -2.277930498123169,
      "logits/rejected": -2.2648355960845947,
      "logps/chosen": -1247.4783935546875,
      "logps/rejected": -1646.6617431640625,
      "loss": 0.1928,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.2569072246551514,
      "rewards/margins": 4.539835453033447,
      "rewards/rejected": -6.7967424392700195,
      "step": 577
    },
    {
      "epoch": 0.9248,
      "grad_norm": 1.8969390392303467,
      "learning_rate": 3.84e-07,
      "logits/chosen": -2.3430492877960205,
      "logits/rejected": -2.28068208694458,
      "logps/chosen": -1240.391845703125,
      "logps/rejected": -1700.8922119140625,
      "loss": 0.15,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.1795662641525269,
      "rewards/margins": 4.7063493728637695,
      "rewards/rejected": -5.885915756225586,
      "step": 578
    },
    {
      "epoch": 0.9264,
      "grad_norm": 0.7092167735099792,
      "learning_rate": 3.7600000000000003e-07,
      "logits/chosen": -2.241347312927246,
      "logits/rejected": -2.3441953659057617,
      "logps/chosen": -958.1686401367188,
      "logps/rejected": -1911.318359375,
      "loss": 0.08,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7222793698310852,
      "rewards/margins": 5.432086944580078,
      "rewards/rejected": -6.154366493225098,
      "step": 579
    },
    {
      "epoch": 0.928,
      "grad_norm": 1.73994779586792,
      "learning_rate": 3.68e-07,
      "logits/chosen": -2.1633660793304443,
      "logits/rejected": -2.1882519721984863,
      "logps/chosen": -1181.760498046875,
      "logps/rejected": -2055.04248046875,
      "loss": 0.0747,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.527626872062683,
      "rewards/margins": 4.745535850524902,
      "rewards/rejected": -6.273163318634033,
      "step": 580
    },
    {
      "epoch": 0.9296,
      "grad_norm": 4.4922027587890625,
      "learning_rate": 3.6e-07,
      "logits/chosen": -2.3781983852386475,
      "logits/rejected": -2.3383584022521973,
      "logps/chosen": -1042.05419921875,
      "logps/rejected": -1200.979736328125,
      "loss": 0.2924,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.567002534866333,
      "rewards/margins": 3.1620802879333496,
      "rewards/rejected": -4.7290825843811035,
      "step": 581
    },
    {
      "epoch": 0.9312,
      "grad_norm": 1.5186573266983032,
      "learning_rate": 3.5200000000000003e-07,
      "logits/chosen": -2.2129416465759277,
      "logits/rejected": -2.327338933944702,
      "logps/chosen": -414.7493896484375,
      "logps/rejected": -1075.1785888671875,
      "loss": 0.1486,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.32449424266815186,
      "rewards/margins": 4.277217864990234,
      "rewards/rejected": -4.601712226867676,
      "step": 582
    },
    {
      "epoch": 0.9328,
      "grad_norm": 0.9626854062080383,
      "learning_rate": 3.44e-07,
      "logits/chosen": -2.2524774074554443,
      "logits/rejected": -2.2850778102874756,
      "logps/chosen": -1057.9449462890625,
      "logps/rejected": -1537.92138671875,
      "loss": 0.0868,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.012740969657898,
      "rewards/margins": 5.591446876525879,
      "rewards/rejected": -6.604187488555908,
      "step": 583
    },
    {
      "epoch": 0.9344,
      "grad_norm": 1.625244140625,
      "learning_rate": 3.36e-07,
      "logits/chosen": -2.187351703643799,
      "logits/rejected": -2.4233529567718506,
      "logps/chosen": -974.0298461914062,
      "logps/rejected": -1754.027099609375,
      "loss": 0.1074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2731508016586304,
      "rewards/margins": 4.669179439544678,
      "rewards/rejected": -5.942330360412598,
      "step": 584
    },
    {
      "epoch": 0.936,
      "grad_norm": 1.08119797706604,
      "learning_rate": 3.280000000000001e-07,
      "logits/chosen": -2.319092273712158,
      "logits/rejected": -2.3705949783325195,
      "logps/chosen": -1017.2353515625,
      "logps/rejected": -1718.9661865234375,
      "loss": 0.0821,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6750632524490356,
      "rewards/margins": 4.568153381347656,
      "rewards/rejected": -5.243216514587402,
      "step": 585
    },
    {
      "epoch": 0.9376,
      "grad_norm": 4.056253433227539,
      "learning_rate": 3.2e-07,
      "logits/chosen": -2.270040273666382,
      "logits/rejected": -2.260653495788574,
      "logps/chosen": -1147.1597900390625,
      "logps/rejected": -1679.0228271484375,
      "loss": 0.1822,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.2889950275421143,
      "rewards/margins": 3.069005250930786,
      "rewards/rejected": -4.357999801635742,
      "step": 586
    },
    {
      "epoch": 0.9392,
      "grad_norm": 0.9603815078735352,
      "learning_rate": 3.12e-07,
      "logits/chosen": -2.3049726486206055,
      "logits/rejected": -2.347388744354248,
      "logps/chosen": -745.5650024414062,
      "logps/rejected": -1415.8828125,
      "loss": 0.0845,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8522503972053528,
      "rewards/margins": 4.5034637451171875,
      "rewards/rejected": -5.355713844299316,
      "step": 587
    },
    {
      "epoch": 0.9408,
      "grad_norm": 2.3056857585906982,
      "learning_rate": 3.04e-07,
      "logits/chosen": -2.3734335899353027,
      "logits/rejected": -2.388723850250244,
      "logps/chosen": -1269.146728515625,
      "logps/rejected": -1979.4049072265625,
      "loss": 0.0839,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.248297929763794,
      "rewards/margins": 5.204474449157715,
      "rewards/rejected": -6.452771186828613,
      "step": 588
    },
    {
      "epoch": 0.9424,
      "grad_norm": 1.1324220895767212,
      "learning_rate": 2.9600000000000006e-07,
      "logits/chosen": -2.4200804233551025,
      "logits/rejected": -2.440885305404663,
      "logps/chosen": -730.319091796875,
      "logps/rejected": -1473.7379150390625,
      "loss": 0.0699,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7532817721366882,
      "rewards/margins": 4.168104648590088,
      "rewards/rejected": -4.92138671875,
      "step": 589
    },
    {
      "epoch": 0.944,
      "grad_norm": 1.3750158548355103,
      "learning_rate": 2.8800000000000004e-07,
      "logits/chosen": -2.332019329071045,
      "logits/rejected": -2.2885611057281494,
      "logps/chosen": -1337.8577880859375,
      "logps/rejected": -2111.003173828125,
      "loss": 0.1045,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3975419998168945,
      "rewards/margins": 4.819274425506592,
      "rewards/rejected": -6.2168169021606445,
      "step": 590
    },
    {
      "epoch": 0.9456,
      "grad_norm": 3.2341604232788086,
      "learning_rate": 2.8e-07,
      "logits/chosen": -2.2340614795684814,
      "logits/rejected": -2.3830604553222656,
      "logps/chosen": -858.575439453125,
      "logps/rejected": -1774.6407470703125,
      "loss": 0.2052,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9760552048683167,
      "rewards/margins": 3.1806228160858154,
      "rewards/rejected": -4.156678199768066,
      "step": 591
    },
    {
      "epoch": 0.9472,
      "grad_norm": 2.381845235824585,
      "learning_rate": 2.72e-07,
      "logits/chosen": -2.4113240242004395,
      "logits/rejected": -2.380049467086792,
      "logps/chosen": -1188.05615234375,
      "logps/rejected": -1584.3087158203125,
      "loss": 0.1476,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.5367989540100098,
      "rewards/margins": 3.715066432952881,
      "rewards/rejected": -5.251865863800049,
      "step": 592
    },
    {
      "epoch": 0.9488,
      "grad_norm": 1.5394669771194458,
      "learning_rate": 2.6400000000000003e-07,
      "logits/chosen": -2.336397886276245,
      "logits/rejected": -2.2403626441955566,
      "logps/chosen": -1051.090576171875,
      "logps/rejected": -1624.4378662109375,
      "loss": 0.0774,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1767051219940186,
      "rewards/margins": 4.227970600128174,
      "rewards/rejected": -5.4046759605407715,
      "step": 593
    },
    {
      "epoch": 0.9504,
      "grad_norm": 3.8579981327056885,
      "learning_rate": 2.56e-07,
      "logits/chosen": -2.117454767227173,
      "logits/rejected": -2.3306732177734375,
      "logps/chosen": -442.741943359375,
      "logps/rejected": -1333.1983642578125,
      "loss": 0.1747,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.712421178817749,
      "rewards/margins": 4.4085469245910645,
      "rewards/rejected": -5.120967864990234,
      "step": 594
    },
    {
      "epoch": 0.952,
      "grad_norm": 2.124802350997925,
      "learning_rate": 2.48e-07,
      "logits/chosen": -2.345956802368164,
      "logits/rejected": -2.3900206089019775,
      "logps/chosen": -1288.0562744140625,
      "logps/rejected": -1797.216796875,
      "loss": 0.1534,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.5085021257400513,
      "rewards/margins": 4.048212051391602,
      "rewards/rejected": -5.556714057922363,
      "step": 595
    },
    {
      "epoch": 0.9536,
      "grad_norm": 4.006537914276123,
      "learning_rate": 2.4000000000000003e-07,
      "logits/chosen": -2.395214796066284,
      "logits/rejected": -2.4216866493225098,
      "logps/chosen": -1355.5946044921875,
      "logps/rejected": -2009.515380859375,
      "loss": 0.1443,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.7068179845809937,
      "rewards/margins": 4.232202053070068,
      "rewards/rejected": -5.939019680023193,
      "step": 596
    },
    {
      "epoch": 0.9552,
      "grad_norm": 1.9658441543579102,
      "learning_rate": 2.32e-07,
      "logits/chosen": -2.2975122928619385,
      "logits/rejected": -2.3543169498443604,
      "logps/chosen": -1360.31787109375,
      "logps/rejected": -1604.159423828125,
      "loss": 0.1069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3459888696670532,
      "rewards/margins": 4.549741744995117,
      "rewards/rejected": -5.895730972290039,
      "step": 597
    },
    {
      "epoch": 0.9568,
      "grad_norm": 1.641167163848877,
      "learning_rate": 2.2400000000000002e-07,
      "logits/chosen": -2.3784985542297363,
      "logits/rejected": -2.333669424057007,
      "logps/chosen": -1557.0472412109375,
      "logps/rejected": -2907.6201171875,
      "loss": 0.0942,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7137178182601929,
      "rewards/margins": 3.9900379180908203,
      "rewards/rejected": -5.703755855560303,
      "step": 598
    },
    {
      "epoch": 0.9584,
      "grad_norm": 2.433048725128174,
      "learning_rate": 2.1600000000000003e-07,
      "logits/chosen": -2.054572343826294,
      "logits/rejected": -2.2038180828094482,
      "logps/chosen": -1706.206787109375,
      "logps/rejected": -1428.05908203125,
      "loss": 0.1409,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6326116323471069,
      "rewards/margins": 3.718397617340088,
      "rewards/rejected": -4.351009368896484,
      "step": 599
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.211324691772461,
      "learning_rate": 2.08e-07,
      "logits/chosen": -2.2741827964782715,
      "logits/rejected": -2.3542985916137695,
      "logps/chosen": -1058.85595703125,
      "logps/rejected": -1678.9647216796875,
      "loss": 0.0539,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0049954652786255,
      "rewards/margins": 5.417974472045898,
      "rewards/rejected": -6.422969818115234,
      "step": 600
    }
  ],
  "logging_steps": 1.0,
  "max_steps": 625,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
