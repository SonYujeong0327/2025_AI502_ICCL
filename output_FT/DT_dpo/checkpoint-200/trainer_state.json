{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.32,
  "eval_steps": 500,
  "global_step": 200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0016,
      "grad_norm": 5.777158260345459,
      "learning_rate": 5e-06,
      "logits/chosen": -2.383577346801758,
      "logits/rejected": -2.5550010204315186,
      "logps/chosen": -997.095947265625,
      "logps/rejected": -1401.2965087890625,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.0032,
      "grad_norm": 29.931734085083008,
      "learning_rate": 4.992e-06,
      "logits/chosen": -2.4591455459594727,
      "logits/rejected": -2.4508743286132812,
      "logps/chosen": -889.494873046875,
      "logps/rejected": -2650.220703125,
      "loss": 0.6859,
      "rewards/accuracies": 0.3125,
      "rewards/chosen": -0.0005279185716062784,
      "rewards/margins": 0.01758369244635105,
      "rewards/rejected": -0.018111608922481537,
      "step": 2
    },
    {
      "epoch": 0.0048,
      "grad_norm": 7.421308517456055,
      "learning_rate": 4.984000000000001e-06,
      "logits/chosen": -2.387298107147217,
      "logits/rejected": -2.400231122970581,
      "logps/chosen": -877.0235595703125,
      "logps/rejected": -1620.46630859375,
      "loss": 0.6878,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.010252094827592373,
      "rewards/margins": 0.011494734324514866,
      "rewards/rejected": -0.0012426384491845965,
      "step": 3
    },
    {
      "epoch": 0.0064,
      "grad_norm": 8.491647720336914,
      "learning_rate": 4.976e-06,
      "logits/chosen": -2.3299200534820557,
      "logits/rejected": -2.475105047225952,
      "logps/chosen": -953.943359375,
      "logps/rejected": -1942.45849609375,
      "loss": 0.6801,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -6.537511944770813e-05,
      "rewards/margins": 0.02661166340112686,
      "rewards/rejected": -0.02667703852057457,
      "step": 4
    },
    {
      "epoch": 0.008,
      "grad_norm": 7.217437267303467,
      "learning_rate": 4.9680000000000005e-06,
      "logits/chosen": -2.424405574798584,
      "logits/rejected": -2.46640944480896,
      "logps/chosen": -1256.431884765625,
      "logps/rejected": -1457.0126953125,
      "loss": 0.6812,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.011346865445375443,
      "rewards/margins": 0.024357369169592857,
      "rewards/rejected": -0.013010501861572266,
      "step": 5
    },
    {
      "epoch": 0.0096,
      "grad_norm": 6.225366115570068,
      "learning_rate": 4.960000000000001e-06,
      "logits/chosen": -2.5838606357574463,
      "logits/rejected": -2.5992836952209473,
      "logps/chosen": -938.2471923828125,
      "logps/rejected": -1745.748291015625,
      "loss": 0.689,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.00911245308816433,
      "rewards/margins": 0.008689593523740768,
      "rewards/rejected": -0.017802048474550247,
      "step": 6
    },
    {
      "epoch": 0.0112,
      "grad_norm": 8.435750007629395,
      "learning_rate": 4.952e-06,
      "logits/chosen": -2.483788013458252,
      "logits/rejected": -2.45876145362854,
      "logps/chosen": -1286.958740234375,
      "logps/rejected": -2144.93798828125,
      "loss": 0.6827,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.0014164212625473738,
      "rewards/margins": 0.021252466365695,
      "rewards/rejected": -0.019836043938994408,
      "step": 7
    },
    {
      "epoch": 0.0128,
      "grad_norm": 6.893909931182861,
      "learning_rate": 4.9440000000000004e-06,
      "logits/chosen": -2.526834726333618,
      "logits/rejected": -2.5802536010742188,
      "logps/chosen": -1098.858154296875,
      "logps/rejected": -1681.0372314453125,
      "loss": 0.6879,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.006822490599006414,
      "rewards/margins": 0.010760593228042126,
      "rewards/rejected": -0.003938103094696999,
      "step": 8
    },
    {
      "epoch": 0.0144,
      "grad_norm": 6.476867198944092,
      "learning_rate": 4.936e-06,
      "logits/chosen": -2.525251626968384,
      "logits/rejected": -2.5307137966156006,
      "logps/chosen": -1156.2413330078125,
      "logps/rejected": -1707.1953125,
      "loss": 0.6761,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.0015508650103583932,
      "rewards/margins": 0.035054970532655716,
      "rewards/rejected": -0.03350410610437393,
      "step": 9
    },
    {
      "epoch": 0.016,
      "grad_norm": 6.029538154602051,
      "learning_rate": 4.928000000000001e-06,
      "logits/chosen": -2.4935433864593506,
      "logits/rejected": -2.474785327911377,
      "logps/chosen": -962.8341674804688,
      "logps/rejected": -1336.4739990234375,
      "loss": 0.6726,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.010607386007905006,
      "rewards/margins": 0.04225526005029678,
      "rewards/rejected": -0.031647875905036926,
      "step": 10
    },
    {
      "epoch": 0.0176,
      "grad_norm": 5.764677047729492,
      "learning_rate": 4.92e-06,
      "logits/chosen": -2.579183340072632,
      "logits/rejected": -2.5417375564575195,
      "logps/chosen": -855.5267333984375,
      "logps/rejected": -1480.712646484375,
      "loss": 0.6719,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.0050948625430464745,
      "rewards/margins": 0.04409470409154892,
      "rewards/rejected": -0.04918956756591797,
      "step": 11
    },
    {
      "epoch": 0.0192,
      "grad_norm": 5.572897434234619,
      "learning_rate": 4.9120000000000006e-06,
      "logits/chosen": -2.5378787517547607,
      "logits/rejected": -2.5528461933135986,
      "logps/chosen": -994.4022216796875,
      "logps/rejected": -1402.746826171875,
      "loss": 0.6692,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.00486366730183363,
      "rewards/margins": 0.05027425289154053,
      "rewards/rejected": -0.05513792484998703,
      "step": 12
    },
    {
      "epoch": 0.0208,
      "grad_norm": 8.677556991577148,
      "learning_rate": 4.904000000000001e-06,
      "logits/chosen": -2.4339964389801025,
      "logits/rejected": -2.392798662185669,
      "logps/chosen": -1155.759033203125,
      "logps/rejected": -1554.5931396484375,
      "loss": 0.6582,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.002712750341743231,
      "rewards/margins": 0.07392475754022598,
      "rewards/rejected": -0.07121200859546661,
      "step": 13
    },
    {
      "epoch": 0.0224,
      "grad_norm": 5.772674083709717,
      "learning_rate": 4.896e-06,
      "logits/chosen": -2.3930609226226807,
      "logits/rejected": -2.4590721130371094,
      "logps/chosen": -1166.37060546875,
      "logps/rejected": -1731.8026123046875,
      "loss": 0.6746,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.00047166342847049236,
      "rewards/margins": 0.037793707102537155,
      "rewards/rejected": -0.037322044372558594,
      "step": 14
    },
    {
      "epoch": 0.024,
      "grad_norm": 5.9789276123046875,
      "learning_rate": 4.8880000000000005e-06,
      "logits/chosen": -2.5120468139648438,
      "logits/rejected": -2.521805763244629,
      "logps/chosen": -825.6015014648438,
      "logps/rejected": -1392.1414794921875,
      "loss": 0.6582,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.003991508856415749,
      "rewards/margins": 0.0750049576163292,
      "rewards/rejected": -0.07899646461009979,
      "step": 15
    },
    {
      "epoch": 0.0256,
      "grad_norm": 7.461836338043213,
      "learning_rate": 4.880000000000001e-06,
      "logits/chosen": -2.482703685760498,
      "logits/rejected": -2.4834096431732178,
      "logps/chosen": -1601.0765380859375,
      "logps/rejected": -1890.500732421875,
      "loss": 0.6417,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.008066796697676182,
      "rewards/margins": 0.10860419273376465,
      "rewards/rejected": -0.11667098850011826,
      "step": 16
    },
    {
      "epoch": 0.0272,
      "grad_norm": 6.696410179138184,
      "learning_rate": 4.872000000000001e-06,
      "logits/chosen": -2.2976319789886475,
      "logits/rejected": -2.504713535308838,
      "logps/chosen": -909.9552612304688,
      "logps/rejected": -1605.83740234375,
      "loss": 0.6628,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.016479289159178734,
      "rewards/margins": 0.06566496938467026,
      "rewards/rejected": -0.08214426785707474,
      "step": 17
    },
    {
      "epoch": 0.0288,
      "grad_norm": 5.730576992034912,
      "learning_rate": 4.864e-06,
      "logits/chosen": -2.494868516921997,
      "logits/rejected": -2.5170273780822754,
      "logps/chosen": -718.1146850585938,
      "logps/rejected": -1341.41845703125,
      "loss": 0.6536,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.006640315055847168,
      "rewards/margins": 0.08292777091264725,
      "rewards/rejected": -0.07628745585680008,
      "step": 18
    },
    {
      "epoch": 0.0304,
      "grad_norm": 5.351961135864258,
      "learning_rate": 4.856e-06,
      "logits/chosen": -2.2484681606292725,
      "logits/rejected": -2.5302162170410156,
      "logps/chosen": -777.997314453125,
      "logps/rejected": -1522.199951171875,
      "loss": 0.6517,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.0043878923170268536,
      "rewards/margins": 0.08642282336950302,
      "rewards/rejected": -0.08203492313623428,
      "step": 19
    },
    {
      "epoch": 0.032,
      "grad_norm": 5.9492926597595215,
      "learning_rate": 4.848000000000001e-06,
      "logits/chosen": -2.427757740020752,
      "logits/rejected": -2.4902050495147705,
      "logps/chosen": -1203.291748046875,
      "logps/rejected": -1451.47900390625,
      "loss": 0.6262,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020780373364686966,
      "rewards/margins": 0.1411726027727127,
      "rewards/rejected": -0.12039223313331604,
      "step": 20
    },
    {
      "epoch": 0.0336,
      "grad_norm": 6.540633678436279,
      "learning_rate": 4.84e-06,
      "logits/chosen": -2.303931713104248,
      "logits/rejected": -2.5109848976135254,
      "logps/chosen": -1161.491455078125,
      "logps/rejected": -1683.808349609375,
      "loss": 0.6433,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.004983187187463045,
      "rewards/margins": 0.10777640342712402,
      "rewards/rejected": -0.11275959014892578,
      "step": 21
    },
    {
      "epoch": 0.0352,
      "grad_norm": 6.436901092529297,
      "learning_rate": 4.8320000000000005e-06,
      "logits/chosen": -2.400743007659912,
      "logits/rejected": -2.4598302841186523,
      "logps/chosen": -853.2847290039062,
      "logps/rejected": -1669.84033203125,
      "loss": 0.6078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.005872583016753197,
      "rewards/margins": 0.18278947472572327,
      "rewards/rejected": -0.1886620670557022,
      "step": 22
    },
    {
      "epoch": 0.0368,
      "grad_norm": 5.8360090255737305,
      "learning_rate": 4.824000000000001e-06,
      "logits/chosen": -2.4765625,
      "logits/rejected": -2.5283117294311523,
      "logps/chosen": -1193.60595703125,
      "logps/rejected": -1400.964599609375,
      "loss": 0.6429,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.009444882161915302,
      "rewards/margins": 0.10741741955280304,
      "rewards/rejected": -0.11686229705810547,
      "step": 23
    },
    {
      "epoch": 0.0384,
      "grad_norm": 5.09824275970459,
      "learning_rate": 4.816e-06,
      "logits/chosen": -2.4321236610412598,
      "logits/rejected": -2.500823974609375,
      "logps/chosen": -684.755859375,
      "logps/rejected": -1265.620361328125,
      "loss": 0.6217,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.00216085952706635,
      "rewards/margins": 0.15424855053424835,
      "rewards/rejected": -0.15208768844604492,
      "step": 24
    },
    {
      "epoch": 0.04,
      "grad_norm": 4.6456685066223145,
      "learning_rate": 4.808e-06,
      "logits/chosen": -2.4003920555114746,
      "logits/rejected": -2.6259267330169678,
      "logps/chosen": -662.1038818359375,
      "logps/rejected": -1401.2833251953125,
      "loss": 0.6219,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.005369471851736307,
      "rewards/margins": 0.15287218987941742,
      "rewards/rejected": -0.14750270545482635,
      "step": 25
    },
    {
      "epoch": 0.0416,
      "grad_norm": 6.444249629974365,
      "learning_rate": 4.800000000000001e-06,
      "logits/chosen": -2.4268743991851807,
      "logits/rejected": -2.515354633331299,
      "logps/chosen": -1249.900634765625,
      "logps/rejected": -1548.016357421875,
      "loss": 0.6071,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.02955174446105957,
      "rewards/margins": 0.19209963083267212,
      "rewards/rejected": -0.2216513752937317,
      "step": 26
    },
    {
      "epoch": 0.0432,
      "grad_norm": 5.8396430015563965,
      "learning_rate": 4.792000000000001e-06,
      "logits/chosen": -2.4963107109069824,
      "logits/rejected": -2.5389151573181152,
      "logps/chosen": -1776.93798828125,
      "logps/rejected": -1911.4761962890625,
      "loss": 0.619,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.008384992368519306,
      "rewards/margins": 0.16205109655857086,
      "rewards/rejected": -0.17043611407279968,
      "step": 27
    },
    {
      "epoch": 0.0448,
      "grad_norm": 4.950774192810059,
      "learning_rate": 4.784e-06,
      "logits/chosen": -2.5377228260040283,
      "logits/rejected": -2.5655124187469482,
      "logps/chosen": -770.48486328125,
      "logps/rejected": -1328.5189208984375,
      "loss": 0.6363,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.019844507798552513,
      "rewards/margins": 0.12086965888738632,
      "rewards/rejected": -0.14071418344974518,
      "step": 28
    },
    {
      "epoch": 0.0464,
      "grad_norm": 4.218019962310791,
      "learning_rate": 4.7760000000000005e-06,
      "logits/chosen": -2.5830776691436768,
      "logits/rejected": -2.615169048309326,
      "logps/chosen": -836.572021484375,
      "logps/rejected": -1111.2818603515625,
      "loss": 0.6193,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.015565921552479267,
      "rewards/margins": 0.16033843159675598,
      "rewards/rejected": -0.17590436339378357,
      "step": 29
    },
    {
      "epoch": 0.048,
      "grad_norm": 6.1509175300598145,
      "learning_rate": 4.768000000000001e-06,
      "logits/chosen": -2.3730645179748535,
      "logits/rejected": -2.498508930206299,
      "logps/chosen": -1609.7783203125,
      "logps/rejected": -1804.330078125,
      "loss": 0.5917,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.015220570378005505,
      "rewards/margins": 0.2305750548839569,
      "rewards/rejected": -0.2457956224679947,
      "step": 30
    },
    {
      "epoch": 0.0496,
      "grad_norm": 4.998894214630127,
      "learning_rate": 4.76e-06,
      "logits/chosen": -2.418651819229126,
      "logits/rejected": -2.497138738632202,
      "logps/chosen": -1092.2430419921875,
      "logps/rejected": -1448.130126953125,
      "loss": 0.5809,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.0014558564871549606,
      "rewards/margins": 0.2704559862613678,
      "rewards/rejected": -0.2719117999076843,
      "step": 31
    },
    {
      "epoch": 0.0512,
      "grad_norm": 7.974624156951904,
      "learning_rate": 4.752e-06,
      "logits/chosen": -2.4644689559936523,
      "logits/rejected": -2.4903476238250732,
      "logps/chosen": -1456.8184814453125,
      "logps/rejected": -1984.0936279296875,
      "loss": 0.6069,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.039417147636413574,
      "rewards/margins": 0.2027800977230072,
      "rewards/rejected": -0.24219724535942078,
      "step": 32
    },
    {
      "epoch": 0.0528,
      "grad_norm": 6.433887481689453,
      "learning_rate": 4.744000000000001e-06,
      "logits/chosen": -2.5184032917022705,
      "logits/rejected": -2.4885895252227783,
      "logps/chosen": -1556.9276123046875,
      "logps/rejected": -2208.9404296875,
      "loss": 0.5729,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.036615803837776184,
      "rewards/margins": 0.2789185047149658,
      "rewards/rejected": -0.3155343532562256,
      "step": 33
    },
    {
      "epoch": 0.0544,
      "grad_norm": 5.127695560455322,
      "learning_rate": 4.736000000000001e-06,
      "logits/chosen": -2.527791976928711,
      "logits/rejected": -2.5352911949157715,
      "logps/chosen": -761.0938720703125,
      "logps/rejected": -1747.624755859375,
      "loss": 0.564,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.0006397361867129803,
      "rewards/margins": 0.28775492310523987,
      "rewards/rejected": -0.2871151864528656,
      "step": 34
    },
    {
      "epoch": 0.056,
      "grad_norm": 4.690290451049805,
      "learning_rate": 4.728e-06,
      "logits/chosen": -2.3896756172180176,
      "logits/rejected": -2.4915108680725098,
      "logps/chosen": -954.8023071289062,
      "logps/rejected": -1395.8271484375,
      "loss": 0.6103,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.022553065791726112,
      "rewards/margins": 0.18402671813964844,
      "rewards/rejected": -0.2065797746181488,
      "step": 35
    },
    {
      "epoch": 0.0576,
      "grad_norm": 5.159278869628906,
      "learning_rate": 4.7200000000000005e-06,
      "logits/chosen": -2.4312891960144043,
      "logits/rejected": -2.5728580951690674,
      "logps/chosen": -1027.1085205078125,
      "logps/rejected": -1698.792236328125,
      "loss": 0.5754,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020159317180514336,
      "rewards/margins": 0.2611401081085205,
      "rewards/rejected": -0.2409808188676834,
      "step": 36
    },
    {
      "epoch": 0.0592,
      "grad_norm": 5.163532257080078,
      "learning_rate": 4.712000000000001e-06,
      "logits/chosen": -2.444011688232422,
      "logits/rejected": -2.545302391052246,
      "logps/chosen": -985.62548828125,
      "logps/rejected": -1722.9822998046875,
      "loss": 0.5289,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.023259827867150307,
      "rewards/margins": 0.4088696837425232,
      "rewards/rejected": -0.38560980558395386,
      "step": 37
    },
    {
      "epoch": 0.0608,
      "grad_norm": 4.443084716796875,
      "learning_rate": 4.704e-06,
      "logits/chosen": -2.4531683921813965,
      "logits/rejected": -2.3953018188476562,
      "logps/chosen": -1051.037109375,
      "logps/rejected": -1488.4656982421875,
      "loss": 0.4829,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03958432748913765,
      "rewards/margins": 0.6120326519012451,
      "rewards/rejected": -0.5724484324455261,
      "step": 38
    },
    {
      "epoch": 0.0624,
      "grad_norm": 4.36039924621582,
      "learning_rate": 4.6960000000000004e-06,
      "logits/chosen": -2.346738815307617,
      "logits/rejected": -2.3932557106018066,
      "logps/chosen": -781.6734619140625,
      "logps/rejected": -1389.060302734375,
      "loss": 0.5071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.025782395154237747,
      "rewards/margins": 0.5120918154716492,
      "rewards/rejected": -0.4863094687461853,
      "step": 39
    },
    {
      "epoch": 0.064,
      "grad_norm": 4.423152446746826,
      "learning_rate": 4.688000000000001e-06,
      "logits/chosen": -2.3941683769226074,
      "logits/rejected": -2.4453883171081543,
      "logps/chosen": -1348.4906005859375,
      "logps/rejected": -1369.6048583984375,
      "loss": 0.5197,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.08326391875743866,
      "rewards/margins": 0.4253552258014679,
      "rewards/rejected": -0.34209129214286804,
      "step": 40
    },
    {
      "epoch": 0.0656,
      "grad_norm": 3.917776346206665,
      "learning_rate": 4.680000000000001e-06,
      "logits/chosen": -2.5225353240966797,
      "logits/rejected": -2.4893646240234375,
      "logps/chosen": -631.3782348632812,
      "logps/rejected": -1237.5419921875,
      "loss": 0.5319,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.003564846236258745,
      "rewards/margins": 0.3783791661262512,
      "rewards/rejected": -0.38194403052330017,
      "step": 41
    },
    {
      "epoch": 0.0672,
      "grad_norm": 6.309618949890137,
      "learning_rate": 4.672e-06,
      "logits/chosen": -2.3947300910949707,
      "logits/rejected": -2.33028244972229,
      "logps/chosen": -997.8880615234375,
      "logps/rejected": -1573.5198974609375,
      "loss": 0.5715,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.01999068260192871,
      "rewards/margins": 0.27362799644470215,
      "rewards/rejected": -0.29361870884895325,
      "step": 42
    },
    {
      "epoch": 0.0688,
      "grad_norm": 4.295537948608398,
      "learning_rate": 4.664000000000001e-06,
      "logits/chosen": -2.4997317790985107,
      "logits/rejected": -2.4784295558929443,
      "logps/chosen": -943.6978149414062,
      "logps/rejected": -1176.74560546875,
      "loss": 0.5582,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.027471639215946198,
      "rewards/margins": 0.3107304871082306,
      "rewards/rejected": -0.3382021188735962,
      "step": 43
    },
    {
      "epoch": 0.0704,
      "grad_norm": 7.20757532119751,
      "learning_rate": 4.656000000000001e-06,
      "logits/chosen": -2.440206289291382,
      "logits/rejected": -2.521519899368286,
      "logps/chosen": -1279.581787109375,
      "logps/rejected": -1728.439453125,
      "loss": 0.5333,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.021382711827754974,
      "rewards/margins": 0.37735024094581604,
      "rewards/rejected": -0.35596752166748047,
      "step": 44
    },
    {
      "epoch": 0.072,
      "grad_norm": 4.294131278991699,
      "learning_rate": 4.648e-06,
      "logits/chosen": -2.427238702774048,
      "logits/rejected": -2.499267339706421,
      "logps/chosen": -936.76953125,
      "logps/rejected": -1329.57373046875,
      "loss": 0.5473,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05417850241065025,
      "rewards/margins": 0.3269869089126587,
      "rewards/rejected": -0.38116541504859924,
      "step": 45
    },
    {
      "epoch": 0.0736,
      "grad_norm": 5.159995079040527,
      "learning_rate": 4.6400000000000005e-06,
      "logits/chosen": -2.423997163772583,
      "logits/rejected": -2.4125783443450928,
      "logps/chosen": -1069.165283203125,
      "logps/rejected": -1962.3826904296875,
      "loss": 0.4657,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.025747397914528847,
      "rewards/margins": 0.7605292797088623,
      "rewards/rejected": -0.786276638507843,
      "step": 46
    },
    {
      "epoch": 0.0752,
      "grad_norm": 6.723729610443115,
      "learning_rate": 4.632000000000001e-06,
      "logits/chosen": -2.5509090423583984,
      "logits/rejected": -2.4923243522644043,
      "logps/chosen": -1556.790771484375,
      "logps/rejected": -1895.181640625,
      "loss": 0.5837,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.12032730132341385,
      "rewards/margins": 0.2908268868923187,
      "rewards/rejected": -0.41115421056747437,
      "step": 47
    },
    {
      "epoch": 0.0768,
      "grad_norm": 4.9094438552856445,
      "learning_rate": 4.624e-06,
      "logits/chosen": -2.403075933456421,
      "logits/rejected": -2.5514211654663086,
      "logps/chosen": -858.0516357421875,
      "logps/rejected": -1559.831298828125,
      "loss": 0.5251,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0030367602594196796,
      "rewards/margins": 0.39764222502708435,
      "rewards/rejected": -0.40067896246910095,
      "step": 48
    },
    {
      "epoch": 0.0784,
      "grad_norm": 5.90323543548584,
      "learning_rate": 4.616e-06,
      "logits/chosen": -2.402954339981079,
      "logits/rejected": -2.5007476806640625,
      "logps/chosen": -1644.49365234375,
      "logps/rejected": -2142.56591796875,
      "loss": 0.4077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04832523688673973,
      "rewards/margins": 0.7789440751075745,
      "rewards/rejected": -0.7306188941001892,
      "step": 49
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.876892566680908,
      "learning_rate": 4.608000000000001e-06,
      "logits/chosen": -2.4634196758270264,
      "logits/rejected": -2.524357795715332,
      "logps/chosen": -1243.4114990234375,
      "logps/rejected": -2200.423095703125,
      "loss": 0.4226,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0012695789337158203,
      "rewards/margins": 0.7439866065979004,
      "rewards/rejected": -0.745256245136261,
      "step": 50
    },
    {
      "epoch": 0.0816,
      "grad_norm": 5.304353713989258,
      "learning_rate": 4.600000000000001e-06,
      "logits/chosen": -2.554231882095337,
      "logits/rejected": -2.532021999359131,
      "logps/chosen": -1630.2579345703125,
      "logps/rejected": -1748.79052734375,
      "loss": 0.4516,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.009376813657581806,
      "rewards/margins": 0.6017025709152222,
      "rewards/rejected": -0.6110793948173523,
      "step": 51
    },
    {
      "epoch": 0.0832,
      "grad_norm": 5.187316417694092,
      "learning_rate": 4.592e-06,
      "logits/chosen": -2.498135566711426,
      "logits/rejected": -2.4083938598632812,
      "logps/chosen": -1384.689208984375,
      "logps/rejected": -1931.995849609375,
      "loss": 0.4644,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.07917461544275284,
      "rewards/margins": 0.5850769877433777,
      "rewards/rejected": -0.6642515659332275,
      "step": 52
    },
    {
      "epoch": 0.0848,
      "grad_norm": 4.838135242462158,
      "learning_rate": 4.5840000000000005e-06,
      "logits/chosen": -2.445882797241211,
      "logits/rejected": -2.4829466342926025,
      "logps/chosen": -1116.0863037109375,
      "logps/rejected": -1792.969970703125,
      "loss": 0.5174,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.07026398181915283,
      "rewards/margins": 0.489179402589798,
      "rewards/rejected": -0.5594433546066284,
      "step": 53
    },
    {
      "epoch": 0.0864,
      "grad_norm": 5.2209553718566895,
      "learning_rate": 4.576000000000001e-06,
      "logits/chosen": -2.413048267364502,
      "logits/rejected": -2.4262566566467285,
      "logps/chosen": -887.2513427734375,
      "logps/rejected": -1720.2169189453125,
      "loss": 0.4544,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.022820793092250824,
      "rewards/margins": 0.6332731246948242,
      "rewards/rejected": -0.6104522347450256,
      "step": 54
    },
    {
      "epoch": 0.088,
      "grad_norm": 4.8002119064331055,
      "learning_rate": 4.568e-06,
      "logits/chosen": -2.254833459854126,
      "logits/rejected": -2.3849010467529297,
      "logps/chosen": -939.0093994140625,
      "logps/rejected": -1890.1427001953125,
      "loss": 0.3753,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.018575191497802734,
      "rewards/margins": 0.9412721395492554,
      "rewards/rejected": -0.9598473310470581,
      "step": 55
    },
    {
      "epoch": 0.0896,
      "grad_norm": 4.960271835327148,
      "learning_rate": 4.56e-06,
      "logits/chosen": -2.579571485519409,
      "logits/rejected": -2.515536069869995,
      "logps/chosen": -1340.374755859375,
      "logps/rejected": -1811.5596923828125,
      "loss": 0.4404,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.053728677332401276,
      "rewards/margins": 0.6789557337760925,
      "rewards/rejected": -0.7326843738555908,
      "step": 56
    },
    {
      "epoch": 0.0912,
      "grad_norm": 3.3769338130950928,
      "learning_rate": 4.552000000000001e-06,
      "logits/chosen": -2.22818660736084,
      "logits/rejected": -2.4143457412719727,
      "logps/chosen": -834.120849609375,
      "logps/rejected": -1612.02587890625,
      "loss": 0.428,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.009922838769853115,
      "rewards/margins": 0.7907403111457825,
      "rewards/rejected": -0.8006631731987,
      "step": 57
    },
    {
      "epoch": 0.0928,
      "grad_norm": 4.254573345184326,
      "learning_rate": 4.544000000000001e-06,
      "logits/chosen": -2.465895652770996,
      "logits/rejected": -2.4853782653808594,
      "logps/chosen": -1072.5191650390625,
      "logps/rejected": -1706.7333984375,
      "loss": 0.4479,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.04329273849725723,
      "rewards/margins": 0.7244612574577332,
      "rewards/rejected": -0.7677540183067322,
      "step": 58
    },
    {
      "epoch": 0.0944,
      "grad_norm": 4.614320278167725,
      "learning_rate": 4.536e-06,
      "logits/chosen": -2.4181833267211914,
      "logits/rejected": -2.4571948051452637,
      "logps/chosen": -1143.388671875,
      "logps/rejected": -1698.9920654296875,
      "loss": 0.4434,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.008206438273191452,
      "rewards/margins": 0.6621529459953308,
      "rewards/rejected": -0.6703594326972961,
      "step": 59
    },
    {
      "epoch": 0.096,
      "grad_norm": 114.27096557617188,
      "learning_rate": 4.5280000000000005e-06,
      "logits/chosen": -2.4065511226654053,
      "logits/rejected": -2.4462428092956543,
      "logps/chosen": -1039.031494140625,
      "logps/rejected": -3243.99658203125,
      "loss": 0.9381,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.0578995943069458,
      "rewards/margins": 0.39896953105926514,
      "rewards/rejected": -0.45686912536621094,
      "step": 60
    },
    {
      "epoch": 0.0976,
      "grad_norm": 4.4341230392456055,
      "learning_rate": 4.520000000000001e-06,
      "logits/chosen": -2.4552948474884033,
      "logits/rejected": -2.548647880554199,
      "logps/chosen": -834.3111572265625,
      "logps/rejected": -1361.443603515625,
      "loss": 0.4711,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0879419595003128,
      "rewards/margins": 0.5348865389823914,
      "rewards/rejected": -0.622828483581543,
      "step": 61
    },
    {
      "epoch": 0.0992,
      "grad_norm": 4.643270969390869,
      "learning_rate": 4.512e-06,
      "logits/chosen": -2.54868221282959,
      "logits/rejected": -2.5269510746002197,
      "logps/chosen": -976.1460571289062,
      "logps/rejected": -1663.8165283203125,
      "loss": 0.4991,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.187369242310524,
      "rewards/margins": 0.749457597732544,
      "rewards/rejected": -0.9368268251419067,
      "step": 62
    },
    {
      "epoch": 0.1008,
      "grad_norm": 4.303009986877441,
      "learning_rate": 4.504e-06,
      "logits/chosen": -2.494508743286133,
      "logits/rejected": -2.4935150146484375,
      "logps/chosen": -1258.249755859375,
      "logps/rejected": -1744.1854248046875,
      "loss": 0.4449,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08252592384815216,
      "rewards/margins": 0.6143494844436646,
      "rewards/rejected": -0.6968754529953003,
      "step": 63
    },
    {
      "epoch": 0.1024,
      "grad_norm": 3.9266281127929688,
      "learning_rate": 4.496000000000001e-06,
      "logits/chosen": -2.4731204509735107,
      "logits/rejected": -2.5203022956848145,
      "logps/chosen": -921.2763671875,
      "logps/rejected": -1744.591064453125,
      "loss": 0.3809,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.022436067461967468,
      "rewards/margins": 0.8827598094940186,
      "rewards/rejected": -0.8603237271308899,
      "step": 64
    },
    {
      "epoch": 0.104,
      "grad_norm": 4.099432945251465,
      "learning_rate": 4.488e-06,
      "logits/chosen": -2.388988971710205,
      "logits/rejected": -2.4264137744903564,
      "logps/chosen": -967.2359008789062,
      "logps/rejected": -2085.13232421875,
      "loss": 0.4029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.023308193311095238,
      "rewards/margins": 0.8329147100448608,
      "rewards/rejected": -0.8562229871749878,
      "step": 65
    },
    {
      "epoch": 0.1056,
      "grad_norm": 3.6696200370788574,
      "learning_rate": 4.48e-06,
      "logits/chosen": -2.2503409385681152,
      "logits/rejected": -2.409578800201416,
      "logps/chosen": -1728.78466796875,
      "logps/rejected": -1662.9283447265625,
      "loss": 0.4228,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.1354823112487793,
      "rewards/margins": 1.030614972114563,
      "rewards/rejected": -0.8951326608657837,
      "step": 66
    },
    {
      "epoch": 0.1072,
      "grad_norm": 4.834355354309082,
      "learning_rate": 4.4720000000000006e-06,
      "logits/chosen": -2.500420093536377,
      "logits/rejected": -2.5279905796051025,
      "logps/chosen": -1192.21923828125,
      "logps/rejected": -2089.546875,
      "loss": 0.413,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.11657924950122833,
      "rewards/margins": 0.784795880317688,
      "rewards/rejected": -0.9013752341270447,
      "step": 67
    },
    {
      "epoch": 0.1088,
      "grad_norm": 3.6707637310028076,
      "learning_rate": 4.464000000000001e-06,
      "logits/chosen": -2.4371845722198486,
      "logits/rejected": -2.486832857131958,
      "logps/chosen": -755.0999755859375,
      "logps/rejected": -1264.963134765625,
      "loss": 0.4467,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.07509183883666992,
      "rewards/margins": 0.7163953185081482,
      "rewards/rejected": -0.7914870977401733,
      "step": 68
    },
    {
      "epoch": 0.1104,
      "grad_norm": 4.412095546722412,
      "learning_rate": 4.456e-06,
      "logits/chosen": -2.5222582817077637,
      "logits/rejected": -2.530050277709961,
      "logps/chosen": -875.586669921875,
      "logps/rejected": -1423.85693359375,
      "loss": 0.4496,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.04253988713026047,
      "rewards/margins": 0.6108039021492004,
      "rewards/rejected": -0.6533437967300415,
      "step": 69
    },
    {
      "epoch": 0.112,
      "grad_norm": 4.693994998931885,
      "learning_rate": 4.4480000000000004e-06,
      "logits/chosen": -2.441682815551758,
      "logits/rejected": -2.4925615787506104,
      "logps/chosen": -1033.46142578125,
      "logps/rejected": -1597.0738525390625,
      "loss": 0.3942,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.015601971186697483,
      "rewards/margins": 0.8712390661239624,
      "rewards/rejected": -0.8868409991264343,
      "step": 70
    },
    {
      "epoch": 0.1136,
      "grad_norm": 3.6723878383636475,
      "learning_rate": 4.440000000000001e-06,
      "logits/chosen": -2.282296657562256,
      "logits/rejected": -2.425055503845215,
      "logps/chosen": -813.8991088867188,
      "logps/rejected": -1360.2625732421875,
      "loss": 0.4578,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.012647485360503197,
      "rewards/margins": 0.6152610778808594,
      "rewards/rejected": -0.6279085278511047,
      "step": 71
    },
    {
      "epoch": 0.1152,
      "grad_norm": 3.3391969203948975,
      "learning_rate": 4.432e-06,
      "logits/chosen": -2.412693500518799,
      "logits/rejected": -2.408931255340576,
      "logps/chosen": -719.9785766601562,
      "logps/rejected": -1575.9459228515625,
      "loss": 0.3826,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.024913480505347252,
      "rewards/margins": 1.0122792720794678,
      "rewards/rejected": -1.037192702293396,
      "step": 72
    },
    {
      "epoch": 0.1168,
      "grad_norm": 5.337649822235107,
      "learning_rate": 4.424e-06,
      "logits/chosen": -2.4722418785095215,
      "logits/rejected": -2.482541799545288,
      "logps/chosen": -1153.8218994140625,
      "logps/rejected": -1240.9375,
      "loss": 0.475,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.11305580288171768,
      "rewards/margins": 0.5441272854804993,
      "rewards/rejected": -0.6571831107139587,
      "step": 73
    },
    {
      "epoch": 0.1184,
      "grad_norm": 3.6771862506866455,
      "learning_rate": 4.416000000000001e-06,
      "logits/chosen": -2.471193552017212,
      "logits/rejected": -2.477119207382202,
      "logps/chosen": -1147.043701171875,
      "logps/rejected": -1417.807861328125,
      "loss": 0.3984,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.03233852609992027,
      "rewards/margins": 0.8718539476394653,
      "rewards/rejected": -0.9041925072669983,
      "step": 74
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.306926727294922,
      "learning_rate": 4.408000000000001e-06,
      "logits/chosen": -2.4748406410217285,
      "logits/rejected": -2.476750373840332,
      "logps/chosen": -981.0155639648438,
      "logps/rejected": -1468.7720947265625,
      "loss": 0.3877,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.16935759782791138,
      "rewards/margins": 0.9771731495857239,
      "rewards/rejected": -1.1465307474136353,
      "step": 75
    },
    {
      "epoch": 0.1216,
      "grad_norm": 2.8831162452697754,
      "learning_rate": 4.4e-06,
      "logits/chosen": -2.281566619873047,
      "logits/rejected": -2.4291300773620605,
      "logps/chosen": -715.8392944335938,
      "logps/rejected": -1480.139404296875,
      "loss": 0.3201,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.03338942676782608,
      "rewards/margins": 1.1474330425262451,
      "rewards/rejected": -1.1808223724365234,
      "step": 76
    },
    {
      "epoch": 0.1232,
      "grad_norm": 4.195013523101807,
      "learning_rate": 4.3920000000000005e-06,
      "logits/chosen": -2.443937301635742,
      "logits/rejected": -2.498157501220703,
      "logps/chosen": -874.0169067382812,
      "logps/rejected": -1316.942626953125,
      "loss": 0.4337,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.1892099231481552,
      "rewards/margins": 0.6941751837730408,
      "rewards/rejected": -0.8833851218223572,
      "step": 77
    },
    {
      "epoch": 0.1248,
      "grad_norm": 3.533186912536621,
      "learning_rate": 4.384000000000001e-06,
      "logits/chosen": -2.460679292678833,
      "logits/rejected": -2.5314974784851074,
      "logps/chosen": -828.7847900390625,
      "logps/rejected": -1679.3978271484375,
      "loss": 0.3738,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1500023752450943,
      "rewards/margins": 1.2177469730377197,
      "rewards/rejected": -1.3677494525909424,
      "step": 78
    },
    {
      "epoch": 0.1264,
      "grad_norm": 5.251435279846191,
      "learning_rate": 4.376e-06,
      "logits/chosen": -2.428579807281494,
      "logits/rejected": -2.4032108783721924,
      "logps/chosen": -1451.02392578125,
      "logps/rejected": -1898.55029296875,
      "loss": 0.3685,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10095509886741638,
      "rewards/margins": 0.9122613668441772,
      "rewards/rejected": -1.0132163763046265,
      "step": 79
    },
    {
      "epoch": 0.128,
      "grad_norm": 3.8912696838378906,
      "learning_rate": 4.368e-06,
      "logits/chosen": -2.4700093269348145,
      "logits/rejected": -2.493675947189331,
      "logps/chosen": -1226.7545166015625,
      "logps/rejected": -1739.671630859375,
      "loss": 0.3921,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1307486891746521,
      "rewards/margins": 0.922287106513977,
      "rewards/rejected": -1.053035855293274,
      "step": 80
    },
    {
      "epoch": 0.1296,
      "grad_norm": 5.438251972198486,
      "learning_rate": 4.360000000000001e-06,
      "logits/chosen": -2.4751548767089844,
      "logits/rejected": -2.474551200866699,
      "logps/chosen": -1537.556640625,
      "logps/rejected": -2213.0029296875,
      "loss": 0.3727,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.28010302782058716,
      "rewards/margins": 1.1754176616668701,
      "rewards/rejected": -1.4555206298828125,
      "step": 81
    },
    {
      "epoch": 0.1312,
      "grad_norm": 3.6982758045196533,
      "learning_rate": 4.352e-06,
      "logits/chosen": -2.3063390254974365,
      "logits/rejected": -2.3717260360717773,
      "logps/chosen": -928.5242919921875,
      "logps/rejected": -1706.3719482421875,
      "loss": 0.4432,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.02406725287437439,
      "rewards/margins": 0.7992755174636841,
      "rewards/rejected": -0.8233427405357361,
      "step": 82
    },
    {
      "epoch": 0.1328,
      "grad_norm": 3.1924326419830322,
      "learning_rate": 4.344e-06,
      "logits/chosen": -2.356764554977417,
      "logits/rejected": -2.308676242828369,
      "logps/chosen": -1075.246337890625,
      "logps/rejected": -1610.909912109375,
      "loss": 0.2689,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.09648031741380692,
      "rewards/margins": 1.542906403541565,
      "rewards/rejected": -1.4464260339736938,
      "step": 83
    },
    {
      "epoch": 0.1344,
      "grad_norm": 3.5851633548736572,
      "learning_rate": 4.3360000000000005e-06,
      "logits/chosen": -2.3311450481414795,
      "logits/rejected": -2.4191408157348633,
      "logps/chosen": -708.0391235351562,
      "logps/rejected": -1201.893798828125,
      "loss": 0.4109,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10602901875972748,
      "rewards/margins": 0.7890390157699585,
      "rewards/rejected": -0.8950679898262024,
      "step": 84
    },
    {
      "epoch": 0.136,
      "grad_norm": 3.3972227573394775,
      "learning_rate": 4.328000000000001e-06,
      "logits/chosen": -2.2745485305786133,
      "logits/rejected": -2.3526556491851807,
      "logps/chosen": -1237.2530517578125,
      "logps/rejected": -1811.6837158203125,
      "loss": 0.2979,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0517534501850605,
      "rewards/margins": 1.3414555788040161,
      "rewards/rejected": -1.3932090997695923,
      "step": 85
    },
    {
      "epoch": 0.1376,
      "grad_norm": 3.0943892002105713,
      "learning_rate": 4.32e-06,
      "logits/chosen": -2.4424753189086914,
      "logits/rejected": -2.6081202030181885,
      "logps/chosen": -863.8726806640625,
      "logps/rejected": -1171.138916015625,
      "loss": 0.4318,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.0013262461870908737,
      "rewards/margins": 0.7555155754089355,
      "rewards/rejected": -0.7541893124580383,
      "step": 86
    },
    {
      "epoch": 0.1392,
      "grad_norm": 6.824993133544922,
      "learning_rate": 4.312e-06,
      "logits/chosen": -2.26567006111145,
      "logits/rejected": -2.4199228286743164,
      "logps/chosen": -1184.958251953125,
      "logps/rejected": -1732.1868896484375,
      "loss": 0.383,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.12924934923648834,
      "rewards/margins": 1.0110704898834229,
      "rewards/rejected": -1.1403197050094604,
      "step": 87
    },
    {
      "epoch": 0.1408,
      "grad_norm": 2.9939441680908203,
      "learning_rate": 4.304000000000001e-06,
      "logits/chosen": -2.4545109272003174,
      "logits/rejected": -2.515630006790161,
      "logps/chosen": -962.5986328125,
      "logps/rejected": -1317.592041015625,
      "loss": 0.3709,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.1769241839647293,
      "rewards/margins": 1.0671230554580688,
      "rewards/rejected": -1.2440472841262817,
      "step": 88
    },
    {
      "epoch": 0.1424,
      "grad_norm": 3.2820374965667725,
      "learning_rate": 4.296e-06,
      "logits/chosen": -2.4707083702087402,
      "logits/rejected": -2.4873335361480713,
      "logps/chosen": -1149.957275390625,
      "logps/rejected": -1625.29931640625,
      "loss": 0.3003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.148725226521492,
      "rewards/margins": 1.2516520023345947,
      "rewards/rejected": -1.4003772735595703,
      "step": 89
    },
    {
      "epoch": 0.144,
      "grad_norm": 4.2410359382629395,
      "learning_rate": 4.288e-06,
      "logits/chosen": -2.292142868041992,
      "logits/rejected": -2.3967607021331787,
      "logps/chosen": -1299.8642578125,
      "logps/rejected": -1860.296630859375,
      "loss": 0.3864,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.1806352585554123,
      "rewards/margins": 1.2282143831253052,
      "rewards/rejected": -1.4088494777679443,
      "step": 90
    },
    {
      "epoch": 0.1456,
      "grad_norm": 3.539700984954834,
      "learning_rate": 4.2800000000000005e-06,
      "logits/chosen": -2.5238661766052246,
      "logits/rejected": -2.4962992668151855,
      "logps/chosen": -942.8016357421875,
      "logps/rejected": -1926.316650390625,
      "loss": 0.3897,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.1027974933385849,
      "rewards/margins": 0.9161090850830078,
      "rewards/rejected": -1.018906593322754,
      "step": 91
    },
    {
      "epoch": 0.1472,
      "grad_norm": 2.327420473098755,
      "learning_rate": 4.272000000000001e-06,
      "logits/chosen": -2.2779834270477295,
      "logits/rejected": -2.38816499710083,
      "logps/chosen": -699.9099731445312,
      "logps/rejected": -1502.68603515625,
      "loss": 0.3084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.15832284092903137,
      "rewards/margins": 1.4348328113555908,
      "rewards/rejected": -1.5931555032730103,
      "step": 92
    },
    {
      "epoch": 0.1488,
      "grad_norm": 3.553140878677368,
      "learning_rate": 4.264e-06,
      "logits/chosen": -2.5239953994750977,
      "logits/rejected": -2.5327048301696777,
      "logps/chosen": -940.0181274414062,
      "logps/rejected": -1413.186767578125,
      "loss": 0.4078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1792048066854477,
      "rewards/margins": 0.768405020236969,
      "rewards/rejected": -0.9476098418235779,
      "step": 93
    },
    {
      "epoch": 0.1504,
      "grad_norm": 2.9112439155578613,
      "learning_rate": 4.256e-06,
      "logits/chosen": -2.4378762245178223,
      "logits/rejected": -2.390841007232666,
      "logps/chosen": -1178.6810302734375,
      "logps/rejected": -1942.3280029296875,
      "loss": 0.2211,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20701630413532257,
      "rewards/margins": 1.681829571723938,
      "rewards/rejected": -1.8888459205627441,
      "step": 94
    },
    {
      "epoch": 0.152,
      "grad_norm": 3.533766031265259,
      "learning_rate": 4.248000000000001e-06,
      "logits/chosen": -2.3642613887786865,
      "logits/rejected": -2.3864657878875732,
      "logps/chosen": -780.42041015625,
      "logps/rejected": -1323.309814453125,
      "loss": 0.3933,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.17855724692344666,
      "rewards/margins": 0.9528135061264038,
      "rewards/rejected": -1.1313707828521729,
      "step": 95
    },
    {
      "epoch": 0.1536,
      "grad_norm": 5.412832260131836,
      "learning_rate": 4.24e-06,
      "logits/chosen": -2.227529525756836,
      "logits/rejected": -2.3135101795196533,
      "logps/chosen": -1793.0361328125,
      "logps/rejected": -2308.60986328125,
      "loss": 0.3618,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.14720723032951355,
      "rewards/margins": 1.1961324214935303,
      "rewards/rejected": -1.343339443206787,
      "step": 96
    },
    {
      "epoch": 0.1552,
      "grad_norm": 2.4717166423797607,
      "learning_rate": 4.232e-06,
      "logits/chosen": -2.4376637935638428,
      "logits/rejected": -2.4160306453704834,
      "logps/chosen": -1514.1527099609375,
      "logps/rejected": -1871.991455078125,
      "loss": 0.2473,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05610981211066246,
      "rewards/margins": 1.9479868412017822,
      "rewards/rejected": -1.8918769359588623,
      "step": 97
    },
    {
      "epoch": 0.1568,
      "grad_norm": 2.8663933277130127,
      "learning_rate": 4.2240000000000006e-06,
      "logits/chosen": -2.4955952167510986,
      "logits/rejected": -2.466695785522461,
      "logps/chosen": -1014.5949096679688,
      "logps/rejected": -1734.2327880859375,
      "loss": 0.2758,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05485974997282028,
      "rewards/margins": 1.458674669265747,
      "rewards/rejected": -1.513534426689148,
      "step": 98
    },
    {
      "epoch": 0.1584,
      "grad_norm": 2.89676833152771,
      "learning_rate": 4.216e-06,
      "logits/chosen": -2.4123430252075195,
      "logits/rejected": -2.445830821990967,
      "logps/chosen": -1041.836181640625,
      "logps/rejected": -1452.9610595703125,
      "loss": 0.3042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.14857217669487,
      "rewards/margins": 1.1992714405059814,
      "rewards/rejected": -1.3478436470031738,
      "step": 99
    },
    {
      "epoch": 0.16,
      "grad_norm": 4.1963019371032715,
      "learning_rate": 4.208e-06,
      "logits/chosen": -2.268817186355591,
      "logits/rejected": -2.4280753135681152,
      "logps/chosen": -832.0985107421875,
      "logps/rejected": -1240.9068603515625,
      "loss": 0.4,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.21588222682476044,
      "rewards/margins": 0.8761605620384216,
      "rewards/rejected": -1.0920428037643433,
      "step": 100
    },
    {
      "epoch": 0.1616,
      "grad_norm": 3.204695701599121,
      "learning_rate": 4.2000000000000004e-06,
      "logits/chosen": -2.4962916374206543,
      "logits/rejected": -2.4844586849212646,
      "logps/chosen": -856.2902221679688,
      "logps/rejected": -1615.654052734375,
      "loss": 0.3368,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.11948814988136292,
      "rewards/margins": 1.130797028541565,
      "rewards/rejected": -1.2502851486206055,
      "step": 101
    },
    {
      "epoch": 0.1632,
      "grad_norm": 2.5167012214660645,
      "learning_rate": 4.192000000000001e-06,
      "logits/chosen": -2.2445967197418213,
      "logits/rejected": -2.4790804386138916,
      "logps/chosen": -1188.63427734375,
      "logps/rejected": -1609.4036865234375,
      "loss": 0.3391,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.07233432680368423,
      "rewards/margins": 1.2304503917694092,
      "rewards/rejected": -1.30278480052948,
      "step": 102
    },
    {
      "epoch": 0.1648,
      "grad_norm": 6.240241050720215,
      "learning_rate": 4.184e-06,
      "logits/chosen": -2.441589832305908,
      "logits/rejected": -2.4485952854156494,
      "logps/chosen": -924.1279907226562,
      "logps/rejected": -1535.0303955078125,
      "loss": 0.4642,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.4198063611984253,
      "rewards/margins": 0.8683212995529175,
      "rewards/rejected": -1.2881277799606323,
      "step": 103
    },
    {
      "epoch": 0.1664,
      "grad_norm": 2.88150691986084,
      "learning_rate": 4.176e-06,
      "logits/chosen": -2.498318672180176,
      "logits/rejected": -2.4959816932678223,
      "logps/chosen": -795.31787109375,
      "logps/rejected": -1326.9429931640625,
      "loss": 0.3413,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.07539597153663635,
      "rewards/margins": 1.062537670135498,
      "rewards/rejected": -1.1379334926605225,
      "step": 104
    },
    {
      "epoch": 0.168,
      "grad_norm": 5.859161853790283,
      "learning_rate": 4.168000000000001e-06,
      "logits/chosen": -2.45375394821167,
      "logits/rejected": -2.396920680999756,
      "logps/chosen": -938.7039184570312,
      "logps/rejected": -1441.9359130859375,
      "loss": 0.4436,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.180232435464859,
      "rewards/margins": 0.9859802722930908,
      "rewards/rejected": -1.166212558746338,
      "step": 105
    },
    {
      "epoch": 0.1696,
      "grad_norm": 3.2874221801757812,
      "learning_rate": 4.16e-06,
      "logits/chosen": -2.3340017795562744,
      "logits/rejected": -2.3949129581451416,
      "logps/chosen": -1465.526123046875,
      "logps/rejected": -2216.86865234375,
      "loss": 0.2324,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.08080911636352539,
      "rewards/margins": 2.21992826461792,
      "rewards/rejected": -2.3007373809814453,
      "step": 106
    },
    {
      "epoch": 0.1712,
      "grad_norm": 3.46250319480896,
      "learning_rate": 4.152e-06,
      "logits/chosen": -2.3385212421417236,
      "logits/rejected": -2.4153292179107666,
      "logps/chosen": -1124.3406982421875,
      "logps/rejected": -1901.711181640625,
      "loss": 0.3279,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04264888912439346,
      "rewards/margins": 1.2065978050231934,
      "rewards/rejected": -1.1639487743377686,
      "step": 107
    },
    {
      "epoch": 0.1728,
      "grad_norm": 5.7182936668396,
      "learning_rate": 4.1440000000000005e-06,
      "logits/chosen": -2.468228816986084,
      "logits/rejected": -2.484130859375,
      "logps/chosen": -1077.501953125,
      "logps/rejected": -1691.16552734375,
      "loss": 0.3233,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.15436001121997833,
      "rewards/margins": 1.2421308755874634,
      "rewards/rejected": -1.3964906930923462,
      "step": 108
    },
    {
      "epoch": 0.1744,
      "grad_norm": 2.5204930305480957,
      "learning_rate": 4.136000000000001e-06,
      "logits/chosen": -2.3205463886260986,
      "logits/rejected": -2.4084458351135254,
      "logps/chosen": -896.6912231445312,
      "logps/rejected": -1418.5079345703125,
      "loss": 0.2326,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.16559544205665588,
      "rewards/margins": 1.595067024230957,
      "rewards/rejected": -1.760662317276001,
      "step": 109
    },
    {
      "epoch": 0.176,
      "grad_norm": 3.672863006591797,
      "learning_rate": 4.128e-06,
      "logits/chosen": -2.415785551071167,
      "logits/rejected": -2.4012420177459717,
      "logps/chosen": -1573.3699951171875,
      "logps/rejected": -1902.076171875,
      "loss": 0.2999,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5752886533737183,
      "rewards/margins": 1.3048595190048218,
      "rewards/rejected": -1.88014817237854,
      "step": 110
    },
    {
      "epoch": 0.1776,
      "grad_norm": 2.758054733276367,
      "learning_rate": 4.12e-06,
      "logits/chosen": -2.2387988567352295,
      "logits/rejected": -2.3464741706848145,
      "logps/chosen": -1092.822265625,
      "logps/rejected": -1934.2626953125,
      "loss": 0.3173,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.14779254794120789,
      "rewards/margins": 1.481509804725647,
      "rewards/rejected": -1.6293023824691772,
      "step": 111
    },
    {
      "epoch": 0.1792,
      "grad_norm": 3.51092529296875,
      "learning_rate": 4.112000000000001e-06,
      "logits/chosen": -2.423769474029541,
      "logits/rejected": -2.40720272064209,
      "logps/chosen": -1258.038330078125,
      "logps/rejected": -1600.9141845703125,
      "loss": 0.3249,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.22913143038749695,
      "rewards/margins": 1.5761014223098755,
      "rewards/rejected": -1.8052328824996948,
      "step": 112
    },
    {
      "epoch": 0.1808,
      "grad_norm": 2.4401259422302246,
      "learning_rate": 4.104e-06,
      "logits/chosen": -2.4996144771575928,
      "logits/rejected": -2.486800193786621,
      "logps/chosen": -1111.9854736328125,
      "logps/rejected": -1758.878173828125,
      "loss": 0.2189,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.2552917003631592,
      "rewards/margins": 1.921882152557373,
      "rewards/rejected": -2.1771740913391113,
      "step": 113
    },
    {
      "epoch": 0.1824,
      "grad_norm": 2.110849618911743,
      "learning_rate": 4.096e-06,
      "logits/chosen": -2.416252374649048,
      "logits/rejected": -2.467639446258545,
      "logps/chosen": -806.2451782226562,
      "logps/rejected": -1394.4798583984375,
      "loss": 0.2791,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08220276981592178,
      "rewards/margins": 1.474043369293213,
      "rewards/rejected": -1.556246042251587,
      "step": 114
    },
    {
      "epoch": 0.184,
      "grad_norm": 4.0337629318237305,
      "learning_rate": 4.0880000000000005e-06,
      "logits/chosen": -2.4232237339019775,
      "logits/rejected": -2.428703546524048,
      "logps/chosen": -732.0713500976562,
      "logps/rejected": -921.5111083984375,
      "loss": 0.447,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.3119714856147766,
      "rewards/margins": 0.8600640892982483,
      "rewards/rejected": -1.172035574913025,
      "step": 115
    },
    {
      "epoch": 0.1856,
      "grad_norm": 2.3061866760253906,
      "learning_rate": 4.08e-06,
      "logits/chosen": -2.372110366821289,
      "logits/rejected": -2.39100980758667,
      "logps/chosen": -535.443359375,
      "logps/rejected": -1018.3807983398438,
      "loss": 0.3431,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.16312366724014282,
      "rewards/margins": 1.183103084564209,
      "rewards/rejected": -1.346226692199707,
      "step": 116
    },
    {
      "epoch": 0.1872,
      "grad_norm": 3.262235164642334,
      "learning_rate": 4.072e-06,
      "logits/chosen": -2.3800668716430664,
      "logits/rejected": -2.3775794506073,
      "logps/chosen": -625.9942626953125,
      "logps/rejected": -1550.088134765625,
      "loss": 0.2523,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.31171715259552,
      "rewards/margins": 1.8031421899795532,
      "rewards/rejected": -2.1148593425750732,
      "step": 117
    },
    {
      "epoch": 0.1888,
      "grad_norm": 2.3869738578796387,
      "learning_rate": 4.064e-06,
      "logits/chosen": -2.492366075515747,
      "logits/rejected": -2.426870107650757,
      "logps/chosen": -857.9932250976562,
      "logps/rejected": -1215.491943359375,
      "loss": 0.2574,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.21735452115535736,
      "rewards/margins": 1.5536785125732422,
      "rewards/rejected": -1.7710330486297607,
      "step": 118
    },
    {
      "epoch": 0.1904,
      "grad_norm": 2.379779100418091,
      "learning_rate": 4.056000000000001e-06,
      "logits/chosen": -2.4281182289123535,
      "logits/rejected": -2.510866641998291,
      "logps/chosen": -1113.99755859375,
      "logps/rejected": -1834.54248046875,
      "loss": 0.287,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.2678978741168976,
      "rewards/margins": 1.5082626342773438,
      "rewards/rejected": -1.7761603593826294,
      "step": 119
    },
    {
      "epoch": 0.192,
      "grad_norm": 1.9459013938903809,
      "learning_rate": 4.048e-06,
      "logits/chosen": -2.459183931350708,
      "logits/rejected": -2.4387874603271484,
      "logps/chosen": -697.8385009765625,
      "logps/rejected": -1850.4478759765625,
      "loss": 0.2326,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.24488157033920288,
      "rewards/margins": 2.0289547443389893,
      "rewards/rejected": -2.273836135864258,
      "step": 120
    },
    {
      "epoch": 0.1936,
      "grad_norm": 2.395322799682617,
      "learning_rate": 4.04e-06,
      "logits/chosen": -2.4002771377563477,
      "logits/rejected": -2.408482551574707,
      "logps/chosen": -937.3818359375,
      "logps/rejected": -1440.01025390625,
      "loss": 0.2274,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.020366281270980835,
      "rewards/margins": 1.7213118076324463,
      "rewards/rejected": -1.741678237915039,
      "step": 121
    },
    {
      "epoch": 0.1952,
      "grad_norm": 3.667409896850586,
      "learning_rate": 4.0320000000000005e-06,
      "logits/chosen": -2.3035333156585693,
      "logits/rejected": -2.3409948348999023,
      "logps/chosen": -526.32470703125,
      "logps/rejected": -1170.1763916015625,
      "loss": 0.32,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.04658423364162445,
      "rewards/margins": 1.9765853881835938,
      "rewards/rejected": -2.02316951751709,
      "step": 122
    },
    {
      "epoch": 0.1968,
      "grad_norm": 3.6410887241363525,
      "learning_rate": 4.024e-06,
      "logits/chosen": -2.41646671295166,
      "logits/rejected": -2.482295036315918,
      "logps/chosen": -1100.54345703125,
      "logps/rejected": -1223.838623046875,
      "loss": 0.3861,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.2879422903060913,
      "rewards/margins": 1.3792297840118408,
      "rewards/rejected": -1.6671720743179321,
      "step": 123
    },
    {
      "epoch": 0.1984,
      "grad_norm": 2.7401483058929443,
      "learning_rate": 4.016e-06,
      "logits/chosen": -2.352450132369995,
      "logits/rejected": -2.415504217147827,
      "logps/chosen": -1372.249267578125,
      "logps/rejected": -1752.1375732421875,
      "loss": 0.2753,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.2517732083797455,
      "rewards/margins": 2.1727797985076904,
      "rewards/rejected": -2.4245529174804688,
      "step": 124
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.897634744644165,
      "learning_rate": 4.008e-06,
      "logits/chosen": -2.3176608085632324,
      "logits/rejected": -2.4674034118652344,
      "logps/chosen": -818.3677368164062,
      "logps/rejected": -1466.919921875,
      "loss": 0.2582,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.003130462020635605,
      "rewards/margins": 1.5885162353515625,
      "rewards/rejected": -1.585385799407959,
      "step": 125
    },
    {
      "epoch": 0.2016,
      "grad_norm": 2.7919366359710693,
      "learning_rate": 4.000000000000001e-06,
      "logits/chosen": -2.4109137058258057,
      "logits/rejected": -2.2715041637420654,
      "logps/chosen": -796.6652221679688,
      "logps/rejected": -1924.887451171875,
      "loss": 0.2462,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.22896552085876465,
      "rewards/margins": 1.598818063735962,
      "rewards/rejected": -1.8277837038040161,
      "step": 126
    },
    {
      "epoch": 0.2032,
      "grad_norm": 2.559756278991699,
      "learning_rate": 3.992e-06,
      "logits/chosen": -2.505685329437256,
      "logits/rejected": -2.4893593788146973,
      "logps/chosen": -1191.7369384765625,
      "logps/rejected": -1581.1273193359375,
      "loss": 0.253,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2606949210166931,
      "rewards/margins": 1.620897889137268,
      "rewards/rejected": -1.8815927505493164,
      "step": 127
    },
    {
      "epoch": 0.2048,
      "grad_norm": 2.052039623260498,
      "learning_rate": 3.984e-06,
      "logits/chosen": -2.2151694297790527,
      "logits/rejected": -2.2838356494903564,
      "logps/chosen": -1385.010986328125,
      "logps/rejected": -2051.345458984375,
      "loss": 0.1875,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.1597253978252411,
      "rewards/margins": 2.723198890686035,
      "rewards/rejected": -2.5634732246398926,
      "step": 128
    },
    {
      "epoch": 0.2064,
      "grad_norm": 1.8168867826461792,
      "learning_rate": 3.9760000000000006e-06,
      "logits/chosen": -2.375739097595215,
      "logits/rejected": -2.4571986198425293,
      "logps/chosen": -1028.0880126953125,
      "logps/rejected": -1826.8101806640625,
      "loss": 0.2142,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.4021643102169037,
      "rewards/margins": 2.261357545852661,
      "rewards/rejected": -2.6635220050811768,
      "step": 129
    },
    {
      "epoch": 0.208,
      "grad_norm": 2.4511003494262695,
      "learning_rate": 3.968e-06,
      "logits/chosen": -2.434173822402954,
      "logits/rejected": -2.473037004470825,
      "logps/chosen": -537.5145874023438,
      "logps/rejected": -1348.2607421875,
      "loss": 0.2379,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.17180082201957703,
      "rewards/margins": 1.5162779092788696,
      "rewards/rejected": -1.6880786418914795,
      "step": 130
    },
    {
      "epoch": 0.2096,
      "grad_norm": 3.697261333465576,
      "learning_rate": 3.96e-06,
      "logits/chosen": -2.3012475967407227,
      "logits/rejected": -2.5040555000305176,
      "logps/chosen": -1158.4647216796875,
      "logps/rejected": -1860.9627685546875,
      "loss": 0.3208,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.27815839648246765,
      "rewards/margins": 1.3586840629577637,
      "rewards/rejected": -1.6368422508239746,
      "step": 131
    },
    {
      "epoch": 0.2112,
      "grad_norm": 1.67403244972229,
      "learning_rate": 3.9520000000000004e-06,
      "logits/chosen": -2.2047948837280273,
      "logits/rejected": -2.4485700130462646,
      "logps/chosen": -962.3466186523438,
      "logps/rejected": -1366.508544921875,
      "loss": 0.2813,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.018666863441467285,
      "rewards/margins": 1.9027272462844849,
      "rewards/rejected": -1.8840605020523071,
      "step": 132
    },
    {
      "epoch": 0.2128,
      "grad_norm": 7.227810382843018,
      "learning_rate": 3.944e-06,
      "logits/chosen": -2.2799153327941895,
      "logits/rejected": -2.1915135383605957,
      "logps/chosen": -735.9043579101562,
      "logps/rejected": -1661.015869140625,
      "loss": 0.3708,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.23493711650371552,
      "rewards/margins": 1.1542118787765503,
      "rewards/rejected": -1.3891489505767822,
      "step": 133
    },
    {
      "epoch": 0.2144,
      "grad_norm": 2.7487289905548096,
      "learning_rate": 3.936e-06,
      "logits/chosen": -2.164417266845703,
      "logits/rejected": -2.1750171184539795,
      "logps/chosen": -1369.783935546875,
      "logps/rejected": -2018.528076171875,
      "loss": 0.28,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.06329622864723206,
      "rewards/margins": 2.0045852661132812,
      "rewards/rejected": -1.9412890672683716,
      "step": 134
    },
    {
      "epoch": 0.216,
      "grad_norm": 2.2185282707214355,
      "learning_rate": 3.928e-06,
      "logits/chosen": -2.393886089324951,
      "logits/rejected": -2.451674461364746,
      "logps/chosen": -1124.8636474609375,
      "logps/rejected": -1539.018310546875,
      "loss": 0.21,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.2566457986831665,
      "rewards/margins": 2.3321776390075684,
      "rewards/rejected": -2.5888233184814453,
      "step": 135
    },
    {
      "epoch": 0.2176,
      "grad_norm": 2.0666964054107666,
      "learning_rate": 3.920000000000001e-06,
      "logits/chosen": -2.4351930618286133,
      "logits/rejected": -2.3645544052124023,
      "logps/chosen": -914.6356811523438,
      "logps/rejected": -1829.501953125,
      "loss": 0.1705,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.43337368965148926,
      "rewards/margins": 2.128699541091919,
      "rewards/rejected": -2.562072992324829,
      "step": 136
    },
    {
      "epoch": 0.2192,
      "grad_norm": 2.7948412895202637,
      "learning_rate": 3.912e-06,
      "logits/chosen": -2.40022873878479,
      "logits/rejected": -2.434770345687866,
      "logps/chosen": -1275.38623046875,
      "logps/rejected": -1721.7816162109375,
      "loss": 0.2446,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.2718428373336792,
      "rewards/margins": 1.9000065326690674,
      "rewards/rejected": -2.171849250793457,
      "step": 137
    },
    {
      "epoch": 0.2208,
      "grad_norm": 2.0689785480499268,
      "learning_rate": 3.904e-06,
      "logits/chosen": -2.3877782821655273,
      "logits/rejected": -2.4453649520874023,
      "logps/chosen": -696.7930297851562,
      "logps/rejected": -1044.6904296875,
      "loss": 0.3154,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20408175885677338,
      "rewards/margins": 1.26399827003479,
      "rewards/rejected": -1.4680800437927246,
      "step": 138
    },
    {
      "epoch": 0.2224,
      "grad_norm": 2.000675916671753,
      "learning_rate": 3.8960000000000005e-06,
      "logits/chosen": -2.24735951423645,
      "logits/rejected": -2.3915257453918457,
      "logps/chosen": -658.0923461914062,
      "logps/rejected": -1295.322998046875,
      "loss": 0.2728,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.16451233625411987,
      "rewards/margins": 2.044132947921753,
      "rewards/rejected": -2.2086453437805176,
      "step": 139
    },
    {
      "epoch": 0.224,
      "grad_norm": 2.777254343032837,
      "learning_rate": 3.888e-06,
      "logits/chosen": -2.4313173294067383,
      "logits/rejected": -2.466491937637329,
      "logps/chosen": -872.178466796875,
      "logps/rejected": -1573.3756103515625,
      "loss": 0.2495,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.11351258307695389,
      "rewards/margins": 1.8166122436523438,
      "rewards/rejected": -1.9301247596740723,
      "step": 140
    },
    {
      "epoch": 0.2256,
      "grad_norm": 2.1828911304473877,
      "learning_rate": 3.88e-06,
      "logits/chosen": -2.3876113891601562,
      "logits/rejected": -2.4259696006774902,
      "logps/chosen": -961.1243286132812,
      "logps/rejected": -1619.15625,
      "loss": 0.2168,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.24345333874225616,
      "rewards/margins": 1.933893084526062,
      "rewards/rejected": -2.1773464679718018,
      "step": 141
    },
    {
      "epoch": 0.2272,
      "grad_norm": 2.33107328414917,
      "learning_rate": 3.872e-06,
      "logits/chosen": -2.3056912422180176,
      "logits/rejected": -2.323157787322998,
      "logps/chosen": -1179.336669921875,
      "logps/rejected": -1982.01904296875,
      "loss": 0.1704,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.2873044013977051,
      "rewards/margins": 2.850069284439087,
      "rewards/rejected": -3.137373685836792,
      "step": 142
    },
    {
      "epoch": 0.2288,
      "grad_norm": 3.128355026245117,
      "learning_rate": 3.864000000000001e-06,
      "logits/chosen": -2.485975742340088,
      "logits/rejected": -2.465226650238037,
      "logps/chosen": -1649.9453125,
      "logps/rejected": -1743.7667236328125,
      "loss": 0.3115,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.44606447219848633,
      "rewards/margins": 1.5215235948562622,
      "rewards/rejected": -1.967588186264038,
      "step": 143
    },
    {
      "epoch": 0.2304,
      "grad_norm": 2.198086977005005,
      "learning_rate": 3.856e-06,
      "logits/chosen": -2.317775011062622,
      "logits/rejected": -2.394287347793579,
      "logps/chosen": -1220.736083984375,
      "logps/rejected": -1814.7510986328125,
      "loss": 0.1951,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.2733727693557739,
      "rewards/margins": 1.919477939605713,
      "rewards/rejected": -2.192850351333618,
      "step": 144
    },
    {
      "epoch": 0.232,
      "grad_norm": 3.693150520324707,
      "learning_rate": 3.848e-06,
      "logits/chosen": -2.47483491897583,
      "logits/rejected": -2.419583797454834,
      "logps/chosen": -1360.066162109375,
      "logps/rejected": -1456.9869384765625,
      "loss": 0.2423,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.5374501347541809,
      "rewards/margins": 1.792967677116394,
      "rewards/rejected": -2.3304178714752197,
      "step": 145
    },
    {
      "epoch": 0.2336,
      "grad_norm": 2.1991612911224365,
      "learning_rate": 3.8400000000000005e-06,
      "logits/chosen": -2.115344762802124,
      "logits/rejected": -2.2781994342803955,
      "logps/chosen": -1125.8660888671875,
      "logps/rejected": -1905.482666015625,
      "loss": 0.1708,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3205452859401703,
      "rewards/margins": 2.2745161056518555,
      "rewards/rejected": -2.5950613021850586,
      "step": 146
    },
    {
      "epoch": 0.2352,
      "grad_norm": 4.570766448974609,
      "learning_rate": 3.832e-06,
      "logits/chosen": -2.4413623809814453,
      "logits/rejected": -2.434114933013916,
      "logps/chosen": -1013.01416015625,
      "logps/rejected": -1565.8284912109375,
      "loss": 0.2593,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.46672937273979187,
      "rewards/margins": 2.4415626525878906,
      "rewards/rejected": -2.9082915782928467,
      "step": 147
    },
    {
      "epoch": 0.2368,
      "grad_norm": 2.356839895248413,
      "learning_rate": 3.824e-06,
      "logits/chosen": -2.3647284507751465,
      "logits/rejected": -2.4543638229370117,
      "logps/chosen": -892.5068969726562,
      "logps/rejected": -1911.655029296875,
      "loss": 0.1632,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3284927010536194,
      "rewards/margins": 2.512971878051758,
      "rewards/rejected": -2.8414649963378906,
      "step": 148
    },
    {
      "epoch": 0.2384,
      "grad_norm": 5.235751628875732,
      "learning_rate": 3.816e-06,
      "logits/chosen": -2.3217933177948,
      "logits/rejected": -2.3714725971221924,
      "logps/chosen": -1194.24853515625,
      "logps/rejected": -1861.245849609375,
      "loss": 0.3665,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.6689460277557373,
      "rewards/margins": 2.074821710586548,
      "rewards/rejected": -2.743767738342285,
      "step": 149
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.1953325271606445,
      "learning_rate": 3.8080000000000006e-06,
      "logits/chosen": -2.2086591720581055,
      "logits/rejected": -2.316559314727783,
      "logps/chosen": -1588.52392578125,
      "logps/rejected": -2365.3974609375,
      "loss": 0.1358,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.13734327256679535,
      "rewards/margins": 3.066324472427368,
      "rewards/rejected": -3.203667640686035,
      "step": 150
    },
    {
      "epoch": 0.2416,
      "grad_norm": 2.225823402404785,
      "learning_rate": 3.8000000000000005e-06,
      "logits/chosen": -2.4408979415893555,
      "logits/rejected": -2.3986165523529053,
      "logps/chosen": -770.1968994140625,
      "logps/rejected": -1311.0177001953125,
      "loss": 0.2846,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.3598247468471527,
      "rewards/margins": 1.9278658628463745,
      "rewards/rejected": -2.2876906394958496,
      "step": 151
    },
    {
      "epoch": 0.2432,
      "grad_norm": 2.1186068058013916,
      "learning_rate": 3.7920000000000003e-06,
      "logits/chosen": -2.2326810359954834,
      "logits/rejected": -2.4166340827941895,
      "logps/chosen": -981.3995361328125,
      "logps/rejected": -1484.55859375,
      "loss": 0.2309,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.48539721965789795,
      "rewards/margins": 2.0392236709594727,
      "rewards/rejected": -2.524620771408081,
      "step": 152
    },
    {
      "epoch": 0.2448,
      "grad_norm": 2.901292085647583,
      "learning_rate": 3.7840000000000005e-06,
      "logits/chosen": -2.2971115112304688,
      "logits/rejected": -2.341630458831787,
      "logps/chosen": -1537.4832763671875,
      "logps/rejected": -1900.0205078125,
      "loss": 0.1807,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.31244587898254395,
      "rewards/margins": 2.435847520828247,
      "rewards/rejected": -2.748293399810791,
      "step": 153
    },
    {
      "epoch": 0.2464,
      "grad_norm": 2.2643656730651855,
      "learning_rate": 3.7760000000000004e-06,
      "logits/chosen": -2.31129789352417,
      "logits/rejected": -2.39145565032959,
      "logps/chosen": -816.6561279296875,
      "logps/rejected": -2015.1668701171875,
      "loss": 0.1696,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.4412989020347595,
      "rewards/margins": 3.2064208984375,
      "rewards/rejected": -3.647719621658325,
      "step": 154
    },
    {
      "epoch": 0.248,
      "grad_norm": 5.6966962814331055,
      "learning_rate": 3.7680000000000006e-06,
      "logits/chosen": -2.3389012813568115,
      "logits/rejected": -2.37499737739563,
      "logps/chosen": -695.6979370117188,
      "logps/rejected": -1319.918212890625,
      "loss": 0.3537,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.388245552778244,
      "rewards/margins": 1.7443039417266846,
      "rewards/rejected": -2.132549524307251,
      "step": 155
    },
    {
      "epoch": 0.2496,
      "grad_norm": 1.7958711385726929,
      "learning_rate": 3.7600000000000004e-06,
      "logits/chosen": -2.283714771270752,
      "logits/rejected": -2.3962247371673584,
      "logps/chosen": -545.1898193359375,
      "logps/rejected": -1428.1845703125,
      "loss": 0.2039,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.27766311168670654,
      "rewards/margins": 2.2130889892578125,
      "rewards/rejected": -2.4907517433166504,
      "step": 156
    },
    {
      "epoch": 0.2512,
      "grad_norm": 1.8370215892791748,
      "learning_rate": 3.7520000000000002e-06,
      "logits/chosen": -2.3790457248687744,
      "logits/rejected": -2.481402635574341,
      "logps/chosen": -1007.8465576171875,
      "logps/rejected": -1430.0509033203125,
      "loss": 0.174,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.37609854340553284,
      "rewards/margins": 2.8198676109313965,
      "rewards/rejected": -3.1959664821624756,
      "step": 157
    },
    {
      "epoch": 0.2528,
      "grad_norm": 2.5481293201446533,
      "learning_rate": 3.7440000000000005e-06,
      "logits/chosen": -2.442845582962036,
      "logits/rejected": -2.4602744579315186,
      "logps/chosen": -1036.7803955078125,
      "logps/rejected": -1693.9356689453125,
      "loss": 0.1743,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4936876595020294,
      "rewards/margins": 2.520641803741455,
      "rewards/rejected": -3.0143299102783203,
      "step": 158
    },
    {
      "epoch": 0.2544,
      "grad_norm": 2.3251798152923584,
      "learning_rate": 3.7360000000000003e-06,
      "logits/chosen": -2.3971097469329834,
      "logits/rejected": -2.407517910003662,
      "logps/chosen": -1139.618896484375,
      "logps/rejected": -1721.0052490234375,
      "loss": 0.2311,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.26937219500541687,
      "rewards/margins": 2.166779041290283,
      "rewards/rejected": -2.4361510276794434,
      "step": 159
    },
    {
      "epoch": 0.256,
      "grad_norm": 1.7349932193756104,
      "learning_rate": 3.7280000000000006e-06,
      "logits/chosen": -2.100235939025879,
      "logits/rejected": -2.2499773502349854,
      "logps/chosen": -1270.231201171875,
      "logps/rejected": -2065.24658203125,
      "loss": 0.1779,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.42029839754104614,
      "rewards/margins": 2.773397922515869,
      "rewards/rejected": -2.3530993461608887,
      "step": 160
    },
    {
      "epoch": 0.2576,
      "grad_norm": 2.5434937477111816,
      "learning_rate": 3.7200000000000004e-06,
      "logits/chosen": -2.437279462814331,
      "logits/rejected": -2.485292434692383,
      "logps/chosen": -1223.253662109375,
      "logps/rejected": -1417.849853515625,
      "loss": 0.2803,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4003908634185791,
      "rewards/margins": 1.537566065788269,
      "rewards/rejected": -1.9379568099975586,
      "step": 161
    },
    {
      "epoch": 0.2592,
      "grad_norm": 2.4364917278289795,
      "learning_rate": 3.712e-06,
      "logits/chosen": -2.4374377727508545,
      "logits/rejected": -2.3169736862182617,
      "logps/chosen": -986.2681274414062,
      "logps/rejected": -1873.625732421875,
      "loss": 0.2074,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.42750999331474304,
      "rewards/margins": 2.0830955505371094,
      "rewards/rejected": -2.510605573654175,
      "step": 162
    },
    {
      "epoch": 0.2608,
      "grad_norm": 5.411618709564209,
      "learning_rate": 3.7040000000000005e-06,
      "logits/chosen": -2.388655662536621,
      "logits/rejected": -2.4405691623687744,
      "logps/chosen": -702.893310546875,
      "logps/rejected": -1612.7685546875,
      "loss": 0.2993,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.29508176445961,
      "rewards/margins": 2.01835560798645,
      "rewards/rejected": -2.3134372234344482,
      "step": 163
    },
    {
      "epoch": 0.2624,
      "grad_norm": 1.7554477453231812,
      "learning_rate": 3.6960000000000003e-06,
      "logits/chosen": -2.3530797958374023,
      "logits/rejected": -2.4237780570983887,
      "logps/chosen": -983.9425048828125,
      "logps/rejected": -1480.0430908203125,
      "loss": 0.1938,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.35396111011505127,
      "rewards/margins": 2.9926342964172363,
      "rewards/rejected": -3.346595287322998,
      "step": 164
    },
    {
      "epoch": 0.264,
      "grad_norm": 2.3769662380218506,
      "learning_rate": 3.6880000000000005e-06,
      "logits/chosen": -2.3254776000976562,
      "logits/rejected": -2.459878444671631,
      "logps/chosen": -794.9078369140625,
      "logps/rejected": -1473.1329345703125,
      "loss": 0.2239,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5464792251586914,
      "rewards/margins": 1.9995028972625732,
      "rewards/rejected": -2.5459821224212646,
      "step": 165
    },
    {
      "epoch": 0.2656,
      "grad_norm": 2.3531956672668457,
      "learning_rate": 3.6800000000000003e-06,
      "logits/chosen": -2.405430316925049,
      "logits/rejected": -2.3857674598693848,
      "logps/chosen": -1573.0726318359375,
      "logps/rejected": -2273.7216796875,
      "loss": 0.1258,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5620136857032776,
      "rewards/margins": 3.2109599113464355,
      "rewards/rejected": -3.7729732990264893,
      "step": 166
    },
    {
      "epoch": 0.2672,
      "grad_norm": 2.4528303146362305,
      "learning_rate": 3.6720000000000006e-06,
      "logits/chosen": -2.3121891021728516,
      "logits/rejected": -2.4042413234710693,
      "logps/chosen": -1148.7208251953125,
      "logps/rejected": -1531.4013671875,
      "loss": 0.2869,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.6466580629348755,
      "rewards/margins": 1.969074010848999,
      "rewards/rejected": -2.615732192993164,
      "step": 167
    },
    {
      "epoch": 0.2688,
      "grad_norm": 1.2126965522766113,
      "learning_rate": 3.6640000000000004e-06,
      "logits/chosen": -2.330474615097046,
      "logits/rejected": -2.3676578998565674,
      "logps/chosen": -1072.44140625,
      "logps/rejected": -1741.8687744140625,
      "loss": 0.1299,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5910494923591614,
      "rewards/margins": 2.817208766937256,
      "rewards/rejected": -3.4082581996917725,
      "step": 168
    },
    {
      "epoch": 0.2704,
      "grad_norm": 1.8774281740188599,
      "learning_rate": 3.6560000000000002e-06,
      "logits/chosen": -2.1512985229492188,
      "logits/rejected": -2.2904136180877686,
      "logps/chosen": -647.2568359375,
      "logps/rejected": -1376.341064453125,
      "loss": 0.1621,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2316291630268097,
      "rewards/margins": 2.501668691635132,
      "rewards/rejected": -2.7332980632781982,
      "step": 169
    },
    {
      "epoch": 0.272,
      "grad_norm": 2.5106778144836426,
      "learning_rate": 3.6480000000000005e-06,
      "logits/chosen": -2.2560336589813232,
      "logits/rejected": -2.2848329544067383,
      "logps/chosen": -1407.9261474609375,
      "logps/rejected": -2304.40966796875,
      "loss": 0.2967,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.5883364677429199,
      "rewards/margins": 2.570617198944092,
      "rewards/rejected": -3.1589536666870117,
      "step": 170
    },
    {
      "epoch": 0.2736,
      "grad_norm": 15.777143478393555,
      "learning_rate": 3.6400000000000003e-06,
      "logits/chosen": -2.31667160987854,
      "logits/rejected": -2.2964959144592285,
      "logps/chosen": -891.256591796875,
      "logps/rejected": -1913.869140625,
      "loss": 0.2851,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.45486700534820557,
      "rewards/margins": 2.4242074489593506,
      "rewards/rejected": -2.8790745735168457,
      "step": 171
    },
    {
      "epoch": 0.2752,
      "grad_norm": 1.2202856540679932,
      "learning_rate": 3.6320000000000005e-06,
      "logits/chosen": -2.323598623275757,
      "logits/rejected": -2.2983949184417725,
      "logps/chosen": -896.8298950195312,
      "logps/rejected": -2022.98876953125,
      "loss": 0.1401,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5342899560928345,
      "rewards/margins": 3.34799861907959,
      "rewards/rejected": -3.8822882175445557,
      "step": 172
    },
    {
      "epoch": 0.2768,
      "grad_norm": 3.2610714435577393,
      "learning_rate": 3.6240000000000004e-06,
      "logits/chosen": -2.2869200706481934,
      "logits/rejected": -2.236400604248047,
      "logps/chosen": -1127.1907958984375,
      "logps/rejected": -1550.057861328125,
      "loss": 0.3128,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.4409853219985962,
      "rewards/margins": 2.834916591644287,
      "rewards/rejected": -3.2759017944335938,
      "step": 173
    },
    {
      "epoch": 0.2784,
      "grad_norm": 1.6443626880645752,
      "learning_rate": 3.616e-06,
      "logits/chosen": -2.4180731773376465,
      "logits/rejected": -2.446880340576172,
      "logps/chosen": -991.0286254882812,
      "logps/rejected": -1389.666259765625,
      "loss": 0.1712,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.35257017612457275,
      "rewards/margins": 2.4060816764831543,
      "rewards/rejected": -2.7586517333984375,
      "step": 174
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.234976053237915,
      "learning_rate": 3.6080000000000004e-06,
      "logits/chosen": -2.3357694149017334,
      "logits/rejected": -2.2921698093414307,
      "logps/chosen": -1137.77734375,
      "logps/rejected": -2157.838134765625,
      "loss": 0.2006,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5414891242980957,
      "rewards/margins": 2.7176294326782227,
      "rewards/rejected": -3.2591187953948975,
      "step": 175
    },
    {
      "epoch": 0.2816,
      "grad_norm": 2.4141323566436768,
      "learning_rate": 3.6000000000000003e-06,
      "logits/chosen": -2.435011386871338,
      "logits/rejected": -2.3603129386901855,
      "logps/chosen": -854.4802856445312,
      "logps/rejected": -1597.15673828125,
      "loss": 0.1642,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6699696779251099,
      "rewards/margins": 3.8395330905914307,
      "rewards/rejected": -4.509502410888672,
      "step": 176
    },
    {
      "epoch": 0.2832,
      "grad_norm": 1.8527511358261108,
      "learning_rate": 3.5920000000000005e-06,
      "logits/chosen": -2.3748509883880615,
      "logits/rejected": -2.392765760421753,
      "logps/chosen": -714.018798828125,
      "logps/rejected": -1320.4990234375,
      "loss": 0.1634,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19486145675182343,
      "rewards/margins": 2.418196439743042,
      "rewards/rejected": -2.613058090209961,
      "step": 177
    },
    {
      "epoch": 0.2848,
      "grad_norm": 1.8339602947235107,
      "learning_rate": 3.5840000000000003e-06,
      "logits/chosen": -2.265319585800171,
      "logits/rejected": -2.355309247970581,
      "logps/chosen": -1932.6475830078125,
      "logps/rejected": -1647.3089599609375,
      "loss": 0.1658,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.4408212900161743,
      "rewards/margins": 3.5309135913848877,
      "rewards/rejected": -3.090092182159424,
      "step": 178
    },
    {
      "epoch": 0.2864,
      "grad_norm": 1.7930437326431274,
      "learning_rate": 3.576e-06,
      "logits/chosen": -2.255856513977051,
      "logits/rejected": -2.3736183643341064,
      "logps/chosen": -703.4029541015625,
      "logps/rejected": -1245.45751953125,
      "loss": 0.2005,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.23038360476493835,
      "rewards/margins": 2.339446544647217,
      "rewards/rejected": -2.5698299407958984,
      "step": 179
    },
    {
      "epoch": 0.288,
      "grad_norm": 2.327746868133545,
      "learning_rate": 3.5680000000000004e-06,
      "logits/chosen": -2.321254014968872,
      "logits/rejected": -2.3379898071289062,
      "logps/chosen": -775.1973876953125,
      "logps/rejected": -1314.758544921875,
      "loss": 0.2267,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.45585110783576965,
      "rewards/margins": 2.09039044380188,
      "rewards/rejected": -2.546241521835327,
      "step": 180
    },
    {
      "epoch": 0.2896,
      "grad_norm": 1.8550668954849243,
      "learning_rate": 3.5600000000000002e-06,
      "logits/chosen": -2.3999218940734863,
      "logits/rejected": -2.4058024883270264,
      "logps/chosen": -1119.43896484375,
      "logps/rejected": -1696.9078369140625,
      "loss": 0.151,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5211852788925171,
      "rewards/margins": 2.6747305393218994,
      "rewards/rejected": -3.195915699005127,
      "step": 181
    },
    {
      "epoch": 0.2912,
      "grad_norm": 2.1074023246765137,
      "learning_rate": 3.5520000000000005e-06,
      "logits/chosen": -2.3173859119415283,
      "logits/rejected": -2.309441328048706,
      "logps/chosen": -1166.6993408203125,
      "logps/rejected": -1855.2772216796875,
      "loss": 0.1392,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6128904223442078,
      "rewards/margins": 4.454507350921631,
      "rewards/rejected": -5.0673980712890625,
      "step": 182
    },
    {
      "epoch": 0.2928,
      "grad_norm": 2.6120569705963135,
      "learning_rate": 3.5440000000000003e-06,
      "logits/chosen": -2.4201416969299316,
      "logits/rejected": -2.416632652282715,
      "logps/chosen": -882.1990966796875,
      "logps/rejected": -1524.1981201171875,
      "loss": 0.1951,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.5338276624679565,
      "rewards/margins": 2.7429747581481934,
      "rewards/rejected": -3.2768025398254395,
      "step": 183
    },
    {
      "epoch": 0.2944,
      "grad_norm": 4.394293785095215,
      "learning_rate": 3.5360000000000005e-06,
      "logits/chosen": -2.1321804523468018,
      "logits/rejected": -2.148343324661255,
      "logps/chosen": -1116.2672119140625,
      "logps/rejected": -2186.41064453125,
      "loss": 0.2697,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.4440643787384033,
      "rewards/margins": 2.50490140914917,
      "rewards/rejected": -2.948965549468994,
      "step": 184
    },
    {
      "epoch": 0.296,
      "grad_norm": 3.77988862991333,
      "learning_rate": 3.5280000000000004e-06,
      "logits/chosen": -2.2071712017059326,
      "logits/rejected": -2.250199317932129,
      "logps/chosen": -1352.15380859375,
      "logps/rejected": -1748.323974609375,
      "loss": 0.1996,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.5272799134254456,
      "rewards/margins": 3.0357818603515625,
      "rewards/rejected": -3.5630617141723633,
      "step": 185
    },
    {
      "epoch": 0.2976,
      "grad_norm": 3.1289355754852295,
      "learning_rate": 3.52e-06,
      "logits/chosen": -2.2949588298797607,
      "logits/rejected": -2.2754909992218018,
      "logps/chosen": -1303.509033203125,
      "logps/rejected": -2237.87451171875,
      "loss": 0.1778,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0635740756988525,
      "rewards/margins": 2.172611713409424,
      "rewards/rejected": -3.2361857891082764,
      "step": 186
    },
    {
      "epoch": 0.2992,
      "grad_norm": 4.410188674926758,
      "learning_rate": 3.5120000000000004e-06,
      "logits/chosen": -2.362032413482666,
      "logits/rejected": -2.43119478225708,
      "logps/chosen": -1248.1905517578125,
      "logps/rejected": -1692.3599853515625,
      "loss": 0.2694,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.032613754272461,
      "rewards/margins": 2.3153738975524902,
      "rewards/rejected": -3.347987651824951,
      "step": 187
    },
    {
      "epoch": 0.3008,
      "grad_norm": 2.258246898651123,
      "learning_rate": 3.5040000000000002e-06,
      "logits/chosen": -2.2911324501037598,
      "logits/rejected": -2.442878007888794,
      "logps/chosen": -720.9606323242188,
      "logps/rejected": -1374.5987548828125,
      "loss": 0.2263,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.522857666015625,
      "rewards/margins": 1.9479507207870483,
      "rewards/rejected": -2.470808267593384,
      "step": 188
    },
    {
      "epoch": 0.3024,
      "grad_norm": 2.2726762294769287,
      "learning_rate": 3.4960000000000005e-06,
      "logits/chosen": -2.3729097843170166,
      "logits/rejected": -2.3510634899139404,
      "logps/chosen": -1042.6658935546875,
      "logps/rejected": -1773.7489013671875,
      "loss": 0.1525,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.39280635118484497,
      "rewards/margins": 3.7140111923217773,
      "rewards/rejected": -4.106817245483398,
      "step": 189
    },
    {
      "epoch": 0.304,
      "grad_norm": 2.3698344230651855,
      "learning_rate": 3.4880000000000003e-06,
      "logits/chosen": -2.188194990158081,
      "logits/rejected": -2.2725374698638916,
      "logps/chosen": -942.1041259765625,
      "logps/rejected": -1585.26611328125,
      "loss": 0.1733,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5274035930633545,
      "rewards/margins": 2.7674686908721924,
      "rewards/rejected": -3.294872283935547,
      "step": 190
    },
    {
      "epoch": 0.3056,
      "grad_norm": 2.1285650730133057,
      "learning_rate": 3.48e-06,
      "logits/chosen": -2.3986411094665527,
      "logits/rejected": -2.4213950634002686,
      "logps/chosen": -1413.6131591796875,
      "logps/rejected": -1834.987548828125,
      "loss": 0.168,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.679044783115387,
      "rewards/margins": 2.2526471614837646,
      "rewards/rejected": -2.931691884994507,
      "step": 191
    },
    {
      "epoch": 0.3072,
      "grad_norm": 3.715106964111328,
      "learning_rate": 3.4720000000000004e-06,
      "logits/chosen": -2.267573356628418,
      "logits/rejected": -2.3407609462738037,
      "logps/chosen": -1132.596435546875,
      "logps/rejected": -1615.272705078125,
      "loss": 0.3439,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.6952680349349976,
      "rewards/margins": 2.5385842323303223,
      "rewards/rejected": -3.233851909637451,
      "step": 192
    },
    {
      "epoch": 0.3088,
      "grad_norm": 1.6077755689620972,
      "learning_rate": 3.464e-06,
      "logits/chosen": -2.3719513416290283,
      "logits/rejected": -2.417867660522461,
      "logps/chosen": -1172.532470703125,
      "logps/rejected": -1571.7464599609375,
      "loss": 0.1173,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.750707745552063,
      "rewards/margins": 3.2077839374542236,
      "rewards/rejected": -3.958491802215576,
      "step": 193
    },
    {
      "epoch": 0.3104,
      "grad_norm": 2.760540723800659,
      "learning_rate": 3.4560000000000005e-06,
      "logits/chosen": -2.224351644515991,
      "logits/rejected": -2.346921682357788,
      "logps/chosen": -805.364013671875,
      "logps/rejected": -1678.970947265625,
      "loss": 0.1944,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6713283061981201,
      "rewards/margins": 3.4182825088500977,
      "rewards/rejected": -4.089611053466797,
      "step": 194
    },
    {
      "epoch": 0.312,
      "grad_norm": 4.159808158874512,
      "learning_rate": 3.4480000000000003e-06,
      "logits/chosen": -2.33426570892334,
      "logits/rejected": -2.420269012451172,
      "logps/chosen": -1133.2972412109375,
      "logps/rejected": -1415.9013671875,
      "loss": 0.2911,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.6552489995956421,
      "rewards/margins": 2.071715831756592,
      "rewards/rejected": -2.7269649505615234,
      "step": 195
    },
    {
      "epoch": 0.3136,
      "grad_norm": 1.311795949935913,
      "learning_rate": 3.44e-06,
      "logits/chosen": -2.1748080253601074,
      "logits/rejected": -2.227570056915283,
      "logps/chosen": -1054.73291015625,
      "logps/rejected": -1792.704345703125,
      "loss": 0.0995,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2765786647796631,
      "rewards/margins": 4.1288580894470215,
      "rewards/rejected": -4.4054365158081055,
      "step": 196
    },
    {
      "epoch": 0.3152,
      "grad_norm": 1.3443551063537598,
      "learning_rate": 3.4320000000000003e-06,
      "logits/chosen": -2.3623170852661133,
      "logits/rejected": -2.294614315032959,
      "logps/chosen": -1004.7554321289062,
      "logps/rejected": -1667.4105224609375,
      "loss": 0.1033,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6549750566482544,
      "rewards/margins": 3.397099018096924,
      "rewards/rejected": -4.052074432373047,
      "step": 197
    },
    {
      "epoch": 0.3168,
      "grad_norm": 1.2824479341506958,
      "learning_rate": 3.424e-06,
      "logits/chosen": -2.368997812271118,
      "logits/rejected": -2.4182991981506348,
      "logps/chosen": -936.3828125,
      "logps/rejected": -1784.031494140625,
      "loss": 0.1354,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5890302062034607,
      "rewards/margins": 3.7321271896362305,
      "rewards/rejected": -4.321157455444336,
      "step": 198
    },
    {
      "epoch": 0.3184,
      "grad_norm": 1.2149852514266968,
      "learning_rate": 3.4160000000000004e-06,
      "logits/chosen": -2.36103892326355,
      "logits/rejected": -2.389537811279297,
      "logps/chosen": -941.8350830078125,
      "logps/rejected": -1589.35546875,
      "loss": 0.0983,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5680639147758484,
      "rewards/margins": 3.2664785385131836,
      "rewards/rejected": -3.834542751312256,
      "step": 199
    },
    {
      "epoch": 0.32,
      "grad_norm": 6.35372257232666,
      "learning_rate": 3.4080000000000002e-06,
      "logits/chosen": -2.3456785678863525,
      "logits/rejected": -2.39849591255188,
      "logps/chosen": -1334.4619140625,
      "logps/rejected": -1133.9503173828125,
      "loss": 0.5131,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.6135604381561279,
      "rewards/margins": 1.5064865350723267,
      "rewards/rejected": -2.120047092437744,
      "step": 200
    }
  ],
  "logging_steps": 1.0,
  "max_steps": 625,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
