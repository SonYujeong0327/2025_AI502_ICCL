{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.16,
  "eval_steps": 500,
  "global_step": 100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0016,
      "grad_norm": 5.777158260345459,
      "learning_rate": 5e-06,
      "logits/chosen": -2.383577346801758,
      "logits/rejected": -2.5550010204315186,
      "logps/chosen": -997.095947265625,
      "logps/rejected": -1401.2965087890625,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.0032,
      "grad_norm": 29.931734085083008,
      "learning_rate": 4.992e-06,
      "logits/chosen": -2.4591455459594727,
      "logits/rejected": -2.4508743286132812,
      "logps/chosen": -889.494873046875,
      "logps/rejected": -2650.220703125,
      "loss": 0.6859,
      "rewards/accuracies": 0.3125,
      "rewards/chosen": -0.0005279185716062784,
      "rewards/margins": 0.01758369244635105,
      "rewards/rejected": -0.018111608922481537,
      "step": 2
    },
    {
      "epoch": 0.0048,
      "grad_norm": 7.421308517456055,
      "learning_rate": 4.984000000000001e-06,
      "logits/chosen": -2.387298107147217,
      "logits/rejected": -2.400231122970581,
      "logps/chosen": -877.0235595703125,
      "logps/rejected": -1620.46630859375,
      "loss": 0.6878,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.010252094827592373,
      "rewards/margins": 0.011494734324514866,
      "rewards/rejected": -0.0012426384491845965,
      "step": 3
    },
    {
      "epoch": 0.0064,
      "grad_norm": 8.491647720336914,
      "learning_rate": 4.976e-06,
      "logits/chosen": -2.3299200534820557,
      "logits/rejected": -2.475105047225952,
      "logps/chosen": -953.943359375,
      "logps/rejected": -1942.45849609375,
      "loss": 0.6801,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -6.537511944770813e-05,
      "rewards/margins": 0.02661166340112686,
      "rewards/rejected": -0.02667703852057457,
      "step": 4
    },
    {
      "epoch": 0.008,
      "grad_norm": 7.217437267303467,
      "learning_rate": 4.9680000000000005e-06,
      "logits/chosen": -2.424405574798584,
      "logits/rejected": -2.46640944480896,
      "logps/chosen": -1256.431884765625,
      "logps/rejected": -1457.0126953125,
      "loss": 0.6812,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.011346865445375443,
      "rewards/margins": 0.024357369169592857,
      "rewards/rejected": -0.013010501861572266,
      "step": 5
    },
    {
      "epoch": 0.0096,
      "grad_norm": 6.225366115570068,
      "learning_rate": 4.960000000000001e-06,
      "logits/chosen": -2.5838606357574463,
      "logits/rejected": -2.5992836952209473,
      "logps/chosen": -938.2471923828125,
      "logps/rejected": -1745.748291015625,
      "loss": 0.689,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.00911245308816433,
      "rewards/margins": 0.008689593523740768,
      "rewards/rejected": -0.017802048474550247,
      "step": 6
    },
    {
      "epoch": 0.0112,
      "grad_norm": 8.435750007629395,
      "learning_rate": 4.952e-06,
      "logits/chosen": -2.483788013458252,
      "logits/rejected": -2.45876145362854,
      "logps/chosen": -1286.958740234375,
      "logps/rejected": -2144.93798828125,
      "loss": 0.6827,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.0014164212625473738,
      "rewards/margins": 0.021252466365695,
      "rewards/rejected": -0.019836043938994408,
      "step": 7
    },
    {
      "epoch": 0.0128,
      "grad_norm": 6.893909931182861,
      "learning_rate": 4.9440000000000004e-06,
      "logits/chosen": -2.526834726333618,
      "logits/rejected": -2.5802536010742188,
      "logps/chosen": -1098.858154296875,
      "logps/rejected": -1681.0372314453125,
      "loss": 0.6879,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.006822490599006414,
      "rewards/margins": 0.010760593228042126,
      "rewards/rejected": -0.003938103094696999,
      "step": 8
    },
    {
      "epoch": 0.0144,
      "grad_norm": 6.476867198944092,
      "learning_rate": 4.936e-06,
      "logits/chosen": -2.525251626968384,
      "logits/rejected": -2.5307137966156006,
      "logps/chosen": -1156.2413330078125,
      "logps/rejected": -1707.1953125,
      "loss": 0.6761,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.0015508650103583932,
      "rewards/margins": 0.035054970532655716,
      "rewards/rejected": -0.03350410610437393,
      "step": 9
    },
    {
      "epoch": 0.016,
      "grad_norm": 6.029538154602051,
      "learning_rate": 4.928000000000001e-06,
      "logits/chosen": -2.4935433864593506,
      "logits/rejected": -2.474785327911377,
      "logps/chosen": -962.8341674804688,
      "logps/rejected": -1336.4739990234375,
      "loss": 0.6726,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.010607386007905006,
      "rewards/margins": 0.04225526005029678,
      "rewards/rejected": -0.031647875905036926,
      "step": 10
    },
    {
      "epoch": 0.0176,
      "grad_norm": 5.764677047729492,
      "learning_rate": 4.92e-06,
      "logits/chosen": -2.579183340072632,
      "logits/rejected": -2.5417375564575195,
      "logps/chosen": -855.5267333984375,
      "logps/rejected": -1480.712646484375,
      "loss": 0.6719,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.0050948625430464745,
      "rewards/margins": 0.04409470409154892,
      "rewards/rejected": -0.04918956756591797,
      "step": 11
    },
    {
      "epoch": 0.0192,
      "grad_norm": 5.572897434234619,
      "learning_rate": 4.9120000000000006e-06,
      "logits/chosen": -2.5378787517547607,
      "logits/rejected": -2.5528461933135986,
      "logps/chosen": -994.4022216796875,
      "logps/rejected": -1402.746826171875,
      "loss": 0.6692,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.00486366730183363,
      "rewards/margins": 0.05027425289154053,
      "rewards/rejected": -0.05513792484998703,
      "step": 12
    },
    {
      "epoch": 0.0208,
      "grad_norm": 8.677556991577148,
      "learning_rate": 4.904000000000001e-06,
      "logits/chosen": -2.4339964389801025,
      "logits/rejected": -2.392798662185669,
      "logps/chosen": -1155.759033203125,
      "logps/rejected": -1554.5931396484375,
      "loss": 0.6582,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.002712750341743231,
      "rewards/margins": 0.07392475754022598,
      "rewards/rejected": -0.07121200859546661,
      "step": 13
    },
    {
      "epoch": 0.0224,
      "grad_norm": 5.772674083709717,
      "learning_rate": 4.896e-06,
      "logits/chosen": -2.3930609226226807,
      "logits/rejected": -2.4590721130371094,
      "logps/chosen": -1166.37060546875,
      "logps/rejected": -1731.8026123046875,
      "loss": 0.6746,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.00047166342847049236,
      "rewards/margins": 0.037793707102537155,
      "rewards/rejected": -0.037322044372558594,
      "step": 14
    },
    {
      "epoch": 0.024,
      "grad_norm": 5.9789276123046875,
      "learning_rate": 4.8880000000000005e-06,
      "logits/chosen": -2.5120468139648438,
      "logits/rejected": -2.521805763244629,
      "logps/chosen": -825.6015014648438,
      "logps/rejected": -1392.1414794921875,
      "loss": 0.6582,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.003991508856415749,
      "rewards/margins": 0.0750049576163292,
      "rewards/rejected": -0.07899646461009979,
      "step": 15
    },
    {
      "epoch": 0.0256,
      "grad_norm": 7.461836338043213,
      "learning_rate": 4.880000000000001e-06,
      "logits/chosen": -2.482703685760498,
      "logits/rejected": -2.4834096431732178,
      "logps/chosen": -1601.0765380859375,
      "logps/rejected": -1890.500732421875,
      "loss": 0.6417,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.008066796697676182,
      "rewards/margins": 0.10860419273376465,
      "rewards/rejected": -0.11667098850011826,
      "step": 16
    },
    {
      "epoch": 0.0272,
      "grad_norm": 6.696410179138184,
      "learning_rate": 4.872000000000001e-06,
      "logits/chosen": -2.2976319789886475,
      "logits/rejected": -2.504713535308838,
      "logps/chosen": -909.9552612304688,
      "logps/rejected": -1605.83740234375,
      "loss": 0.6628,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.016479289159178734,
      "rewards/margins": 0.06566496938467026,
      "rewards/rejected": -0.08214426785707474,
      "step": 17
    },
    {
      "epoch": 0.0288,
      "grad_norm": 5.730576992034912,
      "learning_rate": 4.864e-06,
      "logits/chosen": -2.494868516921997,
      "logits/rejected": -2.5170273780822754,
      "logps/chosen": -718.1146850585938,
      "logps/rejected": -1341.41845703125,
      "loss": 0.6536,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.006640315055847168,
      "rewards/margins": 0.08292777091264725,
      "rewards/rejected": -0.07628745585680008,
      "step": 18
    },
    {
      "epoch": 0.0304,
      "grad_norm": 5.351961135864258,
      "learning_rate": 4.856e-06,
      "logits/chosen": -2.2484681606292725,
      "logits/rejected": -2.5302162170410156,
      "logps/chosen": -777.997314453125,
      "logps/rejected": -1522.199951171875,
      "loss": 0.6517,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.0043878923170268536,
      "rewards/margins": 0.08642282336950302,
      "rewards/rejected": -0.08203492313623428,
      "step": 19
    },
    {
      "epoch": 0.032,
      "grad_norm": 5.9492926597595215,
      "learning_rate": 4.848000000000001e-06,
      "logits/chosen": -2.427757740020752,
      "logits/rejected": -2.4902050495147705,
      "logps/chosen": -1203.291748046875,
      "logps/rejected": -1451.47900390625,
      "loss": 0.6262,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020780373364686966,
      "rewards/margins": 0.1411726027727127,
      "rewards/rejected": -0.12039223313331604,
      "step": 20
    },
    {
      "epoch": 0.0336,
      "grad_norm": 6.540633678436279,
      "learning_rate": 4.84e-06,
      "logits/chosen": -2.303931713104248,
      "logits/rejected": -2.5109848976135254,
      "logps/chosen": -1161.491455078125,
      "logps/rejected": -1683.808349609375,
      "loss": 0.6433,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.004983187187463045,
      "rewards/margins": 0.10777640342712402,
      "rewards/rejected": -0.11275959014892578,
      "step": 21
    },
    {
      "epoch": 0.0352,
      "grad_norm": 6.436901092529297,
      "learning_rate": 4.8320000000000005e-06,
      "logits/chosen": -2.400743007659912,
      "logits/rejected": -2.4598302841186523,
      "logps/chosen": -853.2847290039062,
      "logps/rejected": -1669.84033203125,
      "loss": 0.6078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.005872583016753197,
      "rewards/margins": 0.18278947472572327,
      "rewards/rejected": -0.1886620670557022,
      "step": 22
    },
    {
      "epoch": 0.0368,
      "grad_norm": 5.8360090255737305,
      "learning_rate": 4.824000000000001e-06,
      "logits/chosen": -2.4765625,
      "logits/rejected": -2.5283117294311523,
      "logps/chosen": -1193.60595703125,
      "logps/rejected": -1400.964599609375,
      "loss": 0.6429,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.009444882161915302,
      "rewards/margins": 0.10741741955280304,
      "rewards/rejected": -0.11686229705810547,
      "step": 23
    },
    {
      "epoch": 0.0384,
      "grad_norm": 5.09824275970459,
      "learning_rate": 4.816e-06,
      "logits/chosen": -2.4321236610412598,
      "logits/rejected": -2.500823974609375,
      "logps/chosen": -684.755859375,
      "logps/rejected": -1265.620361328125,
      "loss": 0.6217,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.00216085952706635,
      "rewards/margins": 0.15424855053424835,
      "rewards/rejected": -0.15208768844604492,
      "step": 24
    },
    {
      "epoch": 0.04,
      "grad_norm": 4.6456685066223145,
      "learning_rate": 4.808e-06,
      "logits/chosen": -2.4003920555114746,
      "logits/rejected": -2.6259267330169678,
      "logps/chosen": -662.1038818359375,
      "logps/rejected": -1401.2833251953125,
      "loss": 0.6219,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.005369471851736307,
      "rewards/margins": 0.15287218987941742,
      "rewards/rejected": -0.14750270545482635,
      "step": 25
    },
    {
      "epoch": 0.0416,
      "grad_norm": 6.444249629974365,
      "learning_rate": 4.800000000000001e-06,
      "logits/chosen": -2.4268743991851807,
      "logits/rejected": -2.515354633331299,
      "logps/chosen": -1249.900634765625,
      "logps/rejected": -1548.016357421875,
      "loss": 0.6071,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.02955174446105957,
      "rewards/margins": 0.19209963083267212,
      "rewards/rejected": -0.2216513752937317,
      "step": 26
    },
    {
      "epoch": 0.0432,
      "grad_norm": 5.8396430015563965,
      "learning_rate": 4.792000000000001e-06,
      "logits/chosen": -2.4963107109069824,
      "logits/rejected": -2.5389151573181152,
      "logps/chosen": -1776.93798828125,
      "logps/rejected": -1911.4761962890625,
      "loss": 0.619,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.008384992368519306,
      "rewards/margins": 0.16205109655857086,
      "rewards/rejected": -0.17043611407279968,
      "step": 27
    },
    {
      "epoch": 0.0448,
      "grad_norm": 4.950774192810059,
      "learning_rate": 4.784e-06,
      "logits/chosen": -2.5377228260040283,
      "logits/rejected": -2.5655124187469482,
      "logps/chosen": -770.48486328125,
      "logps/rejected": -1328.5189208984375,
      "loss": 0.6363,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.019844507798552513,
      "rewards/margins": 0.12086965888738632,
      "rewards/rejected": -0.14071418344974518,
      "step": 28
    },
    {
      "epoch": 0.0464,
      "grad_norm": 4.218019962310791,
      "learning_rate": 4.7760000000000005e-06,
      "logits/chosen": -2.5830776691436768,
      "logits/rejected": -2.615169048309326,
      "logps/chosen": -836.572021484375,
      "logps/rejected": -1111.2818603515625,
      "loss": 0.6193,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.015565921552479267,
      "rewards/margins": 0.16033843159675598,
      "rewards/rejected": -0.17590436339378357,
      "step": 29
    },
    {
      "epoch": 0.048,
      "grad_norm": 6.1509175300598145,
      "learning_rate": 4.768000000000001e-06,
      "logits/chosen": -2.3730645179748535,
      "logits/rejected": -2.498508930206299,
      "logps/chosen": -1609.7783203125,
      "logps/rejected": -1804.330078125,
      "loss": 0.5917,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.015220570378005505,
      "rewards/margins": 0.2305750548839569,
      "rewards/rejected": -0.2457956224679947,
      "step": 30
    },
    {
      "epoch": 0.0496,
      "grad_norm": 4.998894214630127,
      "learning_rate": 4.76e-06,
      "logits/chosen": -2.418651819229126,
      "logits/rejected": -2.497138738632202,
      "logps/chosen": -1092.2430419921875,
      "logps/rejected": -1448.130126953125,
      "loss": 0.5809,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.0014558564871549606,
      "rewards/margins": 0.2704559862613678,
      "rewards/rejected": -0.2719117999076843,
      "step": 31
    },
    {
      "epoch": 0.0512,
      "grad_norm": 7.974624156951904,
      "learning_rate": 4.752e-06,
      "logits/chosen": -2.4644689559936523,
      "logits/rejected": -2.4903476238250732,
      "logps/chosen": -1456.8184814453125,
      "logps/rejected": -1984.0936279296875,
      "loss": 0.6069,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.039417147636413574,
      "rewards/margins": 0.2027800977230072,
      "rewards/rejected": -0.24219724535942078,
      "step": 32
    },
    {
      "epoch": 0.0528,
      "grad_norm": 6.433887481689453,
      "learning_rate": 4.744000000000001e-06,
      "logits/chosen": -2.5184032917022705,
      "logits/rejected": -2.4885895252227783,
      "logps/chosen": -1556.9276123046875,
      "logps/rejected": -2208.9404296875,
      "loss": 0.5729,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.036615803837776184,
      "rewards/margins": 0.2789185047149658,
      "rewards/rejected": -0.3155343532562256,
      "step": 33
    },
    {
      "epoch": 0.0544,
      "grad_norm": 5.127695560455322,
      "learning_rate": 4.736000000000001e-06,
      "logits/chosen": -2.527791976928711,
      "logits/rejected": -2.5352911949157715,
      "logps/chosen": -761.0938720703125,
      "logps/rejected": -1747.624755859375,
      "loss": 0.564,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.0006397361867129803,
      "rewards/margins": 0.28775492310523987,
      "rewards/rejected": -0.2871151864528656,
      "step": 34
    },
    {
      "epoch": 0.056,
      "grad_norm": 4.690290451049805,
      "learning_rate": 4.728e-06,
      "logits/chosen": -2.3896756172180176,
      "logits/rejected": -2.4915108680725098,
      "logps/chosen": -954.8023071289062,
      "logps/rejected": -1395.8271484375,
      "loss": 0.6103,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.022553065791726112,
      "rewards/margins": 0.18402671813964844,
      "rewards/rejected": -0.2065797746181488,
      "step": 35
    },
    {
      "epoch": 0.0576,
      "grad_norm": 5.159278869628906,
      "learning_rate": 4.7200000000000005e-06,
      "logits/chosen": -2.4312891960144043,
      "logits/rejected": -2.5728580951690674,
      "logps/chosen": -1027.1085205078125,
      "logps/rejected": -1698.792236328125,
      "loss": 0.5754,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020159317180514336,
      "rewards/margins": 0.2611401081085205,
      "rewards/rejected": -0.2409808188676834,
      "step": 36
    },
    {
      "epoch": 0.0592,
      "grad_norm": 5.163532257080078,
      "learning_rate": 4.712000000000001e-06,
      "logits/chosen": -2.444011688232422,
      "logits/rejected": -2.545302391052246,
      "logps/chosen": -985.62548828125,
      "logps/rejected": -1722.9822998046875,
      "loss": 0.5289,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.023259827867150307,
      "rewards/margins": 0.4088696837425232,
      "rewards/rejected": -0.38560980558395386,
      "step": 37
    },
    {
      "epoch": 0.0608,
      "grad_norm": 4.443084716796875,
      "learning_rate": 4.704e-06,
      "logits/chosen": -2.4531683921813965,
      "logits/rejected": -2.3953018188476562,
      "logps/chosen": -1051.037109375,
      "logps/rejected": -1488.4656982421875,
      "loss": 0.4829,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03958432748913765,
      "rewards/margins": 0.6120326519012451,
      "rewards/rejected": -0.5724484324455261,
      "step": 38
    },
    {
      "epoch": 0.0624,
      "grad_norm": 4.36039924621582,
      "learning_rate": 4.6960000000000004e-06,
      "logits/chosen": -2.346738815307617,
      "logits/rejected": -2.3932557106018066,
      "logps/chosen": -781.6734619140625,
      "logps/rejected": -1389.060302734375,
      "loss": 0.5071,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.025782395154237747,
      "rewards/margins": 0.5120918154716492,
      "rewards/rejected": -0.4863094687461853,
      "step": 39
    },
    {
      "epoch": 0.064,
      "grad_norm": 4.423152446746826,
      "learning_rate": 4.688000000000001e-06,
      "logits/chosen": -2.3941683769226074,
      "logits/rejected": -2.4453883171081543,
      "logps/chosen": -1348.4906005859375,
      "logps/rejected": -1369.6048583984375,
      "loss": 0.5197,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.08326391875743866,
      "rewards/margins": 0.4253552258014679,
      "rewards/rejected": -0.34209129214286804,
      "step": 40
    },
    {
      "epoch": 0.0656,
      "grad_norm": 3.917776346206665,
      "learning_rate": 4.680000000000001e-06,
      "logits/chosen": -2.5225353240966797,
      "logits/rejected": -2.4893646240234375,
      "logps/chosen": -631.3782348632812,
      "logps/rejected": -1237.5419921875,
      "loss": 0.5319,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.003564846236258745,
      "rewards/margins": 0.3783791661262512,
      "rewards/rejected": -0.38194403052330017,
      "step": 41
    },
    {
      "epoch": 0.0672,
      "grad_norm": 6.309618949890137,
      "learning_rate": 4.672e-06,
      "logits/chosen": -2.3947300910949707,
      "logits/rejected": -2.33028244972229,
      "logps/chosen": -997.8880615234375,
      "logps/rejected": -1573.5198974609375,
      "loss": 0.5715,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.01999068260192871,
      "rewards/margins": 0.27362799644470215,
      "rewards/rejected": -0.29361870884895325,
      "step": 42
    },
    {
      "epoch": 0.0688,
      "grad_norm": 4.295537948608398,
      "learning_rate": 4.664000000000001e-06,
      "logits/chosen": -2.4997317790985107,
      "logits/rejected": -2.4784295558929443,
      "logps/chosen": -943.6978149414062,
      "logps/rejected": -1176.74560546875,
      "loss": 0.5582,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.027471639215946198,
      "rewards/margins": 0.3107304871082306,
      "rewards/rejected": -0.3382021188735962,
      "step": 43
    },
    {
      "epoch": 0.0704,
      "grad_norm": 7.20757532119751,
      "learning_rate": 4.656000000000001e-06,
      "logits/chosen": -2.440206289291382,
      "logits/rejected": -2.521519899368286,
      "logps/chosen": -1279.581787109375,
      "logps/rejected": -1728.439453125,
      "loss": 0.5333,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.021382711827754974,
      "rewards/margins": 0.37735024094581604,
      "rewards/rejected": -0.35596752166748047,
      "step": 44
    },
    {
      "epoch": 0.072,
      "grad_norm": 4.294131278991699,
      "learning_rate": 4.648e-06,
      "logits/chosen": -2.427238702774048,
      "logits/rejected": -2.499267339706421,
      "logps/chosen": -936.76953125,
      "logps/rejected": -1329.57373046875,
      "loss": 0.5473,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05417850241065025,
      "rewards/margins": 0.3269869089126587,
      "rewards/rejected": -0.38116541504859924,
      "step": 45
    },
    {
      "epoch": 0.0736,
      "grad_norm": 5.159995079040527,
      "learning_rate": 4.6400000000000005e-06,
      "logits/chosen": -2.423997163772583,
      "logits/rejected": -2.4125783443450928,
      "logps/chosen": -1069.165283203125,
      "logps/rejected": -1962.3826904296875,
      "loss": 0.4657,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.025747397914528847,
      "rewards/margins": 0.7605292797088623,
      "rewards/rejected": -0.786276638507843,
      "step": 46
    },
    {
      "epoch": 0.0752,
      "grad_norm": 6.723729610443115,
      "learning_rate": 4.632000000000001e-06,
      "logits/chosen": -2.5509090423583984,
      "logits/rejected": -2.4923243522644043,
      "logps/chosen": -1556.790771484375,
      "logps/rejected": -1895.181640625,
      "loss": 0.5837,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.12032730132341385,
      "rewards/margins": 0.2908268868923187,
      "rewards/rejected": -0.41115421056747437,
      "step": 47
    },
    {
      "epoch": 0.0768,
      "grad_norm": 4.9094438552856445,
      "learning_rate": 4.624e-06,
      "logits/chosen": -2.403075933456421,
      "logits/rejected": -2.5514211654663086,
      "logps/chosen": -858.0516357421875,
      "logps/rejected": -1559.831298828125,
      "loss": 0.5251,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0030367602594196796,
      "rewards/margins": 0.39764222502708435,
      "rewards/rejected": -0.40067896246910095,
      "step": 48
    },
    {
      "epoch": 0.0784,
      "grad_norm": 5.90323543548584,
      "learning_rate": 4.616e-06,
      "logits/chosen": -2.402954339981079,
      "logits/rejected": -2.5007476806640625,
      "logps/chosen": -1644.49365234375,
      "logps/rejected": -2142.56591796875,
      "loss": 0.4077,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04832523688673973,
      "rewards/margins": 0.7789440751075745,
      "rewards/rejected": -0.7306188941001892,
      "step": 49
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.876892566680908,
      "learning_rate": 4.608000000000001e-06,
      "logits/chosen": -2.4634196758270264,
      "logits/rejected": -2.524357795715332,
      "logps/chosen": -1243.4114990234375,
      "logps/rejected": -2200.423095703125,
      "loss": 0.4226,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0012695789337158203,
      "rewards/margins": 0.7439866065979004,
      "rewards/rejected": -0.745256245136261,
      "step": 50
    },
    {
      "epoch": 0.0816,
      "grad_norm": 5.304353713989258,
      "learning_rate": 4.600000000000001e-06,
      "logits/chosen": -2.554231882095337,
      "logits/rejected": -2.532021999359131,
      "logps/chosen": -1630.2579345703125,
      "logps/rejected": -1748.79052734375,
      "loss": 0.4516,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.009376813657581806,
      "rewards/margins": 0.6017025709152222,
      "rewards/rejected": -0.6110793948173523,
      "step": 51
    },
    {
      "epoch": 0.0832,
      "grad_norm": 5.187316417694092,
      "learning_rate": 4.592e-06,
      "logits/chosen": -2.498135566711426,
      "logits/rejected": -2.4083938598632812,
      "logps/chosen": -1384.689208984375,
      "logps/rejected": -1931.995849609375,
      "loss": 0.4644,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.07917461544275284,
      "rewards/margins": 0.5850769877433777,
      "rewards/rejected": -0.6642515659332275,
      "step": 52
    },
    {
      "epoch": 0.0848,
      "grad_norm": 4.838135242462158,
      "learning_rate": 4.5840000000000005e-06,
      "logits/chosen": -2.445882797241211,
      "logits/rejected": -2.4829466342926025,
      "logps/chosen": -1116.0863037109375,
      "logps/rejected": -1792.969970703125,
      "loss": 0.5174,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.07026398181915283,
      "rewards/margins": 0.489179402589798,
      "rewards/rejected": -0.5594433546066284,
      "step": 53
    },
    {
      "epoch": 0.0864,
      "grad_norm": 5.2209553718566895,
      "learning_rate": 4.576000000000001e-06,
      "logits/chosen": -2.413048267364502,
      "logits/rejected": -2.4262566566467285,
      "logps/chosen": -887.2513427734375,
      "logps/rejected": -1720.2169189453125,
      "loss": 0.4544,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.022820793092250824,
      "rewards/margins": 0.6332731246948242,
      "rewards/rejected": -0.6104522347450256,
      "step": 54
    },
    {
      "epoch": 0.088,
      "grad_norm": 4.8002119064331055,
      "learning_rate": 4.568e-06,
      "logits/chosen": -2.254833459854126,
      "logits/rejected": -2.3849010467529297,
      "logps/chosen": -939.0093994140625,
      "logps/rejected": -1890.1427001953125,
      "loss": 0.3753,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.018575191497802734,
      "rewards/margins": 0.9412721395492554,
      "rewards/rejected": -0.9598473310470581,
      "step": 55
    },
    {
      "epoch": 0.0896,
      "grad_norm": 4.960271835327148,
      "learning_rate": 4.56e-06,
      "logits/chosen": -2.579571485519409,
      "logits/rejected": -2.515536069869995,
      "logps/chosen": -1340.374755859375,
      "logps/rejected": -1811.5596923828125,
      "loss": 0.4404,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.053728677332401276,
      "rewards/margins": 0.6789557337760925,
      "rewards/rejected": -0.7326843738555908,
      "step": 56
    },
    {
      "epoch": 0.0912,
      "grad_norm": 3.3769338130950928,
      "learning_rate": 4.552000000000001e-06,
      "logits/chosen": -2.22818660736084,
      "logits/rejected": -2.4143457412719727,
      "logps/chosen": -834.120849609375,
      "logps/rejected": -1612.02587890625,
      "loss": 0.428,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.009922838769853115,
      "rewards/margins": 0.7907403111457825,
      "rewards/rejected": -0.8006631731987,
      "step": 57
    },
    {
      "epoch": 0.0928,
      "grad_norm": 4.254573345184326,
      "learning_rate": 4.544000000000001e-06,
      "logits/chosen": -2.465895652770996,
      "logits/rejected": -2.4853782653808594,
      "logps/chosen": -1072.5191650390625,
      "logps/rejected": -1706.7333984375,
      "loss": 0.4479,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.04329273849725723,
      "rewards/margins": 0.7244612574577332,
      "rewards/rejected": -0.7677540183067322,
      "step": 58
    },
    {
      "epoch": 0.0944,
      "grad_norm": 4.614320278167725,
      "learning_rate": 4.536e-06,
      "logits/chosen": -2.4181833267211914,
      "logits/rejected": -2.4571948051452637,
      "logps/chosen": -1143.388671875,
      "logps/rejected": -1698.9920654296875,
      "loss": 0.4434,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.008206438273191452,
      "rewards/margins": 0.6621529459953308,
      "rewards/rejected": -0.6703594326972961,
      "step": 59
    },
    {
      "epoch": 0.096,
      "grad_norm": 114.27096557617188,
      "learning_rate": 4.5280000000000005e-06,
      "logits/chosen": -2.4065511226654053,
      "logits/rejected": -2.4462428092956543,
      "logps/chosen": -1039.031494140625,
      "logps/rejected": -3243.99658203125,
      "loss": 0.9381,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.0578995943069458,
      "rewards/margins": 0.39896953105926514,
      "rewards/rejected": -0.45686912536621094,
      "step": 60
    },
    {
      "epoch": 0.0976,
      "grad_norm": 4.4341230392456055,
      "learning_rate": 4.520000000000001e-06,
      "logits/chosen": -2.4552948474884033,
      "logits/rejected": -2.548647880554199,
      "logps/chosen": -834.3111572265625,
      "logps/rejected": -1361.443603515625,
      "loss": 0.4711,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0879419595003128,
      "rewards/margins": 0.5348865389823914,
      "rewards/rejected": -0.622828483581543,
      "step": 61
    },
    {
      "epoch": 0.0992,
      "grad_norm": 4.643270969390869,
      "learning_rate": 4.512e-06,
      "logits/chosen": -2.54868221282959,
      "logits/rejected": -2.5269510746002197,
      "logps/chosen": -976.1460571289062,
      "logps/rejected": -1663.8165283203125,
      "loss": 0.4991,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.187369242310524,
      "rewards/margins": 0.749457597732544,
      "rewards/rejected": -0.9368268251419067,
      "step": 62
    },
    {
      "epoch": 0.1008,
      "grad_norm": 4.303009986877441,
      "learning_rate": 4.504e-06,
      "logits/chosen": -2.494508743286133,
      "logits/rejected": -2.4935150146484375,
      "logps/chosen": -1258.249755859375,
      "logps/rejected": -1744.1854248046875,
      "loss": 0.4449,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.08252592384815216,
      "rewards/margins": 0.6143494844436646,
      "rewards/rejected": -0.6968754529953003,
      "step": 63
    },
    {
      "epoch": 0.1024,
      "grad_norm": 3.9266281127929688,
      "learning_rate": 4.496000000000001e-06,
      "logits/chosen": -2.4731204509735107,
      "logits/rejected": -2.5203022956848145,
      "logps/chosen": -921.2763671875,
      "logps/rejected": -1744.591064453125,
      "loss": 0.3809,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.022436067461967468,
      "rewards/margins": 0.8827598094940186,
      "rewards/rejected": -0.8603237271308899,
      "step": 64
    },
    {
      "epoch": 0.104,
      "grad_norm": 4.099432945251465,
      "learning_rate": 4.488e-06,
      "logits/chosen": -2.388988971710205,
      "logits/rejected": -2.4264137744903564,
      "logps/chosen": -967.2359008789062,
      "logps/rejected": -2085.13232421875,
      "loss": 0.4029,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.023308193311095238,
      "rewards/margins": 0.8329147100448608,
      "rewards/rejected": -0.8562229871749878,
      "step": 65
    },
    {
      "epoch": 0.1056,
      "grad_norm": 3.6696200370788574,
      "learning_rate": 4.48e-06,
      "logits/chosen": -2.2503409385681152,
      "logits/rejected": -2.409578800201416,
      "logps/chosen": -1728.78466796875,
      "logps/rejected": -1662.9283447265625,
      "loss": 0.4228,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.1354823112487793,
      "rewards/margins": 1.030614972114563,
      "rewards/rejected": -0.8951326608657837,
      "step": 66
    },
    {
      "epoch": 0.1072,
      "grad_norm": 4.834355354309082,
      "learning_rate": 4.4720000000000006e-06,
      "logits/chosen": -2.500420093536377,
      "logits/rejected": -2.5279905796051025,
      "logps/chosen": -1192.21923828125,
      "logps/rejected": -2089.546875,
      "loss": 0.413,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.11657924950122833,
      "rewards/margins": 0.784795880317688,
      "rewards/rejected": -0.9013752341270447,
      "step": 67
    },
    {
      "epoch": 0.1088,
      "grad_norm": 3.6707637310028076,
      "learning_rate": 4.464000000000001e-06,
      "logits/chosen": -2.4371845722198486,
      "logits/rejected": -2.486832857131958,
      "logps/chosen": -755.0999755859375,
      "logps/rejected": -1264.963134765625,
      "loss": 0.4467,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.07509183883666992,
      "rewards/margins": 0.7163953185081482,
      "rewards/rejected": -0.7914870977401733,
      "step": 68
    },
    {
      "epoch": 0.1104,
      "grad_norm": 4.412095546722412,
      "learning_rate": 4.456e-06,
      "logits/chosen": -2.5222582817077637,
      "logits/rejected": -2.530050277709961,
      "logps/chosen": -875.586669921875,
      "logps/rejected": -1423.85693359375,
      "loss": 0.4496,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.04253988713026047,
      "rewards/margins": 0.6108039021492004,
      "rewards/rejected": -0.6533437967300415,
      "step": 69
    },
    {
      "epoch": 0.112,
      "grad_norm": 4.693994998931885,
      "learning_rate": 4.4480000000000004e-06,
      "logits/chosen": -2.441682815551758,
      "logits/rejected": -2.4925615787506104,
      "logps/chosen": -1033.46142578125,
      "logps/rejected": -1597.0738525390625,
      "loss": 0.3942,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.015601971186697483,
      "rewards/margins": 0.8712390661239624,
      "rewards/rejected": -0.8868409991264343,
      "step": 70
    },
    {
      "epoch": 0.1136,
      "grad_norm": 3.6723878383636475,
      "learning_rate": 4.440000000000001e-06,
      "logits/chosen": -2.282296657562256,
      "logits/rejected": -2.425055503845215,
      "logps/chosen": -813.8991088867188,
      "logps/rejected": -1360.2625732421875,
      "loss": 0.4578,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.012647485360503197,
      "rewards/margins": 0.6152610778808594,
      "rewards/rejected": -0.6279085278511047,
      "step": 71
    },
    {
      "epoch": 0.1152,
      "grad_norm": 3.3391969203948975,
      "learning_rate": 4.432e-06,
      "logits/chosen": -2.412693500518799,
      "logits/rejected": -2.408931255340576,
      "logps/chosen": -719.9785766601562,
      "logps/rejected": -1575.9459228515625,
      "loss": 0.3826,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.024913480505347252,
      "rewards/margins": 1.0122792720794678,
      "rewards/rejected": -1.037192702293396,
      "step": 72
    },
    {
      "epoch": 0.1168,
      "grad_norm": 5.337649822235107,
      "learning_rate": 4.424e-06,
      "logits/chosen": -2.4722418785095215,
      "logits/rejected": -2.482541799545288,
      "logps/chosen": -1153.8218994140625,
      "logps/rejected": -1240.9375,
      "loss": 0.475,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.11305580288171768,
      "rewards/margins": 0.5441272854804993,
      "rewards/rejected": -0.6571831107139587,
      "step": 73
    },
    {
      "epoch": 0.1184,
      "grad_norm": 3.6771862506866455,
      "learning_rate": 4.416000000000001e-06,
      "logits/chosen": -2.471193552017212,
      "logits/rejected": -2.477119207382202,
      "logps/chosen": -1147.043701171875,
      "logps/rejected": -1417.807861328125,
      "loss": 0.3984,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.03233852609992027,
      "rewards/margins": 0.8718539476394653,
      "rewards/rejected": -0.9041925072669983,
      "step": 74
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.306926727294922,
      "learning_rate": 4.408000000000001e-06,
      "logits/chosen": -2.4748406410217285,
      "logits/rejected": -2.476750373840332,
      "logps/chosen": -981.0155639648438,
      "logps/rejected": -1468.7720947265625,
      "loss": 0.3877,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.16935759782791138,
      "rewards/margins": 0.9771731495857239,
      "rewards/rejected": -1.1465307474136353,
      "step": 75
    },
    {
      "epoch": 0.1216,
      "grad_norm": 2.8831162452697754,
      "learning_rate": 4.4e-06,
      "logits/chosen": -2.281566619873047,
      "logits/rejected": -2.4291300773620605,
      "logps/chosen": -715.8392944335938,
      "logps/rejected": -1480.139404296875,
      "loss": 0.3201,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.03338942676782608,
      "rewards/margins": 1.1474330425262451,
      "rewards/rejected": -1.1808223724365234,
      "step": 76
    },
    {
      "epoch": 0.1232,
      "grad_norm": 4.195013523101807,
      "learning_rate": 4.3920000000000005e-06,
      "logits/chosen": -2.443937301635742,
      "logits/rejected": -2.498157501220703,
      "logps/chosen": -874.0169067382812,
      "logps/rejected": -1316.942626953125,
      "loss": 0.4337,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.1892099231481552,
      "rewards/margins": 0.6941751837730408,
      "rewards/rejected": -0.8833851218223572,
      "step": 77
    },
    {
      "epoch": 0.1248,
      "grad_norm": 3.533186912536621,
      "learning_rate": 4.384000000000001e-06,
      "logits/chosen": -2.460679292678833,
      "logits/rejected": -2.5314974784851074,
      "logps/chosen": -828.7847900390625,
      "logps/rejected": -1679.3978271484375,
      "loss": 0.3738,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1500023752450943,
      "rewards/margins": 1.2177469730377197,
      "rewards/rejected": -1.3677494525909424,
      "step": 78
    },
    {
      "epoch": 0.1264,
      "grad_norm": 5.251435279846191,
      "learning_rate": 4.376e-06,
      "logits/chosen": -2.428579807281494,
      "logits/rejected": -2.4032108783721924,
      "logps/chosen": -1451.02392578125,
      "logps/rejected": -1898.55029296875,
      "loss": 0.3685,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10095509886741638,
      "rewards/margins": 0.9122613668441772,
      "rewards/rejected": -1.0132163763046265,
      "step": 79
    },
    {
      "epoch": 0.128,
      "grad_norm": 3.8912696838378906,
      "learning_rate": 4.368e-06,
      "logits/chosen": -2.4700093269348145,
      "logits/rejected": -2.493675947189331,
      "logps/chosen": -1226.7545166015625,
      "logps/rejected": -1739.671630859375,
      "loss": 0.3921,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1307486891746521,
      "rewards/margins": 0.922287106513977,
      "rewards/rejected": -1.053035855293274,
      "step": 80
    },
    {
      "epoch": 0.1296,
      "grad_norm": 5.438251972198486,
      "learning_rate": 4.360000000000001e-06,
      "logits/chosen": -2.4751548767089844,
      "logits/rejected": -2.474551200866699,
      "logps/chosen": -1537.556640625,
      "logps/rejected": -2213.0029296875,
      "loss": 0.3727,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.28010302782058716,
      "rewards/margins": 1.1754176616668701,
      "rewards/rejected": -1.4555206298828125,
      "step": 81
    },
    {
      "epoch": 0.1312,
      "grad_norm": 3.6982758045196533,
      "learning_rate": 4.352e-06,
      "logits/chosen": -2.3063390254974365,
      "logits/rejected": -2.3717260360717773,
      "logps/chosen": -928.5242919921875,
      "logps/rejected": -1706.3719482421875,
      "loss": 0.4432,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.02406725287437439,
      "rewards/margins": 0.7992755174636841,
      "rewards/rejected": -0.8233427405357361,
      "step": 82
    },
    {
      "epoch": 0.1328,
      "grad_norm": 3.1924326419830322,
      "learning_rate": 4.344e-06,
      "logits/chosen": -2.356764554977417,
      "logits/rejected": -2.308676242828369,
      "logps/chosen": -1075.246337890625,
      "logps/rejected": -1610.909912109375,
      "loss": 0.2689,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.09648031741380692,
      "rewards/margins": 1.542906403541565,
      "rewards/rejected": -1.4464260339736938,
      "step": 83
    },
    {
      "epoch": 0.1344,
      "grad_norm": 3.5851633548736572,
      "learning_rate": 4.3360000000000005e-06,
      "logits/chosen": -2.3311450481414795,
      "logits/rejected": -2.4191408157348633,
      "logps/chosen": -708.0391235351562,
      "logps/rejected": -1201.893798828125,
      "loss": 0.4109,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10602901875972748,
      "rewards/margins": 0.7890390157699585,
      "rewards/rejected": -0.8950679898262024,
      "step": 84
    },
    {
      "epoch": 0.136,
      "grad_norm": 3.3972227573394775,
      "learning_rate": 4.328000000000001e-06,
      "logits/chosen": -2.2745485305786133,
      "logits/rejected": -2.3526556491851807,
      "logps/chosen": -1237.2530517578125,
      "logps/rejected": -1811.6837158203125,
      "loss": 0.2979,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0517534501850605,
      "rewards/margins": 1.3414555788040161,
      "rewards/rejected": -1.3932090997695923,
      "step": 85
    },
    {
      "epoch": 0.1376,
      "grad_norm": 3.0943892002105713,
      "learning_rate": 4.32e-06,
      "logits/chosen": -2.4424753189086914,
      "logits/rejected": -2.6081202030181885,
      "logps/chosen": -863.8726806640625,
      "logps/rejected": -1171.138916015625,
      "loss": 0.4318,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": 0.0013262461870908737,
      "rewards/margins": 0.7555155754089355,
      "rewards/rejected": -0.7541893124580383,
      "step": 86
    },
    {
      "epoch": 0.1392,
      "grad_norm": 6.824993133544922,
      "learning_rate": 4.312e-06,
      "logits/chosen": -2.26567006111145,
      "logits/rejected": -2.4199228286743164,
      "logps/chosen": -1184.958251953125,
      "logps/rejected": -1732.1868896484375,
      "loss": 0.383,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.12924934923648834,
      "rewards/margins": 1.0110704898834229,
      "rewards/rejected": -1.1403197050094604,
      "step": 87
    },
    {
      "epoch": 0.1408,
      "grad_norm": 2.9939441680908203,
      "learning_rate": 4.304000000000001e-06,
      "logits/chosen": -2.4545109272003174,
      "logits/rejected": -2.515630006790161,
      "logps/chosen": -962.5986328125,
      "logps/rejected": -1317.592041015625,
      "loss": 0.3709,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.1769241839647293,
      "rewards/margins": 1.0671230554580688,
      "rewards/rejected": -1.2440472841262817,
      "step": 88
    },
    {
      "epoch": 0.1424,
      "grad_norm": 3.2820374965667725,
      "learning_rate": 4.296e-06,
      "logits/chosen": -2.4707083702087402,
      "logits/rejected": -2.4873335361480713,
      "logps/chosen": -1149.957275390625,
      "logps/rejected": -1625.29931640625,
      "loss": 0.3003,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.148725226521492,
      "rewards/margins": 1.2516520023345947,
      "rewards/rejected": -1.4003772735595703,
      "step": 89
    },
    {
      "epoch": 0.144,
      "grad_norm": 4.2410359382629395,
      "learning_rate": 4.288e-06,
      "logits/chosen": -2.292142868041992,
      "logits/rejected": -2.3967607021331787,
      "logps/chosen": -1299.8642578125,
      "logps/rejected": -1860.296630859375,
      "loss": 0.3864,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.1806352585554123,
      "rewards/margins": 1.2282143831253052,
      "rewards/rejected": -1.4088494777679443,
      "step": 90
    },
    {
      "epoch": 0.1456,
      "grad_norm": 3.539700984954834,
      "learning_rate": 4.2800000000000005e-06,
      "logits/chosen": -2.5238661766052246,
      "logits/rejected": -2.4962992668151855,
      "logps/chosen": -942.8016357421875,
      "logps/rejected": -1926.316650390625,
      "loss": 0.3897,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.1027974933385849,
      "rewards/margins": 0.9161090850830078,
      "rewards/rejected": -1.018906593322754,
      "step": 91
    },
    {
      "epoch": 0.1472,
      "grad_norm": 2.327420473098755,
      "learning_rate": 4.272000000000001e-06,
      "logits/chosen": -2.2779834270477295,
      "logits/rejected": -2.38816499710083,
      "logps/chosen": -699.9099731445312,
      "logps/rejected": -1502.68603515625,
      "loss": 0.3084,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.15832284092903137,
      "rewards/margins": 1.4348328113555908,
      "rewards/rejected": -1.5931555032730103,
      "step": 92
    },
    {
      "epoch": 0.1488,
      "grad_norm": 3.553140878677368,
      "learning_rate": 4.264e-06,
      "logits/chosen": -2.5239953994750977,
      "logits/rejected": -2.5327048301696777,
      "logps/chosen": -940.0181274414062,
      "logps/rejected": -1413.186767578125,
      "loss": 0.4078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1792048066854477,
      "rewards/margins": 0.768405020236969,
      "rewards/rejected": -0.9476098418235779,
      "step": 93
    },
    {
      "epoch": 0.1504,
      "grad_norm": 2.9112439155578613,
      "learning_rate": 4.256e-06,
      "logits/chosen": -2.4378762245178223,
      "logits/rejected": -2.390841007232666,
      "logps/chosen": -1178.6810302734375,
      "logps/rejected": -1942.3280029296875,
      "loss": 0.2211,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20701630413532257,
      "rewards/margins": 1.681829571723938,
      "rewards/rejected": -1.8888459205627441,
      "step": 94
    },
    {
      "epoch": 0.152,
      "grad_norm": 3.533766031265259,
      "learning_rate": 4.248000000000001e-06,
      "logits/chosen": -2.3642613887786865,
      "logits/rejected": -2.3864657878875732,
      "logps/chosen": -780.42041015625,
      "logps/rejected": -1323.309814453125,
      "loss": 0.3933,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.17855724692344666,
      "rewards/margins": 0.9528135061264038,
      "rewards/rejected": -1.1313707828521729,
      "step": 95
    },
    {
      "epoch": 0.1536,
      "grad_norm": 5.412832260131836,
      "learning_rate": 4.24e-06,
      "logits/chosen": -2.227529525756836,
      "logits/rejected": -2.3135101795196533,
      "logps/chosen": -1793.0361328125,
      "logps/rejected": -2308.60986328125,
      "loss": 0.3618,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.14720723032951355,
      "rewards/margins": 1.1961324214935303,
      "rewards/rejected": -1.343339443206787,
      "step": 96
    },
    {
      "epoch": 0.1552,
      "grad_norm": 2.4717166423797607,
      "learning_rate": 4.232e-06,
      "logits/chosen": -2.4376637935638428,
      "logits/rejected": -2.4160306453704834,
      "logps/chosen": -1514.1527099609375,
      "logps/rejected": -1871.991455078125,
      "loss": 0.2473,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.05610981211066246,
      "rewards/margins": 1.9479868412017822,
      "rewards/rejected": -1.8918769359588623,
      "step": 97
    },
    {
      "epoch": 0.1568,
      "grad_norm": 2.8663933277130127,
      "learning_rate": 4.2240000000000006e-06,
      "logits/chosen": -2.4955952167510986,
      "logits/rejected": -2.466695785522461,
      "logps/chosen": -1014.5949096679688,
      "logps/rejected": -1734.2327880859375,
      "loss": 0.2758,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05485974997282028,
      "rewards/margins": 1.458674669265747,
      "rewards/rejected": -1.513534426689148,
      "step": 98
    },
    {
      "epoch": 0.1584,
      "grad_norm": 2.89676833152771,
      "learning_rate": 4.216e-06,
      "logits/chosen": -2.4123430252075195,
      "logits/rejected": -2.445830821990967,
      "logps/chosen": -1041.836181640625,
      "logps/rejected": -1452.9610595703125,
      "loss": 0.3042,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.14857217669487,
      "rewards/margins": 1.1992714405059814,
      "rewards/rejected": -1.3478436470031738,
      "step": 99
    },
    {
      "epoch": 0.16,
      "grad_norm": 4.1963019371032715,
      "learning_rate": 4.208e-06,
      "logits/chosen": -2.268817186355591,
      "logits/rejected": -2.4280753135681152,
      "logps/chosen": -832.0985107421875,
      "logps/rejected": -1240.9068603515625,
      "loss": 0.4,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.21588222682476044,
      "rewards/margins": 0.8761605620384216,
      "rewards/rejected": -1.0920428037643433,
      "step": 100
    }
  ],
  "logging_steps": 1.0,
  "max_steps": 625,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
