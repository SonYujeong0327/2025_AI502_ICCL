{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 625,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0016,
      "grad_norm": 13.84941291809082,
      "learning_rate": 5e-06,
      "logits/chosen": -2.5776219367980957,
      "logits/rejected": -2.7055633068084717,
      "logps/chosen": -1056.15673828125,
      "logps/rejected": -1480.4925537109375,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.0032,
      "grad_norm": 45.007198333740234,
      "learning_rate": 4.992e-06,
      "logits/chosen": -2.6598477363586426,
      "logits/rejected": -2.638962507247925,
      "logps/chosen": -941.6472778320312,
      "logps/rejected": -2749.870361328125,
      "loss": 0.6931,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.001083088107407093,
      "rewards/margins": 0.0015652645379304886,
      "rewards/rejected": -0.0004821792244911194,
      "step": 2
    },
    {
      "epoch": 0.0048,
      "grad_norm": 15.915088653564453,
      "learning_rate": 4.984000000000001e-06,
      "logits/chosen": -2.5835680961608887,
      "logits/rejected": -2.6005897521972656,
      "logps/chosen": -942.9486694335938,
      "logps/rejected": -1709.282470703125,
      "loss": 0.6909,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": -0.008969164453446865,
      "rewards/margins": 0.00461916858330369,
      "rewards/rejected": -0.013588333502411842,
      "step": 3
    },
    {
      "epoch": 0.0064,
      "grad_norm": 18.279870986938477,
      "learning_rate": 4.976e-06,
      "logits/chosen": -2.560264825820923,
      "logits/rejected": -2.6732285022735596,
      "logps/chosen": -1005.6978759765625,
      "logps/rejected": -2042.3685302734375,
      "loss": 0.6841,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.01044774055480957,
      "rewards/margins": 0.01848425902426243,
      "rewards/rejected": -0.008036518469452858,
      "step": 4
    },
    {
      "epoch": 0.008,
      "grad_norm": 19.964435577392578,
      "learning_rate": 4.9680000000000005e-06,
      "logits/chosen": -2.5974249839782715,
      "logits/rejected": -2.6631898880004883,
      "logps/chosen": -1344.29833984375,
      "logps/rejected": -1537.8853759765625,
      "loss": 0.6782,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.001501727499999106,
      "rewards/margins": 0.03174459934234619,
      "rewards/rejected": -0.033246323466300964,
      "step": 5
    },
    {
      "epoch": 0.0096,
      "grad_norm": 16.028396606445312,
      "learning_rate": 4.960000000000001e-06,
      "logits/chosen": -2.712719440460205,
      "logits/rejected": -2.740114212036133,
      "logps/chosen": -1016.0684204101562,
      "logps/rejected": -1872.759765625,
      "loss": 0.6785,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.0006994251161813736,
      "rewards/margins": 0.02997455559670925,
      "rewards/rejected": -0.029275130480527878,
      "step": 6
    },
    {
      "epoch": 0.0112,
      "grad_norm": 19.929445266723633,
      "learning_rate": 4.952e-06,
      "logits/chosen": -2.648043155670166,
      "logits/rejected": -2.657698631286621,
      "logps/chosen": -1366.33935546875,
      "logps/rejected": -2275.148193359375,
      "loss": 0.6747,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.004850960336625576,
      "rewards/margins": 0.0378965400159359,
      "rewards/rejected": -0.033045582473278046,
      "step": 7
    },
    {
      "epoch": 0.0128,
      "grad_norm": 15.290864944458008,
      "learning_rate": 4.9440000000000004e-06,
      "logits/chosen": -2.6867830753326416,
      "logits/rejected": -2.7323524951934814,
      "logps/chosen": -1177.310302734375,
      "logps/rejected": -1798.749755859375,
      "loss": 0.6677,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.003956103231757879,
      "rewards/margins": 0.05204436928033829,
      "rewards/rejected": -0.04808826744556427,
      "step": 8
    },
    {
      "epoch": 0.0144,
      "grad_norm": 14.194281578063965,
      "learning_rate": 4.936e-06,
      "logits/chosen": -2.6973958015441895,
      "logits/rejected": -2.685187816619873,
      "logps/chosen": -1229.772705078125,
      "logps/rejected": -1825.2882080078125,
      "loss": 0.6574,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.01018662378191948,
      "rewards/margins": 0.07471061497926712,
      "rewards/rejected": -0.0848972350358963,
      "step": 9
    },
    {
      "epoch": 0.016,
      "grad_norm": 12.386669158935547,
      "learning_rate": 4.928000000000001e-06,
      "logits/chosen": -2.651186466217041,
      "logits/rejected": -2.6357762813568115,
      "logps/chosen": -1024.188232421875,
      "logps/rejected": -1424.1258544921875,
      "loss": 0.6606,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.00889575481414795,
      "rewards/margins": 0.06773841381072998,
      "rewards/rejected": -0.05884266272187233,
      "step": 10
    },
    {
      "epoch": 0.0176,
      "grad_norm": 14.19550895690918,
      "learning_rate": 4.92e-06,
      "logits/chosen": -2.725515604019165,
      "logits/rejected": -2.7078707218170166,
      "logps/chosen": -916.9689331054688,
      "logps/rejected": -1582.185791015625,
      "loss": 0.6179,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.004241441376507282,
      "rewards/margins": 0.16683509945869446,
      "rewards/rejected": -0.16259366273880005,
      "step": 11
    },
    {
      "epoch": 0.0192,
      "grad_norm": 13.468660354614258,
      "learning_rate": 4.9120000000000006e-06,
      "logits/chosen": -2.6770591735839844,
      "logits/rejected": -2.6983461380004883,
      "logps/chosen": -1057.786865234375,
      "logps/rejected": -1482.583984375,
      "loss": 0.6411,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0019723414443433285,
      "rewards/margins": 0.10990405827760696,
      "rewards/rejected": -0.1079317107796669,
      "step": 12
    },
    {
      "epoch": 0.0208,
      "grad_norm": 15.013222694396973,
      "learning_rate": 4.904000000000001e-06,
      "logits/chosen": -2.605250597000122,
      "logits/rejected": -2.579044818878174,
      "logps/chosen": -1218.3604736328125,
      "logps/rejected": -1650.537109375,
      "loss": 0.6158,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020715704187750816,
      "rewards/margins": 0.17084407806396484,
      "rewards/rejected": -0.15012836456298828,
      "step": 13
    },
    {
      "epoch": 0.0224,
      "grad_norm": 12.808388710021973,
      "learning_rate": 4.896e-06,
      "logits/chosen": -2.5773825645446777,
      "logits/rejected": -2.6381478309631348,
      "logps/chosen": -1189.969482421875,
      "logps/rejected": -1800.74853515625,
      "loss": 0.6406,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.02153639867901802,
      "rewards/margins": 0.1149168461561203,
      "rewards/rejected": -0.13645325601100922,
      "step": 14
    },
    {
      "epoch": 0.024,
      "grad_norm": 13.93730354309082,
      "learning_rate": 4.8880000000000005e-06,
      "logits/chosen": -2.6666598320007324,
      "logits/rejected": -2.6703221797943115,
      "logps/chosen": -870.569580078125,
      "logps/rejected": -1465.5107421875,
      "loss": 0.5985,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.004537200555205345,
      "rewards/margins": 0.21081161499023438,
      "rewards/rejected": -0.21534880995750427,
      "step": 15
    },
    {
      "epoch": 0.0256,
      "grad_norm": 14.93856430053711,
      "learning_rate": 4.880000000000001e-06,
      "logits/chosen": -2.6248462200164795,
      "logits/rejected": -2.6551945209503174,
      "logps/chosen": -1662.058349609375,
      "logps/rejected": -1971.7041015625,
      "loss": 0.5878,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.0158251766115427,
      "rewards/margins": 0.23583078384399414,
      "rewards/rejected": -0.2516559660434723,
      "step": 16
    },
    {
      "epoch": 0.0272,
      "grad_norm": 14.816671371459961,
      "learning_rate": 4.872000000000001e-06,
      "logits/chosen": -2.4937472343444824,
      "logits/rejected": -2.682842254638672,
      "logps/chosen": -948.5371704101562,
      "logps/rejected": -1703.80029296875,
      "loss": 0.6021,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.024558506906032562,
      "rewards/margins": 0.21781323850154877,
      "rewards/rejected": -0.24237176775932312,
      "step": 17
    },
    {
      "epoch": 0.0288,
      "grad_norm": 12.428322792053223,
      "learning_rate": 4.864e-06,
      "logits/chosen": -2.6531989574432373,
      "logits/rejected": -2.682439088821411,
      "logps/chosen": -778.6520385742188,
      "logps/rejected": -1449.53076171875,
      "loss": 0.5676,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03554432466626167,
      "rewards/margins": 0.2960514426231384,
      "rewards/rejected": -0.26050710678100586,
      "step": 18
    },
    {
      "epoch": 0.0304,
      "grad_norm": 12.391500473022461,
      "learning_rate": 4.856e-06,
      "logits/chosen": -2.459970712661743,
      "logits/rejected": -2.6780951023101807,
      "logps/chosen": -818.6551513671875,
      "logps/rejected": -1620.040771484375,
      "loss": 0.588,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.001973985228687525,
      "rewards/margins": 0.22989128530025482,
      "rewards/rejected": -0.22791728377342224,
      "step": 19
    },
    {
      "epoch": 0.032,
      "grad_norm": 13.238450050354004,
      "learning_rate": 4.848000000000001e-06,
      "logits/chosen": -2.618525266647339,
      "logits/rejected": -2.676117420196533,
      "logps/chosen": -1253.937255859375,
      "logps/rejected": -1530.0140380859375,
      "loss": 0.5068,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06150364875793457,
      "rewards/margins": 0.436116486787796,
      "rewards/rejected": -0.37461280822753906,
      "step": 20
    },
    {
      "epoch": 0.0336,
      "grad_norm": 13.758224487304688,
      "learning_rate": 4.84e-06,
      "logits/chosen": -2.4940528869628906,
      "logits/rejected": -2.680453300476074,
      "logps/chosen": -1219.4149169921875,
      "logps/rejected": -1796.268310546875,
      "loss": 0.5717,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.020945407450199127,
      "rewards/margins": 0.28807199001312256,
      "rewards/rejected": -0.3090174198150635,
      "step": 21
    },
    {
      "epoch": 0.0352,
      "grad_norm": 12.679354667663574,
      "learning_rate": 4.8320000000000005e-06,
      "logits/chosen": -2.620319366455078,
      "logits/rejected": -2.6380627155303955,
      "logps/chosen": -909.053955078125,
      "logps/rejected": -1786.5252685546875,
      "loss": 0.5014,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.012473417446017265,
      "rewards/margins": 0.46010851860046387,
      "rewards/rejected": -0.4725819230079651,
      "step": 22
    },
    {
      "epoch": 0.0368,
      "grad_norm": 12.088041305541992,
      "learning_rate": 4.824000000000001e-06,
      "logits/chosen": -2.6463091373443604,
      "logits/rejected": -2.692570209503174,
      "logps/chosen": -1262.638671875,
      "logps/rejected": -1490.438232421875,
      "loss": 0.5319,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.010773072950541973,
      "rewards/margins": 0.377711683511734,
      "rewards/rejected": -0.36693859100341797,
      "step": 23
    },
    {
      "epoch": 0.0384,
      "grad_norm": 9.156482696533203,
      "learning_rate": 4.816e-06,
      "logits/chosen": -2.629567861557007,
      "logits/rejected": -2.6734282970428467,
      "logps/chosen": -711.06689453125,
      "logps/rejected": -1337.4246826171875,
      "loss": 0.4945,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01684603840112686,
      "rewards/margins": 0.5225176811218262,
      "rewards/rejected": -0.5056716203689575,
      "step": 24
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.210918426513672,
      "learning_rate": 4.808e-06,
      "logits/chosen": -2.605032205581665,
      "logits/rejected": -2.7605724334716797,
      "logps/chosen": -707.715087890625,
      "logps/rejected": -1503.8016357421875,
      "loss": 0.5287,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.005686664953827858,
      "rewards/margins": 0.39984220266342163,
      "rewards/rejected": -0.40552884340286255,
      "step": 25
    },
    {
      "epoch": 0.0416,
      "grad_norm": 10.902751922607422,
      "learning_rate": 4.800000000000001e-06,
      "logits/chosen": -2.6249494552612305,
      "logits/rejected": -2.684657096862793,
      "logps/chosen": -1321.66162109375,
      "logps/rejected": -1656.017822265625,
      "loss": 0.4818,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05061459541320801,
      "rewards/margins": 0.5790916681289673,
      "rewards/rejected": -0.6297063231468201,
      "step": 26
    },
    {
      "epoch": 0.0432,
      "grad_norm": 13.00150203704834,
      "learning_rate": 4.792000000000001e-06,
      "logits/chosen": -2.661109685897827,
      "logits/rejected": -2.6814064979553223,
      "logps/chosen": -1847.2550048828125,
      "logps/rejected": -2001.066650390625,
      "loss": 0.5217,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.052199430763721466,
      "rewards/margins": 0.4480840265750885,
      "rewards/rejected": -0.500283420085907,
      "step": 27
    },
    {
      "epoch": 0.0448,
      "grad_norm": 11.524428367614746,
      "learning_rate": 4.784e-06,
      "logits/chosen": -2.683142900466919,
      "logits/rejected": -2.678946018218994,
      "logps/chosen": -812.0352172851562,
      "logps/rejected": -1415.869873046875,
      "loss": 0.555,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.07924625277519226,
      "rewards/margins": 0.3242942690849304,
      "rewards/rejected": -0.4035405218601227,
      "step": 28
    },
    {
      "epoch": 0.0464,
      "grad_norm": 10.014718055725098,
      "learning_rate": 4.7760000000000005e-06,
      "logits/chosen": -2.7155520915985107,
      "logits/rejected": -2.743312120437622,
      "logps/chosen": -883.1109619140625,
      "logps/rejected": -1176.5841064453125,
      "loss": 0.5439,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.05535697937011719,
      "rewards/margins": 0.3843103349208832,
      "rewards/rejected": -0.43966731429100037,
      "step": 29
    },
    {
      "epoch": 0.048,
      "grad_norm": 12.479547500610352,
      "learning_rate": 4.768000000000001e-06,
      "logits/chosen": -2.5600876808166504,
      "logits/rejected": -2.6521291732788086,
      "logps/chosen": -1684.0687255859375,
      "logps/rejected": -1919.569580078125,
      "loss": 0.4945,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.05451701208949089,
      "rewards/margins": 0.5465288162231445,
      "rewards/rejected": -0.6010458469390869,
      "step": 30
    },
    {
      "epoch": 0.0496,
      "grad_norm": 9.141317367553711,
      "learning_rate": 4.76e-06,
      "logits/chosen": -2.6155083179473877,
      "logits/rejected": -2.661296844482422,
      "logps/chosen": -1145.3343505859375,
      "logps/rejected": -1538.8616943359375,
      "loss": 0.456,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.04083683341741562,
      "rewards/margins": 0.710364580154419,
      "rewards/rejected": -0.7512012720108032,
      "step": 31
    },
    {
      "epoch": 0.0512,
      "grad_norm": 15.683066368103027,
      "learning_rate": 4.752e-06,
      "logits/chosen": -2.6129798889160156,
      "logits/rejected": -2.651198387145996,
      "logps/chosen": -1547.58642578125,
      "logps/rejected": -2092.831298828125,
      "loss": 0.4714,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0672839805483818,
      "rewards/margins": 0.6104311347007751,
      "rewards/rejected": -0.6777151226997375,
      "step": 32
    },
    {
      "epoch": 0.0528,
      "grad_norm": 13.576567649841309,
      "learning_rate": 4.744000000000001e-06,
      "logits/chosen": -2.6763916015625,
      "logits/rejected": -2.6504852771759033,
      "logps/chosen": -1628.1005859375,
      "logps/rejected": -2366.822509765625,
      "loss": 0.5079,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.09182074666023254,
      "rewards/margins": 0.5748151540756226,
      "rewards/rejected": -0.6666358113288879,
      "step": 33
    },
    {
      "epoch": 0.0544,
      "grad_norm": 8.886429786682129,
      "learning_rate": 4.736000000000001e-06,
      "logits/chosen": -2.6563825607299805,
      "logits/rejected": -2.676598072052002,
      "logps/chosen": -819.4796752929688,
      "logps/rejected": -1863.988037109375,
      "loss": 0.3805,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.04877452924847603,
      "rewards/margins": 0.835731029510498,
      "rewards/rejected": -0.884505569934845,
      "step": 34
    },
    {
      "epoch": 0.056,
      "grad_norm": 9.606736183166504,
      "learning_rate": 4.728e-06,
      "logits/chosen": -2.580916404724121,
      "logits/rejected": -2.6463654041290283,
      "logps/chosen": -1010.1661376953125,
      "logps/rejected": -1484.5216064453125,
      "loss": 0.5075,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.05720997229218483,
      "rewards/margins": 0.48622170090675354,
      "rewards/rejected": -0.5434316396713257,
      "step": 35
    },
    {
      "epoch": 0.0576,
      "grad_norm": 10.908175468444824,
      "learning_rate": 4.7200000000000005e-06,
      "logits/chosen": -2.584986925125122,
      "logits/rejected": -2.6844449043273926,
      "logps/chosen": -1089.3065185546875,
      "logps/rejected": -1798.8800048828125,
      "loss": 0.4763,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.02441149204969406,
      "rewards/margins": 0.5325495600700378,
      "rewards/rejected": -0.5569610595703125,
      "step": 36
    },
    {
      "epoch": 0.0592,
      "grad_norm": 9.21141242980957,
      "learning_rate": 4.712000000000001e-06,
      "logits/chosen": -2.6176533699035645,
      "logits/rejected": -2.6927223205566406,
      "logps/chosen": -1048.0860595703125,
      "logps/rejected": -1829.177978515625,
      "loss": 0.3697,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.057007838040590286,
      "rewards/margins": 0.9821045994758606,
      "rewards/rejected": -1.0391124486923218,
      "step": 37
    },
    {
      "epoch": 0.0608,
      "grad_norm": 7.803262233734131,
      "learning_rate": 4.704e-06,
      "logits/chosen": -2.62152361869812,
      "logits/rejected": -2.6219406127929688,
      "logps/chosen": -1094.2901611328125,
      "logps/rejected": -1553.5328369140625,
      "loss": 0.3797,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05804776772856712,
      "rewards/margins": 1.0888700485229492,
      "rewards/rejected": -1.146917700767517,
      "step": 38
    },
    {
      "epoch": 0.0624,
      "grad_norm": 8.698044776916504,
      "learning_rate": 4.6960000000000004e-06,
      "logits/chosen": -2.5194172859191895,
      "logits/rejected": -2.606464385986328,
      "logps/chosen": -823.6840209960938,
      "logps/rejected": -1467.3602294921875,
      "loss": 0.392,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.03470757231116295,
      "rewards/margins": 1.0923101902008057,
      "rewards/rejected": -1.127017855644226,
      "step": 39
    },
    {
      "epoch": 0.064,
      "grad_norm": 6.490854740142822,
      "learning_rate": 4.688000000000001e-06,
      "logits/chosen": -2.5940024852752686,
      "logits/rejected": -2.6515138149261475,
      "logps/chosen": -1409.8240966796875,
      "logps/rejected": -1452.734130859375,
      "loss": 0.398,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04286446049809456,
      "rewards/margins": 0.9120444655418396,
      "rewards/rejected": -0.8691800236701965,
      "step": 40
    },
    {
      "epoch": 0.0656,
      "grad_norm": 6.018487930297852,
      "learning_rate": 4.680000000000001e-06,
      "logits/chosen": -2.6572132110595703,
      "logits/rejected": -2.650991678237915,
      "logps/chosen": -678.6035766601562,
      "logps/rejected": -1320.1328125,
      "loss": 0.3627,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.023231374099850655,
      "rewards/margins": 1.0307849645614624,
      "rewards/rejected": -1.054016351699829,
      "step": 41
    },
    {
      "epoch": 0.0672,
      "grad_norm": 8.60428524017334,
      "learning_rate": 4.672e-06,
      "logits/chosen": -2.5752809047698975,
      "logits/rejected": -2.5308589935302734,
      "logps/chosen": -1056.8516845703125,
      "logps/rejected": -1674.0595703125,
      "loss": 0.4416,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10828962177038193,
      "rewards/margins": 0.6796759366989136,
      "rewards/rejected": -0.7879655957221985,
      "step": 42
    },
    {
      "epoch": 0.0688,
      "grad_norm": 8.333077430725098,
      "learning_rate": 4.664000000000001e-06,
      "logits/chosen": -2.6510136127471924,
      "logits/rejected": -2.6296825408935547,
      "logps/chosen": -1003.7109985351562,
      "logps/rejected": -1255.5789794921875,
      "loss": 0.3983,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.09258784353733063,
      "rewards/margins": 0.8654865026473999,
      "rewards/rejected": -0.9580742716789246,
      "step": 43
    },
    {
      "epoch": 0.0704,
      "grad_norm": 12.893444061279297,
      "learning_rate": 4.656000000000001e-06,
      "logits/chosen": -2.6241934299468994,
      "logits/rejected": -2.669456720352173,
      "logps/chosen": -1349.458740234375,
      "logps/rejected": -1825.3187255859375,
      "loss": 0.3823,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0006209835410118103,
      "rewards/margins": 0.8939098119735718,
      "rewards/rejected": -0.893288791179657,
      "step": 44
    },
    {
      "epoch": 0.072,
      "grad_norm": 7.785130977630615,
      "learning_rate": 4.648e-06,
      "logits/chosen": -2.6009161472320557,
      "logits/rejected": -2.6384713649749756,
      "logps/chosen": -983.5662231445312,
      "logps/rejected": -1404.76123046875,
      "loss": 0.4106,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1607060432434082,
      "rewards/margins": 0.8162174224853516,
      "rewards/rejected": -0.9769235253334045,
      "step": 45
    },
    {
      "epoch": 0.0736,
      "grad_norm": 8.571884155273438,
      "learning_rate": 4.6400000000000005e-06,
      "logits/chosen": -2.6217942237854004,
      "logits/rejected": -2.59497332572937,
      "logps/chosen": -1128.59814453125,
      "logps/rejected": -2065.88037109375,
      "loss": 0.336,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05872344970703125,
      "rewards/margins": 1.121235728263855,
      "rewards/rejected": -1.1799592971801758,
      "step": 46
    },
    {
      "epoch": 0.0752,
      "grad_norm": 16.35368537902832,
      "learning_rate": 4.632000000000001e-06,
      "logits/chosen": -2.6781718730926514,
      "logits/rejected": -2.6508777141571045,
      "logps/chosen": -1655.6455078125,
      "logps/rejected": -2002.5736083984375,
      "loss": 0.4995,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.32652801275253296,
      "rewards/margins": 0.6819158792495728,
      "rewards/rejected": -1.008443832397461,
      "step": 47
    },
    {
      "epoch": 0.0768,
      "grad_norm": 9.724340438842773,
      "learning_rate": 4.624e-06,
      "logits/chosen": -2.5264768600463867,
      "logits/rejected": -2.6516530513763428,
      "logps/chosen": -904.1744384765625,
      "logps/rejected": -1660.6083984375,
      "loss": 0.3994,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.10329101234674454,
      "rewards/margins": 0.8224274516105652,
      "rewards/rejected": -0.9257184267044067,
      "step": 48
    },
    {
      "epoch": 0.0784,
      "grad_norm": 7.342824935913086,
      "learning_rate": 4.616e-06,
      "logits/chosen": -2.562744617462158,
      "logits/rejected": -2.625279426574707,
      "logps/chosen": -1723.362060546875,
      "logps/rejected": -2282.564697265625,
      "loss": 0.2484,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.04911966621875763,
      "rewards/margins": 1.6223055124282837,
      "rewards/rejected": -1.671425223350525,
      "step": 49
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.13101577758789,
      "learning_rate": 4.608000000000001e-06,
      "logits/chosen": -2.5979814529418945,
      "logits/rejected": -2.661043643951416,
      "logps/chosen": -1319.5335693359375,
      "logps/rejected": -2360.220703125,
      "loss": 0.2667,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.21965599060058594,
      "rewards/margins": 1.5807113647460938,
      "rewards/rejected": -1.8003673553466797,
      "step": 50
    },
    {
      "epoch": 0.0816,
      "grad_norm": 9.218878746032715,
      "learning_rate": 4.600000000000001e-06,
      "logits/chosen": -2.6896519660949707,
      "logits/rejected": -2.6666102409362793,
      "logps/chosen": -1723.49365234375,
      "logps/rejected": -1863.3173828125,
      "loss": 0.2765,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.16897039115428925,
      "rewards/margins": 1.3319200277328491,
      "rewards/rejected": -1.5008903741836548,
      "step": 51
    },
    {
      "epoch": 0.0832,
      "grad_norm": 8.526917457580566,
      "learning_rate": 4.592e-06,
      "logits/chosen": -2.6378633975982666,
      "logits/rejected": -2.607964515686035,
      "logps/chosen": -1459.769287109375,
      "logps/rejected": -2045.569091796875,
      "loss": 0.2846,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.19974374771118164,
      "rewards/margins": 1.3471102714538574,
      "rewards/rejected": -1.546854019165039,
      "step": 52
    },
    {
      "epoch": 0.0848,
      "grad_norm": 8.359357833862305,
      "learning_rate": 4.5840000000000005e-06,
      "logits/chosen": -2.581343412399292,
      "logits/rejected": -2.611414670944214,
      "logps/chosen": -1180.2904052734375,
      "logps/rejected": -1913.8856201171875,
      "loss": 0.3621,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2716429531574249,
      "rewards/margins": 1.28533136844635,
      "rewards/rejected": -1.556974172592163,
      "step": 53
    },
    {
      "epoch": 0.0864,
      "grad_norm": 7.808363914489746,
      "learning_rate": 4.576000000000001e-06,
      "logits/chosen": -2.5673961639404297,
      "logits/rejected": -2.5948398113250732,
      "logps/chosen": -929.301025390625,
      "logps/rejected": -1806.926513671875,
      "loss": 0.289,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.02968529425561428,
      "rewards/margins": 1.3527212142944336,
      "rewards/rejected": -1.38240647315979,
      "step": 54
    },
    {
      "epoch": 0.088,
      "grad_norm": 5.290113925933838,
      "learning_rate": 4.568e-06,
      "logits/chosen": -2.4589507579803467,
      "logits/rejected": -2.581552743911743,
      "logps/chosen": -977.469482421875,
      "logps/rejected": -1996.3978271484375,
      "loss": 0.1899,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0343940295279026,
      "rewards/margins": 2.1228291988372803,
      "rewards/rejected": -2.1572232246398926,
      "step": 55
    },
    {
      "epoch": 0.0896,
      "grad_norm": 10.652748107910156,
      "learning_rate": 4.56e-06,
      "logits/chosen": -2.7046263217926025,
      "logits/rejected": -2.6611733436584473,
      "logps/chosen": -1413.8262939453125,
      "logps/rejected": -1913.01953125,
      "loss": 0.3432,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.22382622957229614,
      "rewards/margins": 1.2232162952423096,
      "rewards/rejected": -1.447042465209961,
      "step": 56
    },
    {
      "epoch": 0.0912,
      "grad_norm": 5.368223667144775,
      "learning_rate": 4.552000000000001e-06,
      "logits/chosen": -2.4487392902374268,
      "logits/rejected": -2.5721242427825928,
      "logps/chosen": -897.2557373046875,
      "logps/rejected": -1733.1632080078125,
      "loss": 0.3023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19797492027282715,
      "rewards/margins": 1.6058348417282104,
      "rewards/rejected": -1.8038097620010376,
      "step": 57
    },
    {
      "epoch": 0.0928,
      "grad_norm": 7.837594032287598,
      "learning_rate": 4.544000000000001e-06,
      "logits/chosen": -2.5975821018218994,
      "logits/rejected": -2.627551794052124,
      "logps/chosen": -1149.9952392578125,
      "logps/rejected": -1826.286865234375,
      "loss": 0.3125,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.30320632457733154,
      "rewards/margins": 1.412662148475647,
      "rewards/rejected": -1.715868353843689,
      "step": 58
    },
    {
      "epoch": 0.0944,
      "grad_norm": 6.844327926635742,
      "learning_rate": 4.536e-06,
      "logits/chosen": -2.5499839782714844,
      "logits/rejected": -2.6208062171936035,
      "logps/chosen": -1194.30322265625,
      "logps/rejected": -1783.07666015625,
      "loss": 0.2932,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.1366501748561859,
      "rewards/margins": 1.4224952459335327,
      "rewards/rejected": -1.5591453313827515,
      "step": 59
    },
    {
      "epoch": 0.096,
      "grad_norm": 205.78500366210938,
      "learning_rate": 4.5280000000000005e-06,
      "logits/chosen": -2.5601251125335693,
      "logits/rejected": -2.6464507579803467,
      "logps/chosen": -1088.5633544921875,
      "logps/rejected": -3391.80712890625,
      "loss": 0.6305,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.2457173466682434,
      "rewards/margins": 1.3898653984069824,
      "rewards/rejected": -1.6355828046798706,
      "step": 60
    },
    {
      "epoch": 0.0976,
      "grad_norm": 7.930796146392822,
      "learning_rate": 4.520000000000001e-06,
      "logits/chosen": -2.5776097774505615,
      "logits/rejected": -2.6505048274993896,
      "logps/chosen": -886.3343505859375,
      "logps/rejected": -1469.8668212890625,
      "loss": 0.3103,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.39389175176620483,
      "rewards/margins": 1.2291059494018555,
      "rewards/rejected": -1.622997760772705,
      "step": 61
    },
    {
      "epoch": 0.0992,
      "grad_norm": 8.633110046386719,
      "learning_rate": 4.512e-06,
      "logits/chosen": -2.654784679412842,
      "logits/rejected": -2.670534610748291,
      "logps/chosen": -1030.0927734375,
      "logps/rejected": -1780.8121337890625,
      "loss": 0.3556,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.4683406352996826,
      "rewards/margins": 1.7166171073913574,
      "rewards/rejected": -2.184957504272461,
      "step": 62
    },
    {
      "epoch": 0.1008,
      "grad_norm": 6.731282711029053,
      "learning_rate": 4.504e-06,
      "logits/chosen": -2.637357473373413,
      "logits/rejected": -2.647981882095337,
      "logps/chosen": -1333.366455078125,
      "logps/rejected": -1867.4859619140625,
      "loss": 0.2554,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.31539759039878845,
      "rewards/margins": 1.5246522426605225,
      "rewards/rejected": -1.8400498628616333,
      "step": 63
    },
    {
      "epoch": 0.1024,
      "grad_norm": 6.643932342529297,
      "learning_rate": 4.496000000000001e-06,
      "logits/chosen": -2.6055409908294678,
      "logits/rejected": -2.6496598720550537,
      "logps/chosen": -987.0455932617188,
      "logps/rejected": -1864.578857421875,
      "loss": 0.2255,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.18428108096122742,
      "rewards/margins": 1.8586022853851318,
      "rewards/rejected": -2.0428833961486816,
      "step": 64
    },
    {
      "epoch": 0.104,
      "grad_norm": 5.746735095977783,
      "learning_rate": 4.488e-06,
      "logits/chosen": -2.545200824737549,
      "logits/rejected": -2.58896541595459,
      "logps/chosen": -1011.6875610351562,
      "logps/rejected": -2194.0224609375,
      "loss": 0.2347,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20740637183189392,
      "rewards/margins": 1.887122392654419,
      "rewards/rejected": -2.0945286750793457,
      "step": 65
    },
    {
      "epoch": 0.1056,
      "grad_norm": 5.9390034675598145,
      "learning_rate": 4.48e-06,
      "logits/chosen": -2.4846549034118652,
      "logits/rejected": -2.579946517944336,
      "logps/chosen": -1780.724853515625,
      "logps/rejected": -1745.9156494140625,
      "loss": 0.2963,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.25453251600265503,
      "rewards/margins": 1.4832229614257812,
      "rewards/rejected": -1.737755298614502,
      "step": 66
    },
    {
      "epoch": 0.1072,
      "grad_norm": 9.432305335998535,
      "learning_rate": 4.4720000000000006e-06,
      "logits/chosen": -2.617337226867676,
      "logits/rejected": -2.652225971221924,
      "logps/chosen": -1274.79052734375,
      "logps/rejected": -2235.274658203125,
      "loss": 0.2388,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.419139564037323,
      "rewards/margins": 1.8482582569122314,
      "rewards/rejected": -2.267397880554199,
      "step": 67
    },
    {
      "epoch": 0.1088,
      "grad_norm": 6.483062744140625,
      "learning_rate": 4.464000000000001e-06,
      "logits/chosen": -2.5569300651550293,
      "logits/rejected": -2.6234519481658936,
      "logps/chosen": -814.6470947265625,
      "logps/rejected": -1364.955322265625,
      "loss": 0.2891,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.3310353755950928,
      "rewards/margins": 1.6046247482299805,
      "rewards/rejected": -1.9356601238250732,
      "step": 68
    },
    {
      "epoch": 0.1104,
      "grad_norm": 10.457571029663086,
      "learning_rate": 4.456e-06,
      "logits/chosen": -2.635380268096924,
      "logits/rejected": -2.6364290714263916,
      "logps/chosen": -930.0864868164062,
      "logps/rejected": -1519.385498046875,
      "loss": 0.2952,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.2699303925037384,
      "rewards/margins": 1.4024217128753662,
      "rewards/rejected": -1.6723520755767822,
      "step": 69
    },
    {
      "epoch": 0.112,
      "grad_norm": 11.645984649658203,
      "learning_rate": 4.4480000000000004e-06,
      "logits/chosen": -2.570096969604492,
      "logits/rejected": -2.6213490962982178,
      "logps/chosen": -1099.063720703125,
      "logps/rejected": -1705.52685546875,
      "loss": 0.2962,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.2511003911495209,
      "rewards/margins": 1.76143479347229,
      "rewards/rejected": -2.0125350952148438,
      "step": 70
    },
    {
      "epoch": 0.1136,
      "grad_norm": 6.181652069091797,
      "learning_rate": 4.440000000000001e-06,
      "logits/chosen": -2.4734888076782227,
      "logits/rejected": -2.554945707321167,
      "logps/chosen": -874.9252319335938,
      "logps/rejected": -1451.4827880859375,
      "loss": 0.2926,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.327851802110672,
      "rewards/margins": 1.334261417388916,
      "rewards/rejected": -1.6621131896972656,
      "step": 71
    },
    {
      "epoch": 0.1152,
      "grad_norm": 5.611048698425293,
      "learning_rate": 4.432e-06,
      "logits/chosen": -2.550490617752075,
      "logits/rejected": -2.5684547424316406,
      "logps/chosen": -763.820556640625,
      "logps/rejected": -1657.6444091796875,
      "loss": 0.206,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.238494873046875,
      "rewards/margins": 1.9894895553588867,
      "rewards/rejected": -2.2279841899871826,
      "step": 72
    },
    {
      "epoch": 0.1168,
      "grad_norm": 13.854158401489258,
      "learning_rate": 4.424e-06,
      "logits/chosen": -2.5907607078552246,
      "logits/rejected": -2.6045408248901367,
      "logps/chosen": -1226.4503173828125,
      "logps/rejected": -1327.1646728515625,
      "loss": 0.3485,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.4577573537826538,
      "rewards/margins": 1.198114037513733,
      "rewards/rejected": -1.6558715105056763,
      "step": 73
    },
    {
      "epoch": 0.1184,
      "grad_norm": 5.611763000488281,
      "learning_rate": 4.416000000000001e-06,
      "logits/chosen": -2.594604015350342,
      "logits/rejected": -2.618083953857422,
      "logps/chosen": -1221.1024169921875,
      "logps/rejected": -1504.3363037109375,
      "loss": 0.2573,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.3714500665664673,
      "rewards/margins": 1.6484025716781616,
      "rewards/rejected": -2.019852638244629,
      "step": 74
    },
    {
      "epoch": 0.12,
      "grad_norm": 8.361706733703613,
      "learning_rate": 4.408000000000001e-06,
      "logits/chosen": -2.580840587615967,
      "logits/rejected": -2.6079723834991455,
      "logps/chosen": -1046.5628662109375,
      "logps/rejected": -1562.197998046875,
      "loss": 0.307,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6689375638961792,
      "rewards/margins": 1.8238919973373413,
      "rewards/rejected": -2.4928297996520996,
      "step": 75
    },
    {
      "epoch": 0.1216,
      "grad_norm": 3.6236655712127686,
      "learning_rate": 4.4e-06,
      "logits/chosen": -2.4853832721710205,
      "logits/rejected": -2.591280460357666,
      "logps/chosen": -741.3472290039062,
      "logps/rejected": -1564.3145751953125,
      "loss": 0.1902,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3526232838630676,
      "rewards/margins": 2.3361167907714844,
      "rewards/rejected": -2.6887402534484863,
      "step": 76
    },
    {
      "epoch": 0.1232,
      "grad_norm": 8.047240257263184,
      "learning_rate": 4.3920000000000005e-06,
      "logits/chosen": -2.557563543319702,
      "logits/rejected": -2.5950872898101807,
      "logps/chosen": -938.3635864257812,
      "logps/rejected": -1425.4912109375,
      "loss": 0.3002,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.5570125579833984,
      "rewards/margins": 1.5159423351287842,
      "rewards/rejected": -2.0729548931121826,
      "step": 77
    },
    {
      "epoch": 0.1248,
      "grad_norm": 8.9595947265625,
      "learning_rate": 4.384000000000001e-06,
      "logits/chosen": -2.5734753608703613,
      "logits/rejected": -2.6293206214904785,
      "logps/chosen": -895.8095703125,
      "logps/rejected": -1800.114990234375,
      "loss": 0.2564,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.45989689230918884,
      "rewards/margins": 2.351109743118286,
      "rewards/rejected": -2.811006546020508,
      "step": 78
    },
    {
      "epoch": 0.1264,
      "grad_norm": 5.05607271194458,
      "learning_rate": 4.376e-06,
      "logits/chosen": -2.5721628665924072,
      "logits/rejected": -2.5577292442321777,
      "logps/chosen": -1524.828125,
      "logps/rejected": -2003.477783203125,
      "loss": 0.2166,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.642715573310852,
      "rewards/margins": 1.8920629024505615,
      "rewards/rejected": -2.534778594970703,
      "step": 79
    },
    {
      "epoch": 0.128,
      "grad_norm": 7.038112640380859,
      "learning_rate": 4.368e-06,
      "logits/chosen": -2.5882246494293213,
      "logits/rejected": -2.6154489517211914,
      "logps/chosen": -1290.900146484375,
      "logps/rejected": -1854.79052734375,
      "loss": 0.2536,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.52741539478302,
      "rewards/margins": 1.8594735860824585,
      "rewards/rejected": -2.3868889808654785,
      "step": 80
    },
    {
      "epoch": 0.1296,
      "grad_norm": 17.065824508666992,
      "learning_rate": 4.360000000000001e-06,
      "logits/chosen": -2.602525234222412,
      "logits/rejected": -2.614187240600586,
      "logps/chosen": -1639.3414306640625,
      "logps/rejected": -2388.6005859375,
      "loss": 0.5064,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.949549674987793,
      "rewards/margins": 2.212076187133789,
      "rewards/rejected": -3.161626100540161,
      "step": 81
    },
    {
      "epoch": 0.1312,
      "grad_norm": 7.686249732971191,
      "learning_rate": 4.352e-06,
      "logits/chosen": -2.4996836185455322,
      "logits/rejected": -2.5744447708129883,
      "logps/chosen": -989.7198486328125,
      "logps/rejected": -1813.3284912109375,
      "loss": 0.3302,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.3831857442855835,
      "rewards/margins": 1.527978777885437,
      "rewards/rejected": -1.9111645221710205,
      "step": 82
    },
    {
      "epoch": 0.1328,
      "grad_norm": 5.631213188171387,
      "learning_rate": 4.344e-06,
      "logits/chosen": -2.506361961364746,
      "logits/rejected": -2.509040117263794,
      "logps/chosen": -1139.1744384765625,
      "logps/rejected": -1718.2315673828125,
      "loss": 0.1896,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.26063406467437744,
      "rewards/margins": 2.65224289894104,
      "rewards/rejected": -2.912876605987549,
      "step": 83
    },
    {
      "epoch": 0.1344,
      "grad_norm": 4.509877681732178,
      "learning_rate": 4.3360000000000005e-06,
      "logits/chosen": -2.4786159992218018,
      "logits/rejected": -2.5557239055633545,
      "logps/chosen": -748.5143432617188,
      "logps/rejected": -1279.4168701171875,
      "loss": 0.2451,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3035600781440735,
      "rewards/margins": 1.7710323333740234,
      "rewards/rejected": -2.074592351913452,
      "step": 84
    },
    {
      "epoch": 0.136,
      "grad_norm": 5.832723140716553,
      "learning_rate": 4.328000000000001e-06,
      "logits/chosen": -2.4516549110412598,
      "logits/rejected": -2.5038058757781982,
      "logps/chosen": -1300.7103271484375,
      "logps/rejected": -1945.7178955078125,
      "loss": 0.1813,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.5661133527755737,
      "rewards/margins": 2.6094062328338623,
      "rewards/rejected": -3.1755197048187256,
      "step": 85
    },
    {
      "epoch": 0.1376,
      "grad_norm": 5.095184803009033,
      "learning_rate": 4.32e-06,
      "logits/chosen": -2.585329294204712,
      "logits/rejected": -2.676424503326416,
      "logps/chosen": -916.580322265625,
      "logps/rejected": -1257.6103515625,
      "loss": 0.3074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.36674830317497253,
      "rewards/margins": 1.4988261461257935,
      "rewards/rejected": -1.8655743598937988,
      "step": 86
    },
    {
      "epoch": 0.1392,
      "grad_norm": 20.858564376831055,
      "learning_rate": 4.312e-06,
      "logits/chosen": -2.416091203689575,
      "logits/rejected": -2.569261074066162,
      "logps/chosen": -1258.1981201171875,
      "logps/rejected": -1846.1219482421875,
      "loss": 0.2848,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.5368421673774719,
      "rewards/margins": 2.049252986907959,
      "rewards/rejected": -2.586095094680786,
      "step": 87
    },
    {
      "epoch": 0.1408,
      "grad_norm": 6.0946173667907715,
      "learning_rate": 4.304000000000001e-06,
      "logits/chosen": -2.563009262084961,
      "logits/rejected": -2.6318721771240234,
      "logps/chosen": -1039.8516845703125,
      "logps/rejected": -1420.2889404296875,
      "loss": 0.2437,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.5421506762504578,
      "rewards/margins": 2.181781530380249,
      "rewards/rejected": -2.7239322662353516,
      "step": 88
    },
    {
      "epoch": 0.1424,
      "grad_norm": 3.6643338203430176,
      "learning_rate": 4.296e-06,
      "logits/chosen": -2.608748435974121,
      "logits/rejected": -2.6187620162963867,
      "logps/chosen": -1215.0611572265625,
      "logps/rejected": -1734.988037109375,
      "loss": 0.1181,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.44078579545021057,
      "rewards/margins": 2.6274781227111816,
      "rewards/rejected": -3.0682640075683594,
      "step": 89
    },
    {
      "epoch": 0.144,
      "grad_norm": 8.087428092956543,
      "learning_rate": 4.288e-06,
      "logits/chosen": -2.465214252471924,
      "logits/rejected": -2.522395133972168,
      "logps/chosen": -1388.467041015625,
      "logps/rejected": -1995.6883544921875,
      "loss": 0.2867,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.673370897769928,
      "rewards/margins": 2.2415404319763184,
      "rewards/rejected": -2.9149117469787598,
      "step": 90
    },
    {
      "epoch": 0.1456,
      "grad_norm": 4.81944465637207,
      "learning_rate": 4.2800000000000005e-06,
      "logits/chosen": -2.6290841102600098,
      "logits/rejected": -2.615664482116699,
      "logps/chosen": -1001.8236083984375,
      "logps/rejected": -2059.611083984375,
      "loss": 0.2716,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.45704299211502075,
      "rewards/margins": 1.9129340648651123,
      "rewards/rejected": -2.3699769973754883,
      "step": 91
    },
    {
      "epoch": 0.1472,
      "grad_norm": 3.614452600479126,
      "learning_rate": 4.272000000000001e-06,
      "logits/chosen": -2.4316258430480957,
      "logits/rejected": -2.5464510917663574,
      "logps/chosen": -745.938720703125,
      "logps/rejected": -1623.67333984375,
      "loss": 0.1801,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.47279757261276245,
      "rewards/margins": 2.9887681007385254,
      "rewards/rejected": -3.4615654945373535,
      "step": 92
    },
    {
      "epoch": 0.1488,
      "grad_norm": 5.576539039611816,
      "learning_rate": 4.264e-06,
      "logits/chosen": -2.6419267654418945,
      "logits/rejected": -2.6333372592926025,
      "logps/chosen": -987.1685791015625,
      "logps/rejected": -1516.3785400390625,
      "loss": 0.2319,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5648906826972961,
      "rewards/margins": 1.8507626056671143,
      "rewards/rejected": -2.4156529903411865,
      "step": 93
    },
    {
      "epoch": 0.1504,
      "grad_norm": 5.097036838531494,
      "learning_rate": 4.256e-06,
      "logits/chosen": -2.56418776512146,
      "logits/rejected": -2.5272862911224365,
      "logps/chosen": -1249.920654296875,
      "logps/rejected": -2077.8505859375,
      "loss": 0.1224,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.7480093836784363,
      "rewards/margins": 2.954930305480957,
      "rewards/rejected": -3.702939510345459,
      "step": 94
    },
    {
      "epoch": 0.152,
      "grad_norm": 6.1745805740356445,
      "learning_rate": 4.248000000000001e-06,
      "logits/chosen": -2.505357027053833,
      "logits/rejected": -2.543433666229248,
      "logps/chosen": -841.8966674804688,
      "logps/rejected": -1403.500732421875,
      "loss": 0.2898,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.8015140891075134,
      "rewards/margins": 1.7237809896469116,
      "rewards/rejected": -2.5252950191497803,
      "step": 95
    },
    {
      "epoch": 0.1536,
      "grad_norm": 7.1390485763549805,
      "learning_rate": 4.24e-06,
      "logits/chosen": -2.4471356868743896,
      "logits/rejected": -2.5040111541748047,
      "logps/chosen": -1905.2022705078125,
      "logps/rejected": -2456.6328125,
      "loss": 0.204,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7161625027656555,
      "rewards/margins": 2.2444329261779785,
      "rewards/rejected": -2.96059513092041,
      "step": 96
    },
    {
      "epoch": 0.1552,
      "grad_norm": 4.844906806945801,
      "learning_rate": 4.232e-06,
      "logits/chosen": -2.5816986560821533,
      "logits/rejected": -2.5688273906707764,
      "logps/chosen": -1612.9542236328125,
      "logps/rejected": -1981.49658203125,
      "loss": 0.2022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6185023188591003,
      "rewards/margins": 2.7044992446899414,
      "rewards/rejected": -3.3230013847351074,
      "step": 97
    },
    {
      "epoch": 0.1568,
      "grad_norm": 3.969409942626953,
      "learning_rate": 4.2240000000000006e-06,
      "logits/chosen": -2.584040880203247,
      "logits/rejected": -2.6002554893493652,
      "logps/chosen": -1084.38916015625,
      "logps/rejected": -1864.0318603515625,
      "loss": 0.1288,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.634515643119812,
      "rewards/margins": 2.674475908279419,
      "rewards/rejected": -3.3089914321899414,
      "step": 98
    },
    {
      "epoch": 0.1584,
      "grad_norm": 3.6561484336853027,
      "learning_rate": 4.216e-06,
      "logits/chosen": -2.5594630241394043,
      "logits/rejected": -2.5877585411071777,
      "logps/chosen": -1121.3568115234375,
      "logps/rejected": -1565.031005859375,
      "loss": 0.1462,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5637044310569763,
      "rewards/margins": 2.3934009075164795,
      "rewards/rejected": -2.9571051597595215,
      "step": 99
    },
    {
      "epoch": 0.16,
      "grad_norm": 12.20343017578125,
      "learning_rate": 4.208e-06,
      "logits/chosen": -2.4423067569732666,
      "logits/rejected": -2.5798287391662598,
      "logps/chosen": -881.176025390625,
      "logps/rejected": -1321.0848388671875,
      "loss": 0.3971,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.895788311958313,
      "rewards/margins": 1.4614109992980957,
      "rewards/rejected": -2.3571994304656982,
      "step": 100
    },
    {
      "epoch": 0.1616,
      "grad_norm": 5.749557018280029,
      "learning_rate": 4.2000000000000004e-06,
      "logits/chosen": -2.602213144302368,
      "logits/rejected": -2.601937770843506,
      "logps/chosen": -919.701904296875,
      "logps/rejected": -1737.4989013671875,
      "loss": 0.2203,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.606166422367096,
      "rewards/margins": 2.317492961883545,
      "rewards/rejected": -2.923659563064575,
      "step": 101
    },
    {
      "epoch": 0.1632,
      "grad_norm": 4.590999603271484,
      "learning_rate": 4.192000000000001e-06,
      "logits/chosen": -2.3970415592193604,
      "logits/rejected": -2.5931670665740967,
      "logps/chosen": -1294.47119140625,
      "logps/rejected": -1755.6636962890625,
      "loss": 0.2248,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6253247261047363,
      "rewards/margins": 2.2332234382629395,
      "rewards/rejected": -2.858548164367676,
      "step": 102
    },
    {
      "epoch": 0.1648,
      "grad_norm": 16.120969772338867,
      "learning_rate": 4.184e-06,
      "logits/chosen": -2.5599992275238037,
      "logits/rejected": -2.573983907699585,
      "logps/chosen": -1003.275146484375,
      "logps/rejected": -1651.6865234375,
      "loss": 0.4831,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.1576511859893799,
      "rewards/margins": 1.7802574634552002,
      "rewards/rejected": -2.93790864944458,
      "step": 103
    },
    {
      "epoch": 0.1664,
      "grad_norm": 5.281605243682861,
      "learning_rate": 4.176e-06,
      "logits/chosen": -2.607374668121338,
      "logits/rejected": -2.606253147125244,
      "logps/chosen": -850.6956787109375,
      "logps/rejected": -1412.715087890625,
      "loss": 0.1988,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.44642406702041626,
      "rewards/margins": 2.147481918334961,
      "rewards/rejected": -2.5939061641693115,
      "step": 104
    },
    {
      "epoch": 0.168,
      "grad_norm": 11.615784645080566,
      "learning_rate": 4.168000000000001e-06,
      "logits/chosen": -2.5488691329956055,
      "logits/rejected": -2.5383386611938477,
      "logps/chosen": -983.83056640625,
      "logps/rejected": -1517.0146484375,
      "loss": 0.3262,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.5420036315917969,
      "rewards/margins": 1.8067235946655273,
      "rewards/rejected": -2.348727226257324,
      "step": 105
    },
    {
      "epoch": 0.1696,
      "grad_norm": 6.295446872711182,
      "learning_rate": 4.16e-06,
      "logits/chosen": -2.5123789310455322,
      "logits/rejected": -2.5552313327789307,
      "logps/chosen": -1516.11328125,
      "logps/rejected": -2322.301513671875,
      "loss": 0.1412,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.4955001771450043,
      "rewards/margins": 3.6774232387542725,
      "rewards/rejected": -4.1729230880737305,
      "step": 106
    },
    {
      "epoch": 0.1712,
      "grad_norm": 4.434859275817871,
      "learning_rate": 4.152e-06,
      "logits/chosen": -2.536618709564209,
      "logits/rejected": -2.5697824954986572,
      "logps/chosen": -1193.616455078125,
      "logps/rejected": -2063.705322265625,
      "loss": 0.1738,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.48417752981185913,
      "rewards/margins": 2.482280969619751,
      "rewards/rejected": -2.966458320617676,
      "step": 107
    },
    {
      "epoch": 0.1728,
      "grad_norm": 9.057612419128418,
      "learning_rate": 4.1440000000000005e-06,
      "logits/chosen": -2.616786479949951,
      "logits/rejected": -2.611959218978882,
      "logps/chosen": -1132.6375732421875,
      "logps/rejected": -1788.1622314453125,
      "loss": 0.2076,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.5882627367973328,
      "rewards/margins": 2.2522530555725098,
      "rewards/rejected": -2.840515613555908,
      "step": 108
    },
    {
      "epoch": 0.1744,
      "grad_norm": 3.2958192825317383,
      "learning_rate": 4.136000000000001e-06,
      "logits/chosen": -2.499824285507202,
      "logits/rejected": -2.5699918270111084,
      "logps/chosen": -939.944091796875,
      "logps/rejected": -1518.7822265625,
      "loss": 0.1296,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.655009388923645,
      "rewards/margins": 2.581965923309326,
      "rewards/rejected": -3.2369751930236816,
      "step": 109
    },
    {
      "epoch": 0.176,
      "grad_norm": 7.810518741607666,
      "learning_rate": 4.128e-06,
      "logits/chosen": -2.553767204284668,
      "logits/rejected": -2.5513415336608887,
      "logps/chosen": -1652.2960205078125,
      "logps/rejected": -2008.56787109375,
      "loss": 0.2238,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3638471364974976,
      "rewards/margins": 2.126260995864868,
      "rewards/rejected": -3.4901082515716553,
      "step": 110
    },
    {
      "epoch": 0.1776,
      "grad_norm": 4.5927228927612305,
      "learning_rate": 4.12e-06,
      "logits/chosen": -2.413992166519165,
      "logits/rejected": -2.5045244693756104,
      "logps/chosen": -1156.638916015625,
      "logps/rejected": -2067.70654296875,
      "loss": 0.1824,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7974650859832764,
      "rewards/margins": 2.9131991863250732,
      "rewards/rejected": -3.7106642723083496,
      "step": 111
    },
    {
      "epoch": 0.1792,
      "grad_norm": 8.073678970336914,
      "learning_rate": 4.112000000000001e-06,
      "logits/chosen": -2.5610158443450928,
      "logits/rejected": -2.5489323139190674,
      "logps/chosen": -1340.7498779296875,
      "logps/rejected": -1710.4718017578125,
      "loss": 0.2481,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.063918113708496,
      "rewards/margins": 2.275148391723633,
      "rewards/rejected": -3.339066743850708,
      "step": 112
    },
    {
      "epoch": 0.1808,
      "grad_norm": 7.3243184089660645,
      "learning_rate": 4.104e-06,
      "logits/chosen": -2.5899980068206787,
      "logits/rejected": -2.6016769409179688,
      "logps/chosen": -1197.3370361328125,
      "logps/rejected": -1886.951416015625,
      "loss": 0.163,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.103943109512329,
      "rewards/margins": 2.9499807357788086,
      "rewards/rejected": -4.053923606872559,
      "step": 113
    },
    {
      "epoch": 0.1824,
      "grad_norm": 4.7918572425842285,
      "learning_rate": 4.096e-06,
      "logits/chosen": -2.5200982093811035,
      "logits/rejected": -2.5774784088134766,
      "logps/chosen": -847.1478881835938,
      "logps/rejected": -1482.089111328125,
      "loss": 0.1808,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5526469349861145,
      "rewards/margins": 2.572946310043335,
      "rewards/rejected": -3.125593423843384,
      "step": 114
    },
    {
      "epoch": 0.184,
      "grad_norm": 15.692960739135742,
      "learning_rate": 4.0880000000000005e-06,
      "logits/chosen": -2.5463898181915283,
      "logits/rejected": -2.5766215324401855,
      "logps/chosen": -789.5115356445312,
      "logps/rejected": -991.499267578125,
      "loss": 0.4221,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.8561378717422485,
      "rewards/margins": 1.456132173538208,
      "rewards/rejected": -2.312270164489746,
      "step": 115
    },
    {
      "epoch": 0.1856,
      "grad_norm": 3.677607297897339,
      "learning_rate": 4.08e-06,
      "logits/chosen": -2.5052475929260254,
      "logits/rejected": -2.5343563556671143,
      "logps/chosen": -560.2702026367188,
      "logps/rejected": -1089.4345703125,
      "loss": 0.2277,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.4389704763889313,
      "rewards/margins": 2.0417025089263916,
      "rewards/rejected": -2.48067307472229,
      "step": 116
    },
    {
      "epoch": 0.1872,
      "grad_norm": 3.6556031703948975,
      "learning_rate": 4.072e-06,
      "logits/chosen": -2.522127389907837,
      "logits/rejected": -2.544343948364258,
      "logps/chosen": -682.1380615234375,
      "logps/rejected": -1690.5791015625,
      "loss": 0.1131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8120488524436951,
      "rewards/margins": 3.206557035446167,
      "rewards/rejected": -4.018606185913086,
      "step": 117
    },
    {
      "epoch": 0.1888,
      "grad_norm": 4.322643756866455,
      "learning_rate": 4.064e-06,
      "logits/chosen": -2.601647138595581,
      "logits/rejected": -2.59454607963562,
      "logps/chosen": -926.12255859375,
      "logps/rejected": -1310.7066650390625,
      "loss": 0.1852,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.739689826965332,
      "rewards/margins": 2.574465274810791,
      "rewards/rejected": -3.314155101776123,
      "step": 118
    },
    {
      "epoch": 0.1904,
      "grad_norm": 4.198337078094482,
      "learning_rate": 4.056000000000001e-06,
      "logits/chosen": -2.522589683532715,
      "logits/rejected": -2.6258111000061035,
      "logps/chosen": -1165.843505859375,
      "logps/rejected": -1964.45263671875,
      "loss": 0.1764,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9625725150108337,
      "rewards/margins": 2.6513829231262207,
      "rewards/rejected": -3.613955020904541,
      "step": 119
    },
    {
      "epoch": 0.192,
      "grad_norm": 3.156885862350464,
      "learning_rate": 4.048e-06,
      "logits/chosen": -2.5727691650390625,
      "logits/rejected": -2.5709733963012695,
      "logps/chosen": -746.4669799804688,
      "logps/rejected": -1984.4471435546875,
      "loss": 0.1321,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7271446585655212,
      "rewards/margins": 3.445657253265381,
      "rewards/rejected": -4.172801971435547,
      "step": 120
    },
    {
      "epoch": 0.1936,
      "grad_norm": 6.7459716796875,
      "learning_rate": 4.04e-06,
      "logits/chosen": -2.5250120162963867,
      "logits/rejected": -2.5538296699523926,
      "logps/chosen": -992.5125122070312,
      "logps/rejected": -1538.8245849609375,
      "loss": 0.1583,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.7747882008552551,
      "rewards/margins": 2.703141450881958,
      "rewards/rejected": -3.4779298305511475,
      "step": 121
    },
    {
      "epoch": 0.1952,
      "grad_norm": 9.80472183227539,
      "learning_rate": 4.0320000000000005e-06,
      "logits/chosen": -2.4653236865997314,
      "logits/rejected": -2.5068607330322266,
      "logps/chosen": -552.443603515625,
      "logps/rejected": -1238.7698974609375,
      "loss": 0.315,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.31036150455474854,
      "rewards/margins": 2.591792583465576,
      "rewards/rejected": -2.9021544456481934,
      "step": 122
    },
    {
      "epoch": 0.1968,
      "grad_norm": 13.748944282531738,
      "learning_rate": 4.024e-06,
      "logits/chosen": -2.5244879722595215,
      "logits/rejected": -2.597602605819702,
      "logps/chosen": -1166.708251953125,
      "logps/rejected": -1306.92333984375,
      "loss": 0.4899,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.9613562226295471,
      "rewards/margins": 1.8996186256408691,
      "rewards/rejected": -2.8609747886657715,
      "step": 123
    },
    {
      "epoch": 0.1984,
      "grad_norm": 14.293259620666504,
      "learning_rate": 4.016e-06,
      "logits/chosen": -2.5158143043518066,
      "logits/rejected": -2.554211378097534,
      "logps/chosen": -1433.0123291015625,
      "logps/rejected": -1870.782958984375,
      "loss": 0.2966,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.226749300956726,
      "rewards/margins": 3.126378297805786,
      "rewards/rejected": -4.353127956390381,
      "step": 124
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.3207201957702637,
      "learning_rate": 4.008e-06,
      "logits/chosen": -2.496079444885254,
      "logits/rejected": -2.576896905899048,
      "logps/chosen": -859.4109497070312,
      "logps/rejected": -1584.8419189453125,
      "loss": 0.1432,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.42094314098358154,
      "rewards/margins": 3.134261131286621,
      "rewards/rejected": -3.555204153060913,
      "step": 125
    },
    {
      "epoch": 0.2016,
      "grad_norm": 3.332416534423828,
      "learning_rate": 4.000000000000001e-06,
      "logits/chosen": -2.5275533199310303,
      "logits/rejected": -2.483595609664917,
      "logps/chosen": -879.3700561523438,
      "logps/rejected": -2131.501220703125,
      "loss": 0.1392,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9118862748146057,
      "rewards/margins": 2.979250907897949,
      "rewards/rejected": -3.89113712310791,
      "step": 126
    },
    {
      "epoch": 0.2032,
      "grad_norm": 6.760028839111328,
      "learning_rate": 3.992e-06,
      "logits/chosen": -2.608065605163574,
      "logits/rejected": -2.583610773086548,
      "logps/chosen": -1289.19482421875,
      "logps/rejected": -1713.55029296875,
      "loss": 0.2363,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.1525237560272217,
      "rewards/margins": 2.986644983291626,
      "rewards/rejected": -4.139168739318848,
      "step": 127
    },
    {
      "epoch": 0.2048,
      "grad_norm": 3.060511827468872,
      "learning_rate": 3.984e-06,
      "logits/chosen": -2.451570510864258,
      "logits/rejected": -2.5113959312438965,
      "logps/chosen": -1457.956787109375,
      "logps/rejected": -2191.547607421875,
      "loss": 0.1274,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4851548969745636,
      "rewards/margins": 3.52443528175354,
      "rewards/rejected": -4.0095906257629395,
      "step": 128
    },
    {
      "epoch": 0.2064,
      "grad_norm": 2.8927700519561768,
      "learning_rate": 3.9760000000000006e-06,
      "logits/chosen": -2.512958526611328,
      "logits/rejected": -2.574584484100342,
      "logps/chosen": -1085.35498046875,
      "logps/rejected": -1939.70263671875,
      "loss": 0.1125,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9995681643486023,
      "rewards/margins": 3.5580430030822754,
      "rewards/rejected": -4.557610511779785,
      "step": 129
    },
    {
      "epoch": 0.208,
      "grad_norm": 4.129473686218262,
      "learning_rate": 3.968e-06,
      "logits/chosen": -2.565162420272827,
      "logits/rejected": -2.6009206771850586,
      "logps/chosen": -567.710693359375,
      "logps/rejected": -1451.09375,
      "loss": 0.1144,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.4607435464859009,
      "rewards/margins": 2.9835822582244873,
      "rewards/rejected": -3.4443259239196777,
      "step": 130
    },
    {
      "epoch": 0.2096,
      "grad_norm": 4.102241516113281,
      "learning_rate": 3.96e-06,
      "logits/chosen": -2.4444751739501953,
      "logits/rejected": -2.6011734008789062,
      "logps/chosen": -1220.895263671875,
      "logps/rejected": -1985.649658203125,
      "loss": 0.1702,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9114336967468262,
      "rewards/margins": 2.851128578186035,
      "rewards/rejected": -3.7625622749328613,
      "step": 131
    },
    {
      "epoch": 0.2112,
      "grad_norm": 2.884464979171753,
      "learning_rate": 3.9520000000000004e-06,
      "logits/chosen": -2.4112792015075684,
      "logits/rejected": -2.5846099853515625,
      "logps/chosen": -1018.2316284179688,
      "logps/rejected": -1463.556884765625,
      "loss": 0.1952,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.45826709270477295,
      "rewards/margins": 2.8891117572784424,
      "rewards/rejected": -3.347379207611084,
      "step": 132
    },
    {
      "epoch": 0.2128,
      "grad_norm": 15.877314567565918,
      "learning_rate": 3.944e-06,
      "logits/chosen": -2.467106819152832,
      "logits/rejected": -2.41418719291687,
      "logps/chosen": -806.1968994140625,
      "logps/rejected": -1754.9730224609375,
      "loss": 0.2881,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.857244074344635,
      "rewards/margins": 1.6606969833374023,
      "rewards/rejected": -2.5179409980773926,
      "step": 133
    },
    {
      "epoch": 0.2144,
      "grad_norm": 6.443378448486328,
      "learning_rate": 3.936e-06,
      "logits/chosen": -2.3440699577331543,
      "logits/rejected": -2.3869597911834717,
      "logps/chosen": -1463.260498046875,
      "logps/rejected": -2181.1904296875,
      "loss": 0.2211,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9759093523025513,
      "rewards/margins": 2.938526153564453,
      "rewards/rejected": -3.914435625076294,
      "step": 134
    },
    {
      "epoch": 0.216,
      "grad_norm": 9.547797203063965,
      "learning_rate": 3.928e-06,
      "logits/chosen": -2.52040958404541,
      "logits/rejected": -2.551767349243164,
      "logps/chosen": -1197.7349853515625,
      "logps/rejected": -1658.1649169921875,
      "loss": 0.2781,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.3941388130187988,
      "rewards/margins": 3.5148253440856934,
      "rewards/rejected": -4.908964157104492,
      "step": 135
    },
    {
      "epoch": 0.2176,
      "grad_norm": 6.182735919952393,
      "learning_rate": 3.920000000000001e-06,
      "logits/chosen": -2.5605454444885254,
      "logits/rejected": -2.531198024749756,
      "logps/chosen": -988.170654296875,
      "logps/rejected": -1963.998046875,
      "loss": 0.1443,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.5118147134780884,
      "rewards/margins": 3.4174416065216064,
      "rewards/rejected": -4.929256439208984,
      "step": 136
    },
    {
      "epoch": 0.2192,
      "grad_norm": 7.644084930419922,
      "learning_rate": 3.912e-06,
      "logits/chosen": -2.543659210205078,
      "logits/rejected": -2.5699219703674316,
      "logps/chosen": -1353.5325927734375,
      "logps/rejected": -1824.071044921875,
      "loss": 0.2173,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.8958762884140015,
      "rewards/margins": 2.6294684410095215,
      "rewards/rejected": -3.5253448486328125,
      "step": 137
    },
    {
      "epoch": 0.2208,
      "grad_norm": 4.071524143218994,
      "learning_rate": 3.904e-06,
      "logits/chosen": -2.5461974143981934,
      "logits/rejected": -2.5904407501220703,
      "logps/chosen": -745.4497680664062,
      "logps/rejected": -1123.198486328125,
      "loss": 0.2398,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7141005396842957,
      "rewards/margins": 2.1651272773742676,
      "rewards/rejected": -2.879227638244629,
      "step": 138
    },
    {
      "epoch": 0.2224,
      "grad_norm": 3.2782349586486816,
      "learning_rate": 3.8960000000000005e-06,
      "logits/chosen": -2.393317461013794,
      "logits/rejected": -2.5693154335021973,
      "logps/chosen": -692.12646484375,
      "logps/rejected": -1369.6094970703125,
      "loss": 0.1614,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5928390026092529,
      "rewards/margins": 3.0415475368499756,
      "rewards/rejected": -3.6343865394592285,
      "step": 139
    },
    {
      "epoch": 0.224,
      "grad_norm": 6.556819915771484,
      "learning_rate": 3.888e-06,
      "logits/chosen": -2.562467098236084,
      "logits/rejected": -2.602529287338257,
      "logps/chosen": -929.3805541992188,
      "logps/rejected": -1672.493896484375,
      "loss": 0.1168,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6254863739013672,
      "rewards/margins": 3.4893665313720703,
      "rewards/rejected": -4.114852428436279,
      "step": 140
    },
    {
      "epoch": 0.2256,
      "grad_norm": 3.681859254837036,
      "learning_rate": 3.88e-06,
      "logits/chosen": -2.5512917041778564,
      "logits/rejected": -2.58142352104187,
      "logps/chosen": -1000.4212646484375,
      "logps/rejected": -1716.276611328125,
      "loss": 0.1296,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9251458644866943,
      "rewards/margins": 3.016183614730835,
      "rewards/rejected": -3.94132924079895,
      "step": 141
    },
    {
      "epoch": 0.2272,
      "grad_norm": 3.965542793273926,
      "learning_rate": 3.872e-06,
      "logits/chosen": -2.473140001296997,
      "logits/rejected": -2.529681921005249,
      "logps/chosen": -1265.610595703125,
      "logps/rejected": -2101.977783203125,
      "loss": 0.1079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.105962872505188,
      "rewards/margins": 3.8362843990325928,
      "rewards/rejected": -4.942246913909912,
      "step": 142
    },
    {
      "epoch": 0.2288,
      "grad_norm": 12.33871078491211,
      "learning_rate": 3.864000000000001e-06,
      "logits/chosen": -2.6052780151367188,
      "logits/rejected": -2.5888588428497314,
      "logps/chosen": -1761.99755859375,
      "logps/rejected": -1872.0513916015625,
      "loss": 0.393,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.7103888988494873,
      "rewards/margins": 2.1310646533966064,
      "rewards/rejected": -3.8414535522460938,
      "step": 143
    },
    {
      "epoch": 0.2304,
      "grad_norm": 6.233392238616943,
      "learning_rate": 3.856e-06,
      "logits/chosen": -2.484868288040161,
      "logits/rejected": -2.5424606800079346,
      "logps/chosen": -1275.513427734375,
      "logps/rejected": -1927.15966796875,
      "loss": 0.1725,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0840365886688232,
      "rewards/margins": 2.7722628116607666,
      "rewards/rejected": -3.85629940032959,
      "step": 144
    },
    {
      "epoch": 0.232,
      "grad_norm": 15.044837951660156,
      "learning_rate": 3.848e-06,
      "logits/chosen": -2.587812662124634,
      "logits/rejected": -2.5697760581970215,
      "logps/chosen": -1451.53759765625,
      "logps/rejected": -1558.018310546875,
      "loss": 0.2613,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.6009682416915894,
      "rewards/margins": 2.6523478031158447,
      "rewards/rejected": -4.2533159255981445,
      "step": 145
    },
    {
      "epoch": 0.2336,
      "grad_norm": 2.955937385559082,
      "learning_rate": 3.8400000000000005e-06,
      "logits/chosen": -2.3236374855041504,
      "logits/rejected": -2.4855685234069824,
      "logps/chosen": -1205.9501953125,
      "logps/rejected": -2027.85107421875,
      "loss": 0.0878,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8802462816238403,
      "rewards/margins": 3.9469008445739746,
      "rewards/rejected": -4.827147483825684,
      "step": 146
    },
    {
      "epoch": 0.2352,
      "grad_norm": 13.932756423950195,
      "learning_rate": 3.832e-06,
      "logits/chosen": -2.5622191429138184,
      "logits/rejected": -2.5720138549804688,
      "logps/chosen": -1094.4334716796875,
      "logps/rejected": -1675.0225830078125,
      "loss": 0.3347,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.33484947681427,
      "rewards/margins": 3.234825611114502,
      "rewards/rejected": -4.569675445556641,
      "step": 147
    },
    {
      "epoch": 0.2368,
      "grad_norm": 7.701645374298096,
      "learning_rate": 3.824e-06,
      "logits/chosen": -2.527047872543335,
      "logits/rejected": -2.6010050773620605,
      "logps/chosen": -943.8660888671875,
      "logps/rejected": -2046.010009765625,
      "loss": 0.1317,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.838005006313324,
      "rewards/margins": 4.096435070037842,
      "rewards/rejected": -4.9344401359558105,
      "step": 148
    },
    {
      "epoch": 0.2384,
      "grad_norm": 12.196702003479004,
      "learning_rate": 3.816e-06,
      "logits/chosen": -2.5124216079711914,
      "logits/rejected": -2.5599303245544434,
      "logps/chosen": -1259.1593017578125,
      "logps/rejected": -1982.5966796875,
      "loss": 0.3972,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.535642147064209,
      "rewards/margins": 3.216458320617676,
      "rewards/rejected": -4.752099990844727,
      "step": 149
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.5697197914123535,
      "learning_rate": 3.8080000000000006e-06,
      "logits/chosen": -2.433586597442627,
      "logits/rejected": -2.499910831451416,
      "logps/chosen": -1649.861572265625,
      "logps/rejected": -2496.50439453125,
      "loss": 0.0668,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6433301568031311,
      "rewards/margins": 4.68004035949707,
      "rewards/rejected": -5.323369979858398,
      "step": 150
    },
    {
      "epoch": 0.2416,
      "grad_norm": 7.8279805183410645,
      "learning_rate": 3.8000000000000005e-06,
      "logits/chosen": -2.5747785568237305,
      "logits/rejected": -2.559291362762451,
      "logps/chosen": -820.7977294921875,
      "logps/rejected": -1405.263916015625,
      "loss": 0.3255,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.0272091627120972,
      "rewards/margins": 2.8140616416931152,
      "rewards/rejected": -3.841270923614502,
      "step": 151
    },
    {
      "epoch": 0.2432,
      "grad_norm": 3.173461437225342,
      "learning_rate": 3.7920000000000003e-06,
      "logits/chosen": -2.4318127632141113,
      "logits/rejected": -2.585115909576416,
      "logps/chosen": -1032.688720703125,
      "logps/rejected": -1583.291748046875,
      "loss": 0.1284,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.111194372177124,
      "rewards/margins": 3.2179300785064697,
      "rewards/rejected": -4.3291239738464355,
      "step": 152
    },
    {
      "epoch": 0.2448,
      "grad_norm": 3.6623239517211914,
      "learning_rate": 3.7840000000000005e-06,
      "logits/chosen": -2.5094046592712402,
      "logits/rejected": -2.5207059383392334,
      "logps/chosen": -1594.579833984375,
      "logps/rejected": -1993.386474609375,
      "loss": 0.0882,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1914576292037964,
      "rewards/margins": 3.4556005001068115,
      "rewards/rejected": -4.647058010101318,
      "step": 153
    },
    {
      "epoch": 0.2464,
      "grad_norm": 3.744703531265259,
      "learning_rate": 3.7760000000000004e-06,
      "logits/chosen": -2.5003809928894043,
      "logits/rejected": -2.5468146800994873,
      "logps/chosen": -865.556396484375,
      "logps/rejected": -2149.798583984375,
      "loss": 0.1019,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.8671707510948181,
      "rewards/margins": 4.748715400695801,
      "rewards/rejected": -5.615886211395264,
      "step": 154
    },
    {
      "epoch": 0.248,
      "grad_norm": 17.36811065673828,
      "learning_rate": 3.7680000000000006e-06,
      "logits/chosen": -2.5274133682250977,
      "logits/rejected": -2.558795213699341,
      "logps/chosen": -740.86328125,
      "logps/rejected": -1378.2235107421875,
      "loss": 0.4342,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.9914743900299072,
      "rewards/margins": 2.2963926792144775,
      "rewards/rejected": -3.287867546081543,
      "step": 155
    },
    {
      "epoch": 0.2496,
      "grad_norm": 3.5486629009246826,
      "learning_rate": 3.7600000000000004e-06,
      "logits/chosen": -2.4791903495788574,
      "logits/rejected": -2.567417621612549,
      "logps/chosen": -583.0617065429688,
      "logps/rejected": -1531.8818359375,
      "loss": 0.1239,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6217271089553833,
      "rewards/margins": 3.4434759616851807,
      "rewards/rejected": -4.065202713012695,
      "step": 156
    },
    {
      "epoch": 0.2512,
      "grad_norm": 2.6805953979492188,
      "learning_rate": 3.7520000000000002e-06,
      "logits/chosen": -2.535182476043701,
      "logits/rejected": -2.661787271499634,
      "logps/chosen": -1052.324462890625,
      "logps/rejected": -1513.0469970703125,
      "loss": 0.0755,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8459417819976807,
      "rewards/margins": 3.932570457458496,
      "rewards/rejected": -4.778512001037598,
      "step": 157
    },
    {
      "epoch": 0.2528,
      "grad_norm": 5.559194087982178,
      "learning_rate": 3.7440000000000005e-06,
      "logits/chosen": -2.6281018257141113,
      "logits/rejected": -2.618861675262451,
      "logps/chosen": -1111.359375,
      "logps/rejected": -1806.9298095703125,
      "loss": 0.1331,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0560284852981567,
      "rewards/margins": 3.2812447547912598,
      "rewards/rejected": -4.337273597717285,
      "step": 158
    },
    {
      "epoch": 0.2544,
      "grad_norm": 4.672009468078613,
      "learning_rate": 3.7360000000000003e-06,
      "logits/chosen": -2.5824551582336426,
      "logits/rejected": -2.5789971351623535,
      "logps/chosen": -1206.352783203125,
      "logps/rejected": -1826.616943359375,
      "loss": 0.1875,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.9357657432556152,
      "rewards/margins": 2.9747512340545654,
      "rewards/rejected": -3.9105169773101807,
      "step": 159
    },
    {
      "epoch": 0.256,
      "grad_norm": 2.1758320331573486,
      "learning_rate": 3.7280000000000006e-06,
      "logits/chosen": -2.3592708110809326,
      "logits/rejected": -2.4924933910369873,
      "logps/chosen": -1304.7529296875,
      "logps/rejected": -2154.0283203125,
      "loss": 0.091,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05504591390490532,
      "rewards/margins": 3.781249523162842,
      "rewards/rejected": -3.8362953662872314,
      "step": 160
    },
    {
      "epoch": 0.2576,
      "grad_norm": 5.592170715332031,
      "learning_rate": 3.7200000000000004e-06,
      "logits/chosen": -2.596618890762329,
      "logits/rejected": -2.636268377304077,
      "logps/chosen": -1294.7005615234375,
      "logps/rejected": -1496.673828125,
      "loss": 0.2674,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.9745278358459473,
      "rewards/margins": 2.0730347633361816,
      "rewards/rejected": -3.047562599182129,
      "step": 161
    },
    {
      "epoch": 0.2592,
      "grad_norm": 4.225465297698975,
      "learning_rate": 3.712e-06,
      "logits/chosen": -2.604107141494751,
      "logits/rejected": -2.5327961444854736,
      "logps/chosen": -1052.2235107421875,
      "logps/rejected": -1984.7275390625,
      "loss": 0.1498,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.1613636016845703,
      "rewards/margins": 2.999746799468994,
      "rewards/rejected": -4.161109924316406,
      "step": 162
    },
    {
      "epoch": 0.2608,
      "grad_norm": 13.231943130493164,
      "learning_rate": 3.7040000000000005e-06,
      "logits/chosen": -2.5563602447509766,
      "logits/rejected": -2.6158602237701416,
      "logps/chosen": -753.8143920898438,
      "logps/rejected": -1714.21337890625,
      "loss": 0.2646,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6908403635025024,
      "rewards/margins": 2.8612189292907715,
      "rewards/rejected": -3.5520596504211426,
      "step": 163
    },
    {
      "epoch": 0.2624,
      "grad_norm": 3.5434682369232178,
      "learning_rate": 3.6960000000000003e-06,
      "logits/chosen": -2.550386428833008,
      "logits/rejected": -2.608463764190674,
      "logps/chosen": -1036.34375,
      "logps/rejected": -1587.4862060546875,
      "loss": 0.1521,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.7631580233573914,
      "rewards/margins": 3.955127000808716,
      "rewards/rejected": -4.718285083770752,
      "step": 164
    },
    {
      "epoch": 0.264,
      "grad_norm": 4.3760809898376465,
      "learning_rate": 3.6880000000000005e-06,
      "logits/chosen": -2.480346202850342,
      "logits/rejected": -2.609251022338867,
      "logps/chosen": -844.9407348632812,
      "logps/rejected": -1571.84326171875,
      "loss": 0.1485,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9611625075340271,
      "rewards/margins": 3.0325303077697754,
      "rewards/rejected": -3.9936928749084473,
      "step": 165
    },
    {
      "epoch": 0.2656,
      "grad_norm": 3.5551278591156006,
      "learning_rate": 3.6800000000000003e-06,
      "logits/chosen": -2.583606719970703,
      "logits/rejected": -2.578181266784668,
      "logps/chosen": -1678.355224609375,
      "logps/rejected": -2427.929443359375,
      "loss": 0.0667,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3923062086105347,
      "rewards/margins": 4.228941917419434,
      "rewards/rejected": -5.621248245239258,
      "step": 166
    },
    {
      "epoch": 0.2672,
      "grad_norm": 5.965133190155029,
      "learning_rate": 3.6720000000000006e-06,
      "logits/chosen": -2.473832607269287,
      "logits/rejected": -2.587514638900757,
      "logps/chosen": -1203.306396484375,
      "logps/rejected": -1632.327880859375,
      "loss": 0.2674,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.2146199941635132,
      "rewards/margins": 2.4606878757476807,
      "rewards/rejected": -3.6753077507019043,
      "step": 167
    },
    {
      "epoch": 0.2688,
      "grad_norm": 2.344510078430176,
      "learning_rate": 3.6640000000000004e-06,
      "logits/chosen": -2.5106430053710938,
      "logits/rejected": -2.558215379714966,
      "logps/chosen": -1132.7110595703125,
      "logps/rejected": -1853.5338134765625,
      "loss": 0.0833,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9561712741851807,
      "rewards/margins": 4.109459400177002,
      "rewards/rejected": -5.0656304359436035,
      "step": 168
    },
    {
      "epoch": 0.2704,
      "grad_norm": 3.147437572479248,
      "learning_rate": 3.6560000000000002e-06,
      "logits/chosen": -2.408798933029175,
      "logits/rejected": -2.5245728492736816,
      "logps/chosen": -686.130615234375,
      "logps/rejected": -1464.603515625,
      "loss": 0.1324,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6247462630271912,
      "rewards/margins": 3.134340524673462,
      "rewards/rejected": -3.759086847305298,
      "step": 169
    },
    {
      "epoch": 0.272,
      "grad_norm": 5.199261665344238,
      "learning_rate": 3.6480000000000005e-06,
      "logits/chosen": -2.471160411834717,
      "logits/rejected": -2.5039730072021484,
      "logps/chosen": -1498.9571533203125,
      "logps/rejected": -2456.068603515625,
      "loss": 0.235,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.2993308305740356,
      "rewards/margins": 3.6948964595794678,
      "rewards/rejected": -4.994227409362793,
      "step": 170
    },
    {
      "epoch": 0.2736,
      "grad_norm": 4.1564717292785645,
      "learning_rate": 3.6400000000000003e-06,
      "logits/chosen": -2.513864517211914,
      "logits/rejected": -2.485531806945801,
      "logps/chosen": -941.6507568359375,
      "logps/rejected": -2025.3125,
      "loss": 0.1554,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2507903575897217,
      "rewards/margins": 3.5065958499908447,
      "rewards/rejected": -4.757385730743408,
      "step": 171
    },
    {
      "epoch": 0.2752,
      "grad_norm": 2.3447320461273193,
      "learning_rate": 3.6320000000000005e-06,
      "logits/chosen": -2.532189130783081,
      "logits/rejected": -2.5105152130126953,
      "logps/chosen": -956.2445068359375,
      "logps/rejected": -2148.1298828125,
      "loss": 0.1312,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1279031038284302,
      "rewards/margins": 4.147148609161377,
      "rewards/rejected": -5.275052547454834,
      "step": 172
    },
    {
      "epoch": 0.2768,
      "grad_norm": 7.300447463989258,
      "learning_rate": 3.6240000000000004e-06,
      "logits/chosen": -2.47249436378479,
      "logits/rejected": -2.4742612838745117,
      "logps/chosen": -1192.814208984375,
      "logps/rejected": -1652.649169921875,
      "loss": 0.2735,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.1616073846817017,
      "rewards/margins": 3.585350513458252,
      "rewards/rejected": -4.746958255767822,
      "step": 173
    },
    {
      "epoch": 0.2784,
      "grad_norm": 2.6135811805725098,
      "learning_rate": 3.616e-06,
      "logits/chosen": -2.598738193511963,
      "logits/rejected": -2.6391189098358154,
      "logps/chosen": -1050.56982421875,
      "logps/rejected": -1488.3956298828125,
      "loss": 0.1036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.05196213722229,
      "rewards/margins": 2.934633255004883,
      "rewards/rejected": -3.9865946769714355,
      "step": 174
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.3967928886413574,
      "learning_rate": 3.6080000000000004e-06,
      "logits/chosen": -2.53947377204895,
      "logits/rejected": -2.524423599243164,
      "logps/chosen": -1205.1959228515625,
      "logps/rejected": -2305.639404296875,
      "loss": 0.0943,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2355891466140747,
      "rewards/margins": 4.049005031585693,
      "rewards/rejected": -5.2845940589904785,
      "step": 175
    },
    {
      "epoch": 0.2816,
      "grad_norm": 9.8906831741333,
      "learning_rate": 3.6000000000000003e-06,
      "logits/chosen": -2.5823256969451904,
      "logits/rejected": -2.5740480422973633,
      "logps/chosen": -912.4249267578125,
      "logps/rejected": -1685.367431640625,
      "loss": 0.1971,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.4347631931304932,
      "rewards/margins": 4.13980770111084,
      "rewards/rejected": -5.574571132659912,
      "step": 176
    },
    {
      "epoch": 0.2832,
      "grad_norm": 2.6916356086730957,
      "learning_rate": 3.5920000000000005e-06,
      "logits/chosen": -2.5720245838165283,
      "logits/rejected": -2.561096429824829,
      "logps/chosen": -760.9779052734375,
      "logps/rejected": -1412.746826171875,
      "loss": 0.1069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.509262204170227,
      "rewards/margins": 3.2271475791931152,
      "rewards/rejected": -3.736409902572632,
      "step": 177
    },
    {
      "epoch": 0.2848,
      "grad_norm": 5.105088233947754,
      "learning_rate": 3.5840000000000003e-06,
      "logits/chosen": -2.496483325958252,
      "logits/rejected": -2.547045946121216,
      "logps/chosen": -2031.1685791015625,
      "logps/rejected": -1764.676025390625,
      "loss": 0.1635,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.0378704071044922,
      "rewards/margins": 3.592813491821289,
      "rewards/rejected": -4.630683898925781,
      "step": 178
    },
    {
      "epoch": 0.2864,
      "grad_norm": 3.566476821899414,
      "learning_rate": 3.576e-06,
      "logits/chosen": -2.489992618560791,
      "logits/rejected": -2.570265054702759,
      "logps/chosen": -736.7535400390625,
      "logps/rejected": -1326.1339111328125,
      "loss": 0.1274,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6351171731948853,
      "rewards/margins": 3.1115241050720215,
      "rewards/rejected": -3.746641159057617,
      "step": 179
    },
    {
      "epoch": 0.288,
      "grad_norm": 5.3380937576293945,
      "learning_rate": 3.5680000000000004e-06,
      "logits/chosen": -2.491879463195801,
      "logits/rejected": -2.5400686264038086,
      "logps/chosen": -832.5768432617188,
      "logps/rejected": -1422.589599609375,
      "loss": 0.1506,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0026509761810303,
      "rewards/margins": 3.0428786277770996,
      "rewards/rejected": -4.045529365539551,
      "step": 180
    },
    {
      "epoch": 0.2896,
      "grad_norm": 12.920429229736328,
      "learning_rate": 3.5600000000000002e-06,
      "logits/chosen": -2.5590569972991943,
      "logits/rejected": -2.5741870403289795,
      "logps/chosen": -1169.603271484375,
      "logps/rejected": -1815.622314453125,
      "loss": 0.2239,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.4221879243850708,
      "rewards/margins": 3.6321964263916016,
      "rewards/rejected": -5.054384231567383,
      "step": 181
    },
    {
      "epoch": 0.2912,
      "grad_norm": 2.9712719917297363,
      "learning_rate": 3.5520000000000005e-06,
      "logits/chosen": -2.5229058265686035,
      "logits/rejected": -2.555495262145996,
      "logps/chosen": -1224.7794189453125,
      "logps/rejected": -1974.53076171875,
      "loss": 0.1097,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2546778917312622,
      "rewards/margins": 5.311367511749268,
      "rewards/rejected": -6.566045761108398,
      "step": 182
    },
    {
      "epoch": 0.2928,
      "grad_norm": 4.919933319091797,
      "learning_rate": 3.5440000000000003e-06,
      "logits/chosen": -2.5676066875457764,
      "logits/rejected": -2.5965633392333984,
      "logps/chosen": -935.7449340820312,
      "logps/rejected": -1625.33837890625,
      "loss": 0.1665,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0734796524047852,
      "rewards/margins": 3.6381163597106934,
      "rewards/rejected": -4.71159553527832,
      "step": 183
    },
    {
      "epoch": 0.2944,
      "grad_norm": 5.350948810577393,
      "learning_rate": 3.5360000000000005e-06,
      "logits/chosen": -2.399768829345703,
      "logits/rejected": -2.4179036617279053,
      "logps/chosen": -1181.205810546875,
      "logps/rejected": -2331.27197265625,
      "loss": 0.23,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.053093433380127,
      "rewards/margins": 4.022620677947998,
      "rewards/rejected": -5.075714111328125,
      "step": 184
    },
    {
      "epoch": 0.296,
      "grad_norm": 14.647397994995117,
      "learning_rate": 3.5280000000000004e-06,
      "logits/chosen": -2.447864532470703,
      "logits/rejected": -2.475259780883789,
      "logps/chosen": -1439.09326171875,
      "logps/rejected": -1869.244384765625,
      "loss": 0.2553,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3843306303024292,
      "rewards/margins": 3.7077221870422363,
      "rewards/rejected": -5.092053413391113,
      "step": 185
    },
    {
      "epoch": 0.2976,
      "grad_norm": 3.6896514892578125,
      "learning_rate": 3.52e-06,
      "logits/chosen": -2.498772621154785,
      "logits/rejected": -2.5131518840789795,
      "logps/chosen": -1387.4283447265625,
      "logps/rejected": -2372.98486328125,
      "loss": 0.1142,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.143857479095459,
      "rewards/margins": 3.3190314769744873,
      "rewards/rejected": -5.462888717651367,
      "step": 186
    },
    {
      "epoch": 0.2992,
      "grad_norm": 12.598962783813477,
      "learning_rate": 3.5120000000000004e-06,
      "logits/chosen": -2.518904685974121,
      "logits/rejected": -2.593177080154419,
      "logps/chosen": -1334.82373046875,
      "logps/rejected": -1818.3770751953125,
      "loss": 0.3535,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.103634834289551,
      "rewards/margins": 3.040527105331421,
      "rewards/rejected": -5.144162178039551,
      "step": 187
    },
    {
      "epoch": 0.3008,
      "grad_norm": 7.378072261810303,
      "learning_rate": 3.5040000000000002e-06,
      "logits/chosen": -2.4853692054748535,
      "logits/rejected": -2.6245083808898926,
      "logps/chosen": -781.1697387695312,
      "logps/rejected": -1484.8768310546875,
      "loss": 0.1981,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.2396050691604614,
      "rewards/margins": 2.9421732425689697,
      "rewards/rejected": -4.181778430938721,
      "step": 188
    },
    {
      "epoch": 0.3024,
      "grad_norm": 2.6509525775909424,
      "learning_rate": 3.4960000000000005e-06,
      "logits/chosen": -2.5723066329956055,
      "logits/rejected": -2.5821268558502197,
      "logps/chosen": -1104.5064697265625,
      "logps/rejected": -1907.181640625,
      "loss": 0.1211,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8466064929962158,
      "rewards/margins": 4.33903694152832,
      "rewards/rejected": -5.185643196105957,
      "step": 189
    },
    {
      "epoch": 0.304,
      "grad_norm": 5.613494873046875,
      "learning_rate": 3.4880000000000003e-06,
      "logits/chosen": -2.430875539779663,
      "logits/rejected": -2.5076606273651123,
      "logps/chosen": -995.77001953125,
      "logps/rejected": -1692.2021484375,
      "loss": 0.1468,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.144542932510376,
      "rewards/margins": 3.6242854595184326,
      "rewards/rejected": -4.768828392028809,
      "step": 190
    },
    {
      "epoch": 0.3056,
      "grad_norm": 9.442662239074707,
      "learning_rate": 3.48e-06,
      "logits/chosen": -2.599368095397949,
      "logits/rejected": -2.5914101600646973,
      "logps/chosen": -1492.151611328125,
      "logps/rejected": -1937.0401611328125,
      "loss": 0.211,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.6971406936645508,
      "rewards/margins": 2.7931768894195557,
      "rewards/rejected": -4.4903178215026855,
      "step": 191
    },
    {
      "epoch": 0.3072,
      "grad_norm": 14.578059196472168,
      "learning_rate": 3.4720000000000004e-06,
      "logits/chosen": -2.5057389736175537,
      "logits/rejected": -2.551056385040283,
      "logps/chosen": -1192.3515625,
      "logps/rejected": -1713.5738525390625,
      "loss": 0.4637,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.4923242330551147,
      "rewards/margins": 3.1908934116363525,
      "rewards/rejected": -4.683218002319336,
      "step": 192
    },
    {
      "epoch": 0.3088,
      "grad_norm": 5.227137565612793,
      "learning_rate": 3.464e-06,
      "logits/chosen": -2.57104229927063,
      "logits/rejected": -2.6120309829711914,
      "logps/chosen": -1240.624755859375,
      "logps/rejected": -1664.0548095703125,
      "loss": 0.1077,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3353135585784912,
      "rewards/margins": 3.806077003479004,
      "rewards/rejected": -5.141390800476074,
      "step": 193
    },
    {
      "epoch": 0.3104,
      "grad_norm": 5.859711647033691,
      "learning_rate": 3.4560000000000005e-06,
      "logits/chosen": -2.459059238433838,
      "logits/rejected": -2.5761170387268066,
      "logps/chosen": -849.237548828125,
      "logps/rejected": -1782.763671875,
      "loss": 0.1385,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.2599105834960938,
      "rewards/margins": 4.484137535095215,
      "rewards/rejected": -5.744048595428467,
      "step": 194
    },
    {
      "epoch": 0.312,
      "grad_norm": 8.770748138427734,
      "learning_rate": 3.4480000000000003e-06,
      "logits/chosen": -2.5360796451568604,
      "logits/rejected": -2.630948543548584,
      "logps/chosen": -1197.5750732421875,
      "logps/rejected": -1509.372314453125,
      "loss": 0.2601,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.367336392402649,
      "rewards/margins": 2.645585775375366,
      "rewards/rejected": -4.0129218101501465,
      "step": 195
    },
    {
      "epoch": 0.3136,
      "grad_norm": 2.707674026489258,
      "learning_rate": 3.44e-06,
      "logits/chosen": -2.4518167972564697,
      "logits/rejected": -2.502617359161377,
      "logps/chosen": -1101.715576171875,
      "logps/rejected": -1916.680908203125,
      "loss": 0.0981,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8633285164833069,
      "rewards/margins": 4.557366371154785,
      "rewards/rejected": -5.420694828033447,
      "step": 196
    },
    {
      "epoch": 0.3152,
      "grad_norm": 4.522651195526123,
      "learning_rate": 3.4320000000000003e-06,
      "logits/chosen": -2.5625991821289062,
      "logits/rejected": -2.5472517013549805,
      "logps/chosen": -1071.853759765625,
      "logps/rejected": -1767.0283203125,
      "loss": 0.0895,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4371243715286255,
      "rewards/margins": 4.001081943511963,
      "rewards/rejected": -5.438206195831299,
      "step": 197
    },
    {
      "epoch": 0.3168,
      "grad_norm": 2.4463326930999756,
      "learning_rate": 3.424e-06,
      "logits/chosen": -2.5444812774658203,
      "logits/rejected": -2.601208448410034,
      "logps/chosen": -987.9786376953125,
      "logps/rejected": -1882.9088134765625,
      "loss": 0.1016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9818427562713623,
      "rewards/margins": 4.905553340911865,
      "rewards/rejected": -5.887395858764648,
      "step": 198
    },
    {
      "epoch": 0.3184,
      "grad_norm": 2.5404722690582275,
      "learning_rate": 3.4160000000000004e-06,
      "logits/chosen": -2.5638346672058105,
      "logits/rejected": -2.5925920009613037,
      "logps/chosen": -986.482177734375,
      "logps/rejected": -1675.7327880859375,
      "loss": 0.0827,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0711774826049805,
      "rewards/margins": 3.828382968902588,
      "rewards/rejected": -4.899560928344727,
      "step": 199
    },
    {
      "epoch": 0.32,
      "grad_norm": 19.497190475463867,
      "learning_rate": 3.4080000000000002e-06,
      "logits/chosen": -2.5563571453094482,
      "logits/rejected": -2.577699899673462,
      "logps/chosen": -1409.908447265625,
      "logps/rejected": -1210.635498046875,
      "loss": 0.5689,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5012098550796509,
      "rewards/margins": 1.6697648763656616,
      "rewards/rejected": -3.1709747314453125,
      "step": 200
    },
    {
      "epoch": 0.3216,
      "grad_norm": 4.256943702697754,
      "learning_rate": 3.4000000000000005e-06,
      "logits/chosen": -2.5157909393310547,
      "logits/rejected": -2.5631022453308105,
      "logps/chosen": -1261.6212158203125,
      "logps/rejected": -1494.6268310546875,
      "loss": 0.1598,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.707850456237793,
      "rewards/margins": 3.01426362991333,
      "rewards/rejected": -4.722114086151123,
      "step": 201
    },
    {
      "epoch": 0.3232,
      "grad_norm": 8.885608673095703,
      "learning_rate": 3.3920000000000003e-06,
      "logits/chosen": -2.492692232131958,
      "logits/rejected": -2.599560022354126,
      "logps/chosen": -1469.8262939453125,
      "logps/rejected": -2129.52734375,
      "loss": 0.2737,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.5079644918441772,
      "rewards/margins": 3.9503960609436035,
      "rewards/rejected": -5.45836067199707,
      "step": 202
    },
    {
      "epoch": 0.3248,
      "grad_norm": 8.137117385864258,
      "learning_rate": 3.384e-06,
      "logits/chosen": -2.5074000358581543,
      "logits/rejected": -2.5383501052856445,
      "logps/chosen": -1118.7919921875,
      "logps/rejected": -1624.16552734375,
      "loss": 0.1527,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.553321123123169,
      "rewards/margins": 2.9287147521972656,
      "rewards/rejected": -4.4820356369018555,
      "step": 203
    },
    {
      "epoch": 0.3264,
      "grad_norm": 2.0548160076141357,
      "learning_rate": 3.3760000000000004e-06,
      "logits/chosen": -2.5699822902679443,
      "logits/rejected": -2.5527215003967285,
      "logps/chosen": -770.8778076171875,
      "logps/rejected": -1731.614501953125,
      "loss": 0.057,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1194324493408203,
      "rewards/margins": 4.051367282867432,
      "rewards/rejected": -5.17080020904541,
      "step": 204
    },
    {
      "epoch": 0.328,
      "grad_norm": 4.256373405456543,
      "learning_rate": 3.368e-06,
      "logits/chosen": -2.5102758407592773,
      "logits/rejected": -2.58011794090271,
      "logps/chosen": -1062.67724609375,
      "logps/rejected": -1920.072509765625,
      "loss": 0.086,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2497462034225464,
      "rewards/margins": 4.140561103820801,
      "rewards/rejected": -5.390307426452637,
      "step": 205
    },
    {
      "epoch": 0.3296,
      "grad_norm": 2.86893630027771,
      "learning_rate": 3.3600000000000004e-06,
      "logits/chosen": -2.276191473007202,
      "logits/rejected": -2.6018102169036865,
      "logps/chosen": -924.0933227539062,
      "logps/rejected": -2092.952880859375,
      "loss": 0.0456,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6752561330795288,
      "rewards/margins": 4.383556365966797,
      "rewards/rejected": -5.058812141418457,
      "step": 206
    },
    {
      "epoch": 0.3312,
      "grad_norm": 4.499824047088623,
      "learning_rate": 3.3520000000000003e-06,
      "logits/chosen": -2.590446949005127,
      "logits/rejected": -2.6203808784484863,
      "logps/chosen": -1377.171630859375,
      "logps/rejected": -2283.860595703125,
      "loss": 0.1096,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.5695898532867432,
      "rewards/margins": 4.898371696472168,
      "rewards/rejected": -6.467961311340332,
      "step": 207
    },
    {
      "epoch": 0.3328,
      "grad_norm": 1.813210129737854,
      "learning_rate": 3.344e-06,
      "logits/chosen": -2.475703001022339,
      "logits/rejected": -2.518843173980713,
      "logps/chosen": -1421.5172119140625,
      "logps/rejected": -2214.233642578125,
      "loss": 0.0704,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1204628944396973,
      "rewards/margins": 5.239378929138184,
      "rewards/rejected": -6.359841823577881,
      "step": 208
    },
    {
      "epoch": 0.3344,
      "grad_norm": 16.294462203979492,
      "learning_rate": 3.3360000000000003e-06,
      "logits/chosen": -2.4420840740203857,
      "logits/rejected": -2.4967117309570312,
      "logps/chosen": -1632.558837890625,
      "logps/rejected": -2156.6201171875,
      "loss": 0.3799,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.7939900159835815,
      "rewards/margins": 3.95149564743042,
      "rewards/rejected": -5.745486259460449,
      "step": 209
    },
    {
      "epoch": 0.336,
      "grad_norm": 1.6747562885284424,
      "learning_rate": 3.328e-06,
      "logits/chosen": -2.4211626052856445,
      "logits/rejected": -2.539438486099243,
      "logps/chosen": -1243.783935546875,
      "logps/rejected": -2093.599853515625,
      "loss": 0.0549,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1356868743896484,
      "rewards/margins": 4.9105987548828125,
      "rewards/rejected": -6.046285152435303,
      "step": 210
    },
    {
      "epoch": 0.3376,
      "grad_norm": 2.432044744491577,
      "learning_rate": 3.3200000000000004e-06,
      "logits/chosen": -2.555626630783081,
      "logits/rejected": -2.600633382797241,
      "logps/chosen": -1202.2398681640625,
      "logps/rejected": -2374.1640625,
      "loss": 0.0949,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1306040287017822,
      "rewards/margins": 4.184199810028076,
      "rewards/rejected": -5.314803600311279,
      "step": 211
    },
    {
      "epoch": 0.3392,
      "grad_norm": 5.850730895996094,
      "learning_rate": 3.3120000000000002e-06,
      "logits/chosen": -2.488616943359375,
      "logits/rejected": -2.50171160697937,
      "logps/chosen": -919.0217895507812,
      "logps/rejected": -2073.336669921875,
      "loss": 0.1086,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.165505290031433,
      "rewards/margins": 4.573894023895264,
      "rewards/rejected": -5.739399433135986,
      "step": 212
    },
    {
      "epoch": 0.3408,
      "grad_norm": 7.4241814613342285,
      "learning_rate": 3.3040000000000005e-06,
      "logits/chosen": -2.555518627166748,
      "logits/rejected": -2.5972740650177,
      "logps/chosen": -916.5475463867188,
      "logps/rejected": -1574.443115234375,
      "loss": 0.2453,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.7860821485519409,
      "rewards/margins": 3.222635269165039,
      "rewards/rejected": -4.0087175369262695,
      "step": 213
    },
    {
      "epoch": 0.3424,
      "grad_norm": 10.084380149841309,
      "learning_rate": 3.2960000000000003e-06,
      "logits/chosen": -2.4555416107177734,
      "logits/rejected": -2.5872302055358887,
      "logps/chosen": -1167.7220458984375,
      "logps/rejected": -2260.66650390625,
      "loss": 0.1553,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.1317073106765747,
      "rewards/margins": 5.517965793609619,
      "rewards/rejected": -6.649672985076904,
      "step": 214
    },
    {
      "epoch": 0.344,
      "grad_norm": 7.805959224700928,
      "learning_rate": 3.288e-06,
      "logits/chosen": -2.5859267711639404,
      "logits/rejected": -2.608391284942627,
      "logps/chosen": -1241.625244140625,
      "logps/rejected": -1599.02392578125,
      "loss": 0.176,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3215482234954834,
      "rewards/margins": 3.5162553787231445,
      "rewards/rejected": -4.837803840637207,
      "step": 215
    },
    {
      "epoch": 0.3456,
      "grad_norm": 4.686179161071777,
      "learning_rate": 3.2800000000000004e-06,
      "logits/chosen": -2.471771001815796,
      "logits/rejected": -2.5697057247161865,
      "logps/chosen": -962.6893310546875,
      "logps/rejected": -1758.3577880859375,
      "loss": 0.1114,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3839439153671265,
      "rewards/margins": 3.6194169521331787,
      "rewards/rejected": -5.003360748291016,
      "step": 216
    },
    {
      "epoch": 0.3472,
      "grad_norm": 1.6885215044021606,
      "learning_rate": 3.272e-06,
      "logits/chosen": -2.601544141769409,
      "logits/rejected": -2.5770273208618164,
      "logps/chosen": -1030.281005859375,
      "logps/rejected": -1426.1263427734375,
      "loss": 0.0772,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3191276788711548,
      "rewards/margins": 3.5662484169006348,
      "rewards/rejected": -4.885376453399658,
      "step": 217
    },
    {
      "epoch": 0.3488,
      "grad_norm": 15.214163780212402,
      "learning_rate": 3.2640000000000004e-06,
      "logits/chosen": -2.50212025642395,
      "logits/rejected": -2.6343321800231934,
      "logps/chosen": -1073.57421875,
      "logps/rejected": -1812.945556640625,
      "loss": 0.3502,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.222938060760498,
      "rewards/margins": 3.3011398315429688,
      "rewards/rejected": -4.524077415466309,
      "step": 218
    },
    {
      "epoch": 0.3504,
      "grad_norm": 11.816039085388184,
      "learning_rate": 3.2560000000000003e-06,
      "logits/chosen": -2.5371146202087402,
      "logits/rejected": -2.592651128768921,
      "logps/chosen": -1584.1876220703125,
      "logps/rejected": -1695.2802734375,
      "loss": 0.238,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.6237328052520752,
      "rewards/margins": 3.484682559967041,
      "rewards/rejected": -5.108415126800537,
      "step": 219
    },
    {
      "epoch": 0.352,
      "grad_norm": 3.1906938552856445,
      "learning_rate": 3.248e-06,
      "logits/chosen": -2.4968101978302,
      "logits/rejected": -2.5685784816741943,
      "logps/chosen": -888.2464599609375,
      "logps/rejected": -1377.083984375,
      "loss": 0.131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3700792789459229,
      "rewards/margins": 3.341810464859009,
      "rewards/rejected": -4.711889743804932,
      "step": 220
    },
    {
      "epoch": 0.3536,
      "grad_norm": 8.596900939941406,
      "learning_rate": 3.2400000000000003e-06,
      "logits/chosen": -2.5565133094787598,
      "logits/rejected": -2.571512222290039,
      "logps/chosen": -854.202392578125,
      "logps/rejected": -1528.3182373046875,
      "loss": 0.3265,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.369216799736023,
      "rewards/margins": 3.201077461242676,
      "rewards/rejected": -4.570294380187988,
      "step": 221
    },
    {
      "epoch": 0.3552,
      "grad_norm": 4.810607433319092,
      "learning_rate": 3.232e-06,
      "logits/chosen": -2.5115625858306885,
      "logits/rejected": -2.5938096046447754,
      "logps/chosen": -618.1639404296875,
      "logps/rejected": -1085.255126953125,
      "loss": 0.1644,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.807500958442688,
      "rewards/margins": 2.957275867462158,
      "rewards/rejected": -3.7647769451141357,
      "step": 222
    },
    {
      "epoch": 0.3568,
      "grad_norm": 1.180294156074524,
      "learning_rate": 3.2240000000000004e-06,
      "logits/chosen": -2.480365514755249,
      "logits/rejected": -2.574267864227295,
      "logps/chosen": -868.2136840820312,
      "logps/rejected": -1678.6043701171875,
      "loss": 0.0362,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9359333515167236,
      "rewards/margins": 4.7767534255981445,
      "rewards/rejected": -5.712687015533447,
      "step": 223
    },
    {
      "epoch": 0.3584,
      "grad_norm": 6.042659282684326,
      "learning_rate": 3.216e-06,
      "logits/chosen": -2.5353095531463623,
      "logits/rejected": -2.6026735305786133,
      "logps/chosen": -1076.1219482421875,
      "logps/rejected": -1548.418212890625,
      "loss": 0.179,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.2343065738677979,
      "rewards/margins": 3.541318416595459,
      "rewards/rejected": -4.775625228881836,
      "step": 224
    },
    {
      "epoch": 0.36,
      "grad_norm": 6.430001735687256,
      "learning_rate": 3.208e-06,
      "logits/chosen": -2.6438519954681396,
      "logits/rejected": -2.5929393768310547,
      "logps/chosen": -1518.638916015625,
      "logps/rejected": -2140.17138671875,
      "loss": 0.2107,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.508594274520874,
      "rewards/margins": 4.1506476402282715,
      "rewards/rejected": -5.659241676330566,
      "step": 225
    },
    {
      "epoch": 0.3616,
      "grad_norm": 6.275160312652588,
      "learning_rate": 3.2000000000000003e-06,
      "logits/chosen": -2.5819387435913086,
      "logits/rejected": -2.6360816955566406,
      "logps/chosen": -1097.067138671875,
      "logps/rejected": -1895.5546875,
      "loss": 0.1118,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.4656785726547241,
      "rewards/margins": 3.6695728302001953,
      "rewards/rejected": -5.135251522064209,
      "step": 226
    },
    {
      "epoch": 0.3632,
      "grad_norm": 7.696526527404785,
      "learning_rate": 3.192e-06,
      "logits/chosen": -2.5552825927734375,
      "logits/rejected": -2.4985127449035645,
      "logps/chosen": -966.3055419921875,
      "logps/rejected": -1564.5533447265625,
      "loss": 0.1312,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.2959198951721191,
      "rewards/margins": 3.9811863899230957,
      "rewards/rejected": -5.277106285095215,
      "step": 227
    },
    {
      "epoch": 0.3648,
      "grad_norm": 9.139711380004883,
      "learning_rate": 3.1840000000000003e-06,
      "logits/chosen": -2.5066633224487305,
      "logits/rejected": -2.5478382110595703,
      "logps/chosen": -1389.0028076171875,
      "logps/rejected": -1524.0517578125,
      "loss": 0.4613,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.3861054182052612,
      "rewards/margins": 1.978912591934204,
      "rewards/rejected": -3.3650176525115967,
      "step": 228
    },
    {
      "epoch": 0.3664,
      "grad_norm": 3.0350050926208496,
      "learning_rate": 3.176e-06,
      "logits/chosen": -2.5760748386383057,
      "logits/rejected": -2.6276097297668457,
      "logps/chosen": -1053.4500732421875,
      "logps/rejected": -1934.576416015625,
      "loss": 0.0817,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9388302564620972,
      "rewards/margins": 4.825976371765137,
      "rewards/rejected": -5.764806747436523,
      "step": 229
    },
    {
      "epoch": 0.368,
      "grad_norm": 4.191102027893066,
      "learning_rate": 3.1680000000000004e-06,
      "logits/chosen": -2.5474836826324463,
      "logits/rejected": -2.6116952896118164,
      "logps/chosen": -1071.810791015625,
      "logps/rejected": -1489.7335205078125,
      "loss": 0.1904,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4012235403060913,
      "rewards/margins": 3.3978970050811768,
      "rewards/rejected": -4.79911994934082,
      "step": 230
    },
    {
      "epoch": 0.3696,
      "grad_norm": 2.755843162536621,
      "learning_rate": 3.1600000000000002e-06,
      "logits/chosen": -2.5405402183532715,
      "logits/rejected": -2.6193530559539795,
      "logps/chosen": -747.2398681640625,
      "logps/rejected": -1224.064208984375,
      "loss": 0.1411,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9499897360801697,
      "rewards/margins": 2.7965142726898193,
      "rewards/rejected": -3.746504068374634,
      "step": 231
    },
    {
      "epoch": 0.3712,
      "grad_norm": 7.442005157470703,
      "learning_rate": 3.152e-06,
      "logits/chosen": -2.503633975982666,
      "logits/rejected": -2.551819324493408,
      "logps/chosen": -1354.762939453125,
      "logps/rejected": -2208.485595703125,
      "loss": 0.0842,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1891028881072998,
      "rewards/margins": 3.8533308506011963,
      "rewards/rejected": -5.042433738708496,
      "step": 232
    },
    {
      "epoch": 0.3728,
      "grad_norm": 2.6551876068115234,
      "learning_rate": 3.1440000000000003e-06,
      "logits/chosen": -2.4438178539276123,
      "logits/rejected": -2.604722261428833,
      "logps/chosen": -842.2257080078125,
      "logps/rejected": -1260.6781005859375,
      "loss": 0.1463,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8983750939369202,
      "rewards/margins": 3.197171926498413,
      "rewards/rejected": -4.095547199249268,
      "step": 233
    },
    {
      "epoch": 0.3744,
      "grad_norm": 3.000194787979126,
      "learning_rate": 3.136e-06,
      "logits/chosen": -2.583832263946533,
      "logits/rejected": -2.612015724182129,
      "logps/chosen": -939.9361572265625,
      "logps/rejected": -1458.5098876953125,
      "loss": 0.1472,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8676135540008545,
      "rewards/margins": 3.316333293914795,
      "rewards/rejected": -4.1839470863342285,
      "step": 234
    },
    {
      "epoch": 0.376,
      "grad_norm": 3.6747872829437256,
      "learning_rate": 3.1280000000000004e-06,
      "logits/chosen": -2.497922897338867,
      "logits/rejected": -2.5613656044006348,
      "logps/chosen": -1443.151611328125,
      "logps/rejected": -1729.76416015625,
      "loss": 0.1377,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1544232368469238,
      "rewards/margins": 3.250033378601074,
      "rewards/rejected": -4.40445613861084,
      "step": 235
    },
    {
      "epoch": 0.3776,
      "grad_norm": 4.400324821472168,
      "learning_rate": 3.12e-06,
      "logits/chosen": -2.4719369411468506,
      "logits/rejected": -2.5411744117736816,
      "logps/chosen": -953.6556396484375,
      "logps/rejected": -2236.34228515625,
      "loss": 0.0955,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6682908535003662,
      "rewards/margins": 4.259579658508301,
      "rewards/rejected": -4.927870273590088,
      "step": 236
    },
    {
      "epoch": 0.3792,
      "grad_norm": 3.3599772453308105,
      "learning_rate": 3.112e-06,
      "logits/chosen": -2.524421215057373,
      "logits/rejected": -2.604752779006958,
      "logps/chosen": -708.6941528320312,
      "logps/rejected": -1532.0264892578125,
      "loss": 0.121,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9966632723808289,
      "rewards/margins": 4.200922012329102,
      "rewards/rejected": -5.197585105895996,
      "step": 237
    },
    {
      "epoch": 0.3808,
      "grad_norm": 2.3140456676483154,
      "learning_rate": 3.1040000000000003e-06,
      "logits/chosen": -2.5393099784851074,
      "logits/rejected": -2.575636863708496,
      "logps/chosen": -664.1281127929688,
      "logps/rejected": -1390.2349853515625,
      "loss": 0.1201,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8317561149597168,
      "rewards/margins": 3.6591484546661377,
      "rewards/rejected": -4.490904808044434,
      "step": 238
    },
    {
      "epoch": 0.3824,
      "grad_norm": 2.674290418624878,
      "learning_rate": 3.096e-06,
      "logits/chosen": -2.5991013050079346,
      "logits/rejected": -2.6389966011047363,
      "logps/chosen": -941.0255737304688,
      "logps/rejected": -1586.071533203125,
      "loss": 0.0846,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2099943161010742,
      "rewards/margins": 4.124873161315918,
      "rewards/rejected": -5.33486795425415,
      "step": 239
    },
    {
      "epoch": 0.384,
      "grad_norm": 2.438086986541748,
      "learning_rate": 3.0880000000000003e-06,
      "logits/chosen": -2.556187868118286,
      "logits/rejected": -2.555891275405884,
      "logps/chosen": -1333.7813720703125,
      "logps/rejected": -2065.535400390625,
      "loss": 0.0886,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5025749206542969,
      "rewards/margins": 4.556399345397949,
      "rewards/rejected": -6.058974266052246,
      "step": 240
    },
    {
      "epoch": 0.3856,
      "grad_norm": 2.8570475578308105,
      "learning_rate": 3.08e-06,
      "logits/chosen": -2.5491671562194824,
      "logits/rejected": -2.594491958618164,
      "logps/chosen": -1333.0528564453125,
      "logps/rejected": -1898.0169677734375,
      "loss": 0.0624,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.18912672996521,
      "rewards/margins": 3.8931186199188232,
      "rewards/rejected": -5.082245349884033,
      "step": 241
    },
    {
      "epoch": 0.3872,
      "grad_norm": 2.5697333812713623,
      "learning_rate": 3.072e-06,
      "logits/chosen": -2.5543477535247803,
      "logits/rejected": -2.5531952381134033,
      "logps/chosen": -754.8038940429688,
      "logps/rejected": -1814.123779296875,
      "loss": 0.0778,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.875407338142395,
      "rewards/margins": 4.614589214324951,
      "rewards/rejected": -5.489996433258057,
      "step": 242
    },
    {
      "epoch": 0.3888,
      "grad_norm": 6.2191572189331055,
      "learning_rate": 3.0640000000000002e-06,
      "logits/chosen": -2.562436103820801,
      "logits/rejected": -2.607053756713867,
      "logps/chosen": -1129.55078125,
      "logps/rejected": -1673.798583984375,
      "loss": 0.1665,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.1920530796051025,
      "rewards/margins": 3.656630754470825,
      "rewards/rejected": -4.848683834075928,
      "step": 243
    },
    {
      "epoch": 0.3904,
      "grad_norm": 3.078806161880493,
      "learning_rate": 3.056e-06,
      "logits/chosen": -2.55087947845459,
      "logits/rejected": -2.5994462966918945,
      "logps/chosen": -1050.8013916015625,
      "logps/rejected": -1634.142333984375,
      "loss": 0.1393,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2353925704956055,
      "rewards/margins": 3.658726692199707,
      "rewards/rejected": -4.8941192626953125,
      "step": 244
    },
    {
      "epoch": 0.392,
      "grad_norm": 3.419123649597168,
      "learning_rate": 3.0480000000000003e-06,
      "logits/chosen": -2.563817262649536,
      "logits/rejected": -2.6242313385009766,
      "logps/chosen": -721.895263671875,
      "logps/rejected": -1601.697998046875,
      "loss": 0.1414,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.7770218849182129,
      "rewards/margins": 3.2472987174987793,
      "rewards/rejected": -4.024320602416992,
      "step": 245
    },
    {
      "epoch": 0.3936,
      "grad_norm": 2.2508468627929688,
      "learning_rate": 3.04e-06,
      "logits/chosen": -2.426607370376587,
      "logits/rejected": -2.5379059314727783,
      "logps/chosen": -1475.5244140625,
      "logps/rejected": -2307.748046875,
      "loss": 0.0774,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2331137657165527,
      "rewards/margins": 4.709844589233398,
      "rewards/rejected": -5.942958354949951,
      "step": 246
    },
    {
      "epoch": 0.3952,
      "grad_norm": 7.908982753753662,
      "learning_rate": 3.0320000000000004e-06,
      "logits/chosen": -2.554434299468994,
      "logits/rejected": -2.582369565963745,
      "logps/chosen": -759.390625,
      "logps/rejected": -1643.3603515625,
      "loss": 0.1334,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.1159597635269165,
      "rewards/margins": 4.44713830947876,
      "rewards/rejected": -5.563098430633545,
      "step": 247
    },
    {
      "epoch": 0.3968,
      "grad_norm": 5.5153045654296875,
      "learning_rate": 3.024e-06,
      "logits/chosen": -2.513404369354248,
      "logits/rejected": -2.604692220687866,
      "logps/chosen": -885.5068359375,
      "logps/rejected": -1481.0494384765625,
      "loss": 0.2356,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.941753089427948,
      "rewards/margins": 3.5583975315093994,
      "rewards/rejected": -4.500150680541992,
      "step": 248
    },
    {
      "epoch": 0.3984,
      "grad_norm": 7.284621238708496,
      "learning_rate": 3.016e-06,
      "logits/chosen": -2.522106885910034,
      "logits/rejected": -2.5983095169067383,
      "logps/chosen": -618.3292236328125,
      "logps/rejected": -877.8985595703125,
      "loss": 0.2701,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.2042733430862427,
      "rewards/margins": 1.9107731580734253,
      "rewards/rejected": -3.115046501159668,
      "step": 249
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.156658411026001,
      "learning_rate": 3.0080000000000003e-06,
      "logits/chosen": -2.511951446533203,
      "logits/rejected": -2.5772435665130615,
      "logps/chosen": -841.7344360351562,
      "logps/rejected": -1276.323974609375,
      "loss": 0.0793,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.075292706489563,
      "rewards/margins": 3.396242141723633,
      "rewards/rejected": -4.471534729003906,
      "step": 250
    },
    {
      "epoch": 0.4016,
      "grad_norm": 3.8691859245300293,
      "learning_rate": 3e-06,
      "logits/chosen": -2.4887876510620117,
      "logits/rejected": -2.5430264472961426,
      "logps/chosen": -1868.955810546875,
      "logps/rejected": -2685.7158203125,
      "loss": 0.0897,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6776363849639893,
      "rewards/margins": 5.1332807540893555,
      "rewards/rejected": -6.810916900634766,
      "step": 251
    },
    {
      "epoch": 0.4032,
      "grad_norm": 2.994145393371582,
      "learning_rate": 2.9920000000000003e-06,
      "logits/chosen": -2.5769925117492676,
      "logits/rejected": -2.641451358795166,
      "logps/chosen": -1030.0009765625,
      "logps/rejected": -1510.0970458984375,
      "loss": 0.1292,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.1527267694473267,
      "rewards/margins": 3.703706979751587,
      "rewards/rejected": -4.856434345245361,
      "step": 252
    },
    {
      "epoch": 0.4048,
      "grad_norm": 7.805777072906494,
      "learning_rate": 2.984e-06,
      "logits/chosen": -2.5560991764068604,
      "logits/rejected": -2.59074330329895,
      "logps/chosen": -1230.0152587890625,
      "logps/rejected": -1799.1617431640625,
      "loss": 0.1648,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3943111896514893,
      "rewards/margins": 3.9501147270202637,
      "rewards/rejected": -5.34442663192749,
      "step": 253
    },
    {
      "epoch": 0.4064,
      "grad_norm": 2.2988359928131104,
      "learning_rate": 2.976e-06,
      "logits/chosen": -2.4990956783294678,
      "logits/rejected": -2.5810582637786865,
      "logps/chosen": -977.0894775390625,
      "logps/rejected": -1607.9371337890625,
      "loss": 0.1104,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9711529016494751,
      "rewards/margins": 4.141805648803711,
      "rewards/rejected": -5.1129584312438965,
      "step": 254
    },
    {
      "epoch": 0.408,
      "grad_norm": 15.330516815185547,
      "learning_rate": 2.9680000000000002e-06,
      "logits/chosen": -2.578505516052246,
      "logits/rejected": -2.579119920730591,
      "logps/chosen": -1646.5115966796875,
      "logps/rejected": -1983.068115234375,
      "loss": 0.3948,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.4013900756835938,
      "rewards/margins": 2.8742809295654297,
      "rewards/rejected": -5.275671482086182,
      "step": 255
    },
    {
      "epoch": 0.4096,
      "grad_norm": 7.148505210876465,
      "learning_rate": 2.96e-06,
      "logits/chosen": -2.4449071884155273,
      "logits/rejected": -2.5843310356140137,
      "logps/chosen": -1209.696533203125,
      "logps/rejected": -1580.1846923828125,
      "loss": 0.1176,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.068947196006775,
      "rewards/margins": 3.1074650287628174,
      "rewards/rejected": -4.176412582397461,
      "step": 256
    },
    {
      "epoch": 0.4112,
      "grad_norm": 6.96459436416626,
      "learning_rate": 2.9520000000000003e-06,
      "logits/chosen": -2.5791687965393066,
      "logits/rejected": -2.6139302253723145,
      "logps/chosen": -1277.0654296875,
      "logps/rejected": -1577.2930908203125,
      "loss": 0.2472,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.599006175994873,
      "rewards/margins": 3.0063774585723877,
      "rewards/rejected": -4.60538387298584,
      "step": 257
    },
    {
      "epoch": 0.4128,
      "grad_norm": 2.132892370223999,
      "learning_rate": 2.944e-06,
      "logits/chosen": -2.530935764312744,
      "logits/rejected": -2.6270811557769775,
      "logps/chosen": -968.0792846679688,
      "logps/rejected": -1845.17236328125,
      "loss": 0.0777,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2533501386642456,
      "rewards/margins": 4.498602390289307,
      "rewards/rejected": -5.751953125,
      "step": 258
    },
    {
      "epoch": 0.4144,
      "grad_norm": 15.101960182189941,
      "learning_rate": 2.9360000000000003e-06,
      "logits/chosen": -2.590758800506592,
      "logits/rejected": -2.58453369140625,
      "logps/chosen": -1871.5933837890625,
      "logps/rejected": -2782.52294921875,
      "loss": 0.3261,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.174039363861084,
      "rewards/margins": 4.788640975952148,
      "rewards/rejected": -6.962680339813232,
      "step": 259
    },
    {
      "epoch": 0.416,
      "grad_norm": 5.097649574279785,
      "learning_rate": 2.928e-06,
      "logits/chosen": -2.565688133239746,
      "logits/rejected": -2.6167151927948,
      "logps/chosen": -846.7964477539062,
      "logps/rejected": -2205.254150390625,
      "loss": 0.1183,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3293746709823608,
      "rewards/margins": 5.306851387023926,
      "rewards/rejected": -6.636226654052734,
      "step": 260
    },
    {
      "epoch": 0.4176,
      "grad_norm": 4.0268378257751465,
      "learning_rate": 2.92e-06,
      "logits/chosen": -2.5914411544799805,
      "logits/rejected": -2.5897183418273926,
      "logps/chosen": -1290.6180419921875,
      "logps/rejected": -1680.45263671875,
      "loss": 0.1532,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.18404483795166,
      "rewards/margins": 3.314077377319336,
      "rewards/rejected": -5.498122215270996,
      "step": 261
    },
    {
      "epoch": 0.4192,
      "grad_norm": 4.824908256530762,
      "learning_rate": 2.9120000000000002e-06,
      "logits/chosen": -2.4841136932373047,
      "logits/rejected": -2.5519156455993652,
      "logps/chosen": -967.3095092773438,
      "logps/rejected": -1801.6961669921875,
      "loss": 0.1598,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.1650639772415161,
      "rewards/margins": 5.1509928703308105,
      "rewards/rejected": -6.316056728363037,
      "step": 262
    },
    {
      "epoch": 0.4208,
      "grad_norm": 3.9350693225860596,
      "learning_rate": 2.904e-06,
      "logits/chosen": -2.5244925022125244,
      "logits/rejected": -2.543680429458618,
      "logps/chosen": -809.5836181640625,
      "logps/rejected": -1524.593505859375,
      "loss": 0.1611,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9162391424179077,
      "rewards/margins": 4.2629714012146,
      "rewards/rejected": -5.179210662841797,
      "step": 263
    },
    {
      "epoch": 0.4224,
      "grad_norm": 6.649340629577637,
      "learning_rate": 2.8960000000000003e-06,
      "logits/chosen": -2.581373453140259,
      "logits/rejected": -2.621588706970215,
      "logps/chosen": -1478.2449951171875,
      "logps/rejected": -1658.4638671875,
      "loss": 0.1353,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.7621533870697021,
      "rewards/margins": 2.8161404132843018,
      "rewards/rejected": -4.578294277191162,
      "step": 264
    },
    {
      "epoch": 0.424,
      "grad_norm": 2.4465436935424805,
      "learning_rate": 2.888e-06,
      "logits/chosen": -2.5677952766418457,
      "logits/rejected": -2.5444271564483643,
      "logps/chosen": -1592.047607421875,
      "logps/rejected": -2302.630615234375,
      "loss": 0.0611,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7655177116394043,
      "rewards/margins": 4.976721286773682,
      "rewards/rejected": -6.742238998413086,
      "step": 265
    },
    {
      "epoch": 0.4256,
      "grad_norm": 9.342241287231445,
      "learning_rate": 2.88e-06,
      "logits/chosen": -2.485194206237793,
      "logits/rejected": -2.495018482208252,
      "logps/chosen": -943.0191040039062,
      "logps/rejected": -1557.89453125,
      "loss": 0.2559,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.34837007522583,
      "rewards/margins": 3.286684513092041,
      "rewards/rejected": -4.635054588317871,
      "step": 266
    },
    {
      "epoch": 0.4272,
      "grad_norm": 2.79329252243042,
      "learning_rate": 2.872e-06,
      "logits/chosen": -2.530977487564087,
      "logits/rejected": -2.587026357650757,
      "logps/chosen": -942.539794921875,
      "logps/rejected": -1490.31005859375,
      "loss": 0.1236,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3754864931106567,
      "rewards/margins": 2.9551193714141846,
      "rewards/rejected": -4.330605506896973,
      "step": 267
    },
    {
      "epoch": 0.4288,
      "grad_norm": 8.0282621383667,
      "learning_rate": 2.864e-06,
      "logits/chosen": -2.535733699798584,
      "logits/rejected": -2.5986294746398926,
      "logps/chosen": -885.3157348632812,
      "logps/rejected": -1510.211181640625,
      "loss": 0.2405,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.1539394855499268,
      "rewards/margins": 3.739509344100952,
      "rewards/rejected": -4.893448352813721,
      "step": 268
    },
    {
      "epoch": 0.4304,
      "grad_norm": 2.844602108001709,
      "learning_rate": 2.8560000000000003e-06,
      "logits/chosen": -2.4194159507751465,
      "logits/rejected": -2.570033550262451,
      "logps/chosen": -855.587158203125,
      "logps/rejected": -2098.44873046875,
      "loss": 0.0755,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9581248760223389,
      "rewards/margins": 5.364845275878906,
      "rewards/rejected": -6.322970390319824,
      "step": 269
    },
    {
      "epoch": 0.432,
      "grad_norm": 2.5449390411376953,
      "learning_rate": 2.848e-06,
      "logits/chosen": -2.495464324951172,
      "logits/rejected": -2.560527801513672,
      "logps/chosen": -939.7407836914062,
      "logps/rejected": -1477.421142578125,
      "loss": 0.1488,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.949012041091919,
      "rewards/margins": 4.079243183135986,
      "rewards/rejected": -5.028255462646484,
      "step": 270
    },
    {
      "epoch": 0.4336,
      "grad_norm": 2.4715826511383057,
      "learning_rate": 2.84e-06,
      "logits/chosen": -2.5777971744537354,
      "logits/rejected": -2.6322994232177734,
      "logps/chosen": -993.4403076171875,
      "logps/rejected": -1836.1904296875,
      "loss": 0.0829,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4603033065795898,
      "rewards/margins": 3.967618703842163,
      "rewards/rejected": -5.427922248840332,
      "step": 271
    },
    {
      "epoch": 0.4352,
      "grad_norm": 14.368830680847168,
      "learning_rate": 2.832e-06,
      "logits/chosen": -2.5805978775024414,
      "logits/rejected": -2.5855307579040527,
      "logps/chosen": -1219.4796142578125,
      "logps/rejected": -1459.961669921875,
      "loss": 0.476,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.8728725910186768,
      "rewards/margins": 2.5660958290100098,
      "rewards/rejected": -4.438968181610107,
      "step": 272
    },
    {
      "epoch": 0.4368,
      "grad_norm": 2.5000548362731934,
      "learning_rate": 2.824e-06,
      "logits/chosen": -2.4962682723999023,
      "logits/rejected": -2.497814655303955,
      "logps/chosen": -1014.8785400390625,
      "logps/rejected": -1745.6649169921875,
      "loss": 0.0777,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.353419542312622,
      "rewards/margins": 4.1298508644104,
      "rewards/rejected": -5.483270168304443,
      "step": 273
    },
    {
      "epoch": 0.4384,
      "grad_norm": 12.502571105957031,
      "learning_rate": 2.8160000000000002e-06,
      "logits/chosen": -2.4706764221191406,
      "logits/rejected": -2.5952072143554688,
      "logps/chosen": -1174.264892578125,
      "logps/rejected": -1685.1710205078125,
      "loss": 0.307,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.076120376586914,
      "rewards/margins": 4.239624977111816,
      "rewards/rejected": -5.3157453536987305,
      "step": 274
    },
    {
      "epoch": 0.44,
      "grad_norm": 10.208426475524902,
      "learning_rate": 2.808e-06,
      "logits/chosen": -2.520449638366699,
      "logits/rejected": -2.5691163539886475,
      "logps/chosen": -1504.1392822265625,
      "logps/rejected": -1994.0052490234375,
      "loss": 0.1841,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.8375701904296875,
      "rewards/margins": 3.919656753540039,
      "rewards/rejected": -5.757226943969727,
      "step": 275
    },
    {
      "epoch": 0.4416,
      "grad_norm": 5.695871353149414,
      "learning_rate": 2.8000000000000003e-06,
      "logits/chosen": -2.577824592590332,
      "logits/rejected": -2.6167478561401367,
      "logps/chosen": -1176.1890869140625,
      "logps/rejected": -1664.041259765625,
      "loss": 0.1614,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.5597331523895264,
      "rewards/margins": 3.7341501712799072,
      "rewards/rejected": -5.293883323669434,
      "step": 276
    },
    {
      "epoch": 0.4432,
      "grad_norm": 2.1381380558013916,
      "learning_rate": 2.792e-06,
      "logits/chosen": -2.5459117889404297,
      "logits/rejected": -2.57578182220459,
      "logps/chosen": -1014.16796875,
      "logps/rejected": -1799.128662109375,
      "loss": 0.0841,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.140714406967163,
      "rewards/margins": 4.405865669250488,
      "rewards/rejected": -5.5465803146362305,
      "step": 277
    },
    {
      "epoch": 0.4448,
      "grad_norm": 4.909337520599365,
      "learning_rate": 2.784e-06,
      "logits/chosen": -2.538309097290039,
      "logits/rejected": -2.596773147583008,
      "logps/chosen": -1152.9156494140625,
      "logps/rejected": -1456.553955078125,
      "loss": 0.1801,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3397401571273804,
      "rewards/margins": 2.990642547607422,
      "rewards/rejected": -4.330382823944092,
      "step": 278
    },
    {
      "epoch": 0.4464,
      "grad_norm": 4.209530830383301,
      "learning_rate": 2.776e-06,
      "logits/chosen": -2.4958252906799316,
      "logits/rejected": -2.5249991416931152,
      "logps/chosen": -1402.2078857421875,
      "logps/rejected": -2476.65576171875,
      "loss": 0.0758,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9799997806549072,
      "rewards/margins": 4.597545623779297,
      "rewards/rejected": -6.577546119689941,
      "step": 279
    },
    {
      "epoch": 0.448,
      "grad_norm": 2.6318421363830566,
      "learning_rate": 2.768e-06,
      "logits/chosen": -2.4974746704101562,
      "logits/rejected": -2.5190341472625732,
      "logps/chosen": -950.1671142578125,
      "logps/rejected": -1527.9176025390625,
      "loss": 0.0851,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.038181185722351,
      "rewards/margins": 3.85526180267334,
      "rewards/rejected": -4.8934431076049805,
      "step": 280
    },
    {
      "epoch": 0.4496,
      "grad_norm": 2.462489604949951,
      "learning_rate": 2.7600000000000003e-06,
      "logits/chosen": -2.549381971359253,
      "logits/rejected": -2.6457059383392334,
      "logps/chosen": -1189.28466796875,
      "logps/rejected": -1433.89697265625,
      "loss": 0.1154,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9700308442115784,
      "rewards/margins": 4.0343475341796875,
      "rewards/rejected": -5.004378318786621,
      "step": 281
    },
    {
      "epoch": 0.4512,
      "grad_norm": 3.056981086730957,
      "learning_rate": 2.752e-06,
      "logits/chosen": -2.622340202331543,
      "logits/rejected": -2.6232621669769287,
      "logps/chosen": -1695.2978515625,
      "logps/rejected": -2248.868408203125,
      "loss": 0.0839,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7851070165634155,
      "rewards/margins": 4.292938232421875,
      "rewards/rejected": -6.078045845031738,
      "step": 282
    },
    {
      "epoch": 0.4528,
      "grad_norm": 9.299272537231445,
      "learning_rate": 2.744e-06,
      "logits/chosen": -2.5705103874206543,
      "logits/rejected": -2.587751865386963,
      "logps/chosen": -980.4793090820312,
      "logps/rejected": -1841.39501953125,
      "loss": 0.285,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3209049701690674,
      "rewards/margins": 4.807898044586182,
      "rewards/rejected": -6.12880277633667,
      "step": 283
    },
    {
      "epoch": 0.4544,
      "grad_norm": 2.9499990940093994,
      "learning_rate": 2.736e-06,
      "logits/chosen": -2.567467451095581,
      "logits/rejected": -2.6214370727539062,
      "logps/chosen": -653.0496215820312,
      "logps/rejected": -1055.4688720703125,
      "loss": 0.0984,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.259910225868225,
      "rewards/margins": 3.6710362434387207,
      "rewards/rejected": -4.930946350097656,
      "step": 284
    },
    {
      "epoch": 0.456,
      "grad_norm": 2.2398464679718018,
      "learning_rate": 2.728e-06,
      "logits/chosen": -2.5351598262786865,
      "logits/rejected": -2.6527156829833984,
      "logps/chosen": -1090.13232421875,
      "logps/rejected": -1968.6903076171875,
      "loss": 0.1153,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.4237267971038818,
      "rewards/margins": 4.3002753257751465,
      "rewards/rejected": -5.724001407623291,
      "step": 285
    },
    {
      "epoch": 0.4576,
      "grad_norm": 3.1071760654449463,
      "learning_rate": 2.7200000000000002e-06,
      "logits/chosen": -2.604886770248413,
      "logits/rejected": -2.600425958633423,
      "logps/chosen": -909.0460205078125,
      "logps/rejected": -1188.97216796875,
      "loss": 0.1445,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6257458329200745,
      "rewards/margins": 3.6685402393341064,
      "rewards/rejected": -4.294286727905273,
      "step": 286
    },
    {
      "epoch": 0.4592,
      "grad_norm": 1.9274567365646362,
      "learning_rate": 2.712e-06,
      "logits/chosen": -2.6207973957061768,
      "logits/rejected": -2.6480042934417725,
      "logps/chosen": -1216.654296875,
      "logps/rejected": -1815.495849609375,
      "loss": 0.0845,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5172170400619507,
      "rewards/margins": 4.073398113250732,
      "rewards/rejected": -5.590615272521973,
      "step": 287
    },
    {
      "epoch": 0.4608,
      "grad_norm": 2.916658639907837,
      "learning_rate": 2.704e-06,
      "logits/chosen": -2.510185956954956,
      "logits/rejected": -2.613218069076538,
      "logps/chosen": -759.104248046875,
      "logps/rejected": -1674.82373046875,
      "loss": 0.0951,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.015205979347229,
      "rewards/margins": 3.4866111278533936,
      "rewards/rejected": -4.501817226409912,
      "step": 288
    },
    {
      "epoch": 0.4624,
      "grad_norm": 2.0614013671875,
      "learning_rate": 2.696e-06,
      "logits/chosen": -2.59549617767334,
      "logits/rejected": -2.641812324523926,
      "logps/chosen": -751.3426513671875,
      "logps/rejected": -1445.4801025390625,
      "loss": 0.0542,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2242932319641113,
      "rewards/margins": 4.513317108154297,
      "rewards/rejected": -5.737610816955566,
      "step": 289
    },
    {
      "epoch": 0.464,
      "grad_norm": 3.2177979946136475,
      "learning_rate": 2.688e-06,
      "logits/chosen": -2.5090911388397217,
      "logits/rejected": -2.5799102783203125,
      "logps/chosen": -1431.0767822265625,
      "logps/rejected": -1983.4580078125,
      "loss": 0.1049,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5734081268310547,
      "rewards/margins": 4.537472724914551,
      "rewards/rejected": -6.1108808517456055,
      "step": 290
    },
    {
      "epoch": 0.4656,
      "grad_norm": 8.287748336791992,
      "learning_rate": 2.68e-06,
      "logits/chosen": -2.4460368156433105,
      "logits/rejected": -2.534029483795166,
      "logps/chosen": -1194.999755859375,
      "logps/rejected": -1737.7469482421875,
      "loss": 0.2703,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.4288357496261597,
      "rewards/margins": 4.067701816558838,
      "rewards/rejected": -5.496537685394287,
      "step": 291
    },
    {
      "epoch": 0.4672,
      "grad_norm": 7.447126388549805,
      "learning_rate": 2.672e-06,
      "logits/chosen": -2.5873072147369385,
      "logits/rejected": -2.6383769512176514,
      "logps/chosen": -1452.1697998046875,
      "logps/rejected": -1642.8895263671875,
      "loss": 0.2734,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.8386669158935547,
      "rewards/margins": 3.362255811691284,
      "rewards/rejected": -5.20092248916626,
      "step": 292
    },
    {
      "epoch": 0.4688,
      "grad_norm": 14.504598617553711,
      "learning_rate": 2.6640000000000007e-06,
      "logits/chosen": -2.549905300140381,
      "logits/rejected": -2.628748893737793,
      "logps/chosen": -1248.9205322265625,
      "logps/rejected": -1348.542724609375,
      "loss": 0.2706,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.5409419536590576,
      "rewards/margins": 3.342252731323242,
      "rewards/rejected": -4.883194446563721,
      "step": 293
    },
    {
      "epoch": 0.4704,
      "grad_norm": 7.465545654296875,
      "learning_rate": 2.656e-06,
      "logits/chosen": -2.575540065765381,
      "logits/rejected": -2.6146180629730225,
      "logps/chosen": -1788.9046630859375,
      "logps/rejected": -2256.95849609375,
      "loss": 0.1451,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.445233941078186,
      "rewards/margins": 4.701787948608398,
      "rewards/rejected": -6.147021293640137,
      "step": 294
    },
    {
      "epoch": 0.472,
      "grad_norm": 11.46721076965332,
      "learning_rate": 2.648e-06,
      "logits/chosen": -2.5373635292053223,
      "logits/rejected": -2.6270601749420166,
      "logps/chosen": -1265.5325927734375,
      "logps/rejected": -1675.1475830078125,
      "loss": 0.2233,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.6070650815963745,
      "rewards/margins": 3.9108529090881348,
      "rewards/rejected": -5.517918586730957,
      "step": 295
    },
    {
      "epoch": 0.4736,
      "grad_norm": 9.34926700592041,
      "learning_rate": 2.64e-06,
      "logits/chosen": -2.4440715312957764,
      "logits/rejected": -2.4956278800964355,
      "logps/chosen": -1276.4381103515625,
      "logps/rejected": -2554.4931640625,
      "loss": 0.2158,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.4963057041168213,
      "rewards/margins": 5.7465996742248535,
      "rewards/rejected": -7.242905616760254,
      "step": 296
    },
    {
      "epoch": 0.4752,
      "grad_norm": 6.1649370193481445,
      "learning_rate": 2.632e-06,
      "logits/chosen": -2.565753221511841,
      "logits/rejected": -2.6231255531311035,
      "logps/chosen": -717.3287353515625,
      "logps/rejected": -1760.7825927734375,
      "loss": 0.1065,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.141451358795166,
      "rewards/margins": 4.638425827026367,
      "rewards/rejected": -5.779876708984375,
      "step": 297
    },
    {
      "epoch": 0.4768,
      "grad_norm": 5.182777404785156,
      "learning_rate": 2.6240000000000006e-06,
      "logits/chosen": -2.577876329421997,
      "logits/rejected": -2.6154799461364746,
      "logps/chosen": -1141.775146484375,
      "logps/rejected": -1558.1839599609375,
      "loss": 0.1808,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.1072392463684082,
      "rewards/margins": 3.5394086837768555,
      "rewards/rejected": -4.646647930145264,
      "step": 298
    },
    {
      "epoch": 0.4784,
      "grad_norm": 7.597955703735352,
      "learning_rate": 2.616e-06,
      "logits/chosen": -2.432812452316284,
      "logits/rejected": -2.5760769844055176,
      "logps/chosen": -1286.3218994140625,
      "logps/rejected": -1581.3834228515625,
      "loss": 0.2177,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.4851994514465332,
      "rewards/margins": 2.8435869216918945,
      "rewards/rejected": -4.328786373138428,
      "step": 299
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.519573211669922,
      "learning_rate": 2.608e-06,
      "logits/chosen": -2.5068182945251465,
      "logits/rejected": -2.56563663482666,
      "logps/chosen": -1000.50537109375,
      "logps/rejected": -1439.39794921875,
      "loss": 0.1387,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.46939218044281,
      "rewards/margins": 3.3460211753845215,
      "rewards/rejected": -4.815413475036621,
      "step": 300
    },
    {
      "epoch": 0.4816,
      "grad_norm": 4.169301986694336,
      "learning_rate": 2.6e-06,
      "logits/chosen": -2.598973274230957,
      "logits/rejected": -2.618940830230713,
      "logps/chosen": -833.468017578125,
      "logps/rejected": -1318.519287109375,
      "loss": 0.1262,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.07292640209198,
      "rewards/margins": 3.821061849594116,
      "rewards/rejected": -4.893988132476807,
      "step": 301
    },
    {
      "epoch": 0.4832,
      "grad_norm": 3.7427480220794678,
      "learning_rate": 2.592e-06,
      "logits/chosen": -2.4961185455322266,
      "logits/rejected": -2.607804775238037,
      "logps/chosen": -727.626953125,
      "logps/rejected": -1605.7174072265625,
      "loss": 0.2081,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6688829660415649,
      "rewards/margins": 4.136699199676514,
      "rewards/rejected": -4.805582046508789,
      "step": 302
    },
    {
      "epoch": 0.4848,
      "grad_norm": 9.524391174316406,
      "learning_rate": 2.5840000000000006e-06,
      "logits/chosen": -2.6056597232818604,
      "logits/rejected": -2.6050801277160645,
      "logps/chosen": -1101.139404296875,
      "logps/rejected": -1510.6876220703125,
      "loss": 0.2837,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.786833643913269,
      "rewards/margins": 3.570772409439087,
      "rewards/rejected": -5.357606410980225,
      "step": 303
    },
    {
      "epoch": 0.4864,
      "grad_norm": 3.251901149749756,
      "learning_rate": 2.576e-06,
      "logits/chosen": -2.4287948608398438,
      "logits/rejected": -2.535386085510254,
      "logps/chosen": -1117.84716796875,
      "logps/rejected": -1719.5196533203125,
      "loss": 0.1292,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0538108348846436,
      "rewards/margins": 4.211190223693848,
      "rewards/rejected": -5.265000820159912,
      "step": 304
    },
    {
      "epoch": 0.488,
      "grad_norm": 8.910369873046875,
      "learning_rate": 2.568e-06,
      "logits/chosen": -2.4831292629241943,
      "logits/rejected": -2.607759714126587,
      "logps/chosen": -1134.2880859375,
      "logps/rejected": -1609.51708984375,
      "loss": 0.2454,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3181047439575195,
      "rewards/margins": 3.9606237411499023,
      "rewards/rejected": -5.278728485107422,
      "step": 305
    },
    {
      "epoch": 0.4896,
      "grad_norm": 5.505279064178467,
      "learning_rate": 2.56e-06,
      "logits/chosen": -2.5069172382354736,
      "logits/rejected": -2.572186231613159,
      "logps/chosen": -1505.2938232421875,
      "logps/rejected": -2120.88818359375,
      "loss": 0.0983,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.766932487487793,
      "rewards/margins": 4.487650394439697,
      "rewards/rejected": -6.254582405090332,
      "step": 306
    },
    {
      "epoch": 0.4912,
      "grad_norm": 2.8927807807922363,
      "learning_rate": 2.552e-06,
      "logits/chosen": -2.5614378452301025,
      "logits/rejected": -2.637474775314331,
      "logps/chosen": -719.5642700195312,
      "logps/rejected": -1368.6871337890625,
      "loss": 0.0903,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7129974961280823,
      "rewards/margins": 4.3286333084106445,
      "rewards/rejected": -5.041630744934082,
      "step": 307
    },
    {
      "epoch": 0.4928,
      "grad_norm": 1.6432229280471802,
      "learning_rate": 2.5440000000000005e-06,
      "logits/chosen": -2.4775991439819336,
      "logits/rejected": -2.587948799133301,
      "logps/chosen": -481.2333679199219,
      "logps/rejected": -1093.687744140625,
      "loss": 0.0671,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5604342222213745,
      "rewards/margins": 4.4850897789001465,
      "rewards/rejected": -5.045523643493652,
      "step": 308
    },
    {
      "epoch": 0.4944,
      "grad_norm": 1.9519203901290894,
      "learning_rate": 2.536e-06,
      "logits/chosen": -2.545677900314331,
      "logits/rejected": -2.568427801132202,
      "logps/chosen": -807.824951171875,
      "logps/rejected": -1619.8494873046875,
      "loss": 0.0674,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7797113060951233,
      "rewards/margins": 4.76682710647583,
      "rewards/rejected": -5.546538829803467,
      "step": 309
    },
    {
      "epoch": 0.496,
      "grad_norm": 5.796362400054932,
      "learning_rate": 2.5280000000000006e-06,
      "logits/chosen": -2.4729526042938232,
      "logits/rejected": -2.603792190551758,
      "logps/chosen": -908.9285888671875,
      "logps/rejected": -1874.2115478515625,
      "loss": 0.1243,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3342775106430054,
      "rewards/margins": 4.6710004806518555,
      "rewards/rejected": -6.00527811050415,
      "step": 310
    },
    {
      "epoch": 0.4976,
      "grad_norm": 2.763230085372925,
      "learning_rate": 2.52e-06,
      "logits/chosen": -2.6114661693573,
      "logits/rejected": -2.593003273010254,
      "logps/chosen": -908.2786865234375,
      "logps/rejected": -2310.0595703125,
      "loss": 0.0279,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2756726741790771,
      "rewards/margins": 4.62700080871582,
      "rewards/rejected": -5.902673721313477,
      "step": 311
    },
    {
      "epoch": 0.4992,
      "grad_norm": 9.818038940429688,
      "learning_rate": 2.512e-06,
      "logits/chosen": -2.6079089641571045,
      "logits/rejected": -2.611049175262451,
      "logps/chosen": -1360.442138671875,
      "logps/rejected": -2175.482421875,
      "loss": 0.1752,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.3150726556777954,
      "rewards/margins": 4.351291179656982,
      "rewards/rejected": -5.6663641929626465,
      "step": 312
    },
    {
      "epoch": 0.5008,
      "grad_norm": 3.3280487060546875,
      "learning_rate": 2.5040000000000005e-06,
      "logits/chosen": -2.5643935203552246,
      "logits/rejected": -2.650303602218628,
      "logps/chosen": -1746.11865234375,
      "logps/rejected": -2062.697998046875,
      "loss": 0.0705,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6916460394859314,
      "rewards/margins": 5.312620639801025,
      "rewards/rejected": -6.004266262054443,
      "step": 313
    },
    {
      "epoch": 0.5024,
      "grad_norm": 1.7278698682785034,
      "learning_rate": 2.496e-06,
      "logits/chosen": -2.485959529876709,
      "logits/rejected": -2.6240108013153076,
      "logps/chosen": -1167.030517578125,
      "logps/rejected": -1785.546875,
      "loss": 0.0512,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.420474648475647,
      "rewards/margins": 4.008138656616211,
      "rewards/rejected": -5.428613185882568,
      "step": 314
    },
    {
      "epoch": 0.504,
      "grad_norm": 2.656064033508301,
      "learning_rate": 2.488e-06,
      "logits/chosen": -2.561330795288086,
      "logits/rejected": -2.616753101348877,
      "logps/chosen": -1195.54443359375,
      "logps/rejected": -1816.8701171875,
      "loss": 0.0725,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3994258642196655,
      "rewards/margins": 4.43355131149292,
      "rewards/rejected": -5.832977294921875,
      "step": 315
    },
    {
      "epoch": 0.5056,
      "grad_norm": 6.757162094116211,
      "learning_rate": 2.4800000000000004e-06,
      "logits/chosen": -2.5498061180114746,
      "logits/rejected": -2.6089446544647217,
      "logps/chosen": -798.0850219726562,
      "logps/rejected": -1319.1671142578125,
      "loss": 0.1359,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.8408553600311279,
      "rewards/margins": 3.5028557777404785,
      "rewards/rejected": -4.343710899353027,
      "step": 316
    },
    {
      "epoch": 0.5072,
      "grad_norm": 2.2606561183929443,
      "learning_rate": 2.4720000000000002e-06,
      "logits/chosen": -2.4984540939331055,
      "logits/rejected": -2.664580821990967,
      "logps/chosen": -1042.221923828125,
      "logps/rejected": -1179.12109375,
      "loss": 0.0868,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0906028747558594,
      "rewards/margins": 3.321135997772217,
      "rewards/rejected": -4.411738395690918,
      "step": 317
    },
    {
      "epoch": 0.5088,
      "grad_norm": 2.2438230514526367,
      "learning_rate": 2.4640000000000005e-06,
      "logits/chosen": -2.526210069656372,
      "logits/rejected": -2.5805022716522217,
      "logps/chosen": -1170.6474609375,
      "logps/rejected": -1957.964599609375,
      "loss": 0.0707,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0672928094863892,
      "rewards/margins": 4.600808620452881,
      "rewards/rejected": -5.6681013107299805,
      "step": 318
    },
    {
      "epoch": 0.5104,
      "grad_norm": 6.609302997589111,
      "learning_rate": 2.4560000000000003e-06,
      "logits/chosen": -2.4655141830444336,
      "logits/rejected": -2.5525686740875244,
      "logps/chosen": -1668.10498046875,
      "logps/rejected": -1878.5032958984375,
      "loss": 0.2243,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.0890724658966064,
      "rewards/margins": 2.7495169639587402,
      "rewards/rejected": -4.838589191436768,
      "step": 319
    },
    {
      "epoch": 0.512,
      "grad_norm": 2.125328302383423,
      "learning_rate": 2.448e-06,
      "logits/chosen": -2.5402615070343018,
      "logits/rejected": -2.6173548698425293,
      "logps/chosen": -629.603759765625,
      "logps/rejected": -1386.153564453125,
      "loss": 0.0803,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8684490323066711,
      "rewards/margins": 3.8987581729888916,
      "rewards/rejected": -4.767207622528076,
      "step": 320
    },
    {
      "epoch": 0.5136,
      "grad_norm": 3.4847524166107178,
      "learning_rate": 2.4400000000000004e-06,
      "logits/chosen": -2.534377336502075,
      "logits/rejected": -2.5567147731781006,
      "logps/chosen": -1165.306640625,
      "logps/rejected": -2057.555419921875,
      "loss": 0.1028,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.2846088409423828,
      "rewards/margins": 5.155386924743652,
      "rewards/rejected": -6.439995765686035,
      "step": 321
    },
    {
      "epoch": 0.5152,
      "grad_norm": 10.157440185546875,
      "learning_rate": 2.432e-06,
      "logits/chosen": -2.574460983276367,
      "logits/rejected": -2.596545934677124,
      "logps/chosen": -1175.15478515625,
      "logps/rejected": -1815.26904296875,
      "loss": 0.0944,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.7179917097091675,
      "rewards/margins": 4.34267520904541,
      "rewards/rejected": -6.060666561126709,
      "step": 322
    },
    {
      "epoch": 0.5168,
      "grad_norm": 4.3505401611328125,
      "learning_rate": 2.4240000000000004e-06,
      "logits/chosen": -2.50028133392334,
      "logits/rejected": -2.5541443824768066,
      "logps/chosen": -1324.0108642578125,
      "logps/rejected": -2202.60400390625,
      "loss": 0.069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8093321323394775,
      "rewards/margins": 5.452622413635254,
      "rewards/rejected": -7.261955261230469,
      "step": 323
    },
    {
      "epoch": 0.5184,
      "grad_norm": 3.867262125015259,
      "learning_rate": 2.4160000000000002e-06,
      "logits/chosen": -2.6074862480163574,
      "logits/rejected": -2.6673738956451416,
      "logps/chosen": -1533.2779541015625,
      "logps/rejected": -1671.4835205078125,
      "loss": 0.1251,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3083027601242065,
      "rewards/margins": 4.246618270874023,
      "rewards/rejected": -5.5549211502075195,
      "step": 324
    },
    {
      "epoch": 0.52,
      "grad_norm": 18.745038986206055,
      "learning_rate": 2.408e-06,
      "logits/chosen": -2.5669150352478027,
      "logits/rejected": -2.5825066566467285,
      "logps/chosen": -1407.033935546875,
      "logps/rejected": -1623.388916015625,
      "loss": 0.3191,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.5940229892730713,
      "rewards/margins": 3.1898746490478516,
      "rewards/rejected": -4.783897399902344,
      "step": 325
    },
    {
      "epoch": 0.5216,
      "grad_norm": 1.2595820426940918,
      "learning_rate": 2.4000000000000003e-06,
      "logits/chosen": -2.516268014907837,
      "logits/rejected": -2.5554442405700684,
      "logps/chosen": -1319.5457763671875,
      "logps/rejected": -2113.548828125,
      "loss": 0.047,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1926825046539307,
      "rewards/margins": 4.5057148933410645,
      "rewards/rejected": -5.698397159576416,
      "step": 326
    },
    {
      "epoch": 0.5232,
      "grad_norm": 4.793246269226074,
      "learning_rate": 2.392e-06,
      "logits/chosen": -2.564249038696289,
      "logits/rejected": -2.664574384689331,
      "logps/chosen": -849.847900390625,
      "logps/rejected": -1491.2232666015625,
      "loss": 0.1224,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.2537938356399536,
      "rewards/margins": 4.32906436920166,
      "rewards/rejected": -5.582858562469482,
      "step": 327
    },
    {
      "epoch": 0.5248,
      "grad_norm": 1.723156213760376,
      "learning_rate": 2.3840000000000004e-06,
      "logits/chosen": -2.514206647872925,
      "logits/rejected": -2.6061697006225586,
      "logps/chosen": -1692.3983154296875,
      "logps/rejected": -2172.71875,
      "loss": 0.0451,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3735334873199463,
      "rewards/margins": 4.48939323425293,
      "rewards/rejected": -5.862926483154297,
      "step": 328
    },
    {
      "epoch": 0.5264,
      "grad_norm": 1.787247896194458,
      "learning_rate": 2.376e-06,
      "logits/chosen": -2.573894739151001,
      "logits/rejected": -2.605330228805542,
      "logps/chosen": -909.1478881835938,
      "logps/rejected": -1568.1688232421875,
      "loss": 0.0813,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0319589376449585,
      "rewards/margins": 4.411476135253906,
      "rewards/rejected": -5.443435192108154,
      "step": 329
    },
    {
      "epoch": 0.528,
      "grad_norm": 3.5565366744995117,
      "learning_rate": 2.3680000000000005e-06,
      "logits/chosen": -2.534400224685669,
      "logits/rejected": -2.5787482261657715,
      "logps/chosen": -720.5563354492188,
      "logps/rejected": -1884.983154296875,
      "loss": 0.0869,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2042361497879028,
      "rewards/margins": 4.285500526428223,
      "rewards/rejected": -5.489737033843994,
      "step": 330
    },
    {
      "epoch": 0.5296,
      "grad_norm": 6.4959540367126465,
      "learning_rate": 2.3600000000000003e-06,
      "logits/chosen": -2.5714573860168457,
      "logits/rejected": -2.663085460662842,
      "logps/chosen": -1352.681396484375,
      "logps/rejected": -1602.5283203125,
      "loss": 0.1396,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.6935898065567017,
      "rewards/margins": 3.447190761566162,
      "rewards/rejected": -5.140780925750732,
      "step": 331
    },
    {
      "epoch": 0.5312,
      "grad_norm": 3.36942982673645,
      "learning_rate": 2.352e-06,
      "logits/chosen": -2.5248796939849854,
      "logits/rejected": -2.6228466033935547,
      "logps/chosen": -641.2291870117188,
      "logps/rejected": -1590.74365234375,
      "loss": 0.0944,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.096269965171814,
      "rewards/margins": 4.704405784606934,
      "rewards/rejected": -5.800675392150879,
      "step": 332
    },
    {
      "epoch": 0.5328,
      "grad_norm": 2.7894134521484375,
      "learning_rate": 2.3440000000000003e-06,
      "logits/chosen": -2.561748504638672,
      "logits/rejected": -2.6202828884124756,
      "logps/chosen": -1150.97412109375,
      "logps/rejected": -1809.860107421875,
      "loss": 0.0679,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5644282102584839,
      "rewards/margins": 5.118556499481201,
      "rewards/rejected": -6.682983875274658,
      "step": 333
    },
    {
      "epoch": 0.5344,
      "grad_norm": 4.489217758178711,
      "learning_rate": 2.336e-06,
      "logits/chosen": -2.547905921936035,
      "logits/rejected": -2.5928955078125,
      "logps/chosen": -691.1007080078125,
      "logps/rejected": -1109.8358154296875,
      "loss": 0.1603,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0670727491378784,
      "rewards/margins": 2.987473249435425,
      "rewards/rejected": -4.054546356201172,
      "step": 334
    },
    {
      "epoch": 0.536,
      "grad_norm": 5.716826438903809,
      "learning_rate": 2.3280000000000004e-06,
      "logits/chosen": -2.4986979961395264,
      "logits/rejected": -2.6151769161224365,
      "logps/chosen": -712.0337524414062,
      "logps/rejected": -1585.3125,
      "loss": 0.1373,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.154340386390686,
      "rewards/margins": 3.9943885803222656,
      "rewards/rejected": -5.148728847503662,
      "step": 335
    },
    {
      "epoch": 0.5376,
      "grad_norm": 3.1899843215942383,
      "learning_rate": 2.3200000000000002e-06,
      "logits/chosen": -2.403282403945923,
      "logits/rejected": -2.6244754791259766,
      "logps/chosen": -567.7572631835938,
      "logps/rejected": -1782.0137939453125,
      "loss": 0.1087,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6227783560752869,
      "rewards/margins": 4.947134494781494,
      "rewards/rejected": -5.569912433624268,
      "step": 336
    },
    {
      "epoch": 0.5392,
      "grad_norm": 2.794232130050659,
      "learning_rate": 2.312e-06,
      "logits/chosen": -2.521045684814453,
      "logits/rejected": -2.5798532962799072,
      "logps/chosen": -1170.355712890625,
      "logps/rejected": -1764.7222900390625,
      "loss": 0.0878,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3141347169876099,
      "rewards/margins": 4.193735599517822,
      "rewards/rejected": -5.507870197296143,
      "step": 337
    },
    {
      "epoch": 0.5408,
      "grad_norm": 4.209845542907715,
      "learning_rate": 2.3040000000000003e-06,
      "logits/chosen": -2.464144229888916,
      "logits/rejected": -2.5813465118408203,
      "logps/chosen": -1124.1495361328125,
      "logps/rejected": -1653.349609375,
      "loss": 0.1145,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1277437210083008,
      "rewards/margins": 4.38260555267334,
      "rewards/rejected": -5.510349273681641,
      "step": 338
    },
    {
      "epoch": 0.5424,
      "grad_norm": 2.518345355987549,
      "learning_rate": 2.296e-06,
      "logits/chosen": -2.579470157623291,
      "logits/rejected": -2.635308027267456,
      "logps/chosen": -457.72137451171875,
      "logps/rejected": -1137.05615234375,
      "loss": 0.1144,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5649451613426208,
      "rewards/margins": 3.785836696624756,
      "rewards/rejected": -4.3507819175720215,
      "step": 339
    },
    {
      "epoch": 0.544,
      "grad_norm": 4.494256019592285,
      "learning_rate": 2.2880000000000004e-06,
      "logits/chosen": -2.607828140258789,
      "logits/rejected": -2.6303539276123047,
      "logps/chosen": -1827.15625,
      "logps/rejected": -2325.61279296875,
      "loss": 0.0641,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6808180809020996,
      "rewards/margins": 4.68560266494751,
      "rewards/rejected": -6.366420269012451,
      "step": 340
    },
    {
      "epoch": 0.5456,
      "grad_norm": 4.969356060028076,
      "learning_rate": 2.28e-06,
      "logits/chosen": -2.639617919921875,
      "logits/rejected": -2.6245813369750977,
      "logps/chosen": -1410.6304931640625,
      "logps/rejected": -1800.541748046875,
      "loss": 0.1926,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.221967101097107,
      "rewards/margins": 3.336665630340576,
      "rewards/rejected": -4.5586323738098145,
      "step": 341
    },
    {
      "epoch": 0.5472,
      "grad_norm": 2.425349473953247,
      "learning_rate": 2.2720000000000004e-06,
      "logits/chosen": -2.541260242462158,
      "logits/rejected": -2.638730049133301,
      "logps/chosen": -1124.041748046875,
      "logps/rejected": -1640.993408203125,
      "loss": 0.0715,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5542365312576294,
      "rewards/margins": 4.443784236907959,
      "rewards/rejected": -5.998021602630615,
      "step": 342
    },
    {
      "epoch": 0.5488,
      "grad_norm": 5.490383148193359,
      "learning_rate": 2.2640000000000003e-06,
      "logits/chosen": -2.5884852409362793,
      "logits/rejected": -2.6417481899261475,
      "logps/chosen": -1343.902587890625,
      "logps/rejected": -2292.42333984375,
      "loss": 0.0939,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1814444065093994,
      "rewards/margins": 5.108795166015625,
      "rewards/rejected": -6.2902398109436035,
      "step": 343
    },
    {
      "epoch": 0.5504,
      "grad_norm": 2.293210029602051,
      "learning_rate": 2.256e-06,
      "logits/chosen": -2.5783088207244873,
      "logits/rejected": -2.624046802520752,
      "logps/chosen": -1022.118896484375,
      "logps/rejected": -1398.5216064453125,
      "loss": 0.0681,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.189082145690918,
      "rewards/margins": 4.175492763519287,
      "rewards/rejected": -5.364574909210205,
      "step": 344
    },
    {
      "epoch": 0.552,
      "grad_norm": 1.2784770727157593,
      "learning_rate": 2.2480000000000003e-06,
      "logits/chosen": -2.526129961013794,
      "logits/rejected": -2.6293258666992188,
      "logps/chosen": -1016.146728515625,
      "logps/rejected": -1684.50244140625,
      "loss": 0.0509,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.891806960105896,
      "rewards/margins": 4.710116863250732,
      "rewards/rejected": -5.601924419403076,
      "step": 345
    },
    {
      "epoch": 0.5536,
      "grad_norm": 4.00933837890625,
      "learning_rate": 2.24e-06,
      "logits/chosen": -2.643397092819214,
      "logits/rejected": -2.620643138885498,
      "logps/chosen": -1280.7479248046875,
      "logps/rejected": -1744.43115234375,
      "loss": 0.171,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2309415340423584,
      "rewards/margins": 3.746212959289551,
      "rewards/rejected": -4.97715425491333,
      "step": 346
    },
    {
      "epoch": 0.5552,
      "grad_norm": 2.8985817432403564,
      "learning_rate": 2.2320000000000004e-06,
      "logits/chosen": -2.573662757873535,
      "logits/rejected": -2.6314752101898193,
      "logps/chosen": -932.2781982421875,
      "logps/rejected": -1318.8388671875,
      "loss": 0.1215,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4298274517059326,
      "rewards/margins": 3.3154401779174805,
      "rewards/rejected": -4.745267391204834,
      "step": 347
    },
    {
      "epoch": 0.5568,
      "grad_norm": 5.513238906860352,
      "learning_rate": 2.2240000000000002e-06,
      "logits/chosen": -2.595472574234009,
      "logits/rejected": -2.5863988399505615,
      "logps/chosen": -1408.5294189453125,
      "logps/rejected": -1542.1788330078125,
      "loss": 0.1958,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.259768009185791,
      "rewards/margins": 2.9794764518737793,
      "rewards/rejected": -4.2392449378967285,
      "step": 348
    },
    {
      "epoch": 0.5584,
      "grad_norm": 2.580124616622925,
      "learning_rate": 2.216e-06,
      "logits/chosen": -2.4988226890563965,
      "logits/rejected": -2.5683703422546387,
      "logps/chosen": -1432.4805908203125,
      "logps/rejected": -1954.1278076171875,
      "loss": 0.0964,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1799324750900269,
      "rewards/margins": 3.441155195236206,
      "rewards/rejected": -4.621088027954102,
      "step": 349
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.9409589767456055,
      "learning_rate": 2.2080000000000003e-06,
      "logits/chosen": -2.541905164718628,
      "logits/rejected": -2.6292097568511963,
      "logps/chosen": -848.2723999023438,
      "logps/rejected": -1839.05419921875,
      "loss": 0.0613,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2520976066589355,
      "rewards/margins": 5.075382232666016,
      "rewards/rejected": -6.327479839324951,
      "step": 350
    },
    {
      "epoch": 0.5616,
      "grad_norm": 2.014448642730713,
      "learning_rate": 2.2e-06,
      "logits/chosen": -2.6118953227996826,
      "logits/rejected": -2.5919904708862305,
      "logps/chosen": -1462.128662109375,
      "logps/rejected": -2268.36767578125,
      "loss": 0.0576,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8730781078338623,
      "rewards/margins": 5.238338947296143,
      "rewards/rejected": -7.111417293548584,
      "step": 351
    },
    {
      "epoch": 0.5632,
      "grad_norm": 1.6943459510803223,
      "learning_rate": 2.1920000000000004e-06,
      "logits/chosen": -2.4250500202178955,
      "logits/rejected": -2.5505874156951904,
      "logps/chosen": -1102.6256103515625,
      "logps/rejected": -1620.2027587890625,
      "loss": 0.0769,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7470788955688477,
      "rewards/margins": 4.286988735198975,
      "rewards/rejected": -5.0340681076049805,
      "step": 352
    },
    {
      "epoch": 0.5648,
      "grad_norm": 9.165555953979492,
      "learning_rate": 2.184e-06,
      "logits/chosen": -2.621619939804077,
      "logits/rejected": -2.6623735427856445,
      "logps/chosen": -1321.0050048828125,
      "logps/rejected": -2467.724609375,
      "loss": 0.2605,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.4468005895614624,
      "rewards/margins": 7.6689605712890625,
      "rewards/rejected": -9.115761756896973,
      "step": 353
    },
    {
      "epoch": 0.5664,
      "grad_norm": 8.344172477722168,
      "learning_rate": 2.176e-06,
      "logits/chosen": -2.6121087074279785,
      "logits/rejected": -2.609987258911133,
      "logps/chosen": -1284.55078125,
      "logps/rejected": -1897.7716064453125,
      "loss": 0.187,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.7143701314926147,
      "rewards/margins": 5.4103240966796875,
      "rewards/rejected": -7.124694347381592,
      "step": 354
    },
    {
      "epoch": 0.568,
      "grad_norm": 3.564535617828369,
      "learning_rate": 2.1680000000000002e-06,
      "logits/chosen": -2.6099607944488525,
      "logits/rejected": -2.6498405933380127,
      "logps/chosen": -1305.5126953125,
      "logps/rejected": -1801.5421142578125,
      "loss": 0.0735,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7642953395843506,
      "rewards/margins": 3.8692784309387207,
      "rewards/rejected": -5.633573532104492,
      "step": 355
    },
    {
      "epoch": 0.5696,
      "grad_norm": 10.516988754272461,
      "learning_rate": 2.16e-06,
      "logits/chosen": -2.5163419246673584,
      "logits/rejected": -2.530465602874756,
      "logps/chosen": -1004.044189453125,
      "logps/rejected": -1635.92529296875,
      "loss": 0.2535,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.2256938219070435,
      "rewards/margins": 3.942445755004883,
      "rewards/rejected": -5.168139457702637,
      "step": 356
    },
    {
      "epoch": 0.5712,
      "grad_norm": 5.933673858642578,
      "learning_rate": 2.1520000000000003e-06,
      "logits/chosen": -2.5987143516540527,
      "logits/rejected": -2.61128830909729,
      "logps/chosen": -1086.406982421875,
      "logps/rejected": -1557.426513671875,
      "loss": 0.1442,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6510053873062134,
      "rewards/margins": 3.3074607849121094,
      "rewards/rejected": -4.958466053009033,
      "step": 357
    },
    {
      "epoch": 0.5728,
      "grad_norm": 11.4520902633667,
      "learning_rate": 2.144e-06,
      "logits/chosen": -2.4371964931488037,
      "logits/rejected": -2.5603601932525635,
      "logps/chosen": -935.9063110351562,
      "logps/rejected": -1554.20751953125,
      "loss": 0.3448,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.355129599571228,
      "rewards/margins": 4.3128461837768555,
      "rewards/rejected": -5.667975425720215,
      "step": 358
    },
    {
      "epoch": 0.5744,
      "grad_norm": 1.250735878944397,
      "learning_rate": 2.1360000000000004e-06,
      "logits/chosen": -2.576073169708252,
      "logits/rejected": -2.5631585121154785,
      "logps/chosen": -1573.6544189453125,
      "logps/rejected": -2271.6591796875,
      "loss": 0.0443,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9006078243255615,
      "rewards/margins": 4.824616432189941,
      "rewards/rejected": -6.725225448608398,
      "step": 359
    },
    {
      "epoch": 0.576,
      "grad_norm": 13.983480453491211,
      "learning_rate": 2.128e-06,
      "logits/chosen": -2.5999903678894043,
      "logits/rejected": -2.658146381378174,
      "logps/chosen": -1395.1822509765625,
      "logps/rejected": -1984.8138427734375,
      "loss": 0.2954,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.6331521272659302,
      "rewards/margins": 4.272500991821289,
      "rewards/rejected": -5.90565299987793,
      "step": 360
    },
    {
      "epoch": 0.5776,
      "grad_norm": 4.3386077880859375,
      "learning_rate": 2.12e-06,
      "logits/chosen": -2.4649627208709717,
      "logits/rejected": -2.5596764087677,
      "logps/chosen": -896.7146606445312,
      "logps/rejected": -1716.001953125,
      "loss": 0.0692,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.395002841949463,
      "rewards/margins": 4.315776348114014,
      "rewards/rejected": -5.710779190063477,
      "step": 361
    },
    {
      "epoch": 0.5792,
      "grad_norm": 12.984522819519043,
      "learning_rate": 2.1120000000000003e-06,
      "logits/chosen": -2.533766746520996,
      "logits/rejected": -2.590900182723999,
      "logps/chosen": -1047.0570068359375,
      "logps/rejected": -1663.6412353515625,
      "loss": 0.1824,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.372684359550476,
      "rewards/margins": 4.136227607727051,
      "rewards/rejected": -5.508912086486816,
      "step": 362
    },
    {
      "epoch": 0.5808,
      "grad_norm": 1.3359004259109497,
      "learning_rate": 2.104e-06,
      "logits/chosen": -2.527404308319092,
      "logits/rejected": -2.5642433166503906,
      "logps/chosen": -1206.312255859375,
      "logps/rejected": -2215.856689453125,
      "loss": 0.0443,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5568653345108032,
      "rewards/margins": 5.3552985191345215,
      "rewards/rejected": -6.912163257598877,
      "step": 363
    },
    {
      "epoch": 0.5824,
      "grad_norm": 1.165583848953247,
      "learning_rate": 2.0960000000000003e-06,
      "logits/chosen": -2.5873289108276367,
      "logits/rejected": -2.6173157691955566,
      "logps/chosen": -1478.0418701171875,
      "logps/rejected": -3034.6259765625,
      "loss": 0.0316,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8288605213165283,
      "rewards/margins": 6.0257463455200195,
      "rewards/rejected": -7.854606628417969,
      "step": 364
    },
    {
      "epoch": 0.584,
      "grad_norm": 1.7899580001831055,
      "learning_rate": 2.088e-06,
      "logits/chosen": -2.4805283546447754,
      "logits/rejected": -2.600510597229004,
      "logps/chosen": -1054.8714599609375,
      "logps/rejected": -1873.4613037109375,
      "loss": 0.0706,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9028993248939514,
      "rewards/margins": 4.635645389556885,
      "rewards/rejected": -5.53854513168335,
      "step": 365
    },
    {
      "epoch": 0.5856,
      "grad_norm": 1.1477925777435303,
      "learning_rate": 2.08e-06,
      "logits/chosen": -2.526869773864746,
      "logits/rejected": -2.5729358196258545,
      "logps/chosen": -1376.4295654296875,
      "logps/rejected": -1976.1162109375,
      "loss": 0.0435,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.921648383140564,
      "rewards/margins": 5.889340877532959,
      "rewards/rejected": -6.8109893798828125,
      "step": 366
    },
    {
      "epoch": 0.5872,
      "grad_norm": 2.347012758255005,
      "learning_rate": 2.0720000000000002e-06,
      "logits/chosen": -2.506812334060669,
      "logits/rejected": -2.600799560546875,
      "logps/chosen": -935.2844848632812,
      "logps/rejected": -1977.2864990234375,
      "loss": 0.089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3543637990951538,
      "rewards/margins": 4.26426362991333,
      "rewards/rejected": -5.618627548217773,
      "step": 367
    },
    {
      "epoch": 0.5888,
      "grad_norm": 8.677030563354492,
      "learning_rate": 2.064e-06,
      "logits/chosen": -2.49581241607666,
      "logits/rejected": -2.5673866271972656,
      "logps/chosen": -1541.5328369140625,
      "logps/rejected": -2028.678955078125,
      "loss": 0.2118,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.9826085567474365,
      "rewards/margins": 4.856032848358154,
      "rewards/rejected": -6.838641166687012,
      "step": 368
    },
    {
      "epoch": 0.5904,
      "grad_norm": 1.4801571369171143,
      "learning_rate": 2.0560000000000003e-06,
      "logits/chosen": -2.5388078689575195,
      "logits/rejected": -2.584036350250244,
      "logps/chosen": -693.1272583007812,
      "logps/rejected": -2149.02490234375,
      "loss": 0.05,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.688434362411499,
      "rewards/margins": 5.251596450805664,
      "rewards/rejected": -5.940031051635742,
      "step": 369
    },
    {
      "epoch": 0.592,
      "grad_norm": 10.316261291503906,
      "learning_rate": 2.048e-06,
      "logits/chosen": -2.5769879817962646,
      "logits/rejected": -2.6646604537963867,
      "logps/chosen": -1154.4759521484375,
      "logps/rejected": -1279.98193359375,
      "loss": 0.2048,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3586256504058838,
      "rewards/margins": 2.7043297290802,
      "rewards/rejected": -4.062955379486084,
      "step": 370
    },
    {
      "epoch": 0.5936,
      "grad_norm": 1.2189764976501465,
      "learning_rate": 2.04e-06,
      "logits/chosen": -2.527416944503784,
      "logits/rejected": -2.6073081493377686,
      "logps/chosen": -977.0924682617188,
      "logps/rejected": -1724.27294921875,
      "loss": 0.035,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1604242324829102,
      "rewards/margins": 5.386175632476807,
      "rewards/rejected": -6.546599388122559,
      "step": 371
    },
    {
      "epoch": 0.5952,
      "grad_norm": 4.201333045959473,
      "learning_rate": 2.032e-06,
      "logits/chosen": -2.4548163414001465,
      "logits/rejected": -2.5648655891418457,
      "logps/chosen": -841.8934936523438,
      "logps/rejected": -1840.676513671875,
      "loss": 0.1198,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.7998712062835693,
      "rewards/margins": 5.378678321838379,
      "rewards/rejected": -6.178549766540527,
      "step": 372
    },
    {
      "epoch": 0.5968,
      "grad_norm": 5.143548965454102,
      "learning_rate": 2.024e-06,
      "logits/chosen": -2.495922565460205,
      "logits/rejected": -2.559128522872925,
      "logps/chosen": -1039.81787109375,
      "logps/rejected": -1352.9088134765625,
      "loss": 0.125,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4028968811035156,
      "rewards/margins": 3.787860631942749,
      "rewards/rejected": -5.1907572746276855,
      "step": 373
    },
    {
      "epoch": 0.5984,
      "grad_norm": 4.858547210693359,
      "learning_rate": 2.0160000000000003e-06,
      "logits/chosen": -2.5264053344726562,
      "logits/rejected": -2.5772929191589355,
      "logps/chosen": -1348.9388427734375,
      "logps/rejected": -1948.065673828125,
      "loss": 0.0824,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8674321174621582,
      "rewards/margins": 5.223083972930908,
      "rewards/rejected": -7.090516567230225,
      "step": 374
    },
    {
      "epoch": 0.6,
      "grad_norm": 4.03941535949707,
      "learning_rate": 2.008e-06,
      "logits/chosen": -2.491403818130493,
      "logits/rejected": -2.5802247524261475,
      "logps/chosen": -783.2603759765625,
      "logps/rejected": -1515.5760498046875,
      "loss": 0.1146,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9965571165084839,
      "rewards/margins": 3.9173030853271484,
      "rewards/rejected": -4.913860321044922,
      "step": 375
    },
    {
      "epoch": 0.6016,
      "grad_norm": 4.177972316741943,
      "learning_rate": 2.0000000000000003e-06,
      "logits/chosen": -2.5613303184509277,
      "logits/rejected": -2.6270742416381836,
      "logps/chosen": -667.4819946289062,
      "logps/rejected": -1431.4683837890625,
      "loss": 0.0601,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2198117971420288,
      "rewards/margins": 4.620705604553223,
      "rewards/rejected": -5.840517044067383,
      "step": 376
    },
    {
      "epoch": 0.6032,
      "grad_norm": 12.58267593383789,
      "learning_rate": 1.992e-06,
      "logits/chosen": -2.591092109680176,
      "logits/rejected": -2.5795984268188477,
      "logps/chosen": -1313.135986328125,
      "logps/rejected": -2032.7357177734375,
      "loss": 0.3067,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.7478746175765991,
      "rewards/margins": 4.240782260894775,
      "rewards/rejected": -5.988656044006348,
      "step": 377
    },
    {
      "epoch": 0.6048,
      "grad_norm": 1.3581267595291138,
      "learning_rate": 1.984e-06,
      "logits/chosen": -2.468062400817871,
      "logits/rejected": -2.640091896057129,
      "logps/chosen": -690.2947387695312,
      "logps/rejected": -1224.654296875,
      "loss": 0.0588,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0680745840072632,
      "rewards/margins": 4.66342306137085,
      "rewards/rejected": -5.731497287750244,
      "step": 378
    },
    {
      "epoch": 0.6064,
      "grad_norm": 3.7205114364624023,
      "learning_rate": 1.9760000000000002e-06,
      "logits/chosen": -2.6312880516052246,
      "logits/rejected": -2.6622347831726074,
      "logps/chosen": -1143.631103515625,
      "logps/rejected": -1763.43994140625,
      "loss": 0.0791,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3811789751052856,
      "rewards/margins": 4.252488613128662,
      "rewards/rejected": -5.633667469024658,
      "step": 379
    },
    {
      "epoch": 0.608,
      "grad_norm": 7.059126377105713,
      "learning_rate": 1.968e-06,
      "logits/chosen": -2.5180559158325195,
      "logits/rejected": -2.6221671104431152,
      "logps/chosen": -919.6868286132812,
      "logps/rejected": -1267.434814453125,
      "loss": 0.2117,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.0858161449432373,
      "rewards/margins": 3.494032144546509,
      "rewards/rejected": -4.579848289489746,
      "step": 380
    },
    {
      "epoch": 0.6096,
      "grad_norm": 3.1700241565704346,
      "learning_rate": 1.9600000000000003e-06,
      "logits/chosen": -2.487628936767578,
      "logits/rejected": -2.5884180068969727,
      "logps/chosen": -756.3707275390625,
      "logps/rejected": -1375.2799072265625,
      "loss": 0.0934,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.073632836341858,
      "rewards/margins": 3.6776483058929443,
      "rewards/rejected": -4.751281261444092,
      "step": 381
    },
    {
      "epoch": 0.6112,
      "grad_norm": 3.5744740962982178,
      "learning_rate": 1.952e-06,
      "logits/chosen": -2.5816891193389893,
      "logits/rejected": -2.6363425254821777,
      "logps/chosen": -963.7265014648438,
      "logps/rejected": -1703.772216796875,
      "loss": 0.1099,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.1511297225952148,
      "rewards/margins": 4.06461238861084,
      "rewards/rejected": -5.215742588043213,
      "step": 382
    },
    {
      "epoch": 0.6128,
      "grad_norm": 10.328742027282715,
      "learning_rate": 1.944e-06,
      "logits/chosen": -2.5040760040283203,
      "logits/rejected": -2.594158887863159,
      "logps/chosen": -948.8845825195312,
      "logps/rejected": -1711.9827880859375,
      "loss": 0.2964,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.9861558675765991,
      "rewards/margins": 4.998869895935059,
      "rewards/rejected": -5.985024929046631,
      "step": 383
    },
    {
      "epoch": 0.6144,
      "grad_norm": 4.48483419418335,
      "learning_rate": 1.936e-06,
      "logits/chosen": -2.5032553672790527,
      "logits/rejected": -2.5533559322357178,
      "logps/chosen": -538.7980346679688,
      "logps/rejected": -1197.0616455078125,
      "loss": 0.1251,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0421497821807861,
      "rewards/margins": 3.6113381385803223,
      "rewards/rejected": -4.6534881591796875,
      "step": 384
    },
    {
      "epoch": 0.616,
      "grad_norm": 1.034984827041626,
      "learning_rate": 1.928e-06,
      "logits/chosen": -2.514303207397461,
      "logits/rejected": -2.615858554840088,
      "logps/chosen": -567.4463500976562,
      "logps/rejected": -1762.146240234375,
      "loss": 0.043,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8940806984901428,
      "rewards/margins": 5.941140174865723,
      "rewards/rejected": -6.835219860076904,
      "step": 385
    },
    {
      "epoch": 0.6176,
      "grad_norm": 3.079948663711548,
      "learning_rate": 1.9200000000000003e-06,
      "logits/chosen": -2.497039318084717,
      "logits/rejected": -2.593726396560669,
      "logps/chosen": -1139.94580078125,
      "logps/rejected": -1941.575439453125,
      "loss": 0.0601,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3434442281723022,
      "rewards/margins": 4.868208408355713,
      "rewards/rejected": -6.2116522789001465,
      "step": 386
    },
    {
      "epoch": 0.6192,
      "grad_norm": 3.5449163913726807,
      "learning_rate": 1.912e-06,
      "logits/chosen": -2.563767433166504,
      "logits/rejected": -2.619919776916504,
      "logps/chosen": -1170.33935546875,
      "logps/rejected": -1473.5240478515625,
      "loss": 0.1862,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9101592302322388,
      "rewards/margins": 3.1981441974639893,
      "rewards/rejected": -5.108304023742676,
      "step": 387
    },
    {
      "epoch": 0.6208,
      "grad_norm": 3.8008148670196533,
      "learning_rate": 1.9040000000000003e-06,
      "logits/chosen": -2.3602447509765625,
      "logits/rejected": -2.4575517177581787,
      "logps/chosen": -1217.552490234375,
      "logps/rejected": -2493.505859375,
      "loss": 0.0485,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3577709197998047,
      "rewards/margins": 6.850721836090088,
      "rewards/rejected": -8.20849323272705,
      "step": 388
    },
    {
      "epoch": 0.6224,
      "grad_norm": 1.639506220817566,
      "learning_rate": 1.8960000000000001e-06,
      "logits/chosen": -2.4358885288238525,
      "logits/rejected": -2.5630807876586914,
      "logps/chosen": -984.8331298828125,
      "logps/rejected": -1651.8724365234375,
      "loss": 0.0701,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2715435028076172,
      "rewards/margins": 5.3255534172058105,
      "rewards/rejected": -6.597097396850586,
      "step": 389
    },
    {
      "epoch": 0.624,
      "grad_norm": 4.684746265411377,
      "learning_rate": 1.8880000000000002e-06,
      "logits/chosen": -2.5559844970703125,
      "logits/rejected": -2.6057426929473877,
      "logps/chosen": -1506.5126953125,
      "logps/rejected": -1615.63916015625,
      "loss": 0.1366,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8805018663406372,
      "rewards/margins": 3.359758138656616,
      "rewards/rejected": -5.240260124206543,
      "step": 390
    },
    {
      "epoch": 0.6256,
      "grad_norm": 6.888486862182617,
      "learning_rate": 1.8800000000000002e-06,
      "logits/chosen": -2.512174606323242,
      "logits/rejected": -2.5830070972442627,
      "logps/chosen": -931.2431640625,
      "logps/rejected": -1703.4066162109375,
      "loss": 0.1938,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.0755982398986816,
      "rewards/margins": 4.136276721954346,
      "rewards/rejected": -5.211874961853027,
      "step": 391
    },
    {
      "epoch": 0.6272,
      "grad_norm": 1.8344335556030273,
      "learning_rate": 1.8720000000000002e-06,
      "logits/chosen": -2.6058506965637207,
      "logits/rejected": -2.6718053817749023,
      "logps/chosen": -982.5338134765625,
      "logps/rejected": -1446.5179443359375,
      "loss": 0.0658,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.099348545074463,
      "rewards/margins": 4.2853684425354,
      "rewards/rejected": -5.3847174644470215,
      "step": 392
    },
    {
      "epoch": 0.6288,
      "grad_norm": 7.114744186401367,
      "learning_rate": 1.8640000000000003e-06,
      "logits/chosen": -2.5652356147766113,
      "logits/rejected": -2.6103813648223877,
      "logps/chosen": -1294.7734375,
      "logps/rejected": -1958.683349609375,
      "loss": 0.1325,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.5843878984451294,
      "rewards/margins": 4.953463554382324,
      "rewards/rejected": -6.537851810455322,
      "step": 393
    },
    {
      "epoch": 0.6304,
      "grad_norm": 1.9945024251937866,
      "learning_rate": 1.856e-06,
      "logits/chosen": -2.504956007003784,
      "logits/rejected": -2.581188917160034,
      "logps/chosen": -1474.9014892578125,
      "logps/rejected": -2476.716552734375,
      "loss": 0.073,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6635290384292603,
      "rewards/margins": 5.050207138061523,
      "rewards/rejected": -6.713735580444336,
      "step": 394
    },
    {
      "epoch": 0.632,
      "grad_norm": 1.05729341506958,
      "learning_rate": 1.8480000000000001e-06,
      "logits/chosen": -2.4992434978485107,
      "logits/rejected": -2.6249947547912598,
      "logps/chosen": -992.9459228515625,
      "logps/rejected": -2446.4580078125,
      "loss": 0.0216,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3621857166290283,
      "rewards/margins": 8.063810348510742,
      "rewards/rejected": -9.425995826721191,
      "step": 395
    },
    {
      "epoch": 0.6336,
      "grad_norm": 2.3304946422576904,
      "learning_rate": 1.8400000000000002e-06,
      "logits/chosen": -2.6269490718841553,
      "logits/rejected": -2.65020489692688,
      "logps/chosen": -837.6305541992188,
      "logps/rejected": -1361.266357421875,
      "loss": 0.1063,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.217954158782959,
      "rewards/margins": 4.347440242767334,
      "rewards/rejected": -5.565394878387451,
      "step": 396
    },
    {
      "epoch": 0.6352,
      "grad_norm": 10.603856086730957,
      "learning_rate": 1.8320000000000002e-06,
      "logits/chosen": -2.5810954570770264,
      "logits/rejected": -2.646761894226074,
      "logps/chosen": -1337.2862548828125,
      "logps/rejected": -1859.04052734375,
      "loss": 0.2716,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.8859089612960815,
      "rewards/margins": 4.044559478759766,
      "rewards/rejected": -5.9304680824279785,
      "step": 397
    },
    {
      "epoch": 0.6368,
      "grad_norm": 5.680084705352783,
      "learning_rate": 1.8240000000000002e-06,
      "logits/chosen": -2.610194444656372,
      "logits/rejected": -2.617947578430176,
      "logps/chosen": -904.5256958007812,
      "logps/rejected": -1346.179931640625,
      "loss": 0.1368,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.2066375017166138,
      "rewards/margins": 4.2671074867248535,
      "rewards/rejected": -5.473744869232178,
      "step": 398
    },
    {
      "epoch": 0.6384,
      "grad_norm": 4.519698143005371,
      "learning_rate": 1.8160000000000003e-06,
      "logits/chosen": -2.583813190460205,
      "logits/rejected": -2.6160800457000732,
      "logps/chosen": -810.3432006835938,
      "logps/rejected": -1307.552490234375,
      "loss": 0.1145,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.4310988187789917,
      "rewards/margins": 4.65854024887085,
      "rewards/rejected": -6.089638710021973,
      "step": 399
    },
    {
      "epoch": 0.64,
      "grad_norm": 16.557018280029297,
      "learning_rate": 1.808e-06,
      "logits/chosen": -2.5227584838867188,
      "logits/rejected": -2.6052451133728027,
      "logps/chosen": -1800.8255615234375,
      "logps/rejected": -1876.21826171875,
      "loss": 0.3706,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.794036626815796,
      "rewards/margins": 2.9318857192993164,
      "rewards/rejected": -5.725921630859375,
      "step": 400
    },
    {
      "epoch": 0.6416,
      "grad_norm": 8.3748779296875,
      "learning_rate": 1.8000000000000001e-06,
      "logits/chosen": -2.4772160053253174,
      "logits/rejected": -2.542785167694092,
      "logps/chosen": -979.1792602539062,
      "logps/rejected": -1430.081298828125,
      "loss": 0.2451,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.5397312641143799,
      "rewards/margins": 3.9390571117401123,
      "rewards/rejected": -5.478788375854492,
      "step": 401
    },
    {
      "epoch": 0.6432,
      "grad_norm": 1.7965391874313354,
      "learning_rate": 1.7920000000000002e-06,
      "logits/chosen": -2.5233993530273438,
      "logits/rejected": -2.6656270027160645,
      "logps/chosen": -1675.9908447265625,
      "logps/rejected": -2501.333740234375,
      "loss": 0.0293,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4560352563858032,
      "rewards/margins": 5.776444435119629,
      "rewards/rejected": -7.232480525970459,
      "step": 402
    },
    {
      "epoch": 0.6448,
      "grad_norm": 5.27630615234375,
      "learning_rate": 1.7840000000000002e-06,
      "logits/chosen": -2.5536279678344727,
      "logits/rejected": -2.5539703369140625,
      "logps/chosen": -1168.839599609375,
      "logps/rejected": -2141.428466796875,
      "loss": 0.0794,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7775585651397705,
      "rewards/margins": 4.341932773590088,
      "rewards/rejected": -6.119491100311279,
      "step": 403
    },
    {
      "epoch": 0.6464,
      "grad_norm": 4.3580732345581055,
      "learning_rate": 1.7760000000000002e-06,
      "logits/chosen": -2.5796313285827637,
      "logits/rejected": -2.578101396560669,
      "logps/chosen": -1413.4007568359375,
      "logps/rejected": -1994.818603515625,
      "loss": 0.1124,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.050865411758423,
      "rewards/margins": 5.003852844238281,
      "rewards/rejected": -7.054717540740967,
      "step": 404
    },
    {
      "epoch": 0.648,
      "grad_norm": 1.3803261518478394,
      "learning_rate": 1.7680000000000003e-06,
      "logits/chosen": -2.4911067485809326,
      "logits/rejected": -2.620940923690796,
      "logps/chosen": -987.0,
      "logps/rejected": -1657.0352783203125,
      "loss": 0.0495,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9608567953109741,
      "rewards/margins": 4.819233417510986,
      "rewards/rejected": -5.780090808868408,
      "step": 405
    },
    {
      "epoch": 0.6496,
      "grad_norm": 14.244572639465332,
      "learning_rate": 1.76e-06,
      "logits/chosen": -2.584613800048828,
      "logits/rejected": -2.5972299575805664,
      "logps/chosen": -2498.715087890625,
      "logps/rejected": -2405.708984375,
      "loss": 0.2599,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.922224283218384,
      "rewards/margins": 4.370800495147705,
      "rewards/rejected": -7.293024063110352,
      "step": 406
    },
    {
      "epoch": 0.6512,
      "grad_norm": 2.7816009521484375,
      "learning_rate": 1.7520000000000001e-06,
      "logits/chosen": -2.5890121459960938,
      "logits/rejected": -2.658374786376953,
      "logps/chosen": -1127.9354248046875,
      "logps/rejected": -1930.0750732421875,
      "loss": 0.0703,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3456488847732544,
      "rewards/margins": 5.035895347595215,
      "rewards/rejected": -6.38154411315918,
      "step": 407
    },
    {
      "epoch": 0.6528,
      "grad_norm": 12.937127113342285,
      "learning_rate": 1.7440000000000002e-06,
      "logits/chosen": -2.564037322998047,
      "logits/rejected": -2.6040964126586914,
      "logps/chosen": -966.5574951171875,
      "logps/rejected": -1557.5286865234375,
      "loss": 0.2134,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.0553083419799805,
      "rewards/margins": 4.738739490509033,
      "rewards/rejected": -6.7940473556518555,
      "step": 408
    },
    {
      "epoch": 0.6544,
      "grad_norm": 4.919610977172852,
      "learning_rate": 1.7360000000000002e-06,
      "logits/chosen": -2.6455507278442383,
      "logits/rejected": -2.656799793243408,
      "logps/chosen": -1565.7366943359375,
      "logps/rejected": -1828.9918212890625,
      "loss": 0.1056,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.8951083421707153,
      "rewards/margins": 3.6422808170318604,
      "rewards/rejected": -5.537389755249023,
      "step": 409
    },
    {
      "epoch": 0.656,
      "grad_norm": 1.9249382019042969,
      "learning_rate": 1.7280000000000002e-06,
      "logits/chosen": -2.594228982925415,
      "logits/rejected": -2.615638256072998,
      "logps/chosen": -935.9991455078125,
      "logps/rejected": -1638.8033447265625,
      "loss": 0.0949,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.326595664024353,
      "rewards/margins": 4.712367057800293,
      "rewards/rejected": -6.0389628410339355,
      "step": 410
    },
    {
      "epoch": 0.6576,
      "grad_norm": 9.458824157714844,
      "learning_rate": 1.72e-06,
      "logits/chosen": -2.569263458251953,
      "logits/rejected": -2.5751898288726807,
      "logps/chosen": -951.1118774414062,
      "logps/rejected": -1421.3011474609375,
      "loss": 0.3595,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.5259593725204468,
      "rewards/margins": 3.6407833099365234,
      "rewards/rejected": -5.166742324829102,
      "step": 411
    },
    {
      "epoch": 0.6592,
      "grad_norm": 1.163407564163208,
      "learning_rate": 1.712e-06,
      "logits/chosen": -2.6036317348480225,
      "logits/rejected": -2.6196465492248535,
      "logps/chosen": -910.7166748046875,
      "logps/rejected": -2008.8192138671875,
      "loss": 0.0226,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.33744215965271,
      "rewards/margins": 5.2307586669921875,
      "rewards/rejected": -6.568201065063477,
      "step": 412
    },
    {
      "epoch": 0.6608,
      "grad_norm": 4.136987686157227,
      "learning_rate": 1.7040000000000001e-06,
      "logits/chosen": -2.4770357608795166,
      "logits/rejected": -2.4896790981292725,
      "logps/chosen": -1592.118408203125,
      "logps/rejected": -2187.4267578125,
      "loss": 0.1327,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.43373441696167,
      "rewards/margins": 5.5494208335876465,
      "rewards/rejected": -6.983154773712158,
      "step": 413
    },
    {
      "epoch": 0.6624,
      "grad_norm": 1.4540899991989136,
      "learning_rate": 1.6960000000000002e-06,
      "logits/chosen": -2.516998291015625,
      "logits/rejected": -2.5129191875457764,
      "logps/chosen": -1044.7391357421875,
      "logps/rejected": -2187.144287109375,
      "loss": 0.0742,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9748244881629944,
      "rewards/margins": 5.869720458984375,
      "rewards/rejected": -6.844544887542725,
      "step": 414
    },
    {
      "epoch": 0.664,
      "grad_norm": 2.8570995330810547,
      "learning_rate": 1.6880000000000002e-06,
      "logits/chosen": -2.4752304553985596,
      "logits/rejected": -2.6192142963409424,
      "logps/chosen": -688.1417236328125,
      "logps/rejected": -1497.5411376953125,
      "loss": 0.0973,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7805200815200806,
      "rewards/margins": 4.3453264236450195,
      "rewards/rejected": -5.1258463859558105,
      "step": 415
    },
    {
      "epoch": 0.6656,
      "grad_norm": 6.623807907104492,
      "learning_rate": 1.6800000000000002e-06,
      "logits/chosen": -2.517465591430664,
      "logits/rejected": -2.5956759452819824,
      "logps/chosen": -987.1206665039062,
      "logps/rejected": -1649.1741943359375,
      "loss": 0.1878,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3781228065490723,
      "rewards/margins": 5.225915908813477,
      "rewards/rejected": -6.604038238525391,
      "step": 416
    },
    {
      "epoch": 0.6672,
      "grad_norm": 2.5862340927124023,
      "learning_rate": 1.672e-06,
      "logits/chosen": -2.5549514293670654,
      "logits/rejected": -2.5289673805236816,
      "logps/chosen": -1597.8671875,
      "logps/rejected": -2262.235107421875,
      "loss": 0.0542,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9875015020370483,
      "rewards/margins": 5.429045677185059,
      "rewards/rejected": -7.4165472984313965,
      "step": 417
    },
    {
      "epoch": 0.6688,
      "grad_norm": 1.5775989294052124,
      "learning_rate": 1.664e-06,
      "logits/chosen": -2.4061152935028076,
      "logits/rejected": -2.461052894592285,
      "logps/chosen": -1158.742431640625,
      "logps/rejected": -2133.9970703125,
      "loss": 0.0621,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7805426120758057,
      "rewards/margins": 5.088565349578857,
      "rewards/rejected": -5.869108200073242,
      "step": 418
    },
    {
      "epoch": 0.6704,
      "grad_norm": 10.20503044128418,
      "learning_rate": 1.6560000000000001e-06,
      "logits/chosen": -2.6115775108337402,
      "logits/rejected": -2.584317445755005,
      "logps/chosen": -1026.039794921875,
      "logps/rejected": -1450.2962646484375,
      "loss": 0.3751,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.5090309381484985,
      "rewards/margins": 4.222803115844727,
      "rewards/rejected": -5.731833457946777,
      "step": 419
    },
    {
      "epoch": 0.672,
      "grad_norm": 9.79296588897705,
      "learning_rate": 1.6480000000000001e-06,
      "logits/chosen": -2.638401508331299,
      "logits/rejected": -2.642023801803589,
      "logps/chosen": -1259.1829833984375,
      "logps/rejected": -1907.5452880859375,
      "loss": 0.119,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.1698943376541138,
      "rewards/margins": 5.075160980224609,
      "rewards/rejected": -6.245055675506592,
      "step": 420
    },
    {
      "epoch": 0.6736,
      "grad_norm": 4.891185283660889,
      "learning_rate": 1.6400000000000002e-06,
      "logits/chosen": -2.5843491554260254,
      "logits/rejected": -2.58925724029541,
      "logps/chosen": -1115.1689453125,
      "logps/rejected": -1945.2935791015625,
      "loss": 0.1146,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.796576976776123,
      "rewards/margins": 5.043678283691406,
      "rewards/rejected": -6.840255260467529,
      "step": 421
    },
    {
      "epoch": 0.6752,
      "grad_norm": 5.650482177734375,
      "learning_rate": 1.6320000000000002e-06,
      "logits/chosen": -2.5783932209014893,
      "logits/rejected": -2.624793767929077,
      "logps/chosen": -1274.070556640625,
      "logps/rejected": -1813.1011962890625,
      "loss": 0.1728,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.547900676727295,
      "rewards/margins": 4.721770286560059,
      "rewards/rejected": -6.2696709632873535,
      "step": 422
    },
    {
      "epoch": 0.6768,
      "grad_norm": 4.641834259033203,
      "learning_rate": 1.624e-06,
      "logits/chosen": -2.622410535812378,
      "logits/rejected": -2.657175302505493,
      "logps/chosen": -974.7965087890625,
      "logps/rejected": -1144.1834716796875,
      "loss": 0.1676,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1794915199279785,
      "rewards/margins": 3.816880941390991,
      "rewards/rejected": -4.996372222900391,
      "step": 423
    },
    {
      "epoch": 0.6784,
      "grad_norm": 3.7022056579589844,
      "learning_rate": 1.616e-06,
      "logits/chosen": -2.446519374847412,
      "logits/rejected": -2.625088930130005,
      "logps/chosen": -1248.9345703125,
      "logps/rejected": -1430.8040771484375,
      "loss": 0.1209,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7056853771209717,
      "rewards/margins": 3.343656539916992,
      "rewards/rejected": -5.049341678619385,
      "step": 424
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.498464822769165,
      "learning_rate": 1.608e-06,
      "logits/chosen": -2.606583833694458,
      "logits/rejected": -2.626692771911621,
      "logps/chosen": -1354.739501953125,
      "logps/rejected": -1730.0670166015625,
      "loss": 0.0857,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.164536714553833,
      "rewards/margins": 4.410163879394531,
      "rewards/rejected": -6.574700355529785,
      "step": 425
    },
    {
      "epoch": 0.6816,
      "grad_norm": 4.914941787719727,
      "learning_rate": 1.6000000000000001e-06,
      "logits/chosen": -2.6069207191467285,
      "logits/rejected": -2.627575159072876,
      "logps/chosen": -999.9605712890625,
      "logps/rejected": -1675.655029296875,
      "loss": 0.1345,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6252093315124512,
      "rewards/margins": 3.895376682281494,
      "rewards/rejected": -5.5205864906311035,
      "step": 426
    },
    {
      "epoch": 0.6832,
      "grad_norm": 2.2894656658172607,
      "learning_rate": 1.5920000000000002e-06,
      "logits/chosen": -2.610929250717163,
      "logits/rejected": -2.6612207889556885,
      "logps/chosen": -1091.5389404296875,
      "logps/rejected": -1831.9534912109375,
      "loss": 0.0512,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2851482629776,
      "rewards/margins": 4.790820121765137,
      "rewards/rejected": -6.0759687423706055,
      "step": 427
    },
    {
      "epoch": 0.6848,
      "grad_norm": 4.485294342041016,
      "learning_rate": 1.5840000000000002e-06,
      "logits/chosen": -2.5003669261932373,
      "logits/rejected": -2.629953384399414,
      "logps/chosen": -1436.870849609375,
      "logps/rejected": -2187.970458984375,
      "loss": 0.0717,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.440500020980835,
      "rewards/margins": 5.259939670562744,
      "rewards/rejected": -6.700439929962158,
      "step": 428
    },
    {
      "epoch": 0.6864,
      "grad_norm": 2.4832327365875244,
      "learning_rate": 1.576e-06,
      "logits/chosen": -2.640103816986084,
      "logits/rejected": -2.631894111633301,
      "logps/chosen": -1509.4129638671875,
      "logps/rejected": -1568.449462890625,
      "loss": 0.0813,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.430989146232605,
      "rewards/margins": 4.312564373016357,
      "rewards/rejected": -5.74355411529541,
      "step": 429
    },
    {
      "epoch": 0.688,
      "grad_norm": 6.3030476570129395,
      "learning_rate": 1.568e-06,
      "logits/chosen": -2.581610918045044,
      "logits/rejected": -2.5403478145599365,
      "logps/chosen": -1520.05615234375,
      "logps/rejected": -2803.924560546875,
      "loss": 0.1079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.180131196975708,
      "rewards/margins": 5.090346813201904,
      "rewards/rejected": -7.270478248596191,
      "step": 430
    },
    {
      "epoch": 0.6896,
      "grad_norm": 3.961390733718872,
      "learning_rate": 1.56e-06,
      "logits/chosen": -2.6266722679138184,
      "logits/rejected": -2.635458469390869,
      "logps/chosen": -700.1935424804688,
      "logps/rejected": -1483.80224609375,
      "loss": 0.0948,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0042375326156616,
      "rewards/margins": 3.9063568115234375,
      "rewards/rejected": -4.9105939865112305,
      "step": 431
    },
    {
      "epoch": 0.6912,
      "grad_norm": 9.894449234008789,
      "learning_rate": 1.5520000000000001e-06,
      "logits/chosen": -2.6413793563842773,
      "logits/rejected": -2.6270315647125244,
      "logps/chosen": -1030.91650390625,
      "logps/rejected": -1343.795166015625,
      "loss": 0.2495,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.621957778930664,
      "rewards/margins": 3.316488742828369,
      "rewards/rejected": -4.938446521759033,
      "step": 432
    },
    {
      "epoch": 0.6928,
      "grad_norm": 7.143399715423584,
      "learning_rate": 1.5440000000000002e-06,
      "logits/chosen": -2.524240493774414,
      "logits/rejected": -2.6735990047454834,
      "logps/chosen": -1052.4483642578125,
      "logps/rejected": -1738.365234375,
      "loss": 0.1916,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.9017329216003418,
      "rewards/margins": 4.6067633628845215,
      "rewards/rejected": -6.508496284484863,
      "step": 433
    },
    {
      "epoch": 0.6944,
      "grad_norm": 10.82840347290039,
      "learning_rate": 1.536e-06,
      "logits/chosen": -2.6061813831329346,
      "logits/rejected": -2.6237289905548096,
      "logps/chosen": -1730.0616455078125,
      "logps/rejected": -1922.5455322265625,
      "loss": 0.1568,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.9909929037094116,
      "rewards/margins": 5.140088081359863,
      "rewards/rejected": -7.1310811042785645,
      "step": 434
    },
    {
      "epoch": 0.696,
      "grad_norm": 7.112972259521484,
      "learning_rate": 1.528e-06,
      "logits/chosen": -2.4946084022521973,
      "logits/rejected": -2.586878538131714,
      "logps/chosen": -1318.369140625,
      "logps/rejected": -1483.660400390625,
      "loss": 0.2042,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.1435823440551758,
      "rewards/margins": 5.466053485870361,
      "rewards/rejected": -6.609635353088379,
      "step": 435
    },
    {
      "epoch": 0.6976,
      "grad_norm": 4.958597660064697,
      "learning_rate": 1.52e-06,
      "logits/chosen": -2.4332215785980225,
      "logits/rejected": -2.465933322906494,
      "logps/chosen": -1017.56591796875,
      "logps/rejected": -1683.8367919921875,
      "loss": 0.1713,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.3578219413757324,
      "rewards/margins": 4.595547676086426,
      "rewards/rejected": -5.953370094299316,
      "step": 436
    },
    {
      "epoch": 0.6992,
      "grad_norm": 1.9002673625946045,
      "learning_rate": 1.512e-06,
      "logits/chosen": -2.444944381713867,
      "logits/rejected": -2.5676522254943848,
      "logps/chosen": -779.7554931640625,
      "logps/rejected": -1995.16162109375,
      "loss": 0.0709,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8386116027832031,
      "rewards/margins": 6.108801364898682,
      "rewards/rejected": -6.947413444519043,
      "step": 437
    },
    {
      "epoch": 0.7008,
      "grad_norm": 3.0405216217041016,
      "learning_rate": 1.5040000000000001e-06,
      "logits/chosen": -2.6715996265411377,
      "logits/rejected": -2.6708476543426514,
      "logps/chosen": -843.8721923828125,
      "logps/rejected": -1326.109130859375,
      "loss": 0.1244,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.282997965812683,
      "rewards/margins": 4.588602066040039,
      "rewards/rejected": -5.871600151062012,
      "step": 438
    },
    {
      "epoch": 0.7024,
      "grad_norm": 3.709507465362549,
      "learning_rate": 1.4960000000000002e-06,
      "logits/chosen": -2.591306209564209,
      "logits/rejected": -2.6427700519561768,
      "logps/chosen": -710.2747802734375,
      "logps/rejected": -1337.640869140625,
      "loss": 0.1128,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6972649097442627,
      "rewards/margins": 4.678470611572266,
      "rewards/rejected": -5.375735282897949,
      "step": 439
    },
    {
      "epoch": 0.704,
      "grad_norm": 5.054564952850342,
      "learning_rate": 1.488e-06,
      "logits/chosen": -2.614187479019165,
      "logits/rejected": -2.6653449535369873,
      "logps/chosen": -1324.6168212890625,
      "logps/rejected": -1642.4881591796875,
      "loss": 0.1718,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.68501615524292,
      "rewards/margins": 4.275552749633789,
      "rewards/rejected": -5.960568904876709,
      "step": 440
    },
    {
      "epoch": 0.7056,
      "grad_norm": 4.688645839691162,
      "learning_rate": 1.48e-06,
      "logits/chosen": -2.5231776237487793,
      "logits/rejected": -2.6208322048187256,
      "logps/chosen": -1076.320068359375,
      "logps/rejected": -1773.0721435546875,
      "loss": 0.0963,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1855158805847168,
      "rewards/margins": 4.557551860809326,
      "rewards/rejected": -5.743067741394043,
      "step": 441
    },
    {
      "epoch": 0.7072,
      "grad_norm": 4.231751918792725,
      "learning_rate": 1.472e-06,
      "logits/chosen": -2.569711446762085,
      "logits/rejected": -2.615420341491699,
      "logps/chosen": -1171.6365966796875,
      "logps/rejected": -1608.7919921875,
      "loss": 0.1199,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.2428221702575684,
      "rewards/margins": 4.425891876220703,
      "rewards/rejected": -6.66871452331543,
      "step": 442
    },
    {
      "epoch": 0.7088,
      "grad_norm": 2.5083727836608887,
      "learning_rate": 1.464e-06,
      "logits/chosen": -2.5270516872406006,
      "logits/rejected": -2.5665080547332764,
      "logps/chosen": -1261.3714599609375,
      "logps/rejected": -1744.580322265625,
      "loss": 0.0533,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2860074043273926,
      "rewards/margins": 4.893340110778809,
      "rewards/rejected": -6.179347515106201,
      "step": 443
    },
    {
      "epoch": 0.7104,
      "grad_norm": 2.3914010524749756,
      "learning_rate": 1.4560000000000001e-06,
      "logits/chosen": -2.549015998840332,
      "logits/rejected": -2.619748830795288,
      "logps/chosen": -969.6419677734375,
      "logps/rejected": -1607.136962890625,
      "loss": 0.1365,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0297939777374268,
      "rewards/margins": 4.112048149108887,
      "rewards/rejected": -5.141841888427734,
      "step": 444
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.442234605550766,
      "learning_rate": 1.4480000000000002e-06,
      "logits/chosen": -2.430079936981201,
      "logits/rejected": -2.5443179607391357,
      "logps/chosen": -1259.0982666015625,
      "logps/rejected": -2736.2880859375,
      "loss": 0.0089,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3355189561843872,
      "rewards/margins": 7.286812782287598,
      "rewards/rejected": -8.622331619262695,
      "step": 445
    },
    {
      "epoch": 0.7136,
      "grad_norm": 3.3921215534210205,
      "learning_rate": 1.44e-06,
      "logits/chosen": -2.471468448638916,
      "logits/rejected": -2.5712199211120605,
      "logps/chosen": -1301.0037841796875,
      "logps/rejected": -1867.414794921875,
      "loss": 0.0799,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4242334365844727,
      "rewards/margins": 5.22918176651001,
      "rewards/rejected": -6.653415679931641,
      "step": 446
    },
    {
      "epoch": 0.7152,
      "grad_norm": 2.9880166053771973,
      "learning_rate": 1.432e-06,
      "logits/chosen": -2.6229121685028076,
      "logits/rejected": -2.6534676551818848,
      "logps/chosen": -740.42822265625,
      "logps/rejected": -1563.384033203125,
      "loss": 0.108,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.03864324092865,
      "rewards/margins": 5.060420036315918,
      "rewards/rejected": -6.099063396453857,
      "step": 447
    },
    {
      "epoch": 0.7168,
      "grad_norm": 1.0012271404266357,
      "learning_rate": 1.424e-06,
      "logits/chosen": -2.574092388153076,
      "logits/rejected": -2.6434288024902344,
      "logps/chosen": -1100.36669921875,
      "logps/rejected": -1654.541015625,
      "loss": 0.0406,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3412948846817017,
      "rewards/margins": 5.437819480895996,
      "rewards/rejected": -6.779114723205566,
      "step": 448
    },
    {
      "epoch": 0.7184,
      "grad_norm": 5.35884952545166,
      "learning_rate": 1.416e-06,
      "logits/chosen": -2.4806642532348633,
      "logits/rejected": -2.5269577503204346,
      "logps/chosen": -1240.9736328125,
      "logps/rejected": -1764.469482421875,
      "loss": 0.1517,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3489878177642822,
      "rewards/margins": 3.3814306259155273,
      "rewards/rejected": -4.7304182052612305,
      "step": 449
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.7773170471191406,
      "learning_rate": 1.4080000000000001e-06,
      "logits/chosen": -2.6140732765197754,
      "logits/rejected": -2.6396214962005615,
      "logps/chosen": -1087.991943359375,
      "logps/rejected": -1918.5655517578125,
      "loss": 0.0785,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5213441848754883,
      "rewards/margins": 5.716851234436035,
      "rewards/rejected": -7.238195419311523,
      "step": 450
    },
    {
      "epoch": 0.7216,
      "grad_norm": 11.721698760986328,
      "learning_rate": 1.4000000000000001e-06,
      "logits/chosen": -2.555854320526123,
      "logits/rejected": -2.5962536334991455,
      "logps/chosen": -1446.9970703125,
      "logps/rejected": -1938.3616943359375,
      "loss": 0.1261,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.2343854904174805,
      "rewards/margins": 3.7630724906921387,
      "rewards/rejected": -5.997458457946777,
      "step": 451
    },
    {
      "epoch": 0.7232,
      "grad_norm": 1.7782045602798462,
      "learning_rate": 1.392e-06,
      "logits/chosen": -2.5241026878356934,
      "logits/rejected": -2.59805965423584,
      "logps/chosen": -919.235107421875,
      "logps/rejected": -2027.77197265625,
      "loss": 0.0454,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7061347365379333,
      "rewards/margins": 6.043833255767822,
      "rewards/rejected": -6.7499680519104,
      "step": 452
    },
    {
      "epoch": 0.7248,
      "grad_norm": 1.1657838821411133,
      "learning_rate": 1.384e-06,
      "logits/chosen": -2.52791690826416,
      "logits/rejected": -2.5797312259674072,
      "logps/chosen": -1136.6771240234375,
      "logps/rejected": -2191.826904296875,
      "loss": 0.0274,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.546157717704773,
      "rewards/margins": 5.955163955688477,
      "rewards/rejected": -7.501320838928223,
      "step": 453
    },
    {
      "epoch": 0.7264,
      "grad_norm": 2.9552102088928223,
      "learning_rate": 1.376e-06,
      "logits/chosen": -2.5794119834899902,
      "logits/rejected": -2.6420295238494873,
      "logps/chosen": -835.0146484375,
      "logps/rejected": -1550.2216796875,
      "loss": 0.1154,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.5060267448425293,
      "rewards/margins": 5.206306457519531,
      "rewards/rejected": -6.712333679199219,
      "step": 454
    },
    {
      "epoch": 0.728,
      "grad_norm": 10.227591514587402,
      "learning_rate": 1.368e-06,
      "logits/chosen": -2.5998053550720215,
      "logits/rejected": -2.669004201889038,
      "logps/chosen": -1280.17919921875,
      "logps/rejected": -2341.640869140625,
      "loss": 0.1274,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.7437134981155396,
      "rewards/margins": 5.9249067306518555,
      "rewards/rejected": -7.668621063232422,
      "step": 455
    },
    {
      "epoch": 0.7296,
      "grad_norm": 2.6118714809417725,
      "learning_rate": 1.3600000000000001e-06,
      "logits/chosen": -2.5201950073242188,
      "logits/rejected": -2.5535695552825928,
      "logps/chosen": -1322.723388671875,
      "logps/rejected": -2077.627197265625,
      "loss": 0.0847,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8678830862045288,
      "rewards/margins": 5.470590591430664,
      "rewards/rejected": -7.338473320007324,
      "step": 456
    },
    {
      "epoch": 0.7312,
      "grad_norm": 3.2759482860565186,
      "learning_rate": 1.352e-06,
      "logits/chosen": -2.526625633239746,
      "logits/rejected": -2.599979877471924,
      "logps/chosen": -905.9161987304688,
      "logps/rejected": -1379.5518798828125,
      "loss": 0.1222,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.863532304763794,
      "rewards/margins": 4.274559020996094,
      "rewards/rejected": -5.138091564178467,
      "step": 457
    },
    {
      "epoch": 0.7328,
      "grad_norm": 1.7717206478118896,
      "learning_rate": 1.344e-06,
      "logits/chosen": -2.5881829261779785,
      "logits/rejected": -2.5963735580444336,
      "logps/chosen": -695.6844482421875,
      "logps/rejected": -2092.440673828125,
      "loss": 0.0563,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0159579515457153,
      "rewards/margins": 5.602176666259766,
      "rewards/rejected": -6.618134498596191,
      "step": 458
    },
    {
      "epoch": 0.7344,
      "grad_norm": 2.2919764518737793,
      "learning_rate": 1.336e-06,
      "logits/chosen": -2.6059975624084473,
      "logits/rejected": -2.5789098739624023,
      "logps/chosen": -977.9387817382812,
      "logps/rejected": -2169.446044921875,
      "loss": 0.0563,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.604440689086914,
      "rewards/margins": 6.532371997833252,
      "rewards/rejected": -8.136812210083008,
      "step": 459
    },
    {
      "epoch": 0.736,
      "grad_norm": 2.325780153274536,
      "learning_rate": 1.328e-06,
      "logits/chosen": -2.4552738666534424,
      "logits/rejected": -2.59250545501709,
      "logps/chosen": -1302.1734619140625,
      "logps/rejected": -2447.166259765625,
      "loss": 0.0403,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.151373267173767,
      "rewards/margins": 5.669294834136963,
      "rewards/rejected": -6.820667743682861,
      "step": 460
    },
    {
      "epoch": 0.7376,
      "grad_norm": 10.448201179504395,
      "learning_rate": 1.32e-06,
      "logits/chosen": -2.497903347015381,
      "logits/rejected": -2.573526620864868,
      "logps/chosen": -1349.930419921875,
      "logps/rejected": -1663.1727294921875,
      "loss": 0.3113,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.4475558996200562,
      "rewards/margins": 5.023940086364746,
      "rewards/rejected": -6.471495151519775,
      "step": 461
    },
    {
      "epoch": 0.7392,
      "grad_norm": 2.654707670211792,
      "learning_rate": 1.3120000000000003e-06,
      "logits/chosen": -2.5580031871795654,
      "logits/rejected": -2.5737948417663574,
      "logps/chosen": -1325.8994140625,
      "logps/rejected": -2031.872802734375,
      "loss": 0.0917,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3739879131317139,
      "rewards/margins": 4.173264503479004,
      "rewards/rejected": -5.547252178192139,
      "step": 462
    },
    {
      "epoch": 0.7408,
      "grad_norm": 1.371710181236267,
      "learning_rate": 1.304e-06,
      "logits/chosen": -2.554603099822998,
      "logits/rejected": -2.6291089057922363,
      "logps/chosen": -970.2869873046875,
      "logps/rejected": -1787.84912109375,
      "loss": 0.0552,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.272876262664795,
      "rewards/margins": 5.913074970245361,
      "rewards/rejected": -7.185952186584473,
      "step": 463
    },
    {
      "epoch": 0.7424,
      "grad_norm": 17.970703125,
      "learning_rate": 1.296e-06,
      "logits/chosen": -2.5743889808654785,
      "logits/rejected": -2.5959646701812744,
      "logps/chosen": -1190.17578125,
      "logps/rejected": -1664.668701171875,
      "loss": 0.5541,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.2387471199035645,
      "rewards/margins": 3.9775290489196777,
      "rewards/rejected": -5.216275691986084,
      "step": 464
    },
    {
      "epoch": 0.744,
      "grad_norm": 3.4864649772644043,
      "learning_rate": 1.288e-06,
      "logits/chosen": -2.5668394565582275,
      "logits/rejected": -2.6319031715393066,
      "logps/chosen": -657.5660400390625,
      "logps/rejected": -1049.52978515625,
      "loss": 0.119,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9082112908363342,
      "rewards/margins": 3.3654298782348633,
      "rewards/rejected": -4.273641109466553,
      "step": 465
    },
    {
      "epoch": 0.7456,
      "grad_norm": 1.6972591876983643,
      "learning_rate": 1.28e-06,
      "logits/chosen": -2.5797529220581055,
      "logits/rejected": -2.594784736633301,
      "logps/chosen": -892.8880615234375,
      "logps/rejected": -1751.5609130859375,
      "loss": 0.0569,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.413122534751892,
      "rewards/margins": 4.839678764343262,
      "rewards/rejected": -6.252801418304443,
      "step": 466
    },
    {
      "epoch": 0.7472,
      "grad_norm": 1.0732985734939575,
      "learning_rate": 1.2720000000000003e-06,
      "logits/chosen": -2.5569024085998535,
      "logits/rejected": -2.59420108795166,
      "logps/chosen": -1469.866943359375,
      "logps/rejected": -2358.10107421875,
      "loss": 0.0273,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1789226531982422,
      "rewards/margins": 7.313340187072754,
      "rewards/rejected": -8.492263793945312,
      "step": 467
    },
    {
      "epoch": 0.7488,
      "grad_norm": 4.154730319976807,
      "learning_rate": 1.2640000000000003e-06,
      "logits/chosen": -2.566094160079956,
      "logits/rejected": -2.6620359420776367,
      "logps/chosen": -627.9725341796875,
      "logps/rejected": -1561.80224609375,
      "loss": 0.1224,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9723381996154785,
      "rewards/margins": 5.648221969604492,
      "rewards/rejected": -6.6205596923828125,
      "step": 468
    },
    {
      "epoch": 0.7504,
      "grad_norm": 2.7566425800323486,
      "learning_rate": 1.256e-06,
      "logits/chosen": -2.5670359134674072,
      "logits/rejected": -2.5743141174316406,
      "logps/chosen": -1074.1279296875,
      "logps/rejected": -1600.087890625,
      "loss": 0.0624,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1990491151809692,
      "rewards/margins": 4.5999321937561035,
      "rewards/rejected": -5.798981666564941,
      "step": 469
    },
    {
      "epoch": 0.752,
      "grad_norm": 7.22980260848999,
      "learning_rate": 1.248e-06,
      "logits/chosen": -2.5817065238952637,
      "logits/rejected": -2.648240089416504,
      "logps/chosen": -876.6522216796875,
      "logps/rejected": -1686.72265625,
      "loss": 0.1855,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.578993320465088,
      "rewards/margins": 5.5401692390441895,
      "rewards/rejected": -7.119162082672119,
      "step": 470
    },
    {
      "epoch": 0.7536,
      "grad_norm": 1.2690112590789795,
      "learning_rate": 1.2400000000000002e-06,
      "logits/chosen": -2.540203094482422,
      "logits/rejected": -2.5725436210632324,
      "logps/chosen": -972.2258911132812,
      "logps/rejected": -1759.8013916015625,
      "loss": 0.0648,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8691139221191406,
      "rewards/margins": 5.795832633972168,
      "rewards/rejected": -6.66494607925415,
      "step": 471
    },
    {
      "epoch": 0.7552,
      "grad_norm": 2.3537139892578125,
      "learning_rate": 1.2320000000000002e-06,
      "logits/chosen": -2.4971418380737305,
      "logits/rejected": -2.612431049346924,
      "logps/chosen": -879.303955078125,
      "logps/rejected": -1728.2705078125,
      "loss": 0.0821,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1167631149291992,
      "rewards/margins": 5.378955841064453,
      "rewards/rejected": -6.495718479156494,
      "step": 472
    },
    {
      "epoch": 0.7568,
      "grad_norm": 6.803323745727539,
      "learning_rate": 1.224e-06,
      "logits/chosen": -2.59975004196167,
      "logits/rejected": -2.6307125091552734,
      "logps/chosen": -1482.3201904296875,
      "logps/rejected": -1875.154541015625,
      "loss": 0.097,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.8950496912002563,
      "rewards/margins": 4.3787689208984375,
      "rewards/rejected": -6.2738189697265625,
      "step": 473
    },
    {
      "epoch": 0.7584,
      "grad_norm": 0.8644420504570007,
      "learning_rate": 1.216e-06,
      "logits/chosen": -2.5417213439941406,
      "logits/rejected": -2.60429310798645,
      "logps/chosen": -2116.98779296875,
      "logps/rejected": -2239.85302734375,
      "loss": 0.0182,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.376417875289917,
      "rewards/margins": 6.299623012542725,
      "rewards/rejected": -7.676042079925537,
      "step": 474
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.7145544290542603,
      "learning_rate": 1.2080000000000001e-06,
      "logits/chosen": -2.517021656036377,
      "logits/rejected": -2.561631202697754,
      "logps/chosen": -1094.1927490234375,
      "logps/rejected": -2223.0244140625,
      "loss": 0.0221,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2185310125350952,
      "rewards/margins": 6.744261741638184,
      "rewards/rejected": -7.96279239654541,
      "step": 475
    },
    {
      "epoch": 0.7616,
      "grad_norm": 0.5921348929405212,
      "learning_rate": 1.2000000000000002e-06,
      "logits/chosen": -2.5848941802978516,
      "logits/rejected": -2.619981288909912,
      "logps/chosen": -978.6637573242188,
      "logps/rejected": -1733.8564453125,
      "loss": 0.0197,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4275627136230469,
      "rewards/margins": 6.306221961975098,
      "rewards/rejected": -7.733784198760986,
      "step": 476
    },
    {
      "epoch": 0.7632,
      "grad_norm": 10.879152297973633,
      "learning_rate": 1.1920000000000002e-06,
      "logits/chosen": -2.606736660003662,
      "logits/rejected": -2.6543405055999756,
      "logps/chosen": -949.75439453125,
      "logps/rejected": -1676.4569091796875,
      "loss": 0.2028,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.5938037633895874,
      "rewards/margins": 4.814210414886475,
      "rewards/rejected": -6.408013820648193,
      "step": 477
    },
    {
      "epoch": 0.7648,
      "grad_norm": 0.8782214522361755,
      "learning_rate": 1.1840000000000002e-06,
      "logits/chosen": -2.6418728828430176,
      "logits/rejected": -2.6779630184173584,
      "logps/chosen": -1419.9630126953125,
      "logps/rejected": -2405.954833984375,
      "loss": 0.0227,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9828201532363892,
      "rewards/margins": 5.5592169761657715,
      "rewards/rejected": -7.542037010192871,
      "step": 478
    },
    {
      "epoch": 0.7664,
      "grad_norm": 1.8255282640457153,
      "learning_rate": 1.176e-06,
      "logits/chosen": -2.2798752784729004,
      "logits/rejected": -2.6074111461639404,
      "logps/chosen": -1554.723876953125,
      "logps/rejected": -2111.47216796875,
      "loss": 0.0393,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8458272218704224,
      "rewards/margins": 4.444005966186523,
      "rewards/rejected": -6.2898335456848145,
      "step": 479
    },
    {
      "epoch": 0.768,
      "grad_norm": 2.211519479751587,
      "learning_rate": 1.168e-06,
      "logits/chosen": -2.690028190612793,
      "logits/rejected": -2.6274425983428955,
      "logps/chosen": -1254.675537109375,
      "logps/rejected": -2213.505615234375,
      "loss": 0.0681,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6088271141052246,
      "rewards/margins": 5.239823818206787,
      "rewards/rejected": -6.848650932312012,
      "step": 480
    },
    {
      "epoch": 0.7696,
      "grad_norm": 2.006070375442505,
      "learning_rate": 1.1600000000000001e-06,
      "logits/chosen": -2.6064562797546387,
      "logits/rejected": -2.6187291145324707,
      "logps/chosen": -875.6392211914062,
      "logps/rejected": -1648.4110107421875,
      "loss": 0.0497,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5237689018249512,
      "rewards/margins": 4.534499645233154,
      "rewards/rejected": -6.058268070220947,
      "step": 481
    },
    {
      "epoch": 0.7712,
      "grad_norm": 1.9435981512069702,
      "learning_rate": 1.1520000000000002e-06,
      "logits/chosen": -2.362210750579834,
      "logits/rejected": -2.582644462585449,
      "logps/chosen": -746.48876953125,
      "logps/rejected": -1633.66943359375,
      "loss": 0.094,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2911713123321533,
      "rewards/margins": 5.408824920654297,
      "rewards/rejected": -6.6999969482421875,
      "step": 482
    },
    {
      "epoch": 0.7728,
      "grad_norm": 7.07622766494751,
      "learning_rate": 1.1440000000000002e-06,
      "logits/chosen": -2.555959939956665,
      "logits/rejected": -2.575045108795166,
      "logps/chosen": -1121.687255859375,
      "logps/rejected": -1639.87158203125,
      "loss": 0.1819,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.7993106842041016,
      "rewards/margins": 3.628060817718506,
      "rewards/rejected": -5.427371978759766,
      "step": 483
    },
    {
      "epoch": 0.7744,
      "grad_norm": 1.6424553394317627,
      "learning_rate": 1.1360000000000002e-06,
      "logits/chosen": -2.601195812225342,
      "logits/rejected": -2.659416675567627,
      "logps/chosen": -901.9813842773438,
      "logps/rejected": -1927.3280029296875,
      "loss": 0.0558,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9627519845962524,
      "rewards/margins": 6.584030628204346,
      "rewards/rejected": -7.546782493591309,
      "step": 484
    },
    {
      "epoch": 0.776,
      "grad_norm": 1.5394636392593384,
      "learning_rate": 1.128e-06,
      "logits/chosen": -2.4399609565734863,
      "logits/rejected": -2.544044017791748,
      "logps/chosen": -1165.9962158203125,
      "logps/rejected": -2196.02978515625,
      "loss": 0.0515,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.362899899482727,
      "rewards/margins": 5.172306060791016,
      "rewards/rejected": -6.535205841064453,
      "step": 485
    },
    {
      "epoch": 0.7776,
      "grad_norm": 7.296657562255859,
      "learning_rate": 1.12e-06,
      "logits/chosen": -2.5903408527374268,
      "logits/rejected": -2.60172438621521,
      "logps/chosen": -743.404052734375,
      "logps/rejected": -1479.65869140625,
      "loss": 0.1774,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.2814239263534546,
      "rewards/margins": 3.6012697219848633,
      "rewards/rejected": -4.882693767547607,
      "step": 486
    },
    {
      "epoch": 0.7792,
      "grad_norm": 5.351244926452637,
      "learning_rate": 1.1120000000000001e-06,
      "logits/chosen": -2.538182497024536,
      "logits/rejected": -2.611287832260132,
      "logps/chosen": -857.32861328125,
      "logps/rejected": -1814.1982421875,
      "loss": 0.1726,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.576131820678711,
      "rewards/margins": 6.148415565490723,
      "rewards/rejected": -7.724547863006592,
      "step": 487
    },
    {
      "epoch": 0.7808,
      "grad_norm": 0.8505617380142212,
      "learning_rate": 1.1040000000000001e-06,
      "logits/chosen": -2.5315191745758057,
      "logits/rejected": -2.5812718868255615,
      "logps/chosen": -1261.971923828125,
      "logps/rejected": -1929.3092041015625,
      "loss": 0.0282,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3127344846725464,
      "rewards/margins": 6.1830735206604,
      "rewards/rejected": -7.495808124542236,
      "step": 488
    },
    {
      "epoch": 0.7824,
      "grad_norm": 3.9044528007507324,
      "learning_rate": 1.0960000000000002e-06,
      "logits/chosen": -2.419881582260132,
      "logits/rejected": -2.5157575607299805,
      "logps/chosen": -736.06591796875,
      "logps/rejected": -1588.597412109375,
      "loss": 0.0935,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.143357515335083,
      "rewards/margins": 4.5950927734375,
      "rewards/rejected": -5.738450050354004,
      "step": 489
    },
    {
      "epoch": 0.784,
      "grad_norm": 2.794546127319336,
      "learning_rate": 1.088e-06,
      "logits/chosen": -2.491156816482544,
      "logits/rejected": -2.5636794567108154,
      "logps/chosen": -720.31103515625,
      "logps/rejected": -2081.15478515625,
      "loss": 0.1176,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9748365879058838,
      "rewards/margins": 5.508779048919678,
      "rewards/rejected": -6.483614921569824,
      "step": 490
    },
    {
      "epoch": 0.7856,
      "grad_norm": 2.7246692180633545,
      "learning_rate": 1.08e-06,
      "logits/chosen": -2.463705539703369,
      "logits/rejected": -2.6054041385650635,
      "logps/chosen": -1386.3824462890625,
      "logps/rejected": -2160.030517578125,
      "loss": 0.0932,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3385775089263916,
      "rewards/margins": 4.203049182891846,
      "rewards/rejected": -5.541626930236816,
      "step": 491
    },
    {
      "epoch": 0.7872,
      "grad_norm": 4.069042682647705,
      "learning_rate": 1.072e-06,
      "logits/chosen": -2.5964202880859375,
      "logits/rejected": -2.6080853939056396,
      "logps/chosen": -1301.2982177734375,
      "logps/rejected": -1863.71728515625,
      "loss": 0.0692,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5807973146438599,
      "rewards/margins": 4.75507116317749,
      "rewards/rejected": -6.335869312286377,
      "step": 492
    },
    {
      "epoch": 0.7888,
      "grad_norm": 9.751957893371582,
      "learning_rate": 1.064e-06,
      "logits/chosen": -2.5298376083374023,
      "logits/rejected": -2.6039230823516846,
      "logps/chosen": -1583.7987060546875,
      "logps/rejected": -2038.199462890625,
      "loss": 0.2847,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.981618046760559,
      "rewards/margins": 3.7425501346588135,
      "rewards/rejected": -5.724168300628662,
      "step": 493
    },
    {
      "epoch": 0.7904,
      "grad_norm": 1.7352269887924194,
      "learning_rate": 1.0560000000000001e-06,
      "logits/chosen": -2.558953285217285,
      "logits/rejected": -2.5962791442871094,
      "logps/chosen": -975.240478515625,
      "logps/rejected": -1824.2220458984375,
      "loss": 0.0851,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5210022926330566,
      "rewards/margins": 4.579076766967773,
      "rewards/rejected": -6.100079536437988,
      "step": 494
    },
    {
      "epoch": 0.792,
      "grad_norm": 9.94740104675293,
      "learning_rate": 1.0480000000000002e-06,
      "logits/chosen": -2.5468904972076416,
      "logits/rejected": -2.580547332763672,
      "logps/chosen": -671.1109619140625,
      "logps/rejected": -1136.3919677734375,
      "loss": 0.3716,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.5786505937576294,
      "rewards/margins": 3.48500919342041,
      "rewards/rejected": -5.06365966796875,
      "step": 495
    },
    {
      "epoch": 0.7936,
      "grad_norm": 1.1070451736450195,
      "learning_rate": 1.04e-06,
      "logits/chosen": -2.6500895023345947,
      "logits/rejected": -2.6646456718444824,
      "logps/chosen": -1378.921875,
      "logps/rejected": -2066.4619140625,
      "loss": 0.0279,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8015285730361938,
      "rewards/margins": 5.684294700622559,
      "rewards/rejected": -7.485823631286621,
      "step": 496
    },
    {
      "epoch": 0.7952,
      "grad_norm": 7.311251640319824,
      "learning_rate": 1.032e-06,
      "logits/chosen": -2.585796356201172,
      "logits/rejected": -2.608569383621216,
      "logps/chosen": -1549.65869140625,
      "logps/rejected": -2093.762451171875,
      "loss": 0.1448,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.2841436862945557,
      "rewards/margins": 4.977880954742432,
      "rewards/rejected": -7.262023448944092,
      "step": 497
    },
    {
      "epoch": 0.7968,
      "grad_norm": 6.503884315490723,
      "learning_rate": 1.024e-06,
      "logits/chosen": -2.603691816329956,
      "logits/rejected": -2.6594784259796143,
      "logps/chosen": -1322.146484375,
      "logps/rejected": -2075.64111328125,
      "loss": 0.0947,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.6936440467834473,
      "rewards/margins": 6.0967302322387695,
      "rewards/rejected": -7.790374279022217,
      "step": 498
    },
    {
      "epoch": 0.7984,
      "grad_norm": 1.6917996406555176,
      "learning_rate": 1.016e-06,
      "logits/chosen": -2.5982096195220947,
      "logits/rejected": -2.636033773422241,
      "logps/chosen": -1059.775390625,
      "logps/rejected": -1801.336181640625,
      "loss": 0.0319,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6803590059280396,
      "rewards/margins": 5.211846828460693,
      "rewards/rejected": -6.892205715179443,
      "step": 499
    },
    {
      "epoch": 0.8,
      "grad_norm": 7.636498928070068,
      "learning_rate": 1.0080000000000001e-06,
      "logits/chosen": -2.4621944427490234,
      "logits/rejected": -2.5209836959838867,
      "logps/chosen": -1527.8797607421875,
      "logps/rejected": -2277.683349609375,
      "loss": 0.2028,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.2968969345092773,
      "rewards/margins": 6.155980110168457,
      "rewards/rejected": -8.452877044677734,
      "step": 500
    },
    {
      "epoch": 0.8016,
      "grad_norm": 7.533388137817383,
      "learning_rate": 1.0000000000000002e-06,
      "logits/chosen": -2.5055456161499023,
      "logits/rejected": -2.6116392612457275,
      "logps/chosen": -993.144287109375,
      "logps/rejected": -1861.9114990234375,
      "loss": 0.0703,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3504374027252197,
      "rewards/margins": 4.826178550720215,
      "rewards/rejected": -6.176616191864014,
      "step": 501
    },
    {
      "epoch": 0.8032,
      "grad_norm": 1.598889708518982,
      "learning_rate": 9.92e-07,
      "logits/chosen": -2.4697482585906982,
      "logits/rejected": -2.6084136962890625,
      "logps/chosen": -633.5638427734375,
      "logps/rejected": -1174.72119140625,
      "loss": 0.0844,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9543217420578003,
      "rewards/margins": 4.1390790939331055,
      "rewards/rejected": -5.093400955200195,
      "step": 502
    },
    {
      "epoch": 0.8048,
      "grad_norm": 5.707846164703369,
      "learning_rate": 9.84e-07,
      "logits/chosen": -2.5839667320251465,
      "logits/rejected": -2.6146559715270996,
      "logps/chosen": -1039.471435546875,
      "logps/rejected": -1556.281005859375,
      "loss": 0.1308,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4365129470825195,
      "rewards/margins": 4.516627311706543,
      "rewards/rejected": -5.9531402587890625,
      "step": 503
    },
    {
      "epoch": 0.8064,
      "grad_norm": 1.522749900817871,
      "learning_rate": 9.76e-07,
      "logits/chosen": -2.5731399059295654,
      "logits/rejected": -2.624145984649658,
      "logps/chosen": -852.3274536132812,
      "logps/rejected": -1568.948486328125,
      "loss": 0.0484,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.08139967918396,
      "rewards/margins": 5.239947319030762,
      "rewards/rejected": -6.321347236633301,
      "step": 504
    },
    {
      "epoch": 0.808,
      "grad_norm": 5.2037858963012695,
      "learning_rate": 9.68e-07,
      "logits/chosen": -2.512267589569092,
      "logits/rejected": -2.6230034828186035,
      "logps/chosen": -978.53173828125,
      "logps/rejected": -1588.862548828125,
      "loss": 0.1178,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.4505237340927124,
      "rewards/margins": 4.718364238739014,
      "rewards/rejected": -6.168888092041016,
      "step": 505
    },
    {
      "epoch": 0.8096,
      "grad_norm": 3.3664987087249756,
      "learning_rate": 9.600000000000001e-07,
      "logits/chosen": -2.6343839168548584,
      "logits/rejected": -2.647355794906616,
      "logps/chosen": -842.517333984375,
      "logps/rejected": -1678.850341796875,
      "loss": 0.1112,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3297357559204102,
      "rewards/margins": 5.423060417175293,
      "rewards/rejected": -6.752796173095703,
      "step": 506
    },
    {
      "epoch": 0.8112,
      "grad_norm": 8.933133125305176,
      "learning_rate": 9.520000000000002e-07,
      "logits/chosen": -2.5663106441497803,
      "logits/rejected": -2.6129109859466553,
      "logps/chosen": -1511.1455078125,
      "logps/rejected": -1948.3143310546875,
      "loss": 0.1921,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.689269542694092,
      "rewards/margins": 4.118910312652588,
      "rewards/rejected": -6.80817985534668,
      "step": 507
    },
    {
      "epoch": 0.8128,
      "grad_norm": 9.185649871826172,
      "learning_rate": 9.440000000000001e-07,
      "logits/chosen": -2.5528080463409424,
      "logits/rejected": -2.6424808502197266,
      "logps/chosen": -1483.5438232421875,
      "logps/rejected": -2547.832275390625,
      "loss": 0.1381,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.5817314386367798,
      "rewards/margins": 6.71658182144165,
      "rewards/rejected": -8.29831314086914,
      "step": 508
    },
    {
      "epoch": 0.8144,
      "grad_norm": 3.1978256702423096,
      "learning_rate": 9.360000000000001e-07,
      "logits/chosen": -2.573697566986084,
      "logits/rejected": -2.564434051513672,
      "logps/chosen": -1173.3900146484375,
      "logps/rejected": -1713.691650390625,
      "loss": 0.1023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.903385043144226,
      "rewards/margins": 3.303966522216797,
      "rewards/rejected": -5.207351207733154,
      "step": 509
    },
    {
      "epoch": 0.816,
      "grad_norm": 3.489551305770874,
      "learning_rate": 9.28e-07,
      "logits/chosen": -2.5762205123901367,
      "logits/rejected": -2.6362786293029785,
      "logps/chosen": -865.28466796875,
      "logps/rejected": -1320.2752685546875,
      "loss": 0.0817,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4503952264785767,
      "rewards/margins": 3.668612480163574,
      "rewards/rejected": -5.119007587432861,
      "step": 510
    },
    {
      "epoch": 0.8176,
      "grad_norm": 1.6312222480773926,
      "learning_rate": 9.200000000000001e-07,
      "logits/chosen": -2.419515371322632,
      "logits/rejected": -2.5210633277893066,
      "logps/chosen": -998.0565185546875,
      "logps/rejected": -1736.0550537109375,
      "loss": 0.0883,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2871615886688232,
      "rewards/margins": 5.065634727478027,
      "rewards/rejected": -6.352795600891113,
      "step": 511
    },
    {
      "epoch": 0.8192,
      "grad_norm": 8.713788032531738,
      "learning_rate": 9.120000000000001e-07,
      "logits/chosen": -2.5589542388916016,
      "logits/rejected": -2.6082704067230225,
      "logps/chosen": -797.4918212890625,
      "logps/rejected": -1542.3988037109375,
      "loss": 0.1311,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.5622215270996094,
      "rewards/margins": 4.506465911865234,
      "rewards/rejected": -6.068687438964844,
      "step": 512
    },
    {
      "epoch": 0.8208,
      "grad_norm": 0.6600899696350098,
      "learning_rate": 9.04e-07,
      "logits/chosen": -2.5498290061950684,
      "logits/rejected": -2.591310977935791,
      "logps/chosen": -885.635009765625,
      "logps/rejected": -2080.743408203125,
      "loss": 0.0194,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9530148506164551,
      "rewards/margins": 5.721810817718506,
      "rewards/rejected": -6.674825191497803,
      "step": 513
    },
    {
      "epoch": 0.8224,
      "grad_norm": 4.1309380531311035,
      "learning_rate": 8.960000000000001e-07,
      "logits/chosen": -2.6031556129455566,
      "logits/rejected": -2.642364263534546,
      "logps/chosen": -1443.8743896484375,
      "logps/rejected": -1729.4625244140625,
      "loss": 0.1214,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.031916618347168,
      "rewards/margins": 3.993001699447632,
      "rewards/rejected": -6.024918079376221,
      "step": 514
    },
    {
      "epoch": 0.824,
      "grad_norm": 2.398883581161499,
      "learning_rate": 8.880000000000001e-07,
      "logits/chosen": -2.537196636199951,
      "logits/rejected": -2.6119813919067383,
      "logps/chosen": -812.8494873046875,
      "logps/rejected": -1857.4686279296875,
      "loss": 0.066,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0536258220672607,
      "rewards/margins": 5.5419416427612305,
      "rewards/rejected": -6.59556770324707,
      "step": 515
    },
    {
      "epoch": 0.8256,
      "grad_norm": 2.064972400665283,
      "learning_rate": 8.8e-07,
      "logits/chosen": -2.4630560874938965,
      "logits/rejected": -2.591872215270996,
      "logps/chosen": -1272.779541015625,
      "logps/rejected": -2006.7603759765625,
      "loss": 0.0991,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.595503807067871,
      "rewards/margins": 5.918760299682617,
      "rewards/rejected": -7.514264106750488,
      "step": 516
    },
    {
      "epoch": 0.8272,
      "grad_norm": 29.331317901611328,
      "learning_rate": 8.720000000000001e-07,
      "logits/chosen": -2.530346632003784,
      "logits/rejected": -2.571760892868042,
      "logps/chosen": -1367.9224853515625,
      "logps/rejected": -2011.703369140625,
      "loss": 0.2497,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.9701024293899536,
      "rewards/margins": 4.764176845550537,
      "rewards/rejected": -6.734278678894043,
      "step": 517
    },
    {
      "epoch": 0.8288,
      "grad_norm": 2.34732985496521,
      "learning_rate": 8.640000000000001e-07,
      "logits/chosen": -2.594238519668579,
      "logits/rejected": -2.633974313735962,
      "logps/chosen": -983.2596435546875,
      "logps/rejected": -1612.7041015625,
      "loss": 0.0796,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.63201904296875,
      "rewards/margins": 4.637286186218262,
      "rewards/rejected": -6.269305229187012,
      "step": 518
    },
    {
      "epoch": 0.8304,
      "grad_norm": 13.674381256103516,
      "learning_rate": 8.56e-07,
      "logits/chosen": -2.5839731693267822,
      "logits/rejected": -2.6187171936035156,
      "logps/chosen": -786.5847778320312,
      "logps/rejected": -1739.3978271484375,
      "loss": 0.2334,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.2694321870803833,
      "rewards/margins": 5.322177410125732,
      "rewards/rejected": -6.591609954833984,
      "step": 519
    },
    {
      "epoch": 0.832,
      "grad_norm": 1.017586588859558,
      "learning_rate": 8.480000000000001e-07,
      "logits/chosen": -2.5627362728118896,
      "logits/rejected": -2.61301326751709,
      "logps/chosen": -1214.112548828125,
      "logps/rejected": -1839.2427978515625,
      "loss": 0.034,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.633189082145691,
      "rewards/margins": 4.9718427658081055,
      "rewards/rejected": -6.605031967163086,
      "step": 520
    },
    {
      "epoch": 0.8336,
      "grad_norm": 11.885437965393066,
      "learning_rate": 8.400000000000001e-07,
      "logits/chosen": -2.600853204727173,
      "logits/rejected": -2.6069929599761963,
      "logps/chosen": -736.1443481445312,
      "logps/rejected": -1629.9349365234375,
      "loss": 0.3177,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.0449483394622803,
      "rewards/margins": 3.9957618713378906,
      "rewards/rejected": -5.040709972381592,
      "step": 521
    },
    {
      "epoch": 0.8352,
      "grad_norm": 3.1827638149261475,
      "learning_rate": 8.32e-07,
      "logits/chosen": -2.5907366275787354,
      "logits/rejected": -2.683547258377075,
      "logps/chosen": -1366.57763671875,
      "logps/rejected": -1829.4632568359375,
      "loss": 0.0575,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.786751627922058,
      "rewards/margins": 5.729864120483398,
      "rewards/rejected": -7.516616344451904,
      "step": 522
    },
    {
      "epoch": 0.8368,
      "grad_norm": 0.9783771634101868,
      "learning_rate": 8.240000000000001e-07,
      "logits/chosen": -2.5782430171966553,
      "logits/rejected": -2.583047389984131,
      "logps/chosen": -647.4525146484375,
      "logps/rejected": -1430.133056640625,
      "loss": 0.0308,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1627591848373413,
      "rewards/margins": 5.948238372802734,
      "rewards/rejected": -7.110998153686523,
      "step": 523
    },
    {
      "epoch": 0.8384,
      "grad_norm": 8.978615760803223,
      "learning_rate": 8.160000000000001e-07,
      "logits/chosen": -2.6449639797210693,
      "logits/rejected": -2.6337156295776367,
      "logps/chosen": -1671.717041015625,
      "logps/rejected": -2151.72998046875,
      "loss": 0.1964,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.4307398796081543,
      "rewards/margins": 4.470363616943359,
      "rewards/rejected": -6.901103973388672,
      "step": 524
    },
    {
      "epoch": 0.84,
      "grad_norm": 4.073187828063965,
      "learning_rate": 8.08e-07,
      "logits/chosen": -2.596778392791748,
      "logits/rejected": -2.6235156059265137,
      "logps/chosen": -1438.1409912109375,
      "logps/rejected": -1561.128173828125,
      "loss": 0.1081,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.6992958784103394,
      "rewards/margins": 4.286977291107178,
      "rewards/rejected": -5.98627233505249,
      "step": 525
    },
    {
      "epoch": 0.8416,
      "grad_norm": 1.2218223810195923,
      "learning_rate": 8.000000000000001e-07,
      "logits/chosen": -2.513453960418701,
      "logits/rejected": -2.6232006549835205,
      "logps/chosen": -1059.9315185546875,
      "logps/rejected": -1312.021728515625,
      "loss": 0.0524,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4232760667800903,
      "rewards/margins": 4.773440361022949,
      "rewards/rejected": -6.19671630859375,
      "step": 526
    },
    {
      "epoch": 0.8432,
      "grad_norm": 8.818254470825195,
      "learning_rate": 7.920000000000001e-07,
      "logits/chosen": -2.567969799041748,
      "logits/rejected": -2.597161293029785,
      "logps/chosen": -1616.70654296875,
      "logps/rejected": -1911.6199951171875,
      "loss": 0.2717,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.6263031959533691,
      "rewards/margins": 3.4242348670959473,
      "rewards/rejected": -5.050538539886475,
      "step": 527
    },
    {
      "epoch": 0.8448,
      "grad_norm": 1.1440922021865845,
      "learning_rate": 7.84e-07,
      "logits/chosen": -2.53141713142395,
      "logits/rejected": -2.6126248836517334,
      "logps/chosen": -1075.278076171875,
      "logps/rejected": -1821.382568359375,
      "loss": 0.0326,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.55419921875,
      "rewards/margins": 5.910405158996582,
      "rewards/rejected": -7.464604377746582,
      "step": 528
    },
    {
      "epoch": 0.8464,
      "grad_norm": 2.2076146602630615,
      "learning_rate": 7.760000000000001e-07,
      "logits/chosen": -2.4473659992218018,
      "logits/rejected": -2.6122210025787354,
      "logps/chosen": -984.1831665039062,
      "logps/rejected": -1653.3223876953125,
      "loss": 0.064,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.447005271911621,
      "rewards/margins": 4.827670574188232,
      "rewards/rejected": -6.2746758460998535,
      "step": 529
    },
    {
      "epoch": 0.848,
      "grad_norm": 2.9337949752807617,
      "learning_rate": 7.68e-07,
      "logits/chosen": -2.576009750366211,
      "logits/rejected": -2.6164374351501465,
      "logps/chosen": -1006.3280639648438,
      "logps/rejected": -1742.397705078125,
      "loss": 0.0836,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6809170246124268,
      "rewards/margins": 4.736141204833984,
      "rewards/rejected": -6.41705846786499,
      "step": 530
    },
    {
      "epoch": 0.8496,
      "grad_norm": 2.9657952785491943,
      "learning_rate": 7.6e-07,
      "logits/chosen": -2.5132718086242676,
      "logits/rejected": -2.618574619293213,
      "logps/chosen": -1217.545654296875,
      "logps/rejected": -1997.0498046875,
      "loss": 0.0579,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.527422308921814,
      "rewards/margins": 6.880880355834961,
      "rewards/rejected": -8.408302307128906,
      "step": 531
    },
    {
      "epoch": 0.8512,
      "grad_norm": 2.0797839164733887,
      "learning_rate": 7.520000000000001e-07,
      "logits/chosen": -2.5227742195129395,
      "logits/rejected": -2.559122323989868,
      "logps/chosen": -1073.118408203125,
      "logps/rejected": -1992.3973388671875,
      "loss": 0.0642,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0472474098205566,
      "rewards/margins": 4.216313362121582,
      "rewards/rejected": -5.263560771942139,
      "step": 532
    },
    {
      "epoch": 0.8528,
      "grad_norm": 9.224590301513672,
      "learning_rate": 7.44e-07,
      "logits/chosen": -2.6049442291259766,
      "logits/rejected": -2.6016347408294678,
      "logps/chosen": -1192.260986328125,
      "logps/rejected": -2007.385986328125,
      "loss": 0.1704,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.7874226570129395,
      "rewards/margins": 4.550432205200195,
      "rewards/rejected": -6.337854862213135,
      "step": 533
    },
    {
      "epoch": 0.8544,
      "grad_norm": 6.91942834854126,
      "learning_rate": 7.36e-07,
      "logits/chosen": -2.522104263305664,
      "logits/rejected": -2.5496630668640137,
      "logps/chosen": -1075.44775390625,
      "logps/rejected": -1776.8665771484375,
      "loss": 0.1328,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.6971821784973145,
      "rewards/margins": 6.453934669494629,
      "rewards/rejected": -8.151116371154785,
      "step": 534
    },
    {
      "epoch": 0.856,
      "grad_norm": 4.508674144744873,
      "learning_rate": 7.280000000000001e-07,
      "logits/chosen": -2.498924970626831,
      "logits/rejected": -2.587125301361084,
      "logps/chosen": -1063.6640625,
      "logps/rejected": -1875.3203125,
      "loss": 0.0917,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.652224063873291,
      "rewards/margins": 5.032947540283203,
      "rewards/rejected": -6.685171127319336,
      "step": 535
    },
    {
      "epoch": 0.8576,
      "grad_norm": 4.770247936248779,
      "learning_rate": 7.2e-07,
      "logits/chosen": -2.5189530849456787,
      "logits/rejected": -2.6442391872406006,
      "logps/chosen": -686.106201171875,
      "logps/rejected": -1267.6112060546875,
      "loss": 0.1745,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9128559231758118,
      "rewards/margins": 3.5700745582580566,
      "rewards/rejected": -4.482930660247803,
      "step": 536
    },
    {
      "epoch": 0.8592,
      "grad_norm": 3.4746291637420654,
      "learning_rate": 7.12e-07,
      "logits/chosen": -2.6108531951904297,
      "logits/rejected": -2.6344637870788574,
      "logps/chosen": -1156.85888671875,
      "logps/rejected": -1881.620361328125,
      "loss": 0.0501,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6990187168121338,
      "rewards/margins": 5.645461559295654,
      "rewards/rejected": -7.344479560852051,
      "step": 537
    },
    {
      "epoch": 0.8608,
      "grad_norm": 3.3372886180877686,
      "learning_rate": 7.040000000000001e-07,
      "logits/chosen": -2.4826130867004395,
      "logits/rejected": -2.6065680980682373,
      "logps/chosen": -1102.070556640625,
      "logps/rejected": -1278.6298828125,
      "loss": 0.1022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.844080924987793,
      "rewards/margins": 3.6698849201202393,
      "rewards/rejected": -5.513965606689453,
      "step": 538
    },
    {
      "epoch": 0.8624,
      "grad_norm": 1.8177176713943481,
      "learning_rate": 6.96e-07,
      "logits/chosen": -2.480719566345215,
      "logits/rejected": -2.6339313983917236,
      "logps/chosen": -590.3567504882812,
      "logps/rejected": -1335.445556640625,
      "loss": 0.0616,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9882994890213013,
      "rewards/margins": 4.732894420623779,
      "rewards/rejected": -5.721193790435791,
      "step": 539
    },
    {
      "epoch": 0.864,
      "grad_norm": 1.5615254640579224,
      "learning_rate": 6.88e-07,
      "logits/chosen": -2.534884214401245,
      "logits/rejected": -2.586467981338501,
      "logps/chosen": -995.149658203125,
      "logps/rejected": -1843.862060546875,
      "loss": 0.0493,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2596418857574463,
      "rewards/margins": 6.18027925491333,
      "rewards/rejected": -7.4399213790893555,
      "step": 540
    },
    {
      "epoch": 0.8656,
      "grad_norm": 0.6810895800590515,
      "learning_rate": 6.800000000000001e-07,
      "logits/chosen": -2.5853755474090576,
      "logits/rejected": -2.6089179515838623,
      "logps/chosen": -803.4596557617188,
      "logps/rejected": -1639.5731201171875,
      "loss": 0.0185,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3986217975616455,
      "rewards/margins": 5.78141975402832,
      "rewards/rejected": -7.180042266845703,
      "step": 541
    },
    {
      "epoch": 0.8672,
      "grad_norm": 1.185612678527832,
      "learning_rate": 6.72e-07,
      "logits/chosen": -2.5479736328125,
      "logits/rejected": -2.6305785179138184,
      "logps/chosen": -1000.232177734375,
      "logps/rejected": -1428.223876953125,
      "loss": 0.0493,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.242654323577881,
      "rewards/margins": 4.294223785400391,
      "rewards/rejected": -6.5368781089782715,
      "step": 542
    },
    {
      "epoch": 0.8688,
      "grad_norm": 3.170332193374634,
      "learning_rate": 6.64e-07,
      "logits/chosen": -2.5529427528381348,
      "logits/rejected": -2.6276278495788574,
      "logps/chosen": -729.5376586914062,
      "logps/rejected": -1243.0518798828125,
      "loss": 0.0759,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5137625932693481,
      "rewards/margins": 4.709880828857422,
      "rewards/rejected": -6.2236433029174805,
      "step": 543
    },
    {
      "epoch": 0.8704,
      "grad_norm": 6.93063497543335,
      "learning_rate": 6.560000000000002e-07,
      "logits/chosen": -2.5557034015655518,
      "logits/rejected": -2.6626663208007812,
      "logps/chosen": -1797.262451171875,
      "logps/rejected": -2450.388671875,
      "loss": 0.0848,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.7902445793151855,
      "rewards/margins": 5.318219184875488,
      "rewards/rejected": -7.108464241027832,
      "step": 544
    },
    {
      "epoch": 0.872,
      "grad_norm": 1.926314353942871,
      "learning_rate": 6.48e-07,
      "logits/chosen": -2.590611696243286,
      "logits/rejected": -2.5785555839538574,
      "logps/chosen": -1064.8472900390625,
      "logps/rejected": -1762.666015625,
      "loss": 0.0529,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9446120262145996,
      "rewards/margins": 5.513650894165039,
      "rewards/rejected": -7.458263397216797,
      "step": 545
    },
    {
      "epoch": 0.8736,
      "grad_norm": 2.7217657566070557,
      "learning_rate": 6.4e-07,
      "logits/chosen": -2.5162720680236816,
      "logits/rejected": -2.6517796516418457,
      "logps/chosen": -899.4884033203125,
      "logps/rejected": -1774.7344970703125,
      "loss": 0.111,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2848682403564453,
      "rewards/margins": 5.6239399909973145,
      "rewards/rejected": -6.908807754516602,
      "step": 546
    },
    {
      "epoch": 0.8752,
      "grad_norm": 5.097142219543457,
      "learning_rate": 6.320000000000002e-07,
      "logits/chosen": -2.5695583820343018,
      "logits/rejected": -2.620898962020874,
      "logps/chosen": -1140.9801025390625,
      "logps/rejected": -1526.4129638671875,
      "loss": 0.1122,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.701329231262207,
      "rewards/margins": 3.7899465560913086,
      "rewards/rejected": -5.491275787353516,
      "step": 547
    },
    {
      "epoch": 0.8768,
      "grad_norm": 6.465255260467529,
      "learning_rate": 6.24e-07,
      "logits/chosen": -2.601486921310425,
      "logits/rejected": -2.6378121376037598,
      "logps/chosen": -1096.45703125,
      "logps/rejected": -1613.02880859375,
      "loss": 0.1356,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.5455119609832764,
      "rewards/margins": 5.2248101234436035,
      "rewards/rejected": -6.770322322845459,
      "step": 548
    },
    {
      "epoch": 0.8784,
      "grad_norm": 1.6904962062835693,
      "learning_rate": 6.160000000000001e-07,
      "logits/chosen": -2.6290977001190186,
      "logits/rejected": -2.6460390090942383,
      "logps/chosen": -1267.403564453125,
      "logps/rejected": -1637.8468017578125,
      "loss": 0.0767,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.255405306816101,
      "rewards/margins": 3.9237680435180664,
      "rewards/rejected": -5.179173469543457,
      "step": 549
    },
    {
      "epoch": 0.88,
      "grad_norm": 6.341899394989014,
      "learning_rate": 6.08e-07,
      "logits/chosen": -2.6002347469329834,
      "logits/rejected": -2.687816858291626,
      "logps/chosen": -1302.0194091796875,
      "logps/rejected": -1514.90185546875,
      "loss": 0.1972,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.172229766845703,
      "rewards/margins": 3.55538272857666,
      "rewards/rejected": -5.727612495422363,
      "step": 550
    },
    {
      "epoch": 0.8816,
      "grad_norm": 4.756650924682617,
      "learning_rate": 6.000000000000001e-07,
      "logits/chosen": -2.5802650451660156,
      "logits/rejected": -2.636772871017456,
      "logps/chosen": -792.2657470703125,
      "logps/rejected": -1675.79052734375,
      "loss": 0.1448,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.8877935409545898,
      "rewards/margins": 5.112260341644287,
      "rewards/rejected": -7.000053882598877,
      "step": 551
    },
    {
      "epoch": 0.8832,
      "grad_norm": 2.1510446071624756,
      "learning_rate": 5.920000000000001e-07,
      "logits/chosen": -2.6472458839416504,
      "logits/rejected": -2.6490535736083984,
      "logps/chosen": -921.2399291992188,
      "logps/rejected": -1727.8218994140625,
      "loss": 0.0546,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7596038579940796,
      "rewards/margins": 6.258442401885986,
      "rewards/rejected": -8.018046379089355,
      "step": 552
    },
    {
      "epoch": 0.8848,
      "grad_norm": 2.0916478633880615,
      "learning_rate": 5.84e-07,
      "logits/chosen": -2.559004306793213,
      "logits/rejected": -2.6389358043670654,
      "logps/chosen": -682.5999145507812,
      "logps/rejected": -1134.3021240234375,
      "loss": 0.078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0903137922286987,
      "rewards/margins": 4.796265602111816,
      "rewards/rejected": -5.886579513549805,
      "step": 553
    },
    {
      "epoch": 0.8864,
      "grad_norm": 3.3924050331115723,
      "learning_rate": 5.760000000000001e-07,
      "logits/chosen": -2.5507760047912598,
      "logits/rejected": -2.5602097511291504,
      "logps/chosen": -1298.7662353515625,
      "logps/rejected": -3065.038818359375,
      "loss": 0.0925,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.9863767623901367,
      "rewards/margins": 13.776098251342773,
      "rewards/rejected": -15.76247501373291,
      "step": 554
    },
    {
      "epoch": 0.888,
      "grad_norm": 7.862533092498779,
      "learning_rate": 5.680000000000001e-07,
      "logits/chosen": -2.6178598403930664,
      "logits/rejected": -2.596820831298828,
      "logps/chosen": -1710.744384765625,
      "logps/rejected": -2223.77197265625,
      "loss": 0.1893,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.146254301071167,
      "rewards/margins": 5.006982803344727,
      "rewards/rejected": -7.153237819671631,
      "step": 555
    },
    {
      "epoch": 0.8896,
      "grad_norm": 2.020684003829956,
      "learning_rate": 5.6e-07,
      "logits/chosen": -2.600492000579834,
      "logits/rejected": -2.6187167167663574,
      "logps/chosen": -1250.6552734375,
      "logps/rejected": -1890.3699951171875,
      "loss": 0.0331,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.307892084121704,
      "rewards/margins": 5.1490631103515625,
      "rewards/rejected": -7.456955432891846,
      "step": 556
    },
    {
      "epoch": 0.8912,
      "grad_norm": 10.591540336608887,
      "learning_rate": 5.520000000000001e-07,
      "logits/chosen": -2.6179373264312744,
      "logits/rejected": -2.6234588623046875,
      "logps/chosen": -872.0851440429688,
      "logps/rejected": -1242.26171875,
      "loss": 0.1789,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9904037714004517,
      "rewards/margins": 3.774442672729492,
      "rewards/rejected": -4.764846324920654,
      "step": 557
    },
    {
      "epoch": 0.8928,
      "grad_norm": 19.274574279785156,
      "learning_rate": 5.44e-07,
      "logits/chosen": -2.574617624282837,
      "logits/rejected": -2.581296443939209,
      "logps/chosen": -1572.8572998046875,
      "logps/rejected": -1836.459228515625,
      "loss": 0.3996,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.3463735580444336,
      "rewards/margins": 4.5142107009887695,
      "rewards/rejected": -6.860583782196045,
      "step": 558
    },
    {
      "epoch": 0.8944,
      "grad_norm": 6.667768955230713,
      "learning_rate": 5.36e-07,
      "logits/chosen": -2.5400643348693848,
      "logits/rejected": -2.617196798324585,
      "logps/chosen": -871.319580078125,
      "logps/rejected": -1125.2103271484375,
      "loss": 0.2438,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.3001060485839844,
      "rewards/margins": 4.32266902923584,
      "rewards/rejected": -5.622775077819824,
      "step": 559
    },
    {
      "epoch": 0.896,
      "grad_norm": 1.6406304836273193,
      "learning_rate": 5.280000000000001e-07,
      "logits/chosen": -2.606724262237549,
      "logits/rejected": -2.6205005645751953,
      "logps/chosen": -1069.2320556640625,
      "logps/rejected": -1610.5654296875,
      "loss": 0.0919,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.4512068033218384,
      "rewards/margins": 4.342522621154785,
      "rewards/rejected": -5.793729782104492,
      "step": 560
    },
    {
      "epoch": 0.8976,
      "grad_norm": 1.3738445043563843,
      "learning_rate": 5.2e-07,
      "logits/chosen": -2.4369077682495117,
      "logits/rejected": -2.4720706939697266,
      "logps/chosen": -1214.7650146484375,
      "logps/rejected": -2991.5,
      "loss": 0.0244,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4138264656066895,
      "rewards/margins": 6.3646087646484375,
      "rewards/rejected": -7.778436183929443,
      "step": 561
    },
    {
      "epoch": 0.8992,
      "grad_norm": 0.5617823004722595,
      "learning_rate": 5.12e-07,
      "logits/chosen": -2.506322145462036,
      "logits/rejected": -2.6000561714172363,
      "logps/chosen": -603.9468383789062,
      "logps/rejected": -1637.079833984375,
      "loss": 0.0114,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7939570546150208,
      "rewards/margins": 6.450828552246094,
      "rewards/rejected": -7.244785308837891,
      "step": 562
    },
    {
      "epoch": 0.9008,
      "grad_norm": 14.702781677246094,
      "learning_rate": 5.040000000000001e-07,
      "logits/chosen": -2.615715503692627,
      "logits/rejected": -2.622964859008789,
      "logps/chosen": -1780.8094482421875,
      "logps/rejected": -1777.5152587890625,
      "loss": 0.216,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.435023546218872,
      "rewards/margins": 4.46090030670166,
      "rewards/rejected": -6.895924091339111,
      "step": 563
    },
    {
      "epoch": 0.9024,
      "grad_norm": 4.234861850738525,
      "learning_rate": 4.96e-07,
      "logits/chosen": -2.490957498550415,
      "logits/rejected": -2.5764694213867188,
      "logps/chosen": -1481.73583984375,
      "logps/rejected": -1734.32470703125,
      "loss": 0.0993,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.0955352783203125,
      "rewards/margins": 4.805106163024902,
      "rewards/rejected": -6.900641918182373,
      "step": 564
    },
    {
      "epoch": 0.904,
      "grad_norm": 9.648393630981445,
      "learning_rate": 4.88e-07,
      "logits/chosen": -2.53448224067688,
      "logits/rejected": -2.5955002307891846,
      "logps/chosen": -1470.265869140625,
      "logps/rejected": -2026.722900390625,
      "loss": 0.1941,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.8120144605636597,
      "rewards/margins": 5.3085618019104,
      "rewards/rejected": -7.120575904846191,
      "step": 565
    },
    {
      "epoch": 0.9056,
      "grad_norm": 1.9867525100708008,
      "learning_rate": 4.800000000000001e-07,
      "logits/chosen": -2.4945132732391357,
      "logits/rejected": -2.5484158992767334,
      "logps/chosen": -1340.8087158203125,
      "logps/rejected": -1998.302734375,
      "loss": 0.0551,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.343177318572998,
      "rewards/margins": 4.8061957359313965,
      "rewards/rejected": -7.149373531341553,
      "step": 566
    },
    {
      "epoch": 0.9072,
      "grad_norm": 1.0449391603469849,
      "learning_rate": 4.7200000000000004e-07,
      "logits/chosen": -2.4870996475219727,
      "logits/rejected": -2.5691781044006348,
      "logps/chosen": -1172.310791015625,
      "logps/rejected": -1815.6661376953125,
      "loss": 0.0319,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8472869396209717,
      "rewards/margins": 5.810727119445801,
      "rewards/rejected": -7.658014297485352,
      "step": 567
    },
    {
      "epoch": 0.9088,
      "grad_norm": 9.797957420349121,
      "learning_rate": 4.64e-07,
      "logits/chosen": -2.429832935333252,
      "logits/rejected": -2.564723014831543,
      "logps/chosen": -1121.4310302734375,
      "logps/rejected": -1808.6964111328125,
      "loss": 0.2138,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.4559097290039062,
      "rewards/margins": 4.486332893371582,
      "rewards/rejected": -6.94224214553833,
      "step": 568
    },
    {
      "epoch": 0.9104,
      "grad_norm": 2.492595911026001,
      "learning_rate": 4.5600000000000006e-07,
      "logits/chosen": -2.623945951461792,
      "logits/rejected": -2.64107608795166,
      "logps/chosen": -906.7208251953125,
      "logps/rejected": -1441.8631591796875,
      "loss": 0.0643,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5268328189849854,
      "rewards/margins": 4.641479969024658,
      "rewards/rejected": -6.168312072753906,
      "step": 569
    },
    {
      "epoch": 0.912,
      "grad_norm": 3.235659599304199,
      "learning_rate": 4.4800000000000004e-07,
      "logits/chosen": -2.5967445373535156,
      "logits/rejected": -2.594254970550537,
      "logps/chosen": -1140.2764892578125,
      "logps/rejected": -1925.40478515625,
      "loss": 0.0834,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8563481569290161,
      "rewards/margins": 5.776869773864746,
      "rewards/rejected": -7.633217811584473,
      "step": 570
    },
    {
      "epoch": 0.9136,
      "grad_norm": 1.2892355918884277,
      "learning_rate": 4.4e-07,
      "logits/chosen": -2.5977249145507812,
      "logits/rejected": -2.635483980178833,
      "logps/chosen": -638.4691162109375,
      "logps/rejected": -1393.5531005859375,
      "loss": 0.076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8384720683097839,
      "rewards/margins": 4.7747955322265625,
      "rewards/rejected": -5.613267421722412,
      "step": 571
    },
    {
      "epoch": 0.9152,
      "grad_norm": 1.4673339128494263,
      "learning_rate": 4.3200000000000006e-07,
      "logits/chosen": -2.594815254211426,
      "logits/rejected": -2.66255784034729,
      "logps/chosen": -983.9819946289062,
      "logps/rejected": -1895.7020263671875,
      "loss": 0.0645,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.281022310256958,
      "rewards/margins": 5.437478065490723,
      "rewards/rejected": -6.718500137329102,
      "step": 572
    },
    {
      "epoch": 0.9168,
      "grad_norm": 5.212144374847412,
      "learning_rate": 4.2400000000000004e-07,
      "logits/chosen": -2.534583806991577,
      "logits/rejected": -2.60960054397583,
      "logps/chosen": -856.2576904296875,
      "logps/rejected": -1565.4127197265625,
      "loss": 0.148,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3051270246505737,
      "rewards/margins": 5.275938034057617,
      "rewards/rejected": -6.5810651779174805,
      "step": 573
    },
    {
      "epoch": 0.9184,
      "grad_norm": 12.734857559204102,
      "learning_rate": 4.16e-07,
      "logits/chosen": -2.6433959007263184,
      "logits/rejected": -2.6560611724853516,
      "logps/chosen": -1735.414794921875,
      "logps/rejected": -2357.7314453125,
      "loss": 0.3637,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -2.8330905437469482,
      "rewards/margins": 5.037937164306641,
      "rewards/rejected": -7.87102746963501,
      "step": 574
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.7273686528205872,
      "learning_rate": 4.0800000000000005e-07,
      "logits/chosen": -2.5606226921081543,
      "logits/rejected": -2.6509361267089844,
      "logps/chosen": -479.11077880859375,
      "logps/rejected": -1487.5770263671875,
      "loss": 0.0617,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9115835428237915,
      "rewards/margins": 5.211492538452148,
      "rewards/rejected": -6.123075485229492,
      "step": 575
    },
    {
      "epoch": 0.9216,
      "grad_norm": 2.765902042388916,
      "learning_rate": 4.0000000000000003e-07,
      "logits/chosen": -2.565086603164673,
      "logits/rejected": -2.6131088733673096,
      "logps/chosen": -1360.92138671875,
      "logps/rejected": -2292.300537109375,
      "loss": 0.1147,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.015815496444702,
      "rewards/margins": 6.3557515144348145,
      "rewards/rejected": -8.371566772460938,
      "step": 576
    },
    {
      "epoch": 0.9232,
      "grad_norm": 8.298066139221191,
      "learning_rate": 3.92e-07,
      "logits/chosen": -2.5329928398132324,
      "logits/rejected": -2.561307430267334,
      "logps/chosen": -1302.4754638671875,
      "logps/rejected": -1733.0946044921875,
      "loss": 0.2107,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.5186715126037598,
      "rewards/margins": 4.51851749420166,
      "rewards/rejected": -7.0371880531311035,
      "step": 577
    },
    {
      "epoch": 0.9248,
      "grad_norm": 3.2309823036193848,
      "learning_rate": 3.84e-07,
      "logits/chosen": -2.5846633911132812,
      "logits/rejected": -2.5794379711151123,
      "logps/chosen": -1305.2958984375,
      "logps/rejected": -1798.7335205078125,
      "loss": 0.1309,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8390575647354126,
      "rewards/margins": 5.049817085266113,
      "rewards/rejected": -6.888874530792236,
      "step": 578
    },
    {
      "epoch": 0.9264,
      "grad_norm": 1.877026081085205,
      "learning_rate": 3.7600000000000003e-07,
      "logits/chosen": -2.4838664531707764,
      "logits/rejected": -2.587433099746704,
      "logps/chosen": -996.2838134765625,
      "logps/rejected": -2026.072021484375,
      "loss": 0.0814,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2616007328033447,
      "rewards/margins": 6.426081657409668,
      "rewards/rejected": -7.68768310546875,
      "step": 579
    },
    {
      "epoch": 0.928,
      "grad_norm": 11.096726417541504,
      "learning_rate": 3.68e-07,
      "logits/chosen": -2.501744508743286,
      "logits/rejected": -2.521934747695923,
      "logps/chosen": -1273.8465576171875,
      "logps/rejected": -2184.7802734375,
      "loss": 0.1124,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.273989677429199,
      "rewards/margins": 4.8319878578186035,
      "rewards/rejected": -7.105976581573486,
      "step": 580
    },
    {
      "epoch": 0.9296,
      "grad_norm": 8.974775314331055,
      "learning_rate": 3.6e-07,
      "logits/chosen": -2.593329668045044,
      "logits/rejected": -2.5788280963897705,
      "logps/chosen": -1101.03271484375,
      "logps/rejected": -1283.078125,
      "loss": 0.2218,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.8575338125228882,
      "rewards/margins": 3.9413022994995117,
      "rewards/rejected": -5.798836708068848,
      "step": 581
    },
    {
      "epoch": 0.9312,
      "grad_norm": 2.3301825523376465,
      "learning_rate": 3.5200000000000003e-07,
      "logits/chosen": -2.4586174488067627,
      "logits/rejected": -2.5988364219665527,
      "logps/chosen": -440.0155334472656,
      "logps/rejected": -1136.059326171875,
      "loss": 0.0962,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4991762936115265,
      "rewards/margins": 4.5405378341674805,
      "rewards/rejected": -5.039714336395264,
      "step": 582
    },
    {
      "epoch": 0.9328,
      "grad_norm": 1.5442639589309692,
      "learning_rate": 3.44e-07,
      "logits/chosen": -2.5336806774139404,
      "logits/rejected": -2.563275098800659,
      "logps/chosen": -1110.64306640625,
      "logps/rejected": -1625.577392578125,
      "loss": 0.0627,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2282315492630005,
      "rewards/margins": 6.088418006896973,
      "rewards/rejected": -7.316648483276367,
      "step": 583
    },
    {
      "epoch": 0.9344,
      "grad_norm": 4.458874225616455,
      "learning_rate": 3.36e-07,
      "logits/chosen": -2.480445384979248,
      "logits/rejected": -2.655600070953369,
      "logps/chosen": -1040.5535888671875,
      "logps/rejected": -1862.422607421875,
      "loss": 0.0724,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8662209510803223,
      "rewards/margins": 5.71111536026001,
      "rewards/rejected": -7.577336311340332,
      "step": 584
    },
    {
      "epoch": 0.936,
      "grad_norm": 1.3935118913650513,
      "learning_rate": 3.280000000000001e-07,
      "logits/chosen": -2.5872092247009277,
      "logits/rejected": -2.666421413421631,
      "logps/chosen": -1072.21923828125,
      "logps/rejected": -1815.857421875,
      "loss": 0.0508,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9055315256118774,
      "rewards/margins": 5.256885528564453,
      "rewards/rejected": -6.162416458129883,
      "step": 585
    },
    {
      "epoch": 0.9376,
      "grad_norm": 3.8069612979888916,
      "learning_rate": 3.2e-07,
      "logits/chosen": -2.531834602355957,
      "logits/rejected": -2.5371792316436768,
      "logps/chosen": -1204.586669921875,
      "logps/rejected": -1784.773681640625,
      "loss": 0.1214,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3496031761169434,
      "rewards/margins": 3.780578851699829,
      "rewards/rejected": -5.130182266235352,
      "step": 586
    },
    {
      "epoch": 0.9392,
      "grad_norm": 2.2758710384368896,
      "learning_rate": 3.12e-07,
      "logits/chosen": -2.571868419647217,
      "logits/rejected": -2.6210970878601074,
      "logps/chosen": -785.3717041015625,
      "logps/rejected": -1502.2362060546875,
      "loss": 0.0749,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1545323133468628,
      "rewards/margins": 5.198243141174316,
      "rewards/rejected": -6.352775573730469,
      "step": 587
    },
    {
      "epoch": 0.9408,
      "grad_norm": 1.7404426336288452,
      "learning_rate": 3.04e-07,
      "logits/chosen": -2.608292579650879,
      "logits/rejected": -2.6358838081359863,
      "logps/chosen": -1329.2333984375,
      "logps/rejected": -2092.772216796875,
      "loss": 0.0327,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6169843673706055,
      "rewards/margins": 5.722062587738037,
      "rewards/rejected": -7.339047431945801,
      "step": 588
    },
    {
      "epoch": 0.9424,
      "grad_norm": 8.086820602416992,
      "learning_rate": 2.9600000000000006e-07,
      "logits/chosen": -2.6349780559539795,
      "logits/rejected": -2.670917510986328,
      "logps/chosen": -779.7418212890625,
      "logps/rejected": -1570.38916015625,
      "loss": 0.1748,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.046408772468567,
      "rewards/margins": 4.905477046966553,
      "rewards/rejected": -5.951886177062988,
      "step": 589
    },
    {
      "epoch": 0.944,
      "grad_norm": 2.1499953269958496,
      "learning_rate": 2.8800000000000004e-07,
      "logits/chosen": -2.580522060394287,
      "logits/rejected": -2.566347360610962,
      "logps/chosen": -1411.7515869140625,
      "logps/rejected": -2209.168212890625,
      "loss": 0.0568,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0080573558807373,
      "rewards/margins": 5.338512420654297,
      "rewards/rejected": -7.346569538116455,
      "step": 590
    },
    {
      "epoch": 0.9456,
      "grad_norm": 3.0155653953552246,
      "learning_rate": 2.8e-07,
      "logits/chosen": -2.5127944946289062,
      "logits/rejected": -2.6486690044403076,
      "logps/chosen": -882.9175415039062,
      "logps/rejected": -1844.687744140625,
      "loss": 0.1452,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8398205041885376,
      "rewards/margins": 3.716815710067749,
      "rewards/rejected": -4.556636333465576,
      "step": 591
    },
    {
      "epoch": 0.9472,
      "grad_norm": 4.268211841583252,
      "learning_rate": 2.72e-07,
      "logits/chosen": -2.6437690258026123,
      "logits/rejected": -2.614396333694458,
      "logps/chosen": -1261.6343994140625,
      "logps/rejected": -1683.71240234375,
      "loss": 0.1105,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.091756820678711,
      "rewards/margins": 4.5918121337890625,
      "rewards/rejected": -6.683569431304932,
      "step": 592
    },
    {
      "epoch": 0.9488,
      "grad_norm": 8.432318687438965,
      "learning_rate": 2.6400000000000003e-07,
      "logits/chosen": -2.5919055938720703,
      "logits/rejected": -2.5054256916046143,
      "logps/chosen": -1127.3433837890625,
      "logps/rejected": -1764.758056640625,
      "loss": 0.1027,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.6592036485671997,
      "rewards/margins": 4.328568458557129,
      "rewards/rejected": -5.987771987915039,
      "step": 593
    },
    {
      "epoch": 0.9504,
      "grad_norm": 13.967291831970215,
      "learning_rate": 2.56e-07,
      "logits/chosen": -2.4255940914154053,
      "logits/rejected": -2.589353084564209,
      "logps/chosen": -480.3088684082031,
      "logps/rejected": -1410.6395263671875,
      "loss": 0.3279,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0715750455856323,
      "rewards/margins": 4.625113010406494,
      "rewards/rejected": -5.696688175201416,
      "step": 594
    },
    {
      "epoch": 0.952,
      "grad_norm": 5.288936138153076,
      "learning_rate": 2.48e-07,
      "logits/chosen": -2.5919723510742188,
      "logits/rejected": -2.61033296585083,
      "logps/chosen": -1381.037109375,
      "logps/rejected": -1935.4814453125,
      "loss": 0.157,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.0242934226989746,
      "rewards/margins": 5.210514545440674,
      "rewards/rejected": -7.234807968139648,
      "step": 595
    },
    {
      "epoch": 0.9536,
      "grad_norm": 4.200916290283203,
      "learning_rate": 2.4000000000000003e-07,
      "logits/chosen": -2.5880699157714844,
      "logits/rejected": -2.650872230529785,
      "logps/chosen": -1452.12548828125,
      "logps/rejected": -2148.216064453125,
      "loss": 0.0656,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.165214776992798,
      "rewards/margins": 4.906770706176758,
      "rewards/rejected": -7.071985244750977,
      "step": 596
    },
    {
      "epoch": 0.9552,
      "grad_norm": 4.1337432861328125,
      "learning_rate": 2.32e-07,
      "logits/chosen": -2.568941593170166,
      "logits/rejected": -2.6306653022766113,
      "logps/chosen": -1440.42626953125,
      "logps/rejected": -1715.953857421875,
      "loss": 0.0871,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.6892573833465576,
      "rewards/margins": 5.079823970794678,
      "rewards/rejected": -6.7690815925598145,
      "step": 597
    },
    {
      "epoch": 0.9568,
      "grad_norm": 714.7799072265625,
      "learning_rate": 2.2400000000000002e-07,
      "logits/chosen": -2.634580135345459,
      "logits/rejected": -2.59346079826355,
      "logps/chosen": -1641.906005859375,
      "logps/rejected": -2904.77685546875,
      "loss": 0.5025,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.1211819648742676,
      "rewards/margins": 2.9467148780822754,
      "rewards/rejected": -5.067896842956543,
      "step": 598
    },
    {
      "epoch": 0.9584,
      "grad_norm": 7.624429702758789,
      "learning_rate": 2.1600000000000003e-07,
      "logits/chosen": -2.408980131149292,
      "logits/rejected": -2.515495777130127,
      "logps/chosen": -1799.55615234375,
      "logps/rejected": -1540.4837646484375,
      "loss": 0.1727,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.1235294342041016,
      "rewards/margins": 3.9538679122924805,
      "rewards/rejected": -5.077396869659424,
      "step": 599
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.107351779937744,
      "learning_rate": 2.08e-07,
      "logits/chosen": -2.548065662384033,
      "logits/rejected": -2.6210057735443115,
      "logps/chosen": -1117.7879638671875,
      "logps/rejected": -1785.7557373046875,
      "loss": 0.0484,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5467935800552368,
      "rewards/margins": 5.769157409667969,
      "rewards/rejected": -7.315950870513916,
      "step": 600
    },
    {
      "epoch": 0.9616,
      "grad_norm": 1.693280577659607,
      "learning_rate": 2.0000000000000002e-07,
      "logits/chosen": -2.5265233516693115,
      "logits/rejected": -2.604930877685547,
      "logps/chosen": -665.7666015625,
      "logps/rejected": -1743.533447265625,
      "loss": 0.0703,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7739771604537964,
      "rewards/margins": 6.549270153045654,
      "rewards/rejected": -7.32324743270874,
      "step": 601
    },
    {
      "epoch": 0.9632,
      "grad_norm": 1.6757311820983887,
      "learning_rate": 1.92e-07,
      "logits/chosen": -2.590942144393921,
      "logits/rejected": -2.656388759613037,
      "logps/chosen": -649.3171997070312,
      "logps/rejected": -1400.7420654296875,
      "loss": 0.0659,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.712995171546936,
      "rewards/margins": 4.0792765617370605,
      "rewards/rejected": -4.792272090911865,
      "step": 602
    },
    {
      "epoch": 0.9648,
      "grad_norm": 10.043608665466309,
      "learning_rate": 1.84e-07,
      "logits/chosen": -2.565979242324829,
      "logits/rejected": -2.612621784210205,
      "logps/chosen": -1143.821533203125,
      "logps/rejected": -2271.88720703125,
      "loss": 0.297,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.5817582607269287,
      "rewards/margins": 5.003271579742432,
      "rewards/rejected": -6.585029602050781,
      "step": 603
    },
    {
      "epoch": 0.9664,
      "grad_norm": 8.956375122070312,
      "learning_rate": 1.7600000000000001e-07,
      "logits/chosen": -2.583278179168701,
      "logits/rejected": -2.627009630203247,
      "logps/chosen": -1054.60498046875,
      "logps/rejected": -1309.210205078125,
      "loss": 0.1576,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.646041750907898,
      "rewards/margins": 4.916274070739746,
      "rewards/rejected": -6.562315940856934,
      "step": 604
    },
    {
      "epoch": 0.968,
      "grad_norm": 1.461431622505188,
      "learning_rate": 1.68e-07,
      "logits/chosen": -2.6013762950897217,
      "logits/rejected": -2.6208667755126953,
      "logps/chosen": -759.5560302734375,
      "logps/rejected": -2018.2017822265625,
      "loss": 0.0514,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2666292190551758,
      "rewards/margins": 6.485759735107422,
      "rewards/rejected": -7.752388954162598,
      "step": 605
    },
    {
      "epoch": 0.9696,
      "grad_norm": 4.426527976989746,
      "learning_rate": 1.6e-07,
      "logits/chosen": -2.481001853942871,
      "logits/rejected": -2.626991033554077,
      "logps/chosen": -816.0443115234375,
      "logps/rejected": -1518.8505859375,
      "loss": 0.0966,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3514187335968018,
      "rewards/margins": 5.562679290771484,
      "rewards/rejected": -6.914097785949707,
      "step": 606
    },
    {
      "epoch": 0.9712,
      "grad_norm": 2.970243453979492,
      "learning_rate": 1.52e-07,
      "logits/chosen": -2.574216604232788,
      "logits/rejected": -2.641826629638672,
      "logps/chosen": -1078.5809326171875,
      "logps/rejected": -1592.1983642578125,
      "loss": 0.0372,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5844831466674805,
      "rewards/margins": 5.494582653045654,
      "rewards/rejected": -7.079065799713135,
      "step": 607
    },
    {
      "epoch": 0.9728,
      "grad_norm": 2.815680742263794,
      "learning_rate": 1.4400000000000002e-07,
      "logits/chosen": -2.5699892044067383,
      "logits/rejected": -2.581634998321533,
      "logps/chosen": -1124.173583984375,
      "logps/rejected": -1673.160400390625,
      "loss": 0.0644,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0649025440216064,
      "rewards/margins": 5.15848970413208,
      "rewards/rejected": -7.223392486572266,
      "step": 608
    },
    {
      "epoch": 0.9744,
      "grad_norm": 1.6082360744476318,
      "learning_rate": 1.36e-07,
      "logits/chosen": -2.5502076148986816,
      "logits/rejected": -2.6565937995910645,
      "logps/chosen": -1662.93359375,
      "logps/rejected": -1701.986083984375,
      "loss": 0.0562,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.68776273727417,
      "rewards/margins": 4.813743591308594,
      "rewards/rejected": -6.501506328582764,
      "step": 609
    },
    {
      "epoch": 0.976,
      "grad_norm": 3.838090419769287,
      "learning_rate": 1.28e-07,
      "logits/chosen": -2.410625457763672,
      "logits/rejected": -2.65767240524292,
      "logps/chosen": -1466.651123046875,
      "logps/rejected": -2216.985595703125,
      "loss": 0.1377,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8922843933105469,
      "rewards/margins": 4.751506805419922,
      "rewards/rejected": -6.643791198730469,
      "step": 610
    },
    {
      "epoch": 0.9776,
      "grad_norm": 2.3908636569976807,
      "learning_rate": 1.2000000000000002e-07,
      "logits/chosen": -2.5573506355285645,
      "logits/rejected": -2.586136817932129,
      "logps/chosen": -1453.3089599609375,
      "logps/rejected": -2117.2685546875,
      "loss": 0.0551,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.8003027439117432,
      "rewards/margins": 5.840877532958984,
      "rewards/rejected": -7.641180992126465,
      "step": 611
    },
    {
      "epoch": 0.9792,
      "grad_norm": 3.7207889556884766,
      "learning_rate": 1.1200000000000001e-07,
      "logits/chosen": -2.548555374145508,
      "logits/rejected": -2.6713409423828125,
      "logps/chosen": -686.9083251953125,
      "logps/rejected": -1338.6971435546875,
      "loss": 0.0869,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9455188512802124,
      "rewards/margins": 4.525173187255859,
      "rewards/rejected": -5.470692157745361,
      "step": 612
    },
    {
      "epoch": 0.9808,
      "grad_norm": 2.552309513092041,
      "learning_rate": 1.04e-07,
      "logits/chosen": -2.5440332889556885,
      "logits/rejected": -2.61201810836792,
      "logps/chosen": -1515.35107421875,
      "logps/rejected": -2124.731201171875,
      "loss": 0.0578,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9883514642715454,
      "rewards/margins": 5.458928108215332,
      "rewards/rejected": -6.447279930114746,
      "step": 613
    },
    {
      "epoch": 0.9824,
      "grad_norm": 0.4857131540775299,
      "learning_rate": 9.6e-08,
      "logits/chosen": -2.559922456741333,
      "logits/rejected": -2.6179420948028564,
      "logps/chosen": -1256.5091552734375,
      "logps/rejected": -1901.7943115234375,
      "loss": 0.0152,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.968281865119934,
      "rewards/margins": 5.687074661254883,
      "rewards/rejected": -7.655355930328369,
      "step": 614
    },
    {
      "epoch": 0.984,
      "grad_norm": 1.7354389429092407,
      "learning_rate": 8.800000000000001e-08,
      "logits/chosen": -2.5851802825927734,
      "logits/rejected": -2.6339354515075684,
      "logps/chosen": -1439.6807861328125,
      "logps/rejected": -1939.880126953125,
      "loss": 0.0465,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.7035536766052246,
      "rewards/margins": 4.376587390899658,
      "rewards/rejected": -6.080141067504883,
      "step": 615
    },
    {
      "epoch": 0.9856,
      "grad_norm": 0.8524090647697449,
      "learning_rate": 8e-08,
      "logits/chosen": -2.501634120941162,
      "logits/rejected": -2.6053903102874756,
      "logps/chosen": -676.972900390625,
      "logps/rejected": -1998.208984375,
      "loss": 0.0608,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9701347351074219,
      "rewards/margins": 6.096848487854004,
      "rewards/rejected": -7.066984176635742,
      "step": 616
    },
    {
      "epoch": 0.9872,
      "grad_norm": 3.4939138889312744,
      "learning_rate": 7.200000000000001e-08,
      "logits/chosen": -2.511134624481201,
      "logits/rejected": -2.5973596572875977,
      "logps/chosen": -1089.4649658203125,
      "logps/rejected": -1844.8292236328125,
      "loss": 0.0957,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.5354052782058716,
      "rewards/margins": 5.071909427642822,
      "rewards/rejected": -6.607314586639404,
      "step": 617
    },
    {
      "epoch": 0.9888,
      "grad_norm": 4.704599380493164,
      "learning_rate": 6.4e-08,
      "logits/chosen": -2.5190563201904297,
      "logits/rejected": -2.537186622619629,
      "logps/chosen": -1391.3082275390625,
      "logps/rejected": -2292.99853515625,
      "loss": 0.1259,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.5780510902404785,
      "rewards/margins": 4.1028852462768555,
      "rewards/rejected": -6.680936813354492,
      "step": 618
    },
    {
      "epoch": 0.9904,
      "grad_norm": 3.9306702613830566,
      "learning_rate": 5.6000000000000005e-08,
      "logits/chosen": -2.6011834144592285,
      "logits/rejected": -2.589141607284546,
      "logps/chosen": -2132.647216796875,
      "logps/rejected": -2558.22265625,
      "loss": 0.1488,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -2.0818469524383545,
      "rewards/margins": 5.145918846130371,
      "rewards/rejected": -7.227766036987305,
      "step": 619
    },
    {
      "epoch": 0.992,
      "grad_norm": 15.396413803100586,
      "learning_rate": 4.8e-08,
      "logits/chosen": -2.478494882583618,
      "logits/rejected": -2.5174803733825684,
      "logps/chosen": -786.1405639648438,
      "logps/rejected": -1352.881591796875,
      "loss": 0.4247,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.4605108499526978,
      "rewards/margins": 3.9943795204162598,
      "rewards/rejected": -5.454890251159668,
      "step": 620
    },
    {
      "epoch": 0.9936,
      "grad_norm": 3.1089298725128174,
      "learning_rate": 4e-08,
      "logits/chosen": -2.6198134422302246,
      "logits/rejected": -2.651836633682251,
      "logps/chosen": -890.7489013671875,
      "logps/rejected": -1465.1181640625,
      "loss": 0.1399,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1943973302841187,
      "rewards/margins": 3.5895543098449707,
      "rewards/rejected": -4.783952236175537,
      "step": 621
    },
    {
      "epoch": 0.9952,
      "grad_norm": 1.0297553539276123,
      "learning_rate": 3.2e-08,
      "logits/chosen": -2.5284171104431152,
      "logits/rejected": -2.6820244789123535,
      "logps/chosen": -1449.4019775390625,
      "logps/rejected": -1902.76708984375,
      "loss": 0.0425,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2051407098770142,
      "rewards/margins": 6.169405937194824,
      "rewards/rejected": -7.374546051025391,
      "step": 622
    },
    {
      "epoch": 0.9968,
      "grad_norm": 3.005094528198242,
      "learning_rate": 2.4e-08,
      "logits/chosen": -2.5350446701049805,
      "logits/rejected": -2.608349323272705,
      "logps/chosen": -1268.767578125,
      "logps/rejected": -1896.230224609375,
      "loss": 0.0656,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.0746729373931885,
      "rewards/margins": 5.716120719909668,
      "rewards/rejected": -7.790794372558594,
      "step": 623
    },
    {
      "epoch": 0.9984,
      "grad_norm": 3.6716015338897705,
      "learning_rate": 1.6e-08,
      "logits/chosen": -2.507394790649414,
      "logits/rejected": -2.583451986312866,
      "logps/chosen": -970.9457397460938,
      "logps/rejected": -1438.74169921875,
      "loss": 0.0729,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.064797282218933,
      "rewards/margins": 6.110505104064941,
      "rewards/rejected": -7.175302028656006,
      "step": 624
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.7221373319625854,
      "learning_rate": 8e-09,
      "logits/chosen": -2.529637575149536,
      "logits/rejected": -2.6071510314941406,
      "logps/chosen": -933.982421875,
      "logps/rejected": -1574.583984375,
      "loss": 0.0974,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.4289677143096924,
      "rewards/margins": 4.744994163513184,
      "rewards/rejected": -6.173961639404297,
      "step": 625
    }
  ],
  "logging_steps": 1.0,
  "max_steps": 625,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
