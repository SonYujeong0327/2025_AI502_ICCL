{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.32,
  "eval_steps": 500,
  "global_step": 200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0016,
      "grad_norm": 13.84941291809082,
      "learning_rate": 5e-06,
      "logits/chosen": -2.5776219367980957,
      "logits/rejected": -2.7055633068084717,
      "logps/chosen": -1056.15673828125,
      "logps/rejected": -1480.4925537109375,
      "loss": 0.6931,
      "rewards/accuracies": 0.0,
      "rewards/chosen": 0.0,
      "rewards/margins": 0.0,
      "rewards/rejected": 0.0,
      "step": 1
    },
    {
      "epoch": 0.0032,
      "grad_norm": 45.007198333740234,
      "learning_rate": 4.992e-06,
      "logits/chosen": -2.6598477363586426,
      "logits/rejected": -2.638962507247925,
      "logps/chosen": -941.6472778320312,
      "logps/rejected": -2749.870361328125,
      "loss": 0.6931,
      "rewards/accuracies": 0.375,
      "rewards/chosen": 0.001083088107407093,
      "rewards/margins": 0.0015652645379304886,
      "rewards/rejected": -0.0004821792244911194,
      "step": 2
    },
    {
      "epoch": 0.0048,
      "grad_norm": 15.915088653564453,
      "learning_rate": 4.984000000000001e-06,
      "logits/chosen": -2.5835680961608887,
      "logits/rejected": -2.6005897521972656,
      "logps/chosen": -942.9486694335938,
      "logps/rejected": -1709.282470703125,
      "loss": 0.6909,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": -0.008969164453446865,
      "rewards/margins": 0.00461916858330369,
      "rewards/rejected": -0.013588333502411842,
      "step": 3
    },
    {
      "epoch": 0.0064,
      "grad_norm": 18.279870986938477,
      "learning_rate": 4.976e-06,
      "logits/chosen": -2.560264825820923,
      "logits/rejected": -2.6732285022735596,
      "logps/chosen": -1005.6978759765625,
      "logps/rejected": -2042.3685302734375,
      "loss": 0.6841,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.01044774055480957,
      "rewards/margins": 0.01848425902426243,
      "rewards/rejected": -0.008036518469452858,
      "step": 4
    },
    {
      "epoch": 0.008,
      "grad_norm": 19.964435577392578,
      "learning_rate": 4.9680000000000005e-06,
      "logits/chosen": -2.5974249839782715,
      "logits/rejected": -2.6631898880004883,
      "logps/chosen": -1344.29833984375,
      "logps/rejected": -1537.8853759765625,
      "loss": 0.6782,
      "rewards/accuracies": 0.625,
      "rewards/chosen": -0.001501727499999106,
      "rewards/margins": 0.03174459934234619,
      "rewards/rejected": -0.033246323466300964,
      "step": 5
    },
    {
      "epoch": 0.0096,
      "grad_norm": 16.028396606445312,
      "learning_rate": 4.960000000000001e-06,
      "logits/chosen": -2.712719440460205,
      "logits/rejected": -2.740114212036133,
      "logps/chosen": -1016.0684204101562,
      "logps/rejected": -1872.759765625,
      "loss": 0.6785,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.0006994251161813736,
      "rewards/margins": 0.02997455559670925,
      "rewards/rejected": -0.029275130480527878,
      "step": 6
    },
    {
      "epoch": 0.0112,
      "grad_norm": 19.929445266723633,
      "learning_rate": 4.952e-06,
      "logits/chosen": -2.648043155670166,
      "logits/rejected": -2.657698631286621,
      "logps/chosen": -1366.33935546875,
      "logps/rejected": -2275.148193359375,
      "loss": 0.6747,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.004850960336625576,
      "rewards/margins": 0.0378965400159359,
      "rewards/rejected": -0.033045582473278046,
      "step": 7
    },
    {
      "epoch": 0.0128,
      "grad_norm": 15.290864944458008,
      "learning_rate": 4.9440000000000004e-06,
      "logits/chosen": -2.6867830753326416,
      "logits/rejected": -2.7323524951934814,
      "logps/chosen": -1177.310302734375,
      "logps/rejected": -1798.749755859375,
      "loss": 0.6677,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": 0.003956103231757879,
      "rewards/margins": 0.05204436928033829,
      "rewards/rejected": -0.04808826744556427,
      "step": 8
    },
    {
      "epoch": 0.0144,
      "grad_norm": 14.194281578063965,
      "learning_rate": 4.936e-06,
      "logits/chosen": -2.6973958015441895,
      "logits/rejected": -2.685187816619873,
      "logps/chosen": -1229.772705078125,
      "logps/rejected": -1825.2882080078125,
      "loss": 0.6574,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.01018662378191948,
      "rewards/margins": 0.07471061497926712,
      "rewards/rejected": -0.0848972350358963,
      "step": 9
    },
    {
      "epoch": 0.016,
      "grad_norm": 12.386669158935547,
      "learning_rate": 4.928000000000001e-06,
      "logits/chosen": -2.651186466217041,
      "logits/rejected": -2.6357762813568115,
      "logps/chosen": -1024.188232421875,
      "logps/rejected": -1424.1258544921875,
      "loss": 0.6606,
      "rewards/accuracies": 0.75,
      "rewards/chosen": 0.00889575481414795,
      "rewards/margins": 0.06773841381072998,
      "rewards/rejected": -0.05884266272187233,
      "step": 10
    },
    {
      "epoch": 0.0176,
      "grad_norm": 14.19550895690918,
      "learning_rate": 4.92e-06,
      "logits/chosen": -2.725515604019165,
      "logits/rejected": -2.7078707218170166,
      "logps/chosen": -916.9689331054688,
      "logps/rejected": -1582.185791015625,
      "loss": 0.6179,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.004241441376507282,
      "rewards/margins": 0.16683509945869446,
      "rewards/rejected": -0.16259366273880005,
      "step": 11
    },
    {
      "epoch": 0.0192,
      "grad_norm": 13.468660354614258,
      "learning_rate": 4.9120000000000006e-06,
      "logits/chosen": -2.6770591735839844,
      "logits/rejected": -2.6983461380004883,
      "logps/chosen": -1057.786865234375,
      "logps/rejected": -1482.583984375,
      "loss": 0.6411,
      "rewards/accuracies": 0.875,
      "rewards/chosen": 0.0019723414443433285,
      "rewards/margins": 0.10990405827760696,
      "rewards/rejected": -0.1079317107796669,
      "step": 12
    },
    {
      "epoch": 0.0208,
      "grad_norm": 15.013222694396973,
      "learning_rate": 4.904000000000001e-06,
      "logits/chosen": -2.605250597000122,
      "logits/rejected": -2.579044818878174,
      "logps/chosen": -1218.3604736328125,
      "logps/rejected": -1650.537109375,
      "loss": 0.6158,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.020715704187750816,
      "rewards/margins": 0.17084407806396484,
      "rewards/rejected": -0.15012836456298828,
      "step": 13
    },
    {
      "epoch": 0.0224,
      "grad_norm": 12.808388710021973,
      "learning_rate": 4.896e-06,
      "logits/chosen": -2.5773825645446777,
      "logits/rejected": -2.6381478309631348,
      "logps/chosen": -1189.969482421875,
      "logps/rejected": -1800.74853515625,
      "loss": 0.6406,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.02153639867901802,
      "rewards/margins": 0.1149168461561203,
      "rewards/rejected": -0.13645325601100922,
      "step": 14
    },
    {
      "epoch": 0.024,
      "grad_norm": 13.93730354309082,
      "learning_rate": 4.8880000000000005e-06,
      "logits/chosen": -2.6666598320007324,
      "logits/rejected": -2.6703221797943115,
      "logps/chosen": -870.569580078125,
      "logps/rejected": -1465.5107421875,
      "loss": 0.5985,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.004537200555205345,
      "rewards/margins": 0.21081161499023438,
      "rewards/rejected": -0.21534880995750427,
      "step": 15
    },
    {
      "epoch": 0.0256,
      "grad_norm": 14.93856430053711,
      "learning_rate": 4.880000000000001e-06,
      "logits/chosen": -2.6248462200164795,
      "logits/rejected": -2.6551945209503174,
      "logps/chosen": -1662.058349609375,
      "logps/rejected": -1971.7041015625,
      "loss": 0.5878,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.0158251766115427,
      "rewards/margins": 0.23583078384399414,
      "rewards/rejected": -0.2516559660434723,
      "step": 16
    },
    {
      "epoch": 0.0272,
      "grad_norm": 14.816671371459961,
      "learning_rate": 4.872000000000001e-06,
      "logits/chosen": -2.4937472343444824,
      "logits/rejected": -2.682842254638672,
      "logps/chosen": -948.5371704101562,
      "logps/rejected": -1703.80029296875,
      "loss": 0.6021,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.024558506906032562,
      "rewards/margins": 0.21781323850154877,
      "rewards/rejected": -0.24237176775932312,
      "step": 17
    },
    {
      "epoch": 0.0288,
      "grad_norm": 12.428322792053223,
      "learning_rate": 4.864e-06,
      "logits/chosen": -2.6531989574432373,
      "logits/rejected": -2.682439088821411,
      "logps/chosen": -778.6520385742188,
      "logps/rejected": -1449.53076171875,
      "loss": 0.5676,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.03554432466626167,
      "rewards/margins": 0.2960514426231384,
      "rewards/rejected": -0.26050710678100586,
      "step": 18
    },
    {
      "epoch": 0.0304,
      "grad_norm": 12.391500473022461,
      "learning_rate": 4.856e-06,
      "logits/chosen": -2.459970712661743,
      "logits/rejected": -2.6780951023101807,
      "logps/chosen": -818.6551513671875,
      "logps/rejected": -1620.040771484375,
      "loss": 0.588,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.001973985228687525,
      "rewards/margins": 0.22989128530025482,
      "rewards/rejected": -0.22791728377342224,
      "step": 19
    },
    {
      "epoch": 0.032,
      "grad_norm": 13.238450050354004,
      "learning_rate": 4.848000000000001e-06,
      "logits/chosen": -2.618525266647339,
      "logits/rejected": -2.676117420196533,
      "logps/chosen": -1253.937255859375,
      "logps/rejected": -1530.0140380859375,
      "loss": 0.5068,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.06150364875793457,
      "rewards/margins": 0.436116486787796,
      "rewards/rejected": -0.37461280822753906,
      "step": 20
    },
    {
      "epoch": 0.0336,
      "grad_norm": 13.758224487304688,
      "learning_rate": 4.84e-06,
      "logits/chosen": -2.4940528869628906,
      "logits/rejected": -2.680453300476074,
      "logps/chosen": -1219.4149169921875,
      "logps/rejected": -1796.268310546875,
      "loss": 0.5717,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.020945407450199127,
      "rewards/margins": 0.28807199001312256,
      "rewards/rejected": -0.3090174198150635,
      "step": 21
    },
    {
      "epoch": 0.0352,
      "grad_norm": 12.679354667663574,
      "learning_rate": 4.8320000000000005e-06,
      "logits/chosen": -2.620319366455078,
      "logits/rejected": -2.6380627155303955,
      "logps/chosen": -909.053955078125,
      "logps/rejected": -1786.5252685546875,
      "loss": 0.5014,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.012473417446017265,
      "rewards/margins": 0.46010851860046387,
      "rewards/rejected": -0.4725819230079651,
      "step": 22
    },
    {
      "epoch": 0.0368,
      "grad_norm": 12.088041305541992,
      "learning_rate": 4.824000000000001e-06,
      "logits/chosen": -2.6463091373443604,
      "logits/rejected": -2.692570209503174,
      "logps/chosen": -1262.638671875,
      "logps/rejected": -1490.438232421875,
      "loss": 0.5319,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.010773072950541973,
      "rewards/margins": 0.377711683511734,
      "rewards/rejected": -0.36693859100341797,
      "step": 23
    },
    {
      "epoch": 0.0384,
      "grad_norm": 9.156482696533203,
      "learning_rate": 4.816e-06,
      "logits/chosen": -2.629567861557007,
      "logits/rejected": -2.6734282970428467,
      "logps/chosen": -711.06689453125,
      "logps/rejected": -1337.4246826171875,
      "loss": 0.4945,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.01684603840112686,
      "rewards/margins": 0.5225176811218262,
      "rewards/rejected": -0.5056716203689575,
      "step": 24
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.210918426513672,
      "learning_rate": 4.808e-06,
      "logits/chosen": -2.605032205581665,
      "logits/rejected": -2.7605724334716797,
      "logps/chosen": -707.715087890625,
      "logps/rejected": -1503.8016357421875,
      "loss": 0.5287,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.005686664953827858,
      "rewards/margins": 0.39984220266342163,
      "rewards/rejected": -0.40552884340286255,
      "step": 25
    },
    {
      "epoch": 0.0416,
      "grad_norm": 10.902751922607422,
      "learning_rate": 4.800000000000001e-06,
      "logits/chosen": -2.6249494552612305,
      "logits/rejected": -2.684657096862793,
      "logps/chosen": -1321.66162109375,
      "logps/rejected": -1656.017822265625,
      "loss": 0.4818,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05061459541320801,
      "rewards/margins": 0.5790916681289673,
      "rewards/rejected": -0.6297063231468201,
      "step": 26
    },
    {
      "epoch": 0.0432,
      "grad_norm": 13.00150203704834,
      "learning_rate": 4.792000000000001e-06,
      "logits/chosen": -2.661109685897827,
      "logits/rejected": -2.6814064979553223,
      "logps/chosen": -1847.2550048828125,
      "logps/rejected": -2001.066650390625,
      "loss": 0.5217,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.052199430763721466,
      "rewards/margins": 0.4480840265750885,
      "rewards/rejected": -0.500283420085907,
      "step": 27
    },
    {
      "epoch": 0.0448,
      "grad_norm": 11.524428367614746,
      "learning_rate": 4.784e-06,
      "logits/chosen": -2.683142900466919,
      "logits/rejected": -2.678946018218994,
      "logps/chosen": -812.0352172851562,
      "logps/rejected": -1415.869873046875,
      "loss": 0.555,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.07924625277519226,
      "rewards/margins": 0.3242942690849304,
      "rewards/rejected": -0.4035405218601227,
      "step": 28
    },
    {
      "epoch": 0.0464,
      "grad_norm": 10.014718055725098,
      "learning_rate": 4.7760000000000005e-06,
      "logits/chosen": -2.7155520915985107,
      "logits/rejected": -2.743312120437622,
      "logps/chosen": -883.1109619140625,
      "logps/rejected": -1176.5841064453125,
      "loss": 0.5439,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.05535697937011719,
      "rewards/margins": 0.3843103349208832,
      "rewards/rejected": -0.43966731429100037,
      "step": 29
    },
    {
      "epoch": 0.048,
      "grad_norm": 12.479547500610352,
      "learning_rate": 4.768000000000001e-06,
      "logits/chosen": -2.5600876808166504,
      "logits/rejected": -2.6521291732788086,
      "logps/chosen": -1684.0687255859375,
      "logps/rejected": -1919.569580078125,
      "loss": 0.4945,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.05451701208949089,
      "rewards/margins": 0.5465288162231445,
      "rewards/rejected": -0.6010458469390869,
      "step": 30
    },
    {
      "epoch": 0.0496,
      "grad_norm": 9.141317367553711,
      "learning_rate": 4.76e-06,
      "logits/chosen": -2.6155083179473877,
      "logits/rejected": -2.661296844482422,
      "logps/chosen": -1145.3343505859375,
      "logps/rejected": -1538.8616943359375,
      "loss": 0.456,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.04083683341741562,
      "rewards/margins": 0.710364580154419,
      "rewards/rejected": -0.7512012720108032,
      "step": 31
    },
    {
      "epoch": 0.0512,
      "grad_norm": 15.683066368103027,
      "learning_rate": 4.752e-06,
      "logits/chosen": -2.6129798889160156,
      "logits/rejected": -2.651198387145996,
      "logps/chosen": -1547.58642578125,
      "logps/rejected": -2092.831298828125,
      "loss": 0.4714,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0672839805483818,
      "rewards/margins": 0.6104311347007751,
      "rewards/rejected": -0.6777151226997375,
      "step": 32
    },
    {
      "epoch": 0.0528,
      "grad_norm": 13.576567649841309,
      "learning_rate": 4.744000000000001e-06,
      "logits/chosen": -2.6763916015625,
      "logits/rejected": -2.6504852771759033,
      "logps/chosen": -1628.1005859375,
      "logps/rejected": -2366.822509765625,
      "loss": 0.5079,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.09182074666023254,
      "rewards/margins": 0.5748151540756226,
      "rewards/rejected": -0.6666358113288879,
      "step": 33
    },
    {
      "epoch": 0.0544,
      "grad_norm": 8.886429786682129,
      "learning_rate": 4.736000000000001e-06,
      "logits/chosen": -2.6563825607299805,
      "logits/rejected": -2.676598072052002,
      "logps/chosen": -819.4796752929688,
      "logps/rejected": -1863.988037109375,
      "loss": 0.3805,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.04877452924847603,
      "rewards/margins": 0.835731029510498,
      "rewards/rejected": -0.884505569934845,
      "step": 34
    },
    {
      "epoch": 0.056,
      "grad_norm": 9.606736183166504,
      "learning_rate": 4.728e-06,
      "logits/chosen": -2.580916404724121,
      "logits/rejected": -2.6463654041290283,
      "logps/chosen": -1010.1661376953125,
      "logps/rejected": -1484.5216064453125,
      "loss": 0.5075,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.05720997229218483,
      "rewards/margins": 0.48622170090675354,
      "rewards/rejected": -0.5434316396713257,
      "step": 35
    },
    {
      "epoch": 0.0576,
      "grad_norm": 10.908175468444824,
      "learning_rate": 4.7200000000000005e-06,
      "logits/chosen": -2.584986925125122,
      "logits/rejected": -2.6844449043273926,
      "logps/chosen": -1089.3065185546875,
      "logps/rejected": -1798.8800048828125,
      "loss": 0.4763,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.02441149204969406,
      "rewards/margins": 0.5325495600700378,
      "rewards/rejected": -0.5569610595703125,
      "step": 36
    },
    {
      "epoch": 0.0592,
      "grad_norm": 9.21141242980957,
      "learning_rate": 4.712000000000001e-06,
      "logits/chosen": -2.6176533699035645,
      "logits/rejected": -2.6927223205566406,
      "logps/chosen": -1048.0860595703125,
      "logps/rejected": -1829.177978515625,
      "loss": 0.3697,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.057007838040590286,
      "rewards/margins": 0.9821045994758606,
      "rewards/rejected": -1.0391124486923218,
      "step": 37
    },
    {
      "epoch": 0.0608,
      "grad_norm": 7.803262233734131,
      "learning_rate": 4.704e-06,
      "logits/chosen": -2.62152361869812,
      "logits/rejected": -2.6219406127929688,
      "logps/chosen": -1094.2901611328125,
      "logps/rejected": -1553.5328369140625,
      "loss": 0.3797,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05804776772856712,
      "rewards/margins": 1.0888700485229492,
      "rewards/rejected": -1.146917700767517,
      "step": 38
    },
    {
      "epoch": 0.0624,
      "grad_norm": 8.698044776916504,
      "learning_rate": 4.6960000000000004e-06,
      "logits/chosen": -2.5194172859191895,
      "logits/rejected": -2.606464385986328,
      "logps/chosen": -823.6840209960938,
      "logps/rejected": -1467.3602294921875,
      "loss": 0.392,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.03470757231116295,
      "rewards/margins": 1.0923101902008057,
      "rewards/rejected": -1.127017855644226,
      "step": 39
    },
    {
      "epoch": 0.064,
      "grad_norm": 6.490854740142822,
      "learning_rate": 4.688000000000001e-06,
      "logits/chosen": -2.5940024852752686,
      "logits/rejected": -2.6515138149261475,
      "logps/chosen": -1409.8240966796875,
      "logps/rejected": -1452.734130859375,
      "loss": 0.398,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.04286446049809456,
      "rewards/margins": 0.9120444655418396,
      "rewards/rejected": -0.8691800236701965,
      "step": 40
    },
    {
      "epoch": 0.0656,
      "grad_norm": 6.018487930297852,
      "learning_rate": 4.680000000000001e-06,
      "logits/chosen": -2.6572132110595703,
      "logits/rejected": -2.650991678237915,
      "logps/chosen": -678.6035766601562,
      "logps/rejected": -1320.1328125,
      "loss": 0.3627,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.023231374099850655,
      "rewards/margins": 1.0307849645614624,
      "rewards/rejected": -1.054016351699829,
      "step": 41
    },
    {
      "epoch": 0.0672,
      "grad_norm": 8.60428524017334,
      "learning_rate": 4.672e-06,
      "logits/chosen": -2.5752809047698975,
      "logits/rejected": -2.5308589935302734,
      "logps/chosen": -1056.8516845703125,
      "logps/rejected": -1674.0595703125,
      "loss": 0.4416,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.10828962177038193,
      "rewards/margins": 0.6796759366989136,
      "rewards/rejected": -0.7879655957221985,
      "step": 42
    },
    {
      "epoch": 0.0688,
      "grad_norm": 8.333077430725098,
      "learning_rate": 4.664000000000001e-06,
      "logits/chosen": -2.6510136127471924,
      "logits/rejected": -2.6296825408935547,
      "logps/chosen": -1003.7109985351562,
      "logps/rejected": -1255.5789794921875,
      "loss": 0.3983,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.09258784353733063,
      "rewards/margins": 0.8654865026473999,
      "rewards/rejected": -0.9580742716789246,
      "step": 43
    },
    {
      "epoch": 0.0704,
      "grad_norm": 12.893444061279297,
      "learning_rate": 4.656000000000001e-06,
      "logits/chosen": -2.6241934299468994,
      "logits/rejected": -2.669456720352173,
      "logps/chosen": -1349.458740234375,
      "logps/rejected": -1825.3187255859375,
      "loss": 0.3823,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.0006209835410118103,
      "rewards/margins": 0.8939098119735718,
      "rewards/rejected": -0.893288791179657,
      "step": 44
    },
    {
      "epoch": 0.072,
      "grad_norm": 7.785130977630615,
      "learning_rate": 4.648e-06,
      "logits/chosen": -2.6009161472320557,
      "logits/rejected": -2.6384713649749756,
      "logps/chosen": -983.5662231445312,
      "logps/rejected": -1404.76123046875,
      "loss": 0.4106,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.1607060432434082,
      "rewards/margins": 0.8162174224853516,
      "rewards/rejected": -0.9769235253334045,
      "step": 45
    },
    {
      "epoch": 0.0736,
      "grad_norm": 8.571884155273438,
      "learning_rate": 4.6400000000000005e-06,
      "logits/chosen": -2.6217942237854004,
      "logits/rejected": -2.59497332572937,
      "logps/chosen": -1128.59814453125,
      "logps/rejected": -2065.88037109375,
      "loss": 0.336,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05872344970703125,
      "rewards/margins": 1.121235728263855,
      "rewards/rejected": -1.1799592971801758,
      "step": 46
    },
    {
      "epoch": 0.0752,
      "grad_norm": 16.35368537902832,
      "learning_rate": 4.632000000000001e-06,
      "logits/chosen": -2.6781718730926514,
      "logits/rejected": -2.6508777141571045,
      "logps/chosen": -1655.6455078125,
      "logps/rejected": -2002.5736083984375,
      "loss": 0.4995,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.32652801275253296,
      "rewards/margins": 0.6819158792495728,
      "rewards/rejected": -1.008443832397461,
      "step": 47
    },
    {
      "epoch": 0.0768,
      "grad_norm": 9.724340438842773,
      "learning_rate": 4.624e-06,
      "logits/chosen": -2.5264768600463867,
      "logits/rejected": -2.6516530513763428,
      "logps/chosen": -904.1744384765625,
      "logps/rejected": -1660.6083984375,
      "loss": 0.3994,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.10329101234674454,
      "rewards/margins": 0.8224274516105652,
      "rewards/rejected": -0.9257184267044067,
      "step": 48
    },
    {
      "epoch": 0.0784,
      "grad_norm": 7.342824935913086,
      "learning_rate": 4.616e-06,
      "logits/chosen": -2.562744617462158,
      "logits/rejected": -2.625279426574707,
      "logps/chosen": -1723.362060546875,
      "logps/rejected": -2282.564697265625,
      "loss": 0.2484,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.04911966621875763,
      "rewards/margins": 1.6223055124282837,
      "rewards/rejected": -1.671425223350525,
      "step": 49
    },
    {
      "epoch": 0.08,
      "grad_norm": 8.13101577758789,
      "learning_rate": 4.608000000000001e-06,
      "logits/chosen": -2.5979814529418945,
      "logits/rejected": -2.661043643951416,
      "logps/chosen": -1319.5335693359375,
      "logps/rejected": -2360.220703125,
      "loss": 0.2667,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.21965599060058594,
      "rewards/margins": 1.5807113647460938,
      "rewards/rejected": -1.8003673553466797,
      "step": 50
    },
    {
      "epoch": 0.0816,
      "grad_norm": 9.218878746032715,
      "learning_rate": 4.600000000000001e-06,
      "logits/chosen": -2.6896519660949707,
      "logits/rejected": -2.6666102409362793,
      "logps/chosen": -1723.49365234375,
      "logps/rejected": -1863.3173828125,
      "loss": 0.2765,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.16897039115428925,
      "rewards/margins": 1.3319200277328491,
      "rewards/rejected": -1.5008903741836548,
      "step": 51
    },
    {
      "epoch": 0.0832,
      "grad_norm": 8.526917457580566,
      "learning_rate": 4.592e-06,
      "logits/chosen": -2.6378633975982666,
      "logits/rejected": -2.607964515686035,
      "logps/chosen": -1459.769287109375,
      "logps/rejected": -2045.569091796875,
      "loss": 0.2846,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.19974374771118164,
      "rewards/margins": 1.3471102714538574,
      "rewards/rejected": -1.546854019165039,
      "step": 52
    },
    {
      "epoch": 0.0848,
      "grad_norm": 8.359357833862305,
      "learning_rate": 4.5840000000000005e-06,
      "logits/chosen": -2.581343412399292,
      "logits/rejected": -2.611414670944214,
      "logps/chosen": -1180.2904052734375,
      "logps/rejected": -1913.8856201171875,
      "loss": 0.3621,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.2716429531574249,
      "rewards/margins": 1.28533136844635,
      "rewards/rejected": -1.556974172592163,
      "step": 53
    },
    {
      "epoch": 0.0864,
      "grad_norm": 7.808363914489746,
      "learning_rate": 4.576000000000001e-06,
      "logits/chosen": -2.5673961639404297,
      "logits/rejected": -2.5948398113250732,
      "logps/chosen": -929.301025390625,
      "logps/rejected": -1806.926513671875,
      "loss": 0.289,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.02968529425561428,
      "rewards/margins": 1.3527212142944336,
      "rewards/rejected": -1.38240647315979,
      "step": 54
    },
    {
      "epoch": 0.088,
      "grad_norm": 5.290113925933838,
      "learning_rate": 4.568e-06,
      "logits/chosen": -2.4589507579803467,
      "logits/rejected": -2.581552743911743,
      "logps/chosen": -977.469482421875,
      "logps/rejected": -1996.3978271484375,
      "loss": 0.1899,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.0343940295279026,
      "rewards/margins": 2.1228291988372803,
      "rewards/rejected": -2.1572232246398926,
      "step": 55
    },
    {
      "epoch": 0.0896,
      "grad_norm": 10.652748107910156,
      "learning_rate": 4.56e-06,
      "logits/chosen": -2.7046263217926025,
      "logits/rejected": -2.6611733436584473,
      "logps/chosen": -1413.8262939453125,
      "logps/rejected": -1913.01953125,
      "loss": 0.3432,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.22382622957229614,
      "rewards/margins": 1.2232162952423096,
      "rewards/rejected": -1.447042465209961,
      "step": 56
    },
    {
      "epoch": 0.0912,
      "grad_norm": 5.368223667144775,
      "learning_rate": 4.552000000000001e-06,
      "logits/chosen": -2.4487392902374268,
      "logits/rejected": -2.5721242427825928,
      "logps/chosen": -897.2557373046875,
      "logps/rejected": -1733.1632080078125,
      "loss": 0.3023,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.19797492027282715,
      "rewards/margins": 1.6058348417282104,
      "rewards/rejected": -1.8038097620010376,
      "step": 57
    },
    {
      "epoch": 0.0928,
      "grad_norm": 7.837594032287598,
      "learning_rate": 4.544000000000001e-06,
      "logits/chosen": -2.5975821018218994,
      "logits/rejected": -2.627551794052124,
      "logps/chosen": -1149.9952392578125,
      "logps/rejected": -1826.286865234375,
      "loss": 0.3125,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.30320632457733154,
      "rewards/margins": 1.412662148475647,
      "rewards/rejected": -1.715868353843689,
      "step": 58
    },
    {
      "epoch": 0.0944,
      "grad_norm": 6.844327926635742,
      "learning_rate": 4.536e-06,
      "logits/chosen": -2.5499839782714844,
      "logits/rejected": -2.6208062171936035,
      "logps/chosen": -1194.30322265625,
      "logps/rejected": -1783.07666015625,
      "loss": 0.2932,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.1366501748561859,
      "rewards/margins": 1.4224952459335327,
      "rewards/rejected": -1.5591453313827515,
      "step": 59
    },
    {
      "epoch": 0.096,
      "grad_norm": 205.78500366210938,
      "learning_rate": 4.5280000000000005e-06,
      "logits/chosen": -2.5601251125335693,
      "logits/rejected": -2.6464507579803467,
      "logps/chosen": -1088.5633544921875,
      "logps/rejected": -3391.80712890625,
      "loss": 0.6305,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.2457173466682434,
      "rewards/margins": 1.3898653984069824,
      "rewards/rejected": -1.6355828046798706,
      "step": 60
    },
    {
      "epoch": 0.0976,
      "grad_norm": 7.930796146392822,
      "learning_rate": 4.520000000000001e-06,
      "logits/chosen": -2.5776097774505615,
      "logits/rejected": -2.6505048274993896,
      "logps/chosen": -886.3343505859375,
      "logps/rejected": -1469.8668212890625,
      "loss": 0.3103,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.39389175176620483,
      "rewards/margins": 1.2291059494018555,
      "rewards/rejected": -1.622997760772705,
      "step": 61
    },
    {
      "epoch": 0.0992,
      "grad_norm": 8.633110046386719,
      "learning_rate": 4.512e-06,
      "logits/chosen": -2.654784679412842,
      "logits/rejected": -2.670534610748291,
      "logps/chosen": -1030.0927734375,
      "logps/rejected": -1780.8121337890625,
      "loss": 0.3556,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.4683406352996826,
      "rewards/margins": 1.7166171073913574,
      "rewards/rejected": -2.184957504272461,
      "step": 62
    },
    {
      "epoch": 0.1008,
      "grad_norm": 6.731282711029053,
      "learning_rate": 4.504e-06,
      "logits/chosen": -2.637357473373413,
      "logits/rejected": -2.647981882095337,
      "logps/chosen": -1333.366455078125,
      "logps/rejected": -1867.4859619140625,
      "loss": 0.2554,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.31539759039878845,
      "rewards/margins": 1.5246522426605225,
      "rewards/rejected": -1.8400498628616333,
      "step": 63
    },
    {
      "epoch": 0.1024,
      "grad_norm": 6.643932342529297,
      "learning_rate": 4.496000000000001e-06,
      "logits/chosen": -2.6055409908294678,
      "logits/rejected": -2.6496598720550537,
      "logps/chosen": -987.0455932617188,
      "logps/rejected": -1864.578857421875,
      "loss": 0.2255,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.18428108096122742,
      "rewards/margins": 1.8586022853851318,
      "rewards/rejected": -2.0428833961486816,
      "step": 64
    },
    {
      "epoch": 0.104,
      "grad_norm": 5.746735095977783,
      "learning_rate": 4.488e-06,
      "logits/chosen": -2.545200824737549,
      "logits/rejected": -2.58896541595459,
      "logps/chosen": -1011.6875610351562,
      "logps/rejected": -2194.0224609375,
      "loss": 0.2347,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.20740637183189392,
      "rewards/margins": 1.887122392654419,
      "rewards/rejected": -2.0945286750793457,
      "step": 65
    },
    {
      "epoch": 0.1056,
      "grad_norm": 5.9390034675598145,
      "learning_rate": 4.48e-06,
      "logits/chosen": -2.4846549034118652,
      "logits/rejected": -2.579946517944336,
      "logps/chosen": -1780.724853515625,
      "logps/rejected": -1745.9156494140625,
      "loss": 0.2963,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.25453251600265503,
      "rewards/margins": 1.4832229614257812,
      "rewards/rejected": -1.737755298614502,
      "step": 66
    },
    {
      "epoch": 0.1072,
      "grad_norm": 9.432305335998535,
      "learning_rate": 4.4720000000000006e-06,
      "logits/chosen": -2.617337226867676,
      "logits/rejected": -2.652225971221924,
      "logps/chosen": -1274.79052734375,
      "logps/rejected": -2235.274658203125,
      "loss": 0.2388,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.419139564037323,
      "rewards/margins": 1.8482582569122314,
      "rewards/rejected": -2.267397880554199,
      "step": 67
    },
    {
      "epoch": 0.1088,
      "grad_norm": 6.483062744140625,
      "learning_rate": 4.464000000000001e-06,
      "logits/chosen": -2.5569300651550293,
      "logits/rejected": -2.6234519481658936,
      "logps/chosen": -814.6470947265625,
      "logps/rejected": -1364.955322265625,
      "loss": 0.2891,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.3310353755950928,
      "rewards/margins": 1.6046247482299805,
      "rewards/rejected": -1.9356601238250732,
      "step": 68
    },
    {
      "epoch": 0.1104,
      "grad_norm": 10.457571029663086,
      "learning_rate": 4.456e-06,
      "logits/chosen": -2.635380268096924,
      "logits/rejected": -2.6364290714263916,
      "logps/chosen": -930.0864868164062,
      "logps/rejected": -1519.385498046875,
      "loss": 0.2952,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.2699303925037384,
      "rewards/margins": 1.4024217128753662,
      "rewards/rejected": -1.6723520755767822,
      "step": 69
    },
    {
      "epoch": 0.112,
      "grad_norm": 11.645984649658203,
      "learning_rate": 4.4480000000000004e-06,
      "logits/chosen": -2.570096969604492,
      "logits/rejected": -2.6213490962982178,
      "logps/chosen": -1099.063720703125,
      "logps/rejected": -1705.52685546875,
      "loss": 0.2962,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.2511003911495209,
      "rewards/margins": 1.76143479347229,
      "rewards/rejected": -2.0125350952148438,
      "step": 70
    },
    {
      "epoch": 0.1136,
      "grad_norm": 6.181652069091797,
      "learning_rate": 4.440000000000001e-06,
      "logits/chosen": -2.4734888076782227,
      "logits/rejected": -2.554945707321167,
      "logps/chosen": -874.9252319335938,
      "logps/rejected": -1451.4827880859375,
      "loss": 0.2926,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.327851802110672,
      "rewards/margins": 1.334261417388916,
      "rewards/rejected": -1.6621131896972656,
      "step": 71
    },
    {
      "epoch": 0.1152,
      "grad_norm": 5.611048698425293,
      "learning_rate": 4.432e-06,
      "logits/chosen": -2.550490617752075,
      "logits/rejected": -2.5684547424316406,
      "logps/chosen": -763.820556640625,
      "logps/rejected": -1657.6444091796875,
      "loss": 0.206,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.238494873046875,
      "rewards/margins": 1.9894895553588867,
      "rewards/rejected": -2.2279841899871826,
      "step": 72
    },
    {
      "epoch": 0.1168,
      "grad_norm": 13.854158401489258,
      "learning_rate": 4.424e-06,
      "logits/chosen": -2.5907607078552246,
      "logits/rejected": -2.6045408248901367,
      "logps/chosen": -1226.4503173828125,
      "logps/rejected": -1327.1646728515625,
      "loss": 0.3485,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.4577573537826538,
      "rewards/margins": 1.198114037513733,
      "rewards/rejected": -1.6558715105056763,
      "step": 73
    },
    {
      "epoch": 0.1184,
      "grad_norm": 5.611763000488281,
      "learning_rate": 4.416000000000001e-06,
      "logits/chosen": -2.594604015350342,
      "logits/rejected": -2.618083953857422,
      "logps/chosen": -1221.1024169921875,
      "logps/rejected": -1504.3363037109375,
      "loss": 0.2573,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.3714500665664673,
      "rewards/margins": 1.6484025716781616,
      "rewards/rejected": -2.019852638244629,
      "step": 74
    },
    {
      "epoch": 0.12,
      "grad_norm": 8.361706733703613,
      "learning_rate": 4.408000000000001e-06,
      "logits/chosen": -2.580840587615967,
      "logits/rejected": -2.6079723834991455,
      "logps/chosen": -1046.5628662109375,
      "logps/rejected": -1562.197998046875,
      "loss": 0.307,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6689375638961792,
      "rewards/margins": 1.8238919973373413,
      "rewards/rejected": -2.4928297996520996,
      "step": 75
    },
    {
      "epoch": 0.1216,
      "grad_norm": 3.6236655712127686,
      "learning_rate": 4.4e-06,
      "logits/chosen": -2.4853832721710205,
      "logits/rejected": -2.591280460357666,
      "logps/chosen": -741.3472290039062,
      "logps/rejected": -1564.3145751953125,
      "loss": 0.1902,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3526232838630676,
      "rewards/margins": 2.3361167907714844,
      "rewards/rejected": -2.6887402534484863,
      "step": 76
    },
    {
      "epoch": 0.1232,
      "grad_norm": 8.047240257263184,
      "learning_rate": 4.3920000000000005e-06,
      "logits/chosen": -2.557563543319702,
      "logits/rejected": -2.5950872898101807,
      "logps/chosen": -938.3635864257812,
      "logps/rejected": -1425.4912109375,
      "loss": 0.3002,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.5570125579833984,
      "rewards/margins": 1.5159423351287842,
      "rewards/rejected": -2.0729548931121826,
      "step": 77
    },
    {
      "epoch": 0.1248,
      "grad_norm": 8.9595947265625,
      "learning_rate": 4.384000000000001e-06,
      "logits/chosen": -2.5734753608703613,
      "logits/rejected": -2.6293206214904785,
      "logps/chosen": -895.8095703125,
      "logps/rejected": -1800.114990234375,
      "loss": 0.2564,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.45989689230918884,
      "rewards/margins": 2.351109743118286,
      "rewards/rejected": -2.811006546020508,
      "step": 78
    },
    {
      "epoch": 0.1264,
      "grad_norm": 5.05607271194458,
      "learning_rate": 4.376e-06,
      "logits/chosen": -2.5721628665924072,
      "logits/rejected": -2.5577292442321777,
      "logps/chosen": -1524.828125,
      "logps/rejected": -2003.477783203125,
      "loss": 0.2166,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.642715573310852,
      "rewards/margins": 1.8920629024505615,
      "rewards/rejected": -2.534778594970703,
      "step": 79
    },
    {
      "epoch": 0.128,
      "grad_norm": 7.038112640380859,
      "learning_rate": 4.368e-06,
      "logits/chosen": -2.5882246494293213,
      "logits/rejected": -2.6154489517211914,
      "logps/chosen": -1290.900146484375,
      "logps/rejected": -1854.79052734375,
      "loss": 0.2536,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.52741539478302,
      "rewards/margins": 1.8594735860824585,
      "rewards/rejected": -2.3868889808654785,
      "step": 80
    },
    {
      "epoch": 0.1296,
      "grad_norm": 17.065824508666992,
      "learning_rate": 4.360000000000001e-06,
      "logits/chosen": -2.602525234222412,
      "logits/rejected": -2.614187240600586,
      "logps/chosen": -1639.3414306640625,
      "logps/rejected": -2388.6005859375,
      "loss": 0.5064,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.949549674987793,
      "rewards/margins": 2.212076187133789,
      "rewards/rejected": -3.161626100540161,
      "step": 81
    },
    {
      "epoch": 0.1312,
      "grad_norm": 7.686249732971191,
      "learning_rate": 4.352e-06,
      "logits/chosen": -2.4996836185455322,
      "logits/rejected": -2.5744447708129883,
      "logps/chosen": -989.7198486328125,
      "logps/rejected": -1813.3284912109375,
      "loss": 0.3302,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.3831857442855835,
      "rewards/margins": 1.527978777885437,
      "rewards/rejected": -1.9111645221710205,
      "step": 82
    },
    {
      "epoch": 0.1328,
      "grad_norm": 5.631213188171387,
      "learning_rate": 4.344e-06,
      "logits/chosen": -2.506361961364746,
      "logits/rejected": -2.509040117263794,
      "logps/chosen": -1139.1744384765625,
      "logps/rejected": -1718.2315673828125,
      "loss": 0.1896,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.26063406467437744,
      "rewards/margins": 2.65224289894104,
      "rewards/rejected": -2.912876605987549,
      "step": 83
    },
    {
      "epoch": 0.1344,
      "grad_norm": 4.509877681732178,
      "learning_rate": 4.3360000000000005e-06,
      "logits/chosen": -2.4786159992218018,
      "logits/rejected": -2.5557239055633545,
      "logps/chosen": -748.5143432617188,
      "logps/rejected": -1279.4168701171875,
      "loss": 0.2451,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.3035600781440735,
      "rewards/margins": 1.7710323333740234,
      "rewards/rejected": -2.074592351913452,
      "step": 84
    },
    {
      "epoch": 0.136,
      "grad_norm": 5.832723140716553,
      "learning_rate": 4.328000000000001e-06,
      "logits/chosen": -2.4516549110412598,
      "logits/rejected": -2.5038058757781982,
      "logps/chosen": -1300.7103271484375,
      "logps/rejected": -1945.7178955078125,
      "loss": 0.1813,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.5661133527755737,
      "rewards/margins": 2.6094062328338623,
      "rewards/rejected": -3.1755197048187256,
      "step": 85
    },
    {
      "epoch": 0.1376,
      "grad_norm": 5.095184803009033,
      "learning_rate": 4.32e-06,
      "logits/chosen": -2.585329294204712,
      "logits/rejected": -2.676424503326416,
      "logps/chosen": -916.580322265625,
      "logps/rejected": -1257.6103515625,
      "loss": 0.3074,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.36674830317497253,
      "rewards/margins": 1.4988261461257935,
      "rewards/rejected": -1.8655743598937988,
      "step": 86
    },
    {
      "epoch": 0.1392,
      "grad_norm": 20.858564376831055,
      "learning_rate": 4.312e-06,
      "logits/chosen": -2.416091203689575,
      "logits/rejected": -2.569261074066162,
      "logps/chosen": -1258.1981201171875,
      "logps/rejected": -1846.1219482421875,
      "loss": 0.2848,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.5368421673774719,
      "rewards/margins": 2.049252986907959,
      "rewards/rejected": -2.586095094680786,
      "step": 87
    },
    {
      "epoch": 0.1408,
      "grad_norm": 6.0946173667907715,
      "learning_rate": 4.304000000000001e-06,
      "logits/chosen": -2.563009262084961,
      "logits/rejected": -2.6318721771240234,
      "logps/chosen": -1039.8516845703125,
      "logps/rejected": -1420.2889404296875,
      "loss": 0.2437,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.5421506762504578,
      "rewards/margins": 2.181781530380249,
      "rewards/rejected": -2.7239322662353516,
      "step": 88
    },
    {
      "epoch": 0.1424,
      "grad_norm": 3.6643338203430176,
      "learning_rate": 4.296e-06,
      "logits/chosen": -2.608748435974121,
      "logits/rejected": -2.6187620162963867,
      "logps/chosen": -1215.0611572265625,
      "logps/rejected": -1734.988037109375,
      "loss": 0.1181,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.44078579545021057,
      "rewards/margins": 2.6274781227111816,
      "rewards/rejected": -3.0682640075683594,
      "step": 89
    },
    {
      "epoch": 0.144,
      "grad_norm": 8.087428092956543,
      "learning_rate": 4.288e-06,
      "logits/chosen": -2.465214252471924,
      "logits/rejected": -2.522395133972168,
      "logps/chosen": -1388.467041015625,
      "logps/rejected": -1995.6883544921875,
      "loss": 0.2867,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.673370897769928,
      "rewards/margins": 2.2415404319763184,
      "rewards/rejected": -2.9149117469787598,
      "step": 90
    },
    {
      "epoch": 0.1456,
      "grad_norm": 4.81944465637207,
      "learning_rate": 4.2800000000000005e-06,
      "logits/chosen": -2.6290841102600098,
      "logits/rejected": -2.615664482116699,
      "logps/chosen": -1001.8236083984375,
      "logps/rejected": -2059.611083984375,
      "loss": 0.2716,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.45704299211502075,
      "rewards/margins": 1.9129340648651123,
      "rewards/rejected": -2.3699769973754883,
      "step": 91
    },
    {
      "epoch": 0.1472,
      "grad_norm": 3.614452600479126,
      "learning_rate": 4.272000000000001e-06,
      "logits/chosen": -2.4316258430480957,
      "logits/rejected": -2.5464510917663574,
      "logps/chosen": -745.938720703125,
      "logps/rejected": -1623.67333984375,
      "loss": 0.1801,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.47279757261276245,
      "rewards/margins": 2.9887681007385254,
      "rewards/rejected": -3.4615654945373535,
      "step": 92
    },
    {
      "epoch": 0.1488,
      "grad_norm": 5.576539039611816,
      "learning_rate": 4.264e-06,
      "logits/chosen": -2.6419267654418945,
      "logits/rejected": -2.6333372592926025,
      "logps/chosen": -987.1685791015625,
      "logps/rejected": -1516.3785400390625,
      "loss": 0.2319,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5648906826972961,
      "rewards/margins": 1.8507626056671143,
      "rewards/rejected": -2.4156529903411865,
      "step": 93
    },
    {
      "epoch": 0.1504,
      "grad_norm": 5.097036838531494,
      "learning_rate": 4.256e-06,
      "logits/chosen": -2.56418776512146,
      "logits/rejected": -2.5272862911224365,
      "logps/chosen": -1249.920654296875,
      "logps/rejected": -2077.8505859375,
      "loss": 0.1224,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.7480093836784363,
      "rewards/margins": 2.954930305480957,
      "rewards/rejected": -3.702939510345459,
      "step": 94
    },
    {
      "epoch": 0.152,
      "grad_norm": 6.1745805740356445,
      "learning_rate": 4.248000000000001e-06,
      "logits/chosen": -2.505357027053833,
      "logits/rejected": -2.543433666229248,
      "logps/chosen": -841.8966674804688,
      "logps/rejected": -1403.500732421875,
      "loss": 0.2898,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.8015140891075134,
      "rewards/margins": 1.7237809896469116,
      "rewards/rejected": -2.5252950191497803,
      "step": 95
    },
    {
      "epoch": 0.1536,
      "grad_norm": 7.1390485763549805,
      "learning_rate": 4.24e-06,
      "logits/chosen": -2.4471356868743896,
      "logits/rejected": -2.5040111541748047,
      "logps/chosen": -1905.2022705078125,
      "logps/rejected": -2456.6328125,
      "loss": 0.204,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7161625027656555,
      "rewards/margins": 2.2444329261779785,
      "rewards/rejected": -2.96059513092041,
      "step": 96
    },
    {
      "epoch": 0.1552,
      "grad_norm": 4.844906806945801,
      "learning_rate": 4.232e-06,
      "logits/chosen": -2.5816986560821533,
      "logits/rejected": -2.5688273906707764,
      "logps/chosen": -1612.9542236328125,
      "logps/rejected": -1981.49658203125,
      "loss": 0.2022,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6185023188591003,
      "rewards/margins": 2.7044992446899414,
      "rewards/rejected": -3.3230013847351074,
      "step": 97
    },
    {
      "epoch": 0.1568,
      "grad_norm": 3.969409942626953,
      "learning_rate": 4.2240000000000006e-06,
      "logits/chosen": -2.584040880203247,
      "logits/rejected": -2.6002554893493652,
      "logps/chosen": -1084.38916015625,
      "logps/rejected": -1864.0318603515625,
      "loss": 0.1288,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.634515643119812,
      "rewards/margins": 2.674475908279419,
      "rewards/rejected": -3.3089914321899414,
      "step": 98
    },
    {
      "epoch": 0.1584,
      "grad_norm": 3.6561484336853027,
      "learning_rate": 4.216e-06,
      "logits/chosen": -2.5594630241394043,
      "logits/rejected": -2.5877585411071777,
      "logps/chosen": -1121.3568115234375,
      "logps/rejected": -1565.031005859375,
      "loss": 0.1462,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5637044310569763,
      "rewards/margins": 2.3934009075164795,
      "rewards/rejected": -2.9571051597595215,
      "step": 99
    },
    {
      "epoch": 0.16,
      "grad_norm": 12.20343017578125,
      "learning_rate": 4.208e-06,
      "logits/chosen": -2.4423067569732666,
      "logits/rejected": -2.5798287391662598,
      "logps/chosen": -881.176025390625,
      "logps/rejected": -1321.0848388671875,
      "loss": 0.3971,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.895788311958313,
      "rewards/margins": 1.4614109992980957,
      "rewards/rejected": -2.3571994304656982,
      "step": 100
    },
    {
      "epoch": 0.1616,
      "grad_norm": 5.749557018280029,
      "learning_rate": 4.2000000000000004e-06,
      "logits/chosen": -2.602213144302368,
      "logits/rejected": -2.601937770843506,
      "logps/chosen": -919.701904296875,
      "logps/rejected": -1737.4989013671875,
      "loss": 0.2203,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.606166422367096,
      "rewards/margins": 2.317492961883545,
      "rewards/rejected": -2.923659563064575,
      "step": 101
    },
    {
      "epoch": 0.1632,
      "grad_norm": 4.590999603271484,
      "learning_rate": 4.192000000000001e-06,
      "logits/chosen": -2.3970415592193604,
      "logits/rejected": -2.5931670665740967,
      "logps/chosen": -1294.47119140625,
      "logps/rejected": -1755.6636962890625,
      "loss": 0.2248,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6253247261047363,
      "rewards/margins": 2.2332234382629395,
      "rewards/rejected": -2.858548164367676,
      "step": 102
    },
    {
      "epoch": 0.1648,
      "grad_norm": 16.120969772338867,
      "learning_rate": 4.184e-06,
      "logits/chosen": -2.5599992275238037,
      "logits/rejected": -2.573983907699585,
      "logps/chosen": -1003.275146484375,
      "logps/rejected": -1651.6865234375,
      "loss": 0.4831,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.1576511859893799,
      "rewards/margins": 1.7802574634552002,
      "rewards/rejected": -2.93790864944458,
      "step": 103
    },
    {
      "epoch": 0.1664,
      "grad_norm": 5.281605243682861,
      "learning_rate": 4.176e-06,
      "logits/chosen": -2.607374668121338,
      "logits/rejected": -2.606253147125244,
      "logps/chosen": -850.6956787109375,
      "logps/rejected": -1412.715087890625,
      "loss": 0.1988,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.44642406702041626,
      "rewards/margins": 2.147481918334961,
      "rewards/rejected": -2.5939061641693115,
      "step": 104
    },
    {
      "epoch": 0.168,
      "grad_norm": 11.615784645080566,
      "learning_rate": 4.168000000000001e-06,
      "logits/chosen": -2.5488691329956055,
      "logits/rejected": -2.5383386611938477,
      "logps/chosen": -983.83056640625,
      "logps/rejected": -1517.0146484375,
      "loss": 0.3262,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.5420036315917969,
      "rewards/margins": 1.8067235946655273,
      "rewards/rejected": -2.348727226257324,
      "step": 105
    },
    {
      "epoch": 0.1696,
      "grad_norm": 6.295446872711182,
      "learning_rate": 4.16e-06,
      "logits/chosen": -2.5123789310455322,
      "logits/rejected": -2.5552313327789307,
      "logps/chosen": -1516.11328125,
      "logps/rejected": -2322.301513671875,
      "loss": 0.1412,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.4955001771450043,
      "rewards/margins": 3.6774232387542725,
      "rewards/rejected": -4.1729230880737305,
      "step": 106
    },
    {
      "epoch": 0.1712,
      "grad_norm": 4.434859275817871,
      "learning_rate": 4.152e-06,
      "logits/chosen": -2.536618709564209,
      "logits/rejected": -2.5697824954986572,
      "logps/chosen": -1193.616455078125,
      "logps/rejected": -2063.705322265625,
      "loss": 0.1738,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.48417752981185913,
      "rewards/margins": 2.482280969619751,
      "rewards/rejected": -2.966458320617676,
      "step": 107
    },
    {
      "epoch": 0.1728,
      "grad_norm": 9.057612419128418,
      "learning_rate": 4.1440000000000005e-06,
      "logits/chosen": -2.616786479949951,
      "logits/rejected": -2.611959218978882,
      "logps/chosen": -1132.6375732421875,
      "logps/rejected": -1788.1622314453125,
      "loss": 0.2076,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.5882627367973328,
      "rewards/margins": 2.2522530555725098,
      "rewards/rejected": -2.840515613555908,
      "step": 108
    },
    {
      "epoch": 0.1744,
      "grad_norm": 3.2958192825317383,
      "learning_rate": 4.136000000000001e-06,
      "logits/chosen": -2.499824285507202,
      "logits/rejected": -2.5699918270111084,
      "logps/chosen": -939.944091796875,
      "logps/rejected": -1518.7822265625,
      "loss": 0.1296,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.655009388923645,
      "rewards/margins": 2.581965923309326,
      "rewards/rejected": -3.2369751930236816,
      "step": 109
    },
    {
      "epoch": 0.176,
      "grad_norm": 7.810518741607666,
      "learning_rate": 4.128e-06,
      "logits/chosen": -2.553767204284668,
      "logits/rejected": -2.5513415336608887,
      "logps/chosen": -1652.2960205078125,
      "logps/rejected": -2008.56787109375,
      "loss": 0.2238,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3638471364974976,
      "rewards/margins": 2.126260995864868,
      "rewards/rejected": -3.4901082515716553,
      "step": 110
    },
    {
      "epoch": 0.1776,
      "grad_norm": 4.5927228927612305,
      "learning_rate": 4.12e-06,
      "logits/chosen": -2.413992166519165,
      "logits/rejected": -2.5045244693756104,
      "logps/chosen": -1156.638916015625,
      "logps/rejected": -2067.70654296875,
      "loss": 0.1824,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7974650859832764,
      "rewards/margins": 2.9131991863250732,
      "rewards/rejected": -3.7106642723083496,
      "step": 111
    },
    {
      "epoch": 0.1792,
      "grad_norm": 8.073678970336914,
      "learning_rate": 4.112000000000001e-06,
      "logits/chosen": -2.5610158443450928,
      "logits/rejected": -2.5489323139190674,
      "logps/chosen": -1340.7498779296875,
      "logps/rejected": -1710.4718017578125,
      "loss": 0.2481,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.063918113708496,
      "rewards/margins": 2.275148391723633,
      "rewards/rejected": -3.339066743850708,
      "step": 112
    },
    {
      "epoch": 0.1808,
      "grad_norm": 7.3243184089660645,
      "learning_rate": 4.104e-06,
      "logits/chosen": -2.5899980068206787,
      "logits/rejected": -2.6016769409179688,
      "logps/chosen": -1197.3370361328125,
      "logps/rejected": -1886.951416015625,
      "loss": 0.163,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.103943109512329,
      "rewards/margins": 2.9499807357788086,
      "rewards/rejected": -4.053923606872559,
      "step": 113
    },
    {
      "epoch": 0.1824,
      "grad_norm": 4.7918572425842285,
      "learning_rate": 4.096e-06,
      "logits/chosen": -2.5200982093811035,
      "logits/rejected": -2.5774784088134766,
      "logps/chosen": -847.1478881835938,
      "logps/rejected": -1482.089111328125,
      "loss": 0.1808,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5526469349861145,
      "rewards/margins": 2.572946310043335,
      "rewards/rejected": -3.125593423843384,
      "step": 114
    },
    {
      "epoch": 0.184,
      "grad_norm": 15.692960739135742,
      "learning_rate": 4.0880000000000005e-06,
      "logits/chosen": -2.5463898181915283,
      "logits/rejected": -2.5766215324401855,
      "logps/chosen": -789.5115356445312,
      "logps/rejected": -991.499267578125,
      "loss": 0.4221,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -0.8561378717422485,
      "rewards/margins": 1.456132173538208,
      "rewards/rejected": -2.312270164489746,
      "step": 115
    },
    {
      "epoch": 0.1856,
      "grad_norm": 3.677607297897339,
      "learning_rate": 4.08e-06,
      "logits/chosen": -2.5052475929260254,
      "logits/rejected": -2.5343563556671143,
      "logps/chosen": -560.2702026367188,
      "logps/rejected": -1089.4345703125,
      "loss": 0.2277,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.4389704763889313,
      "rewards/margins": 2.0417025089263916,
      "rewards/rejected": -2.48067307472229,
      "step": 116
    },
    {
      "epoch": 0.1872,
      "grad_norm": 3.6556031703948975,
      "learning_rate": 4.072e-06,
      "logits/chosen": -2.522127389907837,
      "logits/rejected": -2.544343948364258,
      "logps/chosen": -682.1380615234375,
      "logps/rejected": -1690.5791015625,
      "loss": 0.1131,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8120488524436951,
      "rewards/margins": 3.206557035446167,
      "rewards/rejected": -4.018606185913086,
      "step": 117
    },
    {
      "epoch": 0.1888,
      "grad_norm": 4.322643756866455,
      "learning_rate": 4.064e-06,
      "logits/chosen": -2.601647138595581,
      "logits/rejected": -2.59454607963562,
      "logps/chosen": -926.12255859375,
      "logps/rejected": -1310.7066650390625,
      "loss": 0.1852,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.739689826965332,
      "rewards/margins": 2.574465274810791,
      "rewards/rejected": -3.314155101776123,
      "step": 118
    },
    {
      "epoch": 0.1904,
      "grad_norm": 4.198337078094482,
      "learning_rate": 4.056000000000001e-06,
      "logits/chosen": -2.522589683532715,
      "logits/rejected": -2.6258111000061035,
      "logps/chosen": -1165.843505859375,
      "logps/rejected": -1964.45263671875,
      "loss": 0.1764,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9625725150108337,
      "rewards/margins": 2.6513829231262207,
      "rewards/rejected": -3.613955020904541,
      "step": 119
    },
    {
      "epoch": 0.192,
      "grad_norm": 3.156885862350464,
      "learning_rate": 4.048e-06,
      "logits/chosen": -2.5727691650390625,
      "logits/rejected": -2.5709733963012695,
      "logps/chosen": -746.4669799804688,
      "logps/rejected": -1984.4471435546875,
      "loss": 0.1321,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7271446585655212,
      "rewards/margins": 3.445657253265381,
      "rewards/rejected": -4.172801971435547,
      "step": 120
    },
    {
      "epoch": 0.1936,
      "grad_norm": 6.7459716796875,
      "learning_rate": 4.04e-06,
      "logits/chosen": -2.5250120162963867,
      "logits/rejected": -2.5538296699523926,
      "logps/chosen": -992.5125122070312,
      "logps/rejected": -1538.8245849609375,
      "loss": 0.1583,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.7747882008552551,
      "rewards/margins": 2.703141450881958,
      "rewards/rejected": -3.4779298305511475,
      "step": 121
    },
    {
      "epoch": 0.1952,
      "grad_norm": 9.80472183227539,
      "learning_rate": 4.0320000000000005e-06,
      "logits/chosen": -2.4653236865997314,
      "logits/rejected": -2.5068607330322266,
      "logps/chosen": -552.443603515625,
      "logps/rejected": -1238.7698974609375,
      "loss": 0.315,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.31036150455474854,
      "rewards/margins": 2.591792583465576,
      "rewards/rejected": -2.9021544456481934,
      "step": 122
    },
    {
      "epoch": 0.1968,
      "grad_norm": 13.748944282531738,
      "learning_rate": 4.024e-06,
      "logits/chosen": -2.5244879722595215,
      "logits/rejected": -2.597602605819702,
      "logps/chosen": -1166.708251953125,
      "logps/rejected": -1306.92333984375,
      "loss": 0.4899,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -0.9613562226295471,
      "rewards/margins": 1.8996186256408691,
      "rewards/rejected": -2.8609747886657715,
      "step": 123
    },
    {
      "epoch": 0.1984,
      "grad_norm": 14.293259620666504,
      "learning_rate": 4.016e-06,
      "logits/chosen": -2.5158143043518066,
      "logits/rejected": -2.554211378097534,
      "logps/chosen": -1433.0123291015625,
      "logps/rejected": -1870.782958984375,
      "loss": 0.2966,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.226749300956726,
      "rewards/margins": 3.126378297805786,
      "rewards/rejected": -4.353127956390381,
      "step": 124
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.3207201957702637,
      "learning_rate": 4.008e-06,
      "logits/chosen": -2.496079444885254,
      "logits/rejected": -2.576896905899048,
      "logps/chosen": -859.4109497070312,
      "logps/rejected": -1584.8419189453125,
      "loss": 0.1432,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.42094314098358154,
      "rewards/margins": 3.134261131286621,
      "rewards/rejected": -3.555204153060913,
      "step": 125
    },
    {
      "epoch": 0.2016,
      "grad_norm": 3.332416534423828,
      "learning_rate": 4.000000000000001e-06,
      "logits/chosen": -2.5275533199310303,
      "logits/rejected": -2.483595609664917,
      "logps/chosen": -879.3700561523438,
      "logps/rejected": -2131.501220703125,
      "loss": 0.1392,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9118862748146057,
      "rewards/margins": 2.979250907897949,
      "rewards/rejected": -3.89113712310791,
      "step": 126
    },
    {
      "epoch": 0.2032,
      "grad_norm": 6.760028839111328,
      "learning_rate": 3.992e-06,
      "logits/chosen": -2.608065605163574,
      "logits/rejected": -2.583610773086548,
      "logps/chosen": -1289.19482421875,
      "logps/rejected": -1713.55029296875,
      "loss": 0.2363,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.1525237560272217,
      "rewards/margins": 2.986644983291626,
      "rewards/rejected": -4.139168739318848,
      "step": 127
    },
    {
      "epoch": 0.2048,
      "grad_norm": 3.060511827468872,
      "learning_rate": 3.984e-06,
      "logits/chosen": -2.451570510864258,
      "logits/rejected": -2.5113959312438965,
      "logps/chosen": -1457.956787109375,
      "logps/rejected": -2191.547607421875,
      "loss": 0.1274,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.4851548969745636,
      "rewards/margins": 3.52443528175354,
      "rewards/rejected": -4.0095906257629395,
      "step": 128
    },
    {
      "epoch": 0.2064,
      "grad_norm": 2.8927700519561768,
      "learning_rate": 3.9760000000000006e-06,
      "logits/chosen": -2.512958526611328,
      "logits/rejected": -2.574584484100342,
      "logps/chosen": -1085.35498046875,
      "logps/rejected": -1939.70263671875,
      "loss": 0.1125,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9995681643486023,
      "rewards/margins": 3.5580430030822754,
      "rewards/rejected": -4.557610511779785,
      "step": 129
    },
    {
      "epoch": 0.208,
      "grad_norm": 4.129473686218262,
      "learning_rate": 3.968e-06,
      "logits/chosen": -2.565162420272827,
      "logits/rejected": -2.6009206771850586,
      "logps/chosen": -567.710693359375,
      "logps/rejected": -1451.09375,
      "loss": 0.1144,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.4607435464859009,
      "rewards/margins": 2.9835822582244873,
      "rewards/rejected": -3.4443259239196777,
      "step": 130
    },
    {
      "epoch": 0.2096,
      "grad_norm": 4.102241516113281,
      "learning_rate": 3.96e-06,
      "logits/chosen": -2.4444751739501953,
      "logits/rejected": -2.6011734008789062,
      "logps/chosen": -1220.895263671875,
      "logps/rejected": -1985.649658203125,
      "loss": 0.1702,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9114336967468262,
      "rewards/margins": 2.851128578186035,
      "rewards/rejected": -3.7625622749328613,
      "step": 131
    },
    {
      "epoch": 0.2112,
      "grad_norm": 2.884464979171753,
      "learning_rate": 3.9520000000000004e-06,
      "logits/chosen": -2.4112792015075684,
      "logits/rejected": -2.5846099853515625,
      "logps/chosen": -1018.2316284179688,
      "logps/rejected": -1463.556884765625,
      "loss": 0.1952,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.45826709270477295,
      "rewards/margins": 2.8891117572784424,
      "rewards/rejected": -3.347379207611084,
      "step": 132
    },
    {
      "epoch": 0.2128,
      "grad_norm": 15.877314567565918,
      "learning_rate": 3.944e-06,
      "logits/chosen": -2.467106819152832,
      "logits/rejected": -2.41418719291687,
      "logps/chosen": -806.1968994140625,
      "logps/rejected": -1754.9730224609375,
      "loss": 0.2881,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.857244074344635,
      "rewards/margins": 1.6606969833374023,
      "rewards/rejected": -2.5179409980773926,
      "step": 133
    },
    {
      "epoch": 0.2144,
      "grad_norm": 6.443378448486328,
      "learning_rate": 3.936e-06,
      "logits/chosen": -2.3440699577331543,
      "logits/rejected": -2.3869597911834717,
      "logps/chosen": -1463.260498046875,
      "logps/rejected": -2181.1904296875,
      "loss": 0.2211,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.9759093523025513,
      "rewards/margins": 2.938526153564453,
      "rewards/rejected": -3.914435625076294,
      "step": 134
    },
    {
      "epoch": 0.216,
      "grad_norm": 9.547797203063965,
      "learning_rate": 3.928e-06,
      "logits/chosen": -2.52040958404541,
      "logits/rejected": -2.551767349243164,
      "logps/chosen": -1197.7349853515625,
      "logps/rejected": -1658.1649169921875,
      "loss": 0.2781,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.3941388130187988,
      "rewards/margins": 3.5148253440856934,
      "rewards/rejected": -4.908964157104492,
      "step": 135
    },
    {
      "epoch": 0.2176,
      "grad_norm": 6.182735919952393,
      "learning_rate": 3.920000000000001e-06,
      "logits/chosen": -2.5605454444885254,
      "logits/rejected": -2.531198024749756,
      "logps/chosen": -988.170654296875,
      "logps/rejected": -1963.998046875,
      "loss": 0.1443,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.5118147134780884,
      "rewards/margins": 3.4174416065216064,
      "rewards/rejected": -4.929256439208984,
      "step": 136
    },
    {
      "epoch": 0.2192,
      "grad_norm": 7.644084930419922,
      "learning_rate": 3.912e-06,
      "logits/chosen": -2.543659210205078,
      "logits/rejected": -2.5699219703674316,
      "logps/chosen": -1353.5325927734375,
      "logps/rejected": -1824.071044921875,
      "loss": 0.2173,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.8958762884140015,
      "rewards/margins": 2.6294684410095215,
      "rewards/rejected": -3.5253448486328125,
      "step": 137
    },
    {
      "epoch": 0.2208,
      "grad_norm": 4.071524143218994,
      "learning_rate": 3.904e-06,
      "logits/chosen": -2.5461974143981934,
      "logits/rejected": -2.5904407501220703,
      "logps/chosen": -745.4497680664062,
      "logps/rejected": -1123.198486328125,
      "loss": 0.2398,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.7141005396842957,
      "rewards/margins": 2.1651272773742676,
      "rewards/rejected": -2.879227638244629,
      "step": 138
    },
    {
      "epoch": 0.2224,
      "grad_norm": 3.2782349586486816,
      "learning_rate": 3.8960000000000005e-06,
      "logits/chosen": -2.393317461013794,
      "logits/rejected": -2.5693154335021973,
      "logps/chosen": -692.12646484375,
      "logps/rejected": -1369.6094970703125,
      "loss": 0.1614,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.5928390026092529,
      "rewards/margins": 3.0415475368499756,
      "rewards/rejected": -3.6343865394592285,
      "step": 139
    },
    {
      "epoch": 0.224,
      "grad_norm": 6.556819915771484,
      "learning_rate": 3.888e-06,
      "logits/chosen": -2.562467098236084,
      "logits/rejected": -2.602529287338257,
      "logps/chosen": -929.3805541992188,
      "logps/rejected": -1672.493896484375,
      "loss": 0.1168,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6254863739013672,
      "rewards/margins": 3.4893665313720703,
      "rewards/rejected": -4.114852428436279,
      "step": 140
    },
    {
      "epoch": 0.2256,
      "grad_norm": 3.681859254837036,
      "learning_rate": 3.88e-06,
      "logits/chosen": -2.5512917041778564,
      "logits/rejected": -2.58142352104187,
      "logps/chosen": -1000.4212646484375,
      "logps/rejected": -1716.276611328125,
      "loss": 0.1296,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9251458644866943,
      "rewards/margins": 3.016183614730835,
      "rewards/rejected": -3.94132924079895,
      "step": 141
    },
    {
      "epoch": 0.2272,
      "grad_norm": 3.965542793273926,
      "learning_rate": 3.872e-06,
      "logits/chosen": -2.473140001296997,
      "logits/rejected": -2.529681921005249,
      "logps/chosen": -1265.610595703125,
      "logps/rejected": -2101.977783203125,
      "loss": 0.1079,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.105962872505188,
      "rewards/margins": 3.8362843990325928,
      "rewards/rejected": -4.942246913909912,
      "step": 142
    },
    {
      "epoch": 0.2288,
      "grad_norm": 12.33871078491211,
      "learning_rate": 3.864000000000001e-06,
      "logits/chosen": -2.6052780151367188,
      "logits/rejected": -2.5888588428497314,
      "logps/chosen": -1761.99755859375,
      "logps/rejected": -1872.0513916015625,
      "loss": 0.393,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.7103888988494873,
      "rewards/margins": 2.1310646533966064,
      "rewards/rejected": -3.8414535522460938,
      "step": 143
    },
    {
      "epoch": 0.2304,
      "grad_norm": 6.233392238616943,
      "learning_rate": 3.856e-06,
      "logits/chosen": -2.484868288040161,
      "logits/rejected": -2.5424606800079346,
      "logps/chosen": -1275.513427734375,
      "logps/rejected": -1927.15966796875,
      "loss": 0.1725,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0840365886688232,
      "rewards/margins": 2.7722628116607666,
      "rewards/rejected": -3.85629940032959,
      "step": 144
    },
    {
      "epoch": 0.232,
      "grad_norm": 15.044837951660156,
      "learning_rate": 3.848e-06,
      "logits/chosen": -2.587812662124634,
      "logits/rejected": -2.5697760581970215,
      "logps/chosen": -1451.53759765625,
      "logps/rejected": -1558.018310546875,
      "loss": 0.2613,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.6009682416915894,
      "rewards/margins": 2.6523478031158447,
      "rewards/rejected": -4.2533159255981445,
      "step": 145
    },
    {
      "epoch": 0.2336,
      "grad_norm": 2.955937385559082,
      "learning_rate": 3.8400000000000005e-06,
      "logits/chosen": -2.3236374855041504,
      "logits/rejected": -2.4855685234069824,
      "logps/chosen": -1205.9501953125,
      "logps/rejected": -2027.85107421875,
      "loss": 0.0878,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8802462816238403,
      "rewards/margins": 3.9469008445739746,
      "rewards/rejected": -4.827147483825684,
      "step": 146
    },
    {
      "epoch": 0.2352,
      "grad_norm": 13.932756423950195,
      "learning_rate": 3.832e-06,
      "logits/chosen": -2.5622191429138184,
      "logits/rejected": -2.5720138549804688,
      "logps/chosen": -1094.4334716796875,
      "logps/rejected": -1675.0225830078125,
      "loss": 0.3347,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.33484947681427,
      "rewards/margins": 3.234825611114502,
      "rewards/rejected": -4.569675445556641,
      "step": 147
    },
    {
      "epoch": 0.2368,
      "grad_norm": 7.701645374298096,
      "learning_rate": 3.824e-06,
      "logits/chosen": -2.527047872543335,
      "logits/rejected": -2.6010050773620605,
      "logps/chosen": -943.8660888671875,
      "logps/rejected": -2046.010009765625,
      "loss": 0.1317,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.838005006313324,
      "rewards/margins": 4.096435070037842,
      "rewards/rejected": -4.9344401359558105,
      "step": 148
    },
    {
      "epoch": 0.2384,
      "grad_norm": 12.196702003479004,
      "learning_rate": 3.816e-06,
      "logits/chosen": -2.5124216079711914,
      "logits/rejected": -2.5599303245544434,
      "logps/chosen": -1259.1593017578125,
      "logps/rejected": -1982.5966796875,
      "loss": 0.3972,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.535642147064209,
      "rewards/margins": 3.216458320617676,
      "rewards/rejected": -4.752099990844727,
      "step": 149
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.5697197914123535,
      "learning_rate": 3.8080000000000006e-06,
      "logits/chosen": -2.433586597442627,
      "logits/rejected": -2.499910831451416,
      "logps/chosen": -1649.861572265625,
      "logps/rejected": -2496.50439453125,
      "loss": 0.0668,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6433301568031311,
      "rewards/margins": 4.68004035949707,
      "rewards/rejected": -5.323369979858398,
      "step": 150
    },
    {
      "epoch": 0.2416,
      "grad_norm": 7.8279805183410645,
      "learning_rate": 3.8000000000000005e-06,
      "logits/chosen": -2.5747785568237305,
      "logits/rejected": -2.559291362762451,
      "logps/chosen": -820.7977294921875,
      "logps/rejected": -1405.263916015625,
      "loss": 0.3255,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.0272091627120972,
      "rewards/margins": 2.8140616416931152,
      "rewards/rejected": -3.841270923614502,
      "step": 151
    },
    {
      "epoch": 0.2432,
      "grad_norm": 3.173461437225342,
      "learning_rate": 3.7920000000000003e-06,
      "logits/chosen": -2.4318127632141113,
      "logits/rejected": -2.585115909576416,
      "logps/chosen": -1032.688720703125,
      "logps/rejected": -1583.291748046875,
      "loss": 0.1284,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.111194372177124,
      "rewards/margins": 3.2179300785064697,
      "rewards/rejected": -4.3291239738464355,
      "step": 152
    },
    {
      "epoch": 0.2448,
      "grad_norm": 3.6623239517211914,
      "learning_rate": 3.7840000000000005e-06,
      "logits/chosen": -2.5094046592712402,
      "logits/rejected": -2.5207059383392334,
      "logps/chosen": -1594.579833984375,
      "logps/rejected": -1993.386474609375,
      "loss": 0.0882,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1914576292037964,
      "rewards/margins": 3.4556005001068115,
      "rewards/rejected": -4.647058010101318,
      "step": 153
    },
    {
      "epoch": 0.2464,
      "grad_norm": 3.744703531265259,
      "learning_rate": 3.7760000000000004e-06,
      "logits/chosen": -2.5003809928894043,
      "logits/rejected": -2.5468146800994873,
      "logps/chosen": -865.556396484375,
      "logps/rejected": -2149.798583984375,
      "loss": 0.1019,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.8671707510948181,
      "rewards/margins": 4.748715400695801,
      "rewards/rejected": -5.615886211395264,
      "step": 154
    },
    {
      "epoch": 0.248,
      "grad_norm": 17.36811065673828,
      "learning_rate": 3.7680000000000006e-06,
      "logits/chosen": -2.5274133682250977,
      "logits/rejected": -2.558795213699341,
      "logps/chosen": -740.86328125,
      "logps/rejected": -1378.2235107421875,
      "loss": 0.4342,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.9914743900299072,
      "rewards/margins": 2.2963926792144775,
      "rewards/rejected": -3.287867546081543,
      "step": 155
    },
    {
      "epoch": 0.2496,
      "grad_norm": 3.5486629009246826,
      "learning_rate": 3.7600000000000004e-06,
      "logits/chosen": -2.4791903495788574,
      "logits/rejected": -2.567417621612549,
      "logps/chosen": -583.0617065429688,
      "logps/rejected": -1531.8818359375,
      "loss": 0.1239,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6217271089553833,
      "rewards/margins": 3.4434759616851807,
      "rewards/rejected": -4.065202713012695,
      "step": 156
    },
    {
      "epoch": 0.2512,
      "grad_norm": 2.6805953979492188,
      "learning_rate": 3.7520000000000002e-06,
      "logits/chosen": -2.535182476043701,
      "logits/rejected": -2.661787271499634,
      "logps/chosen": -1052.324462890625,
      "logps/rejected": -1513.0469970703125,
      "loss": 0.0755,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8459417819976807,
      "rewards/margins": 3.932570457458496,
      "rewards/rejected": -4.778512001037598,
      "step": 157
    },
    {
      "epoch": 0.2528,
      "grad_norm": 5.559194087982178,
      "learning_rate": 3.7440000000000005e-06,
      "logits/chosen": -2.6281018257141113,
      "logits/rejected": -2.618861675262451,
      "logps/chosen": -1111.359375,
      "logps/rejected": -1806.9298095703125,
      "loss": 0.1331,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0560284852981567,
      "rewards/margins": 3.2812447547912598,
      "rewards/rejected": -4.337273597717285,
      "step": 158
    },
    {
      "epoch": 0.2544,
      "grad_norm": 4.672009468078613,
      "learning_rate": 3.7360000000000003e-06,
      "logits/chosen": -2.5824551582336426,
      "logits/rejected": -2.5789971351623535,
      "logps/chosen": -1206.352783203125,
      "logps/rejected": -1826.616943359375,
      "loss": 0.1875,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.9357657432556152,
      "rewards/margins": 2.9747512340545654,
      "rewards/rejected": -3.9105169773101807,
      "step": 159
    },
    {
      "epoch": 0.256,
      "grad_norm": 2.1758320331573486,
      "learning_rate": 3.7280000000000006e-06,
      "logits/chosen": -2.3592708110809326,
      "logits/rejected": -2.4924933910369873,
      "logps/chosen": -1304.7529296875,
      "logps/rejected": -2154.0283203125,
      "loss": 0.091,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.05504591390490532,
      "rewards/margins": 3.781249523162842,
      "rewards/rejected": -3.8362953662872314,
      "step": 160
    },
    {
      "epoch": 0.2576,
      "grad_norm": 5.592170715332031,
      "learning_rate": 3.7200000000000004e-06,
      "logits/chosen": -2.596618890762329,
      "logits/rejected": -2.636268377304077,
      "logps/chosen": -1294.7005615234375,
      "logps/rejected": -1496.673828125,
      "loss": 0.2674,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -0.9745278358459473,
      "rewards/margins": 2.0730347633361816,
      "rewards/rejected": -3.047562599182129,
      "step": 161
    },
    {
      "epoch": 0.2592,
      "grad_norm": 4.225465297698975,
      "learning_rate": 3.712e-06,
      "logits/chosen": -2.604107141494751,
      "logits/rejected": -2.5327961444854736,
      "logps/chosen": -1052.2235107421875,
      "logps/rejected": -1984.7275390625,
      "loss": 0.1498,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.1613636016845703,
      "rewards/margins": 2.999746799468994,
      "rewards/rejected": -4.161109924316406,
      "step": 162
    },
    {
      "epoch": 0.2608,
      "grad_norm": 13.231943130493164,
      "learning_rate": 3.7040000000000005e-06,
      "logits/chosen": -2.5563602447509766,
      "logits/rejected": -2.6158602237701416,
      "logps/chosen": -753.8143920898438,
      "logps/rejected": -1714.21337890625,
      "loss": 0.2646,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.6908403635025024,
      "rewards/margins": 2.8612189292907715,
      "rewards/rejected": -3.5520596504211426,
      "step": 163
    },
    {
      "epoch": 0.2624,
      "grad_norm": 3.5434682369232178,
      "learning_rate": 3.6960000000000003e-06,
      "logits/chosen": -2.550386428833008,
      "logits/rejected": -2.608463764190674,
      "logps/chosen": -1036.34375,
      "logps/rejected": -1587.4862060546875,
      "loss": 0.1521,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -0.7631580233573914,
      "rewards/margins": 3.955127000808716,
      "rewards/rejected": -4.718285083770752,
      "step": 164
    },
    {
      "epoch": 0.264,
      "grad_norm": 4.3760809898376465,
      "learning_rate": 3.6880000000000005e-06,
      "logits/chosen": -2.480346202850342,
      "logits/rejected": -2.609251022338867,
      "logps/chosen": -844.9407348632812,
      "logps/rejected": -1571.84326171875,
      "loss": 0.1485,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9611625075340271,
      "rewards/margins": 3.0325303077697754,
      "rewards/rejected": -3.9936928749084473,
      "step": 165
    },
    {
      "epoch": 0.2656,
      "grad_norm": 3.5551278591156006,
      "learning_rate": 3.6800000000000003e-06,
      "logits/chosen": -2.583606719970703,
      "logits/rejected": -2.578181266784668,
      "logps/chosen": -1678.355224609375,
      "logps/rejected": -2427.929443359375,
      "loss": 0.0667,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.3923062086105347,
      "rewards/margins": 4.228941917419434,
      "rewards/rejected": -5.621248245239258,
      "step": 166
    },
    {
      "epoch": 0.2672,
      "grad_norm": 5.965133190155029,
      "learning_rate": 3.6720000000000006e-06,
      "logits/chosen": -2.473832607269287,
      "logits/rejected": -2.587514638900757,
      "logps/chosen": -1203.306396484375,
      "logps/rejected": -1632.327880859375,
      "loss": 0.2674,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.2146199941635132,
      "rewards/margins": 2.4606878757476807,
      "rewards/rejected": -3.6753077507019043,
      "step": 167
    },
    {
      "epoch": 0.2688,
      "grad_norm": 2.344510078430176,
      "learning_rate": 3.6640000000000004e-06,
      "logits/chosen": -2.5106430053710938,
      "logits/rejected": -2.558215379714966,
      "logps/chosen": -1132.7110595703125,
      "logps/rejected": -1853.5338134765625,
      "loss": 0.0833,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9561712741851807,
      "rewards/margins": 4.109459400177002,
      "rewards/rejected": -5.0656304359436035,
      "step": 168
    },
    {
      "epoch": 0.2704,
      "grad_norm": 3.147437572479248,
      "learning_rate": 3.6560000000000002e-06,
      "logits/chosen": -2.408798933029175,
      "logits/rejected": -2.5245728492736816,
      "logps/chosen": -686.130615234375,
      "logps/rejected": -1464.603515625,
      "loss": 0.1324,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6247462630271912,
      "rewards/margins": 3.134340524673462,
      "rewards/rejected": -3.759086847305298,
      "step": 169
    },
    {
      "epoch": 0.272,
      "grad_norm": 5.199261665344238,
      "learning_rate": 3.6480000000000005e-06,
      "logits/chosen": -2.471160411834717,
      "logits/rejected": -2.5039730072021484,
      "logps/chosen": -1498.9571533203125,
      "logps/rejected": -2456.068603515625,
      "loss": 0.235,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -1.2993308305740356,
      "rewards/margins": 3.6948964595794678,
      "rewards/rejected": -4.994227409362793,
      "step": 170
    },
    {
      "epoch": 0.2736,
      "grad_norm": 4.1564717292785645,
      "learning_rate": 3.6400000000000003e-06,
      "logits/chosen": -2.513864517211914,
      "logits/rejected": -2.485531806945801,
      "logps/chosen": -941.6507568359375,
      "logps/rejected": -2025.3125,
      "loss": 0.1554,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2507903575897217,
      "rewards/margins": 3.5065958499908447,
      "rewards/rejected": -4.757385730743408,
      "step": 171
    },
    {
      "epoch": 0.2752,
      "grad_norm": 2.3447320461273193,
      "learning_rate": 3.6320000000000005e-06,
      "logits/chosen": -2.532189130783081,
      "logits/rejected": -2.5105152130126953,
      "logps/chosen": -956.2445068359375,
      "logps/rejected": -2148.1298828125,
      "loss": 0.1312,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.1279031038284302,
      "rewards/margins": 4.147148609161377,
      "rewards/rejected": -5.275052547454834,
      "step": 172
    },
    {
      "epoch": 0.2768,
      "grad_norm": 7.300447463989258,
      "learning_rate": 3.6240000000000004e-06,
      "logits/chosen": -2.47249436378479,
      "logits/rejected": -2.4742612838745117,
      "logps/chosen": -1192.814208984375,
      "logps/rejected": -1652.649169921875,
      "loss": 0.2735,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.1616073846817017,
      "rewards/margins": 3.585350513458252,
      "rewards/rejected": -4.746958255767822,
      "step": 173
    },
    {
      "epoch": 0.2784,
      "grad_norm": 2.6135811805725098,
      "learning_rate": 3.616e-06,
      "logits/chosen": -2.598738193511963,
      "logits/rejected": -2.6391189098358154,
      "logps/chosen": -1050.56982421875,
      "logps/rejected": -1488.3956298828125,
      "loss": 0.1036,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.05196213722229,
      "rewards/margins": 2.934633255004883,
      "rewards/rejected": -3.9865946769714355,
      "step": 174
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.3967928886413574,
      "learning_rate": 3.6080000000000004e-06,
      "logits/chosen": -2.53947377204895,
      "logits/rejected": -2.524423599243164,
      "logps/chosen": -1205.1959228515625,
      "logps/rejected": -2305.639404296875,
      "loss": 0.0943,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2355891466140747,
      "rewards/margins": 4.049005031585693,
      "rewards/rejected": -5.2845940589904785,
      "step": 175
    },
    {
      "epoch": 0.2816,
      "grad_norm": 9.8906831741333,
      "learning_rate": 3.6000000000000003e-06,
      "logits/chosen": -2.5823256969451904,
      "logits/rejected": -2.5740480422973633,
      "logps/chosen": -912.4249267578125,
      "logps/rejected": -1685.367431640625,
      "loss": 0.1971,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.4347631931304932,
      "rewards/margins": 4.13980770111084,
      "rewards/rejected": -5.574571132659912,
      "step": 176
    },
    {
      "epoch": 0.2832,
      "grad_norm": 2.6916356086730957,
      "learning_rate": 3.5920000000000005e-06,
      "logits/chosen": -2.5720245838165283,
      "logits/rejected": -2.561096429824829,
      "logps/chosen": -760.9779052734375,
      "logps/rejected": -1412.746826171875,
      "loss": 0.1069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.509262204170227,
      "rewards/margins": 3.2271475791931152,
      "rewards/rejected": -3.736409902572632,
      "step": 177
    },
    {
      "epoch": 0.2848,
      "grad_norm": 5.105088233947754,
      "learning_rate": 3.5840000000000003e-06,
      "logits/chosen": -2.496483325958252,
      "logits/rejected": -2.547045946121216,
      "logps/chosen": -2031.1685791015625,
      "logps/rejected": -1764.676025390625,
      "loss": 0.1635,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.0378704071044922,
      "rewards/margins": 3.592813491821289,
      "rewards/rejected": -4.630683898925781,
      "step": 178
    },
    {
      "epoch": 0.2864,
      "grad_norm": 3.566476821899414,
      "learning_rate": 3.576e-06,
      "logits/chosen": -2.489992618560791,
      "logits/rejected": -2.570265054702759,
      "logps/chosen": -736.7535400390625,
      "logps/rejected": -1326.1339111328125,
      "loss": 0.1274,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.6351171731948853,
      "rewards/margins": 3.1115241050720215,
      "rewards/rejected": -3.746641159057617,
      "step": 179
    },
    {
      "epoch": 0.288,
      "grad_norm": 5.3380937576293945,
      "learning_rate": 3.5680000000000004e-06,
      "logits/chosen": -2.491879463195801,
      "logits/rejected": -2.5400686264038086,
      "logps/chosen": -832.5768432617188,
      "logps/rejected": -1422.589599609375,
      "loss": 0.1506,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.0026509761810303,
      "rewards/margins": 3.0428786277770996,
      "rewards/rejected": -4.045529365539551,
      "step": 180
    },
    {
      "epoch": 0.2896,
      "grad_norm": 12.920429229736328,
      "learning_rate": 3.5600000000000002e-06,
      "logits/chosen": -2.5590569972991943,
      "logits/rejected": -2.5741870403289795,
      "logps/chosen": -1169.603271484375,
      "logps/rejected": -1815.622314453125,
      "loss": 0.2239,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.4221879243850708,
      "rewards/margins": 3.6321964263916016,
      "rewards/rejected": -5.054384231567383,
      "step": 181
    },
    {
      "epoch": 0.2912,
      "grad_norm": 2.9712719917297363,
      "learning_rate": 3.5520000000000005e-06,
      "logits/chosen": -2.5229058265686035,
      "logits/rejected": -2.555495262145996,
      "logps/chosen": -1224.7794189453125,
      "logps/rejected": -1974.53076171875,
      "loss": 0.1097,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.2546778917312622,
      "rewards/margins": 5.311367511749268,
      "rewards/rejected": -6.566045761108398,
      "step": 182
    },
    {
      "epoch": 0.2928,
      "grad_norm": 4.919933319091797,
      "learning_rate": 3.5440000000000003e-06,
      "logits/chosen": -2.5676066875457764,
      "logits/rejected": -2.5965633392333984,
      "logps/chosen": -935.7449340820312,
      "logps/rejected": -1625.33837890625,
      "loss": 0.1665,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0734796524047852,
      "rewards/margins": 3.6381163597106934,
      "rewards/rejected": -4.71159553527832,
      "step": 183
    },
    {
      "epoch": 0.2944,
      "grad_norm": 5.350948810577393,
      "learning_rate": 3.5360000000000005e-06,
      "logits/chosen": -2.399768829345703,
      "logits/rejected": -2.4179036617279053,
      "logps/chosen": -1181.205810546875,
      "logps/rejected": -2331.27197265625,
      "loss": 0.23,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.053093433380127,
      "rewards/margins": 4.022620677947998,
      "rewards/rejected": -5.075714111328125,
      "step": 184
    },
    {
      "epoch": 0.296,
      "grad_norm": 14.647397994995117,
      "learning_rate": 3.5280000000000004e-06,
      "logits/chosen": -2.447864532470703,
      "logits/rejected": -2.475259780883789,
      "logps/chosen": -1439.09326171875,
      "logps/rejected": -1869.244384765625,
      "loss": 0.2553,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3843306303024292,
      "rewards/margins": 3.7077221870422363,
      "rewards/rejected": -5.092053413391113,
      "step": 185
    },
    {
      "epoch": 0.2976,
      "grad_norm": 3.6896514892578125,
      "learning_rate": 3.52e-06,
      "logits/chosen": -2.498772621154785,
      "logits/rejected": -2.5131518840789795,
      "logps/chosen": -1387.4283447265625,
      "logps/rejected": -2372.98486328125,
      "loss": 0.1142,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -2.143857479095459,
      "rewards/margins": 3.3190314769744873,
      "rewards/rejected": -5.462888717651367,
      "step": 186
    },
    {
      "epoch": 0.2992,
      "grad_norm": 12.598962783813477,
      "learning_rate": 3.5120000000000004e-06,
      "logits/chosen": -2.518904685974121,
      "logits/rejected": -2.593177080154419,
      "logps/chosen": -1334.82373046875,
      "logps/rejected": -1818.3770751953125,
      "loss": 0.3535,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -2.103634834289551,
      "rewards/margins": 3.040527105331421,
      "rewards/rejected": -5.144162178039551,
      "step": 187
    },
    {
      "epoch": 0.3008,
      "grad_norm": 7.378072261810303,
      "learning_rate": 3.5040000000000002e-06,
      "logits/chosen": -2.4853692054748535,
      "logits/rejected": -2.6245083808898926,
      "logps/chosen": -781.1697387695312,
      "logps/rejected": -1484.8768310546875,
      "loss": 0.1981,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.2396050691604614,
      "rewards/margins": 2.9421732425689697,
      "rewards/rejected": -4.181778430938721,
      "step": 188
    },
    {
      "epoch": 0.3024,
      "grad_norm": 2.6509525775909424,
      "learning_rate": 3.4960000000000005e-06,
      "logits/chosen": -2.5723066329956055,
      "logits/rejected": -2.5821268558502197,
      "logps/chosen": -1104.5064697265625,
      "logps/rejected": -1907.181640625,
      "loss": 0.1211,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8466064929962158,
      "rewards/margins": 4.33903694152832,
      "rewards/rejected": -5.185643196105957,
      "step": 189
    },
    {
      "epoch": 0.304,
      "grad_norm": 5.613494873046875,
      "learning_rate": 3.4880000000000003e-06,
      "logits/chosen": -2.430875539779663,
      "logits/rejected": -2.5076606273651123,
      "logps/chosen": -995.77001953125,
      "logps/rejected": -1692.2021484375,
      "loss": 0.1468,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.144542932510376,
      "rewards/margins": 3.6242854595184326,
      "rewards/rejected": -4.768828392028809,
      "step": 190
    },
    {
      "epoch": 0.3056,
      "grad_norm": 9.442662239074707,
      "learning_rate": 3.48e-06,
      "logits/chosen": -2.599368095397949,
      "logits/rejected": -2.5914101600646973,
      "logps/chosen": -1492.151611328125,
      "logps/rejected": -1937.0401611328125,
      "loss": 0.211,
      "rewards/accuracies": 0.875,
      "rewards/chosen": -1.6971406936645508,
      "rewards/margins": 2.7931768894195557,
      "rewards/rejected": -4.4903178215026855,
      "step": 191
    },
    {
      "epoch": 0.3072,
      "grad_norm": 14.578059196472168,
      "learning_rate": 3.4720000000000004e-06,
      "logits/chosen": -2.5057389736175537,
      "logits/rejected": -2.551056385040283,
      "logps/chosen": -1192.3515625,
      "logps/rejected": -1713.5738525390625,
      "loss": 0.4637,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.4923242330551147,
      "rewards/margins": 3.1908934116363525,
      "rewards/rejected": -4.683218002319336,
      "step": 192
    },
    {
      "epoch": 0.3088,
      "grad_norm": 5.227137565612793,
      "learning_rate": 3.464e-06,
      "logits/chosen": -2.57104229927063,
      "logits/rejected": -2.6120309829711914,
      "logps/chosen": -1240.624755859375,
      "logps/rejected": -1664.0548095703125,
      "loss": 0.1077,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.3353135585784912,
      "rewards/margins": 3.806077003479004,
      "rewards/rejected": -5.141390800476074,
      "step": 193
    },
    {
      "epoch": 0.3104,
      "grad_norm": 5.859711647033691,
      "learning_rate": 3.4560000000000005e-06,
      "logits/chosen": -2.459059238433838,
      "logits/rejected": -2.5761170387268066,
      "logps/chosen": -849.237548828125,
      "logps/rejected": -1782.763671875,
      "loss": 0.1385,
      "rewards/accuracies": 0.9375,
      "rewards/chosen": -1.2599105834960938,
      "rewards/margins": 4.484137535095215,
      "rewards/rejected": -5.744048595428467,
      "step": 194
    },
    {
      "epoch": 0.312,
      "grad_norm": 8.770748138427734,
      "learning_rate": 3.4480000000000003e-06,
      "logits/chosen": -2.5360796451568604,
      "logits/rejected": -2.630948543548584,
      "logps/chosen": -1197.5750732421875,
      "logps/rejected": -1509.372314453125,
      "loss": 0.2601,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.367336392402649,
      "rewards/margins": 2.645585775375366,
      "rewards/rejected": -4.0129218101501465,
      "step": 195
    },
    {
      "epoch": 0.3136,
      "grad_norm": 2.707674026489258,
      "learning_rate": 3.44e-06,
      "logits/chosen": -2.4518167972564697,
      "logits/rejected": -2.502617359161377,
      "logps/chosen": -1101.715576171875,
      "logps/rejected": -1916.680908203125,
      "loss": 0.0981,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.8633285164833069,
      "rewards/margins": 4.557366371154785,
      "rewards/rejected": -5.420694828033447,
      "step": 196
    },
    {
      "epoch": 0.3152,
      "grad_norm": 4.522651195526123,
      "learning_rate": 3.4320000000000003e-06,
      "logits/chosen": -2.5625991821289062,
      "logits/rejected": -2.5472517013549805,
      "logps/chosen": -1071.853759765625,
      "logps/rejected": -1767.0283203125,
      "loss": 0.0895,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.4371243715286255,
      "rewards/margins": 4.001081943511963,
      "rewards/rejected": -5.438206195831299,
      "step": 197
    },
    {
      "epoch": 0.3168,
      "grad_norm": 2.4463326930999756,
      "learning_rate": 3.424e-06,
      "logits/chosen": -2.5444812774658203,
      "logits/rejected": -2.601208448410034,
      "logps/chosen": -987.9786376953125,
      "logps/rejected": -1882.9088134765625,
      "loss": 0.1016,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -0.9818427562713623,
      "rewards/margins": 4.905553340911865,
      "rewards/rejected": -5.887395858764648,
      "step": 198
    },
    {
      "epoch": 0.3184,
      "grad_norm": 2.5404722690582275,
      "learning_rate": 3.4160000000000004e-06,
      "logits/chosen": -2.5638346672058105,
      "logits/rejected": -2.5925920009613037,
      "logps/chosen": -986.482177734375,
      "logps/rejected": -1675.7327880859375,
      "loss": 0.0827,
      "rewards/accuracies": 1.0,
      "rewards/chosen": -1.0711774826049805,
      "rewards/margins": 3.828382968902588,
      "rewards/rejected": -4.899560928344727,
      "step": 199
    },
    {
      "epoch": 0.32,
      "grad_norm": 19.497190475463867,
      "learning_rate": 3.4080000000000002e-06,
      "logits/chosen": -2.5563571453094482,
      "logits/rejected": -2.577699899673462,
      "logps/chosen": -1409.908447265625,
      "logps/rejected": -1210.635498046875,
      "loss": 0.5689,
      "rewards/accuracies": 0.8125,
      "rewards/chosen": -1.5012098550796509,
      "rewards/margins": 1.6697648763656616,
      "rewards/rejected": -3.1709747314453125,
      "step": 200
    }
  ],
  "logging_steps": 1.0,
  "max_steps": 625,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
